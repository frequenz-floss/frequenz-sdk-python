{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Frequenz Python SDK \u00a4 A development kit to interact with the Frequenz development platform. Supported Python versions \u00a4 For x86_64 Python 3.8 - 3.10 are supported (tested). For arm64 only Python 3.8 is supported (due to some dependencies that only support 3.8). Contributing \u00a4 If you want to know how to build this project and contribute to it, please check out the Contributing Guide .","title":"Home"},{"location":"#frequenz-python-sdk","text":"A development kit to interact with the Frequenz development platform.","title":"Frequenz Python SDK"},{"location":"#supported-python-versions","text":"For x86_64 Python 3.8 - 3.10 are supported (tested). For arm64 only Python 3.8 is supported (due to some dependencies that only support 3.8).","title":"Supported Python versions"},{"location":"#contributing","text":"If you want to know how to build this project and contribute to it, please check out the Contributing Guide .","title":"Contributing"},{"location":"CONTRIBUTING/","text":"Contributing to frequenz-sdk \u00a4 Build \u00a4 You can use build to simply build the source and binary distribution: python -m pip install build python -m build Local development \u00a4 You can use editable installs to develop the project locally (it will install all the dependencies too): python -m pip install -e . You can also use nox to run the tests and other checks: python -m pip install nox nox You can also use nox -R to reuse the current testing environment to speed up test at the expense of a higher chance to end up with a dirty test environment. Running tests individually \u00a4 For a better development test cycle you can install the runtime and test dependencies and run pytest manually. python -m pip install . python -m pip install pytest pytest-asyncio # And for example pytest tests/test_sdk.py To build the documentation, first install the dependencies: python -m pip install -e . [ docs ] Then you can build the documentation (it will be written in the site/ directory): mkdocs build Or you can just serve the documentation without building it using: mkdocs serve Your site will be updated live when you change your files (provided that you used pip install -e . , beware of a common pitfall of using pip install without -e , in that case the API reference won't change unless you do a new pip install ). To build multi-version documentation, we use mike . If you want to see how the multi-version sites looks like locally, you can use: mike deploy my-version mike set-default my-version mike serve mike works in mysterious ways. Some basic information: mike deploy will do a mike build and write the results to your local gh-pages branch. my-version is an arbitrary name for the local version you want to preview. mike set-default is needed so when you serve the documentation, it goes to your newly produced documentation by default. mike serve will serve the contents of your local gh-pages branch. Be aware that, unlike mkdocs serve , changes to the sources won't be shown live, as the mike deploy step is needed to refresh them. Be careful not to use --push with mike deploy , otherwise it will push your local gh-pages branch to the origin remote. That said, if you want to test the actual website in your fork , you can always use mike deploy --push --remote your-fork-remote , and then access the GitHub pages produced for your fork. Releasing \u00a4 These are the steps to create a new release: Get the latest head you want to create a release from. Update the RELEASE_NOTES.md file if it is not complete, up to date, and clean from template comments ( <!-- ... -> ) and empty sections. Submit a pull request if an update is needed, wait until it is merged, and update the latest head you want to create a release from to get the new merged pull request. Create a new signed tag using the release notes and a semver compatible version number with a v prefix, for example: git tag -s -F RELEASE_NOTES.md v0.0.1 Push the new tag. A GitHub action will test the tag and if all goes well it will create a GitHub Release , create a new announcement about the release, and upload a new package to PyPI automatically. Once this is done, reset the RELEASE_NOTES.md with the template: cp .github/RELEASE_NOTES.template.md RELEASE_NOTES.md Commit the new release notes and create a PR (this step should be automated eventually too). Celebrate!","title":"Development"},{"location":"CONTRIBUTING/#contributing-to-frequenz-sdk","text":"","title":"Contributing to frequenz-sdk"},{"location":"CONTRIBUTING/#build","text":"You can use build to simply build the source and binary distribution: python -m pip install build python -m build","title":"Build"},{"location":"CONTRIBUTING/#local-development","text":"You can use editable installs to develop the project locally (it will install all the dependencies too): python -m pip install -e . You can also use nox to run the tests and other checks: python -m pip install nox nox You can also use nox -R to reuse the current testing environment to speed up test at the expense of a higher chance to end up with a dirty test environment.","title":"Local development"},{"location":"CONTRIBUTING/#running-tests-individually","text":"For a better development test cycle you can install the runtime and test dependencies and run pytest manually. python -m pip install . python -m pip install pytest pytest-asyncio # And for example pytest tests/test_sdk.py To build the documentation, first install the dependencies: python -m pip install -e . [ docs ] Then you can build the documentation (it will be written in the site/ directory): mkdocs build Or you can just serve the documentation without building it using: mkdocs serve Your site will be updated live when you change your files (provided that you used pip install -e . , beware of a common pitfall of using pip install without -e , in that case the API reference won't change unless you do a new pip install ). To build multi-version documentation, we use mike . If you want to see how the multi-version sites looks like locally, you can use: mike deploy my-version mike set-default my-version mike serve mike works in mysterious ways. Some basic information: mike deploy will do a mike build and write the results to your local gh-pages branch. my-version is an arbitrary name for the local version you want to preview. mike set-default is needed so when you serve the documentation, it goes to your newly produced documentation by default. mike serve will serve the contents of your local gh-pages branch. Be aware that, unlike mkdocs serve , changes to the sources won't be shown live, as the mike deploy step is needed to refresh them. Be careful not to use --push with mike deploy , otherwise it will push your local gh-pages branch to the origin remote. That said, if you want to test the actual website in your fork , you can always use mike deploy --push --remote your-fork-remote , and then access the GitHub pages produced for your fork.","title":"Running tests individually"},{"location":"CONTRIBUTING/#releasing","text":"These are the steps to create a new release: Get the latest head you want to create a release from. Update the RELEASE_NOTES.md file if it is not complete, up to date, and clean from template comments ( <!-- ... -> ) and empty sections. Submit a pull request if an update is needed, wait until it is merged, and update the latest head you want to create a release from to get the new merged pull request. Create a new signed tag using the release notes and a semver compatible version number with a v prefix, for example: git tag -s -F RELEASE_NOTES.md v0.0.1 Push the new tag. A GitHub action will test the tag and if all goes well it will create a GitHub Release , create a new announcement about the release, and upload a new package to PyPI automatically. Once this is done, reset the RELEASE_NOTES.md with the template: cp .github/RELEASE_NOTES.template.md RELEASE_NOTES.md Commit the new release notes and create a PR (this step should be automated eventually too). Celebrate!","title":"Releasing"},{"location":"SUMMARY/","text":"Home API Reference Development","title":"SUMMARY"},{"location":"reference/SUMMARY/","text":"frequenz sdk actor channel_registry data_sourcing data_sourcing microgrid_api_source types decorator resampling api_client api_client configs config config_manager data_handling formula gen_historic_data_features handle_historic_data power time_series data_ingestion component_info constants formula_calculator gen_component_receivers load_historic_data microgrid_data microgrid client component component_data component_states connection graph microgrid_api retry power_distribution distribution_algorithm power_distributor utils timeseries sample","title":"SUMMARY"},{"location":"reference/frequenz/sdk/","text":"frequenz.sdk \u00a4 Frequenz Python SDK.","title":"sdk"},{"location":"reference/frequenz/sdk/#frequenz.sdk","text":"Frequenz Python SDK.","title":"sdk"},{"location":"reference/frequenz/sdk/actor/","text":"frequenz.sdk.actor \u00a4 A base class for creating simple composable actors. Classes \u00a4 frequenz.sdk.actor.ChannelRegistry \u00a4 Dynamically creates, own and provide access to channels. It can be used by actors to dynamically establish a communication channel between each other. Channels are identified by string names. Source code in frequenz/sdk/actor/channel_registry.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 class ChannelRegistry : \"\"\"Dynamically creates, own and provide access to channels. It can be used by actors to dynamically establish a communication channel between each other. Channels are identified by string names. \"\"\" def __init__ ( self , * , name : str ) -> None : \"\"\"Create a `ChannelRegistry` instance. Args: name: A unique name for the registry. \"\"\" self . _name = name self . _channels : Dict [ str , Broadcast [ Any ]] = {} def new_sender ( self , key : str ) -> Sender [ Any ]: \"\"\"Get a sender to a dynamically created channel with the given key. Args: key: A key to identify the channel. Returns: A sender to a dynamically created channel with the given key. \"\"\" if key not in self . _channels : self . _channels [ key ] = Broadcast ( f \" { self . _name } - { key } \" ) return self . _channels [ key ] . new_sender () def new_receiver ( self , key : str ) -> Receiver [ Any ]: \"\"\"Get a receiver to a dynamically created channel with the given key. Args: key: A key to identify the channel. Returns: A receiver for a dynamically created channel with the given key. \"\"\" if key not in self . _channels : self . _channels [ key ] = Broadcast ( f \" { self . _name } - { key } \" ) return self . _channels [ key ] . new_receiver () Functions \u00a4 __init__ ( * , name ) \u00a4 Create a ChannelRegistry instance. PARAMETER DESCRIPTION name A unique name for the registry. TYPE: str Source code in frequenz/sdk/actor/channel_registry.py 18 19 20 21 22 23 24 25 def __init__ ( self , * , name : str ) -> None : \"\"\"Create a `ChannelRegistry` instance. Args: name: A unique name for the registry. \"\"\" self . _name = name self . _channels : Dict [ str , Broadcast [ Any ]] = {} new_receiver ( key ) \u00a4 Get a receiver to a dynamically created channel with the given key. PARAMETER DESCRIPTION key A key to identify the channel. TYPE: str RETURNS DESCRIPTION Receiver [ Any ] A receiver for a dynamically created channel with the given key. Source code in frequenz/sdk/actor/channel_registry.py 40 41 42 43 44 45 46 47 48 49 50 51 def new_receiver ( self , key : str ) -> Receiver [ Any ]: \"\"\"Get a receiver to a dynamically created channel with the given key. Args: key: A key to identify the channel. Returns: A receiver for a dynamically created channel with the given key. \"\"\" if key not in self . _channels : self . _channels [ key ] = Broadcast ( f \" { self . _name } - { key } \" ) return self . _channels [ key ] . new_receiver () new_sender ( key ) \u00a4 Get a sender to a dynamically created channel with the given key. PARAMETER DESCRIPTION key A key to identify the channel. TYPE: str RETURNS DESCRIPTION Sender [ Any ] A sender to a dynamically created channel with the given key. Source code in frequenz/sdk/actor/channel_registry.py 27 28 29 30 31 32 33 34 35 36 37 38 def new_sender ( self , key : str ) -> Sender [ Any ]: \"\"\"Get a sender to a dynamically created channel with the given key. Args: key: A key to identify the channel. Returns: A sender to a dynamically created channel with the given key. \"\"\" if key not in self . _channels : self . _channels [ key ] = Broadcast ( f \" { self . _name } - { key } \" ) return self . _channels [ key ] . new_sender () Functions \u00a4 frequenz . sdk . actor . actor ( cls ) \u00a4 Decorate a class into a simple composable actor. A actor using the actor decorator should define an async def run(self) method, that loops over incoming data, and sends results out. Channels can be used to implement communication between actors, as shown in the examples below. PARAMETER DESCRIPTION cls the class to decorate. TYPE: Type [ Any ] RETURNS DESCRIPTION Type [ Any ] The decorated class. RAISES DESCRIPTION TypeError when the class doesn't have a run method as per spec. Example (one actor receiving from two receivers): @actor class EchoActor : def __init__ ( self , name : str , recv1 : Receiver [ bool ], recv2 : Receiver [ bool ], output : Sender [ bool ], ) -> None : self . name = name self . _recv1 = recv1 self . _recv2 = recv2 self . _output = output async def run ( self ) -> None : select = Select ( channel_1 = self . _recv1 , channel_2 = self . _recv2 ) while await select . ready (): if msg := select . channel_1 : await self . _output . send ( msg . inner ) elif msg := select . channel_2 : await self . _output . send ( msg . inner ) input_chan_1 : Broadcast [ bool ] = Broadcast ( \"input_chan_1\" ) input_chan_2 : Broadcast [ bool ] = Broadcast ( \"input_chan_2\" ) echo_chan : Broadcast [ bool ] = Broadcast ( \"EchoChannel\" ) echo_actor = EchoActor ( \"EchoActor\" , recv1 = input_chan_1 . new_receiver (), recv2 = input_chan_2 . new_receiver (), output = echo_chan . new_sender (), ) echo_rx = echo_chan . new_receiver () await input_chan_2 . new_sender () . send ( True ) msg = await echo_rx . receive () Example (two Actors composed): @actor class Actor1 : def __init__ ( self , name : str , recv : Receiver [ bool ], output : Sender [ bool ], ) -> None : self . name = name self . _recv = recv self . _output = output async def run ( self ) -> None : async for msg in self . _recv : await self . _output . send ( msg ) @actor class Actor2 : def __init__ ( self , name : str , recv : Receiver [ bool ], output : Sender [ bool ], ) -> None : self . name = name self . _recv = recv self . _output = output async def run ( self ) -> None : async for msg in self . _recv : await self . _output . send ( msg ) input_chan : Broadcast [ bool ] = Broadcast ( \"Input to A1\" ) a1_chan : Broadcast [ bool ] = Broadcast [ \"A1 stream\" ] a2_chan : Broadcast [ bool ] = Broadcast [ \"A2 stream\" ] a1 = Actor1 ( name = \"ActorOne\" , recv = input_chan . new_receiver (), output = a1_chan . new_sender (), ) a2 = Actor2 ( name = \"ActorTwo\" , recv = a1_chan . new_receiver (), output = a2_chan . new_sender (), ) a2_rx = a2_chan . new_receiver () await input_chan . new_sender () . send ( True ) msg = await a2_rx . receive () Source code in frequenz/sdk/actor/decorator.py 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 def actor ( cls : Type [ Any ]) -> Type [ Any ]: \"\"\"Decorate a class into a simple composable actor. A actor using the `actor` decorator should define an `async def run(self)` method, that loops over incoming data, and sends results out. Channels can be used to implement communication between actors, as shown in the examples below. Args: cls: the class to decorate. Returns: The decorated class. Raises: TypeError: when the class doesn't have a `run` method as per spec. Example (one actor receiving from two receivers): ``` python @actor class EchoActor: def __init__( self, name: str, recv1: Receiver[bool], recv2: Receiver[bool], output: Sender[bool], ) -> None: self.name = name self._recv1 = recv1 self._recv2 = recv2 self._output = output async def run(self) -> None: select = Select(channel_1=self._recv1, channel_2=self._recv2) while await select.ready(): if msg := select.channel_1: await self._output.send(msg.inner) elif msg := select.channel_2: await self._output.send(msg.inner) input_chan_1: Broadcast[bool] = Broadcast(\"input_chan_1\") input_chan_2: Broadcast[bool] = Broadcast(\"input_chan_2\") echo_chan: Broadcast[bool] = Broadcast(\"EchoChannel\") echo_actor = EchoActor( \"EchoActor\", recv1=input_chan_1.new_receiver(), recv2=input_chan_2.new_receiver(), output=echo_chan.new_sender(), ) echo_rx = echo_chan.new_receiver() await input_chan_2.new_sender().send(True) msg = await echo_rx.receive() ``` Example (two Actors composed): ``` python @actor class Actor1: def __init__( self, name: str, recv: Receiver[bool], output: Sender[bool], ) -> None: self.name = name self._recv = recv self._output = output async def run(self) -> None: async for msg in self._recv: await self._output.send(msg) @actor class Actor2: def __init__( self, name: str, recv: Receiver[bool], output: Sender[bool], ) -> None: self.name = name self._recv = recv self._output = output async def run(self) -> None: async for msg in self._recv: await self._output.send(msg) input_chan: Broadcast[bool] = Broadcast(\"Input to A1\") a1_chan: Broadcast[bool] = Broadcast[\"A1 stream\"] a2_chan: Broadcast[bool] = Broadcast[\"A2 stream\"] a1 = Actor1( name=\"ActorOne\", recv=input_chan.new_receiver(), output=a1_chan.new_sender(), ) a2 = Actor2( name=\"ActorTwo\", recv=a1_chan.new_receiver(), output=a2_chan.new_sender(), ) a2_rx = a2_chan.new_receiver() await input_chan.new_sender().send(True) msg = await a2_rx.receive() ``` \"\"\" if not inspect . isclass ( cls ): raise TypeError ( \"The `@actor` decorator can only be applied for classes.\" ) _check_run_method_exists ( cls ) class ActorClass ( cls , BaseActor , Generic [ OT ]): # type: ignore \"\"\"A wrapper class to make an actor.\"\"\" def __init__ ( self , * args : Any , ** kwargs : Any ) -> None : \"\"\"Create an `ActorClass` instance. Also call __init__ on `cls`. Args: *args: Any positional arguments to `cls.__init__`. **kwargs: Any keyword arguments to `cls.__init__`. \"\"\" super () . __init__ ( * args , ** kwargs ) self . _actor_task = asyncio . create_task ( self . _start_actor ()) async def _start_actor ( self ) -> None : \"\"\"Run the main logic of the actor as a coroutine. Raises: asyncio.CancelledError: when the actor's task gets cancelled. \"\"\" logger . debug ( \"Starting actor: %s \" , cls . __name__ ) number_of_restarts = 0 while True : try : await super () . run () except asyncio . CancelledError : logger . debug ( \"Cancelling actor: %s \" , cls . __name__ ) raise except Exception as err : # pylint: disable=broad-except logger . exception ( \"Actor ( %s ) crashed with error: %s \" , cls . __name__ , err ) if ( self . restart_limit is None or number_of_restarts < self . restart_limit ): number_of_restarts += 1 logger . info ( \"Restarting actor: %s \" , cls . __name__ ) else : logger . info ( \"Shutting down actor: %s \" , cls . __name__ ) break async def _stop ( self ) -> None : \"\"\"Stop an running actor.\"\"\" self . _actor_task . cancel () try : await self . _actor_task except asyncio . CancelledError : pass async def join ( self ) -> None : \"\"\"Await the actor's task, and return when the task completes.\"\"\" await self . _actor_task return ActorClass","title":"actor"},{"location":"reference/frequenz/sdk/actor/#frequenz.sdk.actor","text":"A base class for creating simple composable actors.","title":"actor"},{"location":"reference/frequenz/sdk/actor/#frequenz.sdk.actor-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/actor/#frequenz.sdk.actor.ChannelRegistry","text":"Dynamically creates, own and provide access to channels. It can be used by actors to dynamically establish a communication channel between each other. Channels are identified by string names. Source code in frequenz/sdk/actor/channel_registry.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 class ChannelRegistry : \"\"\"Dynamically creates, own and provide access to channels. It can be used by actors to dynamically establish a communication channel between each other. Channels are identified by string names. \"\"\" def __init__ ( self , * , name : str ) -> None : \"\"\"Create a `ChannelRegistry` instance. Args: name: A unique name for the registry. \"\"\" self . _name = name self . _channels : Dict [ str , Broadcast [ Any ]] = {} def new_sender ( self , key : str ) -> Sender [ Any ]: \"\"\"Get a sender to a dynamically created channel with the given key. Args: key: A key to identify the channel. Returns: A sender to a dynamically created channel with the given key. \"\"\" if key not in self . _channels : self . _channels [ key ] = Broadcast ( f \" { self . _name } - { key } \" ) return self . _channels [ key ] . new_sender () def new_receiver ( self , key : str ) -> Receiver [ Any ]: \"\"\"Get a receiver to a dynamically created channel with the given key. Args: key: A key to identify the channel. Returns: A receiver for a dynamically created channel with the given key. \"\"\" if key not in self . _channels : self . _channels [ key ] = Broadcast ( f \" { self . _name } - { key } \" ) return self . _channels [ key ] . new_receiver ()","title":"ChannelRegistry"},{"location":"reference/frequenz/sdk/actor/#frequenz.sdk.actor.ChannelRegistry-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/actor/#frequenz.sdk.actor.channel_registry.ChannelRegistry.__init__","text":"Create a ChannelRegistry instance. PARAMETER DESCRIPTION name A unique name for the registry. TYPE: str Source code in frequenz/sdk/actor/channel_registry.py 18 19 20 21 22 23 24 25 def __init__ ( self , * , name : str ) -> None : \"\"\"Create a `ChannelRegistry` instance. Args: name: A unique name for the registry. \"\"\" self . _name = name self . _channels : Dict [ str , Broadcast [ Any ]] = {}","title":"__init__()"},{"location":"reference/frequenz/sdk/actor/#frequenz.sdk.actor.channel_registry.ChannelRegistry.new_receiver","text":"Get a receiver to a dynamically created channel with the given key. PARAMETER DESCRIPTION key A key to identify the channel. TYPE: str RETURNS DESCRIPTION Receiver [ Any ] A receiver for a dynamically created channel with the given key. Source code in frequenz/sdk/actor/channel_registry.py 40 41 42 43 44 45 46 47 48 49 50 51 def new_receiver ( self , key : str ) -> Receiver [ Any ]: \"\"\"Get a receiver to a dynamically created channel with the given key. Args: key: A key to identify the channel. Returns: A receiver for a dynamically created channel with the given key. \"\"\" if key not in self . _channels : self . _channels [ key ] = Broadcast ( f \" { self . _name } - { key } \" ) return self . _channels [ key ] . new_receiver ()","title":"new_receiver()"},{"location":"reference/frequenz/sdk/actor/#frequenz.sdk.actor.channel_registry.ChannelRegistry.new_sender","text":"Get a sender to a dynamically created channel with the given key. PARAMETER DESCRIPTION key A key to identify the channel. TYPE: str RETURNS DESCRIPTION Sender [ Any ] A sender to a dynamically created channel with the given key. Source code in frequenz/sdk/actor/channel_registry.py 27 28 29 30 31 32 33 34 35 36 37 38 def new_sender ( self , key : str ) -> Sender [ Any ]: \"\"\"Get a sender to a dynamically created channel with the given key. Args: key: A key to identify the channel. Returns: A sender to a dynamically created channel with the given key. \"\"\" if key not in self . _channels : self . _channels [ key ] = Broadcast ( f \" { self . _name } - { key } \" ) return self . _channels [ key ] . new_sender ()","title":"new_sender()"},{"location":"reference/frequenz/sdk/actor/#frequenz.sdk.actor-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/actor/#frequenz.sdk.actor.actor","text":"Decorate a class into a simple composable actor. A actor using the actor decorator should define an async def run(self) method, that loops over incoming data, and sends results out. Channels can be used to implement communication between actors, as shown in the examples below. PARAMETER DESCRIPTION cls the class to decorate. TYPE: Type [ Any ] RETURNS DESCRIPTION Type [ Any ] The decorated class. RAISES DESCRIPTION TypeError when the class doesn't have a run method as per spec. Example (one actor receiving from two receivers): @actor class EchoActor : def __init__ ( self , name : str , recv1 : Receiver [ bool ], recv2 : Receiver [ bool ], output : Sender [ bool ], ) -> None : self . name = name self . _recv1 = recv1 self . _recv2 = recv2 self . _output = output async def run ( self ) -> None : select = Select ( channel_1 = self . _recv1 , channel_2 = self . _recv2 ) while await select . ready (): if msg := select . channel_1 : await self . _output . send ( msg . inner ) elif msg := select . channel_2 : await self . _output . send ( msg . inner ) input_chan_1 : Broadcast [ bool ] = Broadcast ( \"input_chan_1\" ) input_chan_2 : Broadcast [ bool ] = Broadcast ( \"input_chan_2\" ) echo_chan : Broadcast [ bool ] = Broadcast ( \"EchoChannel\" ) echo_actor = EchoActor ( \"EchoActor\" , recv1 = input_chan_1 . new_receiver (), recv2 = input_chan_2 . new_receiver (), output = echo_chan . new_sender (), ) echo_rx = echo_chan . new_receiver () await input_chan_2 . new_sender () . send ( True ) msg = await echo_rx . receive () Example (two Actors composed): @actor class Actor1 : def __init__ ( self , name : str , recv : Receiver [ bool ], output : Sender [ bool ], ) -> None : self . name = name self . _recv = recv self . _output = output async def run ( self ) -> None : async for msg in self . _recv : await self . _output . send ( msg ) @actor class Actor2 : def __init__ ( self , name : str , recv : Receiver [ bool ], output : Sender [ bool ], ) -> None : self . name = name self . _recv = recv self . _output = output async def run ( self ) -> None : async for msg in self . _recv : await self . _output . send ( msg ) input_chan : Broadcast [ bool ] = Broadcast ( \"Input to A1\" ) a1_chan : Broadcast [ bool ] = Broadcast [ \"A1 stream\" ] a2_chan : Broadcast [ bool ] = Broadcast [ \"A2 stream\" ] a1 = Actor1 ( name = \"ActorOne\" , recv = input_chan . new_receiver (), output = a1_chan . new_sender (), ) a2 = Actor2 ( name = \"ActorTwo\" , recv = a1_chan . new_receiver (), output = a2_chan . new_sender (), ) a2_rx = a2_chan . new_receiver () await input_chan . new_sender () . send ( True ) msg = await a2_rx . receive () Source code in frequenz/sdk/actor/decorator.py 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 def actor ( cls : Type [ Any ]) -> Type [ Any ]: \"\"\"Decorate a class into a simple composable actor. A actor using the `actor` decorator should define an `async def run(self)` method, that loops over incoming data, and sends results out. Channels can be used to implement communication between actors, as shown in the examples below. Args: cls: the class to decorate. Returns: The decorated class. Raises: TypeError: when the class doesn't have a `run` method as per spec. Example (one actor receiving from two receivers): ``` python @actor class EchoActor: def __init__( self, name: str, recv1: Receiver[bool], recv2: Receiver[bool], output: Sender[bool], ) -> None: self.name = name self._recv1 = recv1 self._recv2 = recv2 self._output = output async def run(self) -> None: select = Select(channel_1=self._recv1, channel_2=self._recv2) while await select.ready(): if msg := select.channel_1: await self._output.send(msg.inner) elif msg := select.channel_2: await self._output.send(msg.inner) input_chan_1: Broadcast[bool] = Broadcast(\"input_chan_1\") input_chan_2: Broadcast[bool] = Broadcast(\"input_chan_2\") echo_chan: Broadcast[bool] = Broadcast(\"EchoChannel\") echo_actor = EchoActor( \"EchoActor\", recv1=input_chan_1.new_receiver(), recv2=input_chan_2.new_receiver(), output=echo_chan.new_sender(), ) echo_rx = echo_chan.new_receiver() await input_chan_2.new_sender().send(True) msg = await echo_rx.receive() ``` Example (two Actors composed): ``` python @actor class Actor1: def __init__( self, name: str, recv: Receiver[bool], output: Sender[bool], ) -> None: self.name = name self._recv = recv self._output = output async def run(self) -> None: async for msg in self._recv: await self._output.send(msg) @actor class Actor2: def __init__( self, name: str, recv: Receiver[bool], output: Sender[bool], ) -> None: self.name = name self._recv = recv self._output = output async def run(self) -> None: async for msg in self._recv: await self._output.send(msg) input_chan: Broadcast[bool] = Broadcast(\"Input to A1\") a1_chan: Broadcast[bool] = Broadcast[\"A1 stream\"] a2_chan: Broadcast[bool] = Broadcast[\"A2 stream\"] a1 = Actor1( name=\"ActorOne\", recv=input_chan.new_receiver(), output=a1_chan.new_sender(), ) a2 = Actor2( name=\"ActorTwo\", recv=a1_chan.new_receiver(), output=a2_chan.new_sender(), ) a2_rx = a2_chan.new_receiver() await input_chan.new_sender().send(True) msg = await a2_rx.receive() ``` \"\"\" if not inspect . isclass ( cls ): raise TypeError ( \"The `@actor` decorator can only be applied for classes.\" ) _check_run_method_exists ( cls ) class ActorClass ( cls , BaseActor , Generic [ OT ]): # type: ignore \"\"\"A wrapper class to make an actor.\"\"\" def __init__ ( self , * args : Any , ** kwargs : Any ) -> None : \"\"\"Create an `ActorClass` instance. Also call __init__ on `cls`. Args: *args: Any positional arguments to `cls.__init__`. **kwargs: Any keyword arguments to `cls.__init__`. \"\"\" super () . __init__ ( * args , ** kwargs ) self . _actor_task = asyncio . create_task ( self . _start_actor ()) async def _start_actor ( self ) -> None : \"\"\"Run the main logic of the actor as a coroutine. Raises: asyncio.CancelledError: when the actor's task gets cancelled. \"\"\" logger . debug ( \"Starting actor: %s \" , cls . __name__ ) number_of_restarts = 0 while True : try : await super () . run () except asyncio . CancelledError : logger . debug ( \"Cancelling actor: %s \" , cls . __name__ ) raise except Exception as err : # pylint: disable=broad-except logger . exception ( \"Actor ( %s ) crashed with error: %s \" , cls . __name__ , err ) if ( self . restart_limit is None or number_of_restarts < self . restart_limit ): number_of_restarts += 1 logger . info ( \"Restarting actor: %s \" , cls . __name__ ) else : logger . info ( \"Shutting down actor: %s \" , cls . __name__ ) break async def _stop ( self ) -> None : \"\"\"Stop an running actor.\"\"\" self . _actor_task . cancel () try : await self . _actor_task except asyncio . CancelledError : pass async def join ( self ) -> None : \"\"\"Await the actor's task, and return when the task completes.\"\"\" await self . _actor_task return ActorClass","title":"actor()"},{"location":"reference/frequenz/sdk/actor/channel_registry/","text":"frequenz.sdk.actor.channel_registry \u00a4 A class that would dynamically create, own and provide access to channels. Classes \u00a4 frequenz.sdk.actor.channel_registry.ChannelRegistry \u00a4 Dynamically creates, own and provide access to channels. It can be used by actors to dynamically establish a communication channel between each other. Channels are identified by string names. Source code in frequenz/sdk/actor/channel_registry.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 class ChannelRegistry : \"\"\"Dynamically creates, own and provide access to channels. It can be used by actors to dynamically establish a communication channel between each other. Channels are identified by string names. \"\"\" def __init__ ( self , * , name : str ) -> None : \"\"\"Create a `ChannelRegistry` instance. Args: name: A unique name for the registry. \"\"\" self . _name = name self . _channels : Dict [ str , Broadcast [ Any ]] = {} def new_sender ( self , key : str ) -> Sender [ Any ]: \"\"\"Get a sender to a dynamically created channel with the given key. Args: key: A key to identify the channel. Returns: A sender to a dynamically created channel with the given key. \"\"\" if key not in self . _channels : self . _channels [ key ] = Broadcast ( f \" { self . _name } - { key } \" ) return self . _channels [ key ] . new_sender () def new_receiver ( self , key : str ) -> Receiver [ Any ]: \"\"\"Get a receiver to a dynamically created channel with the given key. Args: key: A key to identify the channel. Returns: A receiver for a dynamically created channel with the given key. \"\"\" if key not in self . _channels : self . _channels [ key ] = Broadcast ( f \" { self . _name } - { key } \" ) return self . _channels [ key ] . new_receiver () Functions \u00a4 __init__ ( * , name ) \u00a4 Create a ChannelRegistry instance. PARAMETER DESCRIPTION name A unique name for the registry. TYPE: str Source code in frequenz/sdk/actor/channel_registry.py 18 19 20 21 22 23 24 25 def __init__ ( self , * , name : str ) -> None : \"\"\"Create a `ChannelRegistry` instance. Args: name: A unique name for the registry. \"\"\" self . _name = name self . _channels : Dict [ str , Broadcast [ Any ]] = {} new_receiver ( key ) \u00a4 Get a receiver to a dynamically created channel with the given key. PARAMETER DESCRIPTION key A key to identify the channel. TYPE: str RETURNS DESCRIPTION Receiver [ Any ] A receiver for a dynamically created channel with the given key. Source code in frequenz/sdk/actor/channel_registry.py 40 41 42 43 44 45 46 47 48 49 50 51 def new_receiver ( self , key : str ) -> Receiver [ Any ]: \"\"\"Get a receiver to a dynamically created channel with the given key. Args: key: A key to identify the channel. Returns: A receiver for a dynamically created channel with the given key. \"\"\" if key not in self . _channels : self . _channels [ key ] = Broadcast ( f \" { self . _name } - { key } \" ) return self . _channels [ key ] . new_receiver () new_sender ( key ) \u00a4 Get a sender to a dynamically created channel with the given key. PARAMETER DESCRIPTION key A key to identify the channel. TYPE: str RETURNS DESCRIPTION Sender [ Any ] A sender to a dynamically created channel with the given key. Source code in frequenz/sdk/actor/channel_registry.py 27 28 29 30 31 32 33 34 35 36 37 38 def new_sender ( self , key : str ) -> Sender [ Any ]: \"\"\"Get a sender to a dynamically created channel with the given key. Args: key: A key to identify the channel. Returns: A sender to a dynamically created channel with the given key. \"\"\" if key not in self . _channels : self . _channels [ key ] = Broadcast ( f \" { self . _name } - { key } \" ) return self . _channels [ key ] . new_sender ()","title":"channel_registry"},{"location":"reference/frequenz/sdk/actor/channel_registry/#frequenz.sdk.actor.channel_registry","text":"A class that would dynamically create, own and provide access to channels.","title":"channel_registry"},{"location":"reference/frequenz/sdk/actor/channel_registry/#frequenz.sdk.actor.channel_registry-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/actor/channel_registry/#frequenz.sdk.actor.channel_registry.ChannelRegistry","text":"Dynamically creates, own and provide access to channels. It can be used by actors to dynamically establish a communication channel between each other. Channels are identified by string names. Source code in frequenz/sdk/actor/channel_registry.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 class ChannelRegistry : \"\"\"Dynamically creates, own and provide access to channels. It can be used by actors to dynamically establish a communication channel between each other. Channels are identified by string names. \"\"\" def __init__ ( self , * , name : str ) -> None : \"\"\"Create a `ChannelRegistry` instance. Args: name: A unique name for the registry. \"\"\" self . _name = name self . _channels : Dict [ str , Broadcast [ Any ]] = {} def new_sender ( self , key : str ) -> Sender [ Any ]: \"\"\"Get a sender to a dynamically created channel with the given key. Args: key: A key to identify the channel. Returns: A sender to a dynamically created channel with the given key. \"\"\" if key not in self . _channels : self . _channels [ key ] = Broadcast ( f \" { self . _name } - { key } \" ) return self . _channels [ key ] . new_sender () def new_receiver ( self , key : str ) -> Receiver [ Any ]: \"\"\"Get a receiver to a dynamically created channel with the given key. Args: key: A key to identify the channel. Returns: A receiver for a dynamically created channel with the given key. \"\"\" if key not in self . _channels : self . _channels [ key ] = Broadcast ( f \" { self . _name } - { key } \" ) return self . _channels [ key ] . new_receiver ()","title":"ChannelRegistry"},{"location":"reference/frequenz/sdk/actor/channel_registry/#frequenz.sdk.actor.channel_registry.ChannelRegistry-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/actor/channel_registry/#frequenz.sdk.actor.channel_registry.ChannelRegistry.__init__","text":"Create a ChannelRegistry instance. PARAMETER DESCRIPTION name A unique name for the registry. TYPE: str Source code in frequenz/sdk/actor/channel_registry.py 18 19 20 21 22 23 24 25 def __init__ ( self , * , name : str ) -> None : \"\"\"Create a `ChannelRegistry` instance. Args: name: A unique name for the registry. \"\"\" self . _name = name self . _channels : Dict [ str , Broadcast [ Any ]] = {}","title":"__init__()"},{"location":"reference/frequenz/sdk/actor/channel_registry/#frequenz.sdk.actor.channel_registry.ChannelRegistry.new_receiver","text":"Get a receiver to a dynamically created channel with the given key. PARAMETER DESCRIPTION key A key to identify the channel. TYPE: str RETURNS DESCRIPTION Receiver [ Any ] A receiver for a dynamically created channel with the given key. Source code in frequenz/sdk/actor/channel_registry.py 40 41 42 43 44 45 46 47 48 49 50 51 def new_receiver ( self , key : str ) -> Receiver [ Any ]: \"\"\"Get a receiver to a dynamically created channel with the given key. Args: key: A key to identify the channel. Returns: A receiver for a dynamically created channel with the given key. \"\"\" if key not in self . _channels : self . _channels [ key ] = Broadcast ( f \" { self . _name } - { key } \" ) return self . _channels [ key ] . new_receiver ()","title":"new_receiver()"},{"location":"reference/frequenz/sdk/actor/channel_registry/#frequenz.sdk.actor.channel_registry.ChannelRegistry.new_sender","text":"Get a sender to a dynamically created channel with the given key. PARAMETER DESCRIPTION key A key to identify the channel. TYPE: str RETURNS DESCRIPTION Sender [ Any ] A sender to a dynamically created channel with the given key. Source code in frequenz/sdk/actor/channel_registry.py 27 28 29 30 31 32 33 34 35 36 37 38 def new_sender ( self , key : str ) -> Sender [ Any ]: \"\"\"Get a sender to a dynamically created channel with the given key. Args: key: A key to identify the channel. Returns: A sender to a dynamically created channel with the given key. \"\"\" if key not in self . _channels : self . _channels [ key ] = Broadcast ( f \" { self . _name } - { key } \" ) return self . _channels [ key ] . new_sender ()","title":"new_sender()"},{"location":"reference/frequenz/sdk/actor/decorator/","text":"frequenz.sdk.actor.decorator \u00a4 A decorator for creating simple composable actors. Supports multiple input channels and a single output channel. Note that if your use-case needs multiple output channels, you may instead consider using several actors. Classes \u00a4 frequenz.sdk.actor.decorator.BaseActor \u00a4 Base class to provide common attributes for all actors. Source code in frequenz/sdk/actor/decorator.py 50 51 52 53 54 55 class BaseActor : \"\"\"Base class to provide common attributes for all actors.\"\"\" # None is unlimited, 0 is no restarts. After restarts are exhausted the # exception will be re-raised. restart_limit : Optional [ int ] = None Functions \u00a4 frequenz . sdk . actor . decorator . actor ( cls ) \u00a4 Decorate a class into a simple composable actor. A actor using the actor decorator should define an async def run(self) method, that loops over incoming data, and sends results out. Channels can be used to implement communication between actors, as shown in the examples below. PARAMETER DESCRIPTION cls the class to decorate. TYPE: Type [ Any ] RETURNS DESCRIPTION Type [ Any ] The decorated class. RAISES DESCRIPTION TypeError when the class doesn't have a run method as per spec. Example (one actor receiving from two receivers): @actor class EchoActor : def __init__ ( self , name : str , recv1 : Receiver [ bool ], recv2 : Receiver [ bool ], output : Sender [ bool ], ) -> None : self . name = name self . _recv1 = recv1 self . _recv2 = recv2 self . _output = output async def run ( self ) -> None : select = Select ( channel_1 = self . _recv1 , channel_2 = self . _recv2 ) while await select . ready (): if msg := select . channel_1 : await self . _output . send ( msg . inner ) elif msg := select . channel_2 : await self . _output . send ( msg . inner ) input_chan_1 : Broadcast [ bool ] = Broadcast ( \"input_chan_1\" ) input_chan_2 : Broadcast [ bool ] = Broadcast ( \"input_chan_2\" ) echo_chan : Broadcast [ bool ] = Broadcast ( \"EchoChannel\" ) echo_actor = EchoActor ( \"EchoActor\" , recv1 = input_chan_1 . new_receiver (), recv2 = input_chan_2 . new_receiver (), output = echo_chan . new_sender (), ) echo_rx = echo_chan . new_receiver () await input_chan_2 . new_sender () . send ( True ) msg = await echo_rx . receive () Example (two Actors composed): @actor class Actor1 : def __init__ ( self , name : str , recv : Receiver [ bool ], output : Sender [ bool ], ) -> None : self . name = name self . _recv = recv self . _output = output async def run ( self ) -> None : async for msg in self . _recv : await self . _output . send ( msg ) @actor class Actor2 : def __init__ ( self , name : str , recv : Receiver [ bool ], output : Sender [ bool ], ) -> None : self . name = name self . _recv = recv self . _output = output async def run ( self ) -> None : async for msg in self . _recv : await self . _output . send ( msg ) input_chan : Broadcast [ bool ] = Broadcast ( \"Input to A1\" ) a1_chan : Broadcast [ bool ] = Broadcast [ \"A1 stream\" ] a2_chan : Broadcast [ bool ] = Broadcast [ \"A2 stream\" ] a1 = Actor1 ( name = \"ActorOne\" , recv = input_chan . new_receiver (), output = a1_chan . new_sender (), ) a2 = Actor2 ( name = \"ActorTwo\" , recv = a1_chan . new_receiver (), output = a2_chan . new_sender (), ) a2_rx = a2_chan . new_receiver () await input_chan . new_sender () . send ( True ) msg = await a2_rx . receive () Source code in frequenz/sdk/actor/decorator.py 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 def actor ( cls : Type [ Any ]) -> Type [ Any ]: \"\"\"Decorate a class into a simple composable actor. A actor using the `actor` decorator should define an `async def run(self)` method, that loops over incoming data, and sends results out. Channels can be used to implement communication between actors, as shown in the examples below. Args: cls: the class to decorate. Returns: The decorated class. Raises: TypeError: when the class doesn't have a `run` method as per spec. Example (one actor receiving from two receivers): ``` python @actor class EchoActor: def __init__( self, name: str, recv1: Receiver[bool], recv2: Receiver[bool], output: Sender[bool], ) -> None: self.name = name self._recv1 = recv1 self._recv2 = recv2 self._output = output async def run(self) -> None: select = Select(channel_1=self._recv1, channel_2=self._recv2) while await select.ready(): if msg := select.channel_1: await self._output.send(msg.inner) elif msg := select.channel_2: await self._output.send(msg.inner) input_chan_1: Broadcast[bool] = Broadcast(\"input_chan_1\") input_chan_2: Broadcast[bool] = Broadcast(\"input_chan_2\") echo_chan: Broadcast[bool] = Broadcast(\"EchoChannel\") echo_actor = EchoActor( \"EchoActor\", recv1=input_chan_1.new_receiver(), recv2=input_chan_2.new_receiver(), output=echo_chan.new_sender(), ) echo_rx = echo_chan.new_receiver() await input_chan_2.new_sender().send(True) msg = await echo_rx.receive() ``` Example (two Actors composed): ``` python @actor class Actor1: def __init__( self, name: str, recv: Receiver[bool], output: Sender[bool], ) -> None: self.name = name self._recv = recv self._output = output async def run(self) -> None: async for msg in self._recv: await self._output.send(msg) @actor class Actor2: def __init__( self, name: str, recv: Receiver[bool], output: Sender[bool], ) -> None: self.name = name self._recv = recv self._output = output async def run(self) -> None: async for msg in self._recv: await self._output.send(msg) input_chan: Broadcast[bool] = Broadcast(\"Input to A1\") a1_chan: Broadcast[bool] = Broadcast[\"A1 stream\"] a2_chan: Broadcast[bool] = Broadcast[\"A2 stream\"] a1 = Actor1( name=\"ActorOne\", recv=input_chan.new_receiver(), output=a1_chan.new_sender(), ) a2 = Actor2( name=\"ActorTwo\", recv=a1_chan.new_receiver(), output=a2_chan.new_sender(), ) a2_rx = a2_chan.new_receiver() await input_chan.new_sender().send(True) msg = await a2_rx.receive() ``` \"\"\" if not inspect . isclass ( cls ): raise TypeError ( \"The `@actor` decorator can only be applied for classes.\" ) _check_run_method_exists ( cls ) class ActorClass ( cls , BaseActor , Generic [ OT ]): # type: ignore \"\"\"A wrapper class to make an actor.\"\"\" def __init__ ( self , * args : Any , ** kwargs : Any ) -> None : \"\"\"Create an `ActorClass` instance. Also call __init__ on `cls`. Args: *args: Any positional arguments to `cls.__init__`. **kwargs: Any keyword arguments to `cls.__init__`. \"\"\" super () . __init__ ( * args , ** kwargs ) self . _actor_task = asyncio . create_task ( self . _start_actor ()) async def _start_actor ( self ) -> None : \"\"\"Run the main logic of the actor as a coroutine. Raises: asyncio.CancelledError: when the actor's task gets cancelled. \"\"\" logger . debug ( \"Starting actor: %s \" , cls . __name__ ) number_of_restarts = 0 while True : try : await super () . run () except asyncio . CancelledError : logger . debug ( \"Cancelling actor: %s \" , cls . __name__ ) raise except Exception as err : # pylint: disable=broad-except logger . exception ( \"Actor ( %s ) crashed with error: %s \" , cls . __name__ , err ) if ( self . restart_limit is None or number_of_restarts < self . restart_limit ): number_of_restarts += 1 logger . info ( \"Restarting actor: %s \" , cls . __name__ ) else : logger . info ( \"Shutting down actor: %s \" , cls . __name__ ) break async def _stop ( self ) -> None : \"\"\"Stop an running actor.\"\"\" self . _actor_task . cancel () try : await self . _actor_task except asyncio . CancelledError : pass async def join ( self ) -> None : \"\"\"Await the actor's task, and return when the task completes.\"\"\" await self . _actor_task return ActorClass","title":"decorator"},{"location":"reference/frequenz/sdk/actor/decorator/#frequenz.sdk.actor.decorator","text":"A decorator for creating simple composable actors. Supports multiple input channels and a single output channel. Note that if your use-case needs multiple output channels, you may instead consider using several actors.","title":"decorator"},{"location":"reference/frequenz/sdk/actor/decorator/#frequenz.sdk.actor.decorator-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/actor/decorator/#frequenz.sdk.actor.decorator.BaseActor","text":"Base class to provide common attributes for all actors. Source code in frequenz/sdk/actor/decorator.py 50 51 52 53 54 55 class BaseActor : \"\"\"Base class to provide common attributes for all actors.\"\"\" # None is unlimited, 0 is no restarts. After restarts are exhausted the # exception will be re-raised. restart_limit : Optional [ int ] = None","title":"BaseActor"},{"location":"reference/frequenz/sdk/actor/decorator/#frequenz.sdk.actor.decorator-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/actor/decorator/#frequenz.sdk.actor.decorator.actor","text":"Decorate a class into a simple composable actor. A actor using the actor decorator should define an async def run(self) method, that loops over incoming data, and sends results out. Channels can be used to implement communication between actors, as shown in the examples below. PARAMETER DESCRIPTION cls the class to decorate. TYPE: Type [ Any ] RETURNS DESCRIPTION Type [ Any ] The decorated class. RAISES DESCRIPTION TypeError when the class doesn't have a run method as per spec. Example (one actor receiving from two receivers): @actor class EchoActor : def __init__ ( self , name : str , recv1 : Receiver [ bool ], recv2 : Receiver [ bool ], output : Sender [ bool ], ) -> None : self . name = name self . _recv1 = recv1 self . _recv2 = recv2 self . _output = output async def run ( self ) -> None : select = Select ( channel_1 = self . _recv1 , channel_2 = self . _recv2 ) while await select . ready (): if msg := select . channel_1 : await self . _output . send ( msg . inner ) elif msg := select . channel_2 : await self . _output . send ( msg . inner ) input_chan_1 : Broadcast [ bool ] = Broadcast ( \"input_chan_1\" ) input_chan_2 : Broadcast [ bool ] = Broadcast ( \"input_chan_2\" ) echo_chan : Broadcast [ bool ] = Broadcast ( \"EchoChannel\" ) echo_actor = EchoActor ( \"EchoActor\" , recv1 = input_chan_1 . new_receiver (), recv2 = input_chan_2 . new_receiver (), output = echo_chan . new_sender (), ) echo_rx = echo_chan . new_receiver () await input_chan_2 . new_sender () . send ( True ) msg = await echo_rx . receive () Example (two Actors composed): @actor class Actor1 : def __init__ ( self , name : str , recv : Receiver [ bool ], output : Sender [ bool ], ) -> None : self . name = name self . _recv = recv self . _output = output async def run ( self ) -> None : async for msg in self . _recv : await self . _output . send ( msg ) @actor class Actor2 : def __init__ ( self , name : str , recv : Receiver [ bool ], output : Sender [ bool ], ) -> None : self . name = name self . _recv = recv self . _output = output async def run ( self ) -> None : async for msg in self . _recv : await self . _output . send ( msg ) input_chan : Broadcast [ bool ] = Broadcast ( \"Input to A1\" ) a1_chan : Broadcast [ bool ] = Broadcast [ \"A1 stream\" ] a2_chan : Broadcast [ bool ] = Broadcast [ \"A2 stream\" ] a1 = Actor1 ( name = \"ActorOne\" , recv = input_chan . new_receiver (), output = a1_chan . new_sender (), ) a2 = Actor2 ( name = \"ActorTwo\" , recv = a1_chan . new_receiver (), output = a2_chan . new_sender (), ) a2_rx = a2_chan . new_receiver () await input_chan . new_sender () . send ( True ) msg = await a2_rx . receive () Source code in frequenz/sdk/actor/decorator.py 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 def actor ( cls : Type [ Any ]) -> Type [ Any ]: \"\"\"Decorate a class into a simple composable actor. A actor using the `actor` decorator should define an `async def run(self)` method, that loops over incoming data, and sends results out. Channels can be used to implement communication between actors, as shown in the examples below. Args: cls: the class to decorate. Returns: The decorated class. Raises: TypeError: when the class doesn't have a `run` method as per spec. Example (one actor receiving from two receivers): ``` python @actor class EchoActor: def __init__( self, name: str, recv1: Receiver[bool], recv2: Receiver[bool], output: Sender[bool], ) -> None: self.name = name self._recv1 = recv1 self._recv2 = recv2 self._output = output async def run(self) -> None: select = Select(channel_1=self._recv1, channel_2=self._recv2) while await select.ready(): if msg := select.channel_1: await self._output.send(msg.inner) elif msg := select.channel_2: await self._output.send(msg.inner) input_chan_1: Broadcast[bool] = Broadcast(\"input_chan_1\") input_chan_2: Broadcast[bool] = Broadcast(\"input_chan_2\") echo_chan: Broadcast[bool] = Broadcast(\"EchoChannel\") echo_actor = EchoActor( \"EchoActor\", recv1=input_chan_1.new_receiver(), recv2=input_chan_2.new_receiver(), output=echo_chan.new_sender(), ) echo_rx = echo_chan.new_receiver() await input_chan_2.new_sender().send(True) msg = await echo_rx.receive() ``` Example (two Actors composed): ``` python @actor class Actor1: def __init__( self, name: str, recv: Receiver[bool], output: Sender[bool], ) -> None: self.name = name self._recv = recv self._output = output async def run(self) -> None: async for msg in self._recv: await self._output.send(msg) @actor class Actor2: def __init__( self, name: str, recv: Receiver[bool], output: Sender[bool], ) -> None: self.name = name self._recv = recv self._output = output async def run(self) -> None: async for msg in self._recv: await self._output.send(msg) input_chan: Broadcast[bool] = Broadcast(\"Input to A1\") a1_chan: Broadcast[bool] = Broadcast[\"A1 stream\"] a2_chan: Broadcast[bool] = Broadcast[\"A2 stream\"] a1 = Actor1( name=\"ActorOne\", recv=input_chan.new_receiver(), output=a1_chan.new_sender(), ) a2 = Actor2( name=\"ActorTwo\", recv=a1_chan.new_receiver(), output=a2_chan.new_sender(), ) a2_rx = a2_chan.new_receiver() await input_chan.new_sender().send(True) msg = await a2_rx.receive() ``` \"\"\" if not inspect . isclass ( cls ): raise TypeError ( \"The `@actor` decorator can only be applied for classes.\" ) _check_run_method_exists ( cls ) class ActorClass ( cls , BaseActor , Generic [ OT ]): # type: ignore \"\"\"A wrapper class to make an actor.\"\"\" def __init__ ( self , * args : Any , ** kwargs : Any ) -> None : \"\"\"Create an `ActorClass` instance. Also call __init__ on `cls`. Args: *args: Any positional arguments to `cls.__init__`. **kwargs: Any keyword arguments to `cls.__init__`. \"\"\" super () . __init__ ( * args , ** kwargs ) self . _actor_task = asyncio . create_task ( self . _start_actor ()) async def _start_actor ( self ) -> None : \"\"\"Run the main logic of the actor as a coroutine. Raises: asyncio.CancelledError: when the actor's task gets cancelled. \"\"\" logger . debug ( \"Starting actor: %s \" , cls . __name__ ) number_of_restarts = 0 while True : try : await super () . run () except asyncio . CancelledError : logger . debug ( \"Cancelling actor: %s \" , cls . __name__ ) raise except Exception as err : # pylint: disable=broad-except logger . exception ( \"Actor ( %s ) crashed with error: %s \" , cls . __name__ , err ) if ( self . restart_limit is None or number_of_restarts < self . restart_limit ): number_of_restarts += 1 logger . info ( \"Restarting actor: %s \" , cls . __name__ ) else : logger . info ( \"Shutting down actor: %s \" , cls . __name__ ) break async def _stop ( self ) -> None : \"\"\"Stop an running actor.\"\"\" self . _actor_task . cancel () try : await self . _actor_task except asyncio . CancelledError : pass async def join ( self ) -> None : \"\"\"Await the actor's task, and return when the task completes.\"\"\" await self . _actor_task return ActorClass","title":"actor()"},{"location":"reference/frequenz/sdk/actor/resampling/","text":"frequenz.sdk.actor.resampling \u00a4 ComponentMetricsResamplingActor used to subscribe for resampled component metrics. Attributes \u00a4 Classes \u00a4 frequenz.sdk.actor.resampling.ComponentMetricsResamplingActor \u00a4 ComponentMetricsResamplingActor used to ingest component data and resample it. Source code in frequenz/sdk/actor/resampling.py 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 @actor class ComponentMetricsResamplingActor : \"\"\"ComponentMetricsResamplingActor used to ingest component data and resample it.\"\"\" def __init__ ( # pylint: disable=too-many-arguments self , channel_registry : ChannelRegistry , subscription_sender : Sender [ ComponentMetricRequest ], subscription_receiver : Receiver [ ComponentMetricRequest ], resampling_period_s : float = 0.2 , max_data_age_in_periods : float = 3.0 , resampling_function : ResamplingFunction = average , ) -> None : \"\"\"Initialize the ComponentMetricsResamplingActor. Args: channel_registry: global channel registry used for receiving component data from DataSource and for sending resampled samples downstream subscription_sender: channel for sending component metric requests to the DataSourcing actor subscription_receiver: channel for receiving component metric requests resampling_period_s: value describing how often resampling should be performed, in seconds max_data_age_in_periods: max age that samples shouldn't exceed in order to be used in the resampling function resampling_function: function to be applied to a sequence of samples within a resampling period to produce a single output sample Example: ```python async def run() -> None: await microgrid_api.initialize(HOST, PORT) channel_registry = ChannelRegistry(name=\"Microgrid Channel Registry\") data_source_request_channel = Broadcast[ComponentMetricRequest]( \"Data Source Request Channel\" ) data_source_request_sender = data_source_request_channel.new_sender() data_source_request_receiver = data_source_request_channel.new_receiver() resampling_actor_request_channel = Broadcast[ComponentMetricRequest]( \"Resampling Actor Request Channel\" ) resampling_actor_request_sender = resampling_actor_request_channel.new_sender() resampling_actor_request_receiver = resampling_actor_request_channel.new_receiver() _data_sourcing_actor = DataSourcingActor( request_receiver=data_source_request_receiver, registry=channel_registry ) _resampling_actor = ComponentMetricsResamplingActor( channel_registry=channel_registry, subscription_sender=data_source_request_sender, subscription_receiver=resampling_actor_request_receiver, resampling_period_s=1.0, ) components = await microgrid_api.get().microgrid_api_client.components() battery_ids = [ comp.component_id for comp in components if comp.category == ComponentCategory.BATTERY ] subscription_requests = [ ComponentMetricRequest( namespace=\"Resampling\", component_id=component_id, metric_id=ComponentMetricId.SOC, start_time=None, ) for component_id in battery_ids ] await asyncio.gather( *[ resampling_actor_request_sender.send(request) for request in subscription_requests ] ) sample_receiver = MergeNamed( **{ channel_name: channel_registry.new_receiver(channel_name) for channel_name in map( lambda req: req.get_channel_name(), subscription_requests ) } ) async for channel_name, msg in sample_receiver: print(msg) asyncio.run(run()) ``` \"\"\" self . _channel_registry = channel_registry self . _subscription_sender = subscription_sender self . _subscription_receiver = subscription_receiver self . _resampling_period_s = resampling_period_s self . _max_data_age_in_periods : float = max_data_age_in_periods self . _resampling_function : ResamplingFunction = resampling_function self . _resampler = GroupResampler ( resampling_period_s = resampling_period_s , max_data_age_in_periods = max_data_age_in_periods , initial_resampling_function = resampling_function , ) self . _input_receivers : Dict [ str , Receiver [ Sample ]] = {} self . _output_senders : Dict [ str , Sender [ Sample ]] = {} self . _resampling_timer = Timer ( interval = self . _resampling_period_s ) async def subscribe ( self , request : ComponentMetricRequest ) -> None : \"\"\"Subscribe for data for a specific time series. Args: request: subscription request for a specific component metric \"\"\" channel_name = request . get_channel_name () data_source_request = dataclasses . replace ( request , ** dict ( namespace = \"Source\" )) data_source_channel_name = data_source_request . get_channel_name () if channel_name not in self . _input_receivers : await self . _subscription_sender . send ( data_source_request ) receiver : Receiver [ Sample ] = self . _channel_registry . new_receiver ( data_source_channel_name ) self . _input_receivers [ data_source_channel_name ] = receiver self . _resampler . add_time_series ( time_series_id = data_source_channel_name ) if channel_name not in self . _output_senders : sender : Sender [ Sample ] = self . _channel_registry . new_sender ( channel_name ) # This means that the `sender` will be sending samples to the channel with # name `channel_name` based on samples collected from the channel named # `data_source_channel_name` self . _output_senders [ data_source_channel_name ] = sender def is_sample_valid ( self , sample : Sample ) -> bool : \"\"\"Check if the provided sample is valid. Args: sample: sample to be validated Returns: True if the sample is valid, False otherwise \"\"\" if sample . value is None or math . isnan ( sample . value ): return False return True async def run ( self ) -> None : \"\"\"Run the actor. Raises: ConnectionError: When the provider of the subscription channel closes the connection \"\"\" while True : select = Select ( resampling_timer = self . _resampling_timer , subscription_receiver = self . _subscription_receiver , component_data_receiver = MergeNamed ( ** self . _input_receivers ), ) while await select . ready (): if msg := select . resampling_timer : assert msg . inner is not None , \"The timer should never be 'closed'\" timestamp = msg . inner awaitables = [ self . _output_senders [ channel_name ] . send ( sample ) for channel_name , sample in self . _resampler . resample ( timestamp ) ] await asyncio . gather ( * awaitables ) if msg := select . component_data_receiver : if msg . inner is None : # When this happens, then DataSourcingActor has closed the channel # for sending data for a specific `ComponentMetricRequest`, # which may need to be handled properly here, e.g. unsubscribe continue channel_name , sample = msg . inner if self . is_sample_valid ( sample = sample ): self . _resampler . add_sample ( time_series_id = channel_name , sample = sample , ) if msg := select . subscription_receiver : if msg . inner is None : raise ConnectionError ( \"Subscription channel connection has been closed!\" ) await self . subscribe ( request = msg . inner ) # Breaking out from the loop is required to regenerate # component_data_receivers to be able to fulfil this # subscription (later can be optimized by checking if # an output channel already existed in the `subscribe()` method) break Functions \u00a4 __init__ ( channel_registry , subscription_sender , subscription_receiver , resampling_period_s = 0.2 , max_data_age_in_periods = 3.0 , resampling_function = average ) \u00a4 Initialize the ComponentMetricsResamplingActor. PARAMETER DESCRIPTION channel_registry global channel registry used for receiving component data from DataSource and for sending resampled samples downstream TYPE: ChannelRegistry subscription_sender channel for sending component metric requests to the DataSourcing actor TYPE: Sender [ ComponentMetricRequest ] subscription_receiver channel for receiving component metric requests TYPE: Receiver [ ComponentMetricRequest ] resampling_period_s value describing how often resampling should be performed, in seconds TYPE: float DEFAULT: 0.2 max_data_age_in_periods max age that samples shouldn't exceed in order to be used in the resampling function TYPE: float DEFAULT: 3.0 resampling_function function to be applied to a sequence of samples within a resampling period to produce a single output sample TYPE: ResamplingFunction DEFAULT: average Example async def run () -> None : await microgrid_api . initialize ( HOST , PORT ) channel_registry = ChannelRegistry ( name = \"Microgrid Channel Registry\" ) data_source_request_channel = Broadcast [ ComponentMetricRequest ]( \"Data Source Request Channel\" ) data_source_request_sender = data_source_request_channel . new_sender () data_source_request_receiver = data_source_request_channel . new_receiver () resampling_actor_request_channel = Broadcast [ ComponentMetricRequest ]( \"Resampling Actor Request Channel\" ) resampling_actor_request_sender = resampling_actor_request_channel . new_sender () resampling_actor_request_receiver = resampling_actor_request_channel . new_receiver () _data_sourcing_actor = DataSourcingActor ( request_receiver = data_source_request_receiver , registry = channel_registry ) _resampling_actor = ComponentMetricsResamplingActor ( channel_registry = channel_registry , subscription_sender = data_source_request_sender , subscription_receiver = resampling_actor_request_receiver , resampling_period_s = 1.0 , ) components = await microgrid_api . get () . microgrid_api_client . components () battery_ids = [ comp . component_id for comp in components if comp . category == ComponentCategory . BATTERY ] subscription_requests = [ ComponentMetricRequest ( namespace = \"Resampling\" , component_id = component_id , metric_id = ComponentMetricId . SOC , start_time = None , ) for component_id in battery_ids ] await asyncio . gather ( * [ resampling_actor_request_sender . send ( request ) for request in subscription_requests ] ) sample_receiver = MergeNamed ( ** { channel_name : channel_registry . new_receiver ( channel_name ) for channel_name in map ( lambda req : req . get_channel_name (), subscription_requests ) } ) async for channel_name , msg in sample_receiver : print ( msg ) asyncio . run ( run ()) Source code in frequenz/sdk/actor/resampling.py 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 def __init__ ( # pylint: disable=too-many-arguments self , channel_registry : ChannelRegistry , subscription_sender : Sender [ ComponentMetricRequest ], subscription_receiver : Receiver [ ComponentMetricRequest ], resampling_period_s : float = 0.2 , max_data_age_in_periods : float = 3.0 , resampling_function : ResamplingFunction = average , ) -> None : \"\"\"Initialize the ComponentMetricsResamplingActor. Args: channel_registry: global channel registry used for receiving component data from DataSource and for sending resampled samples downstream subscription_sender: channel for sending component metric requests to the DataSourcing actor subscription_receiver: channel for receiving component metric requests resampling_period_s: value describing how often resampling should be performed, in seconds max_data_age_in_periods: max age that samples shouldn't exceed in order to be used in the resampling function resampling_function: function to be applied to a sequence of samples within a resampling period to produce a single output sample Example: ```python async def run() -> None: await microgrid_api.initialize(HOST, PORT) channel_registry = ChannelRegistry(name=\"Microgrid Channel Registry\") data_source_request_channel = Broadcast[ComponentMetricRequest]( \"Data Source Request Channel\" ) data_source_request_sender = data_source_request_channel.new_sender() data_source_request_receiver = data_source_request_channel.new_receiver() resampling_actor_request_channel = Broadcast[ComponentMetricRequest]( \"Resampling Actor Request Channel\" ) resampling_actor_request_sender = resampling_actor_request_channel.new_sender() resampling_actor_request_receiver = resampling_actor_request_channel.new_receiver() _data_sourcing_actor = DataSourcingActor( request_receiver=data_source_request_receiver, registry=channel_registry ) _resampling_actor = ComponentMetricsResamplingActor( channel_registry=channel_registry, subscription_sender=data_source_request_sender, subscription_receiver=resampling_actor_request_receiver, resampling_period_s=1.0, ) components = await microgrid_api.get().microgrid_api_client.components() battery_ids = [ comp.component_id for comp in components if comp.category == ComponentCategory.BATTERY ] subscription_requests = [ ComponentMetricRequest( namespace=\"Resampling\", component_id=component_id, metric_id=ComponentMetricId.SOC, start_time=None, ) for component_id in battery_ids ] await asyncio.gather( *[ resampling_actor_request_sender.send(request) for request in subscription_requests ] ) sample_receiver = MergeNamed( **{ channel_name: channel_registry.new_receiver(channel_name) for channel_name in map( lambda req: req.get_channel_name(), subscription_requests ) } ) async for channel_name, msg in sample_receiver: print(msg) asyncio.run(run()) ``` \"\"\" self . _channel_registry = channel_registry self . _subscription_sender = subscription_sender self . _subscription_receiver = subscription_receiver self . _resampling_period_s = resampling_period_s self . _max_data_age_in_periods : float = max_data_age_in_periods self . _resampling_function : ResamplingFunction = resampling_function self . _resampler = GroupResampler ( resampling_period_s = resampling_period_s , max_data_age_in_periods = max_data_age_in_periods , initial_resampling_function = resampling_function , ) self . _input_receivers : Dict [ str , Receiver [ Sample ]] = {} self . _output_senders : Dict [ str , Sender [ Sample ]] = {} self . _resampling_timer = Timer ( interval = self . _resampling_period_s ) is_sample_valid ( sample ) \u00a4 Check if the provided sample is valid. PARAMETER DESCRIPTION sample sample to be validated TYPE: Sample RETURNS DESCRIPTION bool True if the sample is valid, False otherwise Source code in frequenz/sdk/actor/resampling.py 185 186 187 188 189 190 191 192 193 194 195 196 def is_sample_valid ( self , sample : Sample ) -> bool : \"\"\"Check if the provided sample is valid. Args: sample: sample to be validated Returns: True if the sample is valid, False otherwise \"\"\" if sample . value is None or math . isnan ( sample . value ): return False return True run () async \u00a4 Run the actor. RAISES DESCRIPTION ConnectionError When the provider of the subscription channel closes the connection Source code in frequenz/sdk/actor/resampling.py 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 async def run ( self ) -> None : \"\"\"Run the actor. Raises: ConnectionError: When the provider of the subscription channel closes the connection \"\"\" while True : select = Select ( resampling_timer = self . _resampling_timer , subscription_receiver = self . _subscription_receiver , component_data_receiver = MergeNamed ( ** self . _input_receivers ), ) while await select . ready (): if msg := select . resampling_timer : assert msg . inner is not None , \"The timer should never be 'closed'\" timestamp = msg . inner awaitables = [ self . _output_senders [ channel_name ] . send ( sample ) for channel_name , sample in self . _resampler . resample ( timestamp ) ] await asyncio . gather ( * awaitables ) if msg := select . component_data_receiver : if msg . inner is None : # When this happens, then DataSourcingActor has closed the channel # for sending data for a specific `ComponentMetricRequest`, # which may need to be handled properly here, e.g. unsubscribe continue channel_name , sample = msg . inner if self . is_sample_valid ( sample = sample ): self . _resampler . add_sample ( time_series_id = channel_name , sample = sample , ) if msg := select . subscription_receiver : if msg . inner is None : raise ConnectionError ( \"Subscription channel connection has been closed!\" ) await self . subscribe ( request = msg . inner ) # Breaking out from the loop is required to regenerate # component_data_receivers to be able to fulfil this # subscription (later can be optimized by checking if # an output channel already existed in the `subscribe()` method) break subscribe ( request ) async \u00a4 Subscribe for data for a specific time series. PARAMETER DESCRIPTION request subscription request for a specific component metric TYPE: ComponentMetricRequest Source code in frequenz/sdk/actor/resampling.py 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 async def subscribe ( self , request : ComponentMetricRequest ) -> None : \"\"\"Subscribe for data for a specific time series. Args: request: subscription request for a specific component metric \"\"\" channel_name = request . get_channel_name () data_source_request = dataclasses . replace ( request , ** dict ( namespace = \"Source\" )) data_source_channel_name = data_source_request . get_channel_name () if channel_name not in self . _input_receivers : await self . _subscription_sender . send ( data_source_request ) receiver : Receiver [ Sample ] = self . _channel_registry . new_receiver ( data_source_channel_name ) self . _input_receivers [ data_source_channel_name ] = receiver self . _resampler . add_time_series ( time_series_id = data_source_channel_name ) if channel_name not in self . _output_senders : sender : Sender [ Sample ] = self . _channel_registry . new_sender ( channel_name ) # This means that the `sender` will be sending samples to the channel with # name `channel_name` based on samples collected from the channel named # `data_source_channel_name` self . _output_senders [ data_source_channel_name ] = sender Functions \u00a4 frequenz . sdk . actor . resampling . average ( samples , resampling_period_s ) \u00a4 Calculate average of the provided values. PARAMETER DESCRIPTION samples sequences of samples to apply the average to. It must be non-empty. TYPE: Sequence [ Sample ] resampling_period_s value describing how often resampling should be performed, in seconds TYPE: float RETURNS DESCRIPTION float average of all the sample values Source code in frequenz/sdk/actor/resampling.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 def average ( samples : Sequence [ Sample ], resampling_period_s : float ) -> float : \"\"\"Calculate average of the provided values. Args: samples: sequences of samples to apply the average to. It must be non-empty. resampling_period_s: value describing how often resampling should be performed, in seconds Returns: average of all the sample values \"\"\" assert len ( samples ) > 0 , \"Average cannot be given an empty list of samples\" values = list ( sample . value for sample in samples if sample . value is not None ) return sum ( values ) / len ( values )","title":"resampling"},{"location":"reference/frequenz/sdk/actor/resampling/#frequenz.sdk.actor.resampling","text":"ComponentMetricsResamplingActor used to subscribe for resampled component metrics.","title":"resampling"},{"location":"reference/frequenz/sdk/actor/resampling/#frequenz.sdk.actor.resampling-attributes","text":"","title":"Attributes"},{"location":"reference/frequenz/sdk/actor/resampling/#frequenz.sdk.actor.resampling-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/actor/resampling/#frequenz.sdk.actor.resampling.ComponentMetricsResamplingActor","text":"ComponentMetricsResamplingActor used to ingest component data and resample it. Source code in frequenz/sdk/actor/resampling.py 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 @actor class ComponentMetricsResamplingActor : \"\"\"ComponentMetricsResamplingActor used to ingest component data and resample it.\"\"\" def __init__ ( # pylint: disable=too-many-arguments self , channel_registry : ChannelRegistry , subscription_sender : Sender [ ComponentMetricRequest ], subscription_receiver : Receiver [ ComponentMetricRequest ], resampling_period_s : float = 0.2 , max_data_age_in_periods : float = 3.0 , resampling_function : ResamplingFunction = average , ) -> None : \"\"\"Initialize the ComponentMetricsResamplingActor. Args: channel_registry: global channel registry used for receiving component data from DataSource and for sending resampled samples downstream subscription_sender: channel for sending component metric requests to the DataSourcing actor subscription_receiver: channel for receiving component metric requests resampling_period_s: value describing how often resampling should be performed, in seconds max_data_age_in_periods: max age that samples shouldn't exceed in order to be used in the resampling function resampling_function: function to be applied to a sequence of samples within a resampling period to produce a single output sample Example: ```python async def run() -> None: await microgrid_api.initialize(HOST, PORT) channel_registry = ChannelRegistry(name=\"Microgrid Channel Registry\") data_source_request_channel = Broadcast[ComponentMetricRequest]( \"Data Source Request Channel\" ) data_source_request_sender = data_source_request_channel.new_sender() data_source_request_receiver = data_source_request_channel.new_receiver() resampling_actor_request_channel = Broadcast[ComponentMetricRequest]( \"Resampling Actor Request Channel\" ) resampling_actor_request_sender = resampling_actor_request_channel.new_sender() resampling_actor_request_receiver = resampling_actor_request_channel.new_receiver() _data_sourcing_actor = DataSourcingActor( request_receiver=data_source_request_receiver, registry=channel_registry ) _resampling_actor = ComponentMetricsResamplingActor( channel_registry=channel_registry, subscription_sender=data_source_request_sender, subscription_receiver=resampling_actor_request_receiver, resampling_period_s=1.0, ) components = await microgrid_api.get().microgrid_api_client.components() battery_ids = [ comp.component_id for comp in components if comp.category == ComponentCategory.BATTERY ] subscription_requests = [ ComponentMetricRequest( namespace=\"Resampling\", component_id=component_id, metric_id=ComponentMetricId.SOC, start_time=None, ) for component_id in battery_ids ] await asyncio.gather( *[ resampling_actor_request_sender.send(request) for request in subscription_requests ] ) sample_receiver = MergeNamed( **{ channel_name: channel_registry.new_receiver(channel_name) for channel_name in map( lambda req: req.get_channel_name(), subscription_requests ) } ) async for channel_name, msg in sample_receiver: print(msg) asyncio.run(run()) ``` \"\"\" self . _channel_registry = channel_registry self . _subscription_sender = subscription_sender self . _subscription_receiver = subscription_receiver self . _resampling_period_s = resampling_period_s self . _max_data_age_in_periods : float = max_data_age_in_periods self . _resampling_function : ResamplingFunction = resampling_function self . _resampler = GroupResampler ( resampling_period_s = resampling_period_s , max_data_age_in_periods = max_data_age_in_periods , initial_resampling_function = resampling_function , ) self . _input_receivers : Dict [ str , Receiver [ Sample ]] = {} self . _output_senders : Dict [ str , Sender [ Sample ]] = {} self . _resampling_timer = Timer ( interval = self . _resampling_period_s ) async def subscribe ( self , request : ComponentMetricRequest ) -> None : \"\"\"Subscribe for data for a specific time series. Args: request: subscription request for a specific component metric \"\"\" channel_name = request . get_channel_name () data_source_request = dataclasses . replace ( request , ** dict ( namespace = \"Source\" )) data_source_channel_name = data_source_request . get_channel_name () if channel_name not in self . _input_receivers : await self . _subscription_sender . send ( data_source_request ) receiver : Receiver [ Sample ] = self . _channel_registry . new_receiver ( data_source_channel_name ) self . _input_receivers [ data_source_channel_name ] = receiver self . _resampler . add_time_series ( time_series_id = data_source_channel_name ) if channel_name not in self . _output_senders : sender : Sender [ Sample ] = self . _channel_registry . new_sender ( channel_name ) # This means that the `sender` will be sending samples to the channel with # name `channel_name` based on samples collected from the channel named # `data_source_channel_name` self . _output_senders [ data_source_channel_name ] = sender def is_sample_valid ( self , sample : Sample ) -> bool : \"\"\"Check if the provided sample is valid. Args: sample: sample to be validated Returns: True if the sample is valid, False otherwise \"\"\" if sample . value is None or math . isnan ( sample . value ): return False return True async def run ( self ) -> None : \"\"\"Run the actor. Raises: ConnectionError: When the provider of the subscription channel closes the connection \"\"\" while True : select = Select ( resampling_timer = self . _resampling_timer , subscription_receiver = self . _subscription_receiver , component_data_receiver = MergeNamed ( ** self . _input_receivers ), ) while await select . ready (): if msg := select . resampling_timer : assert msg . inner is not None , \"The timer should never be 'closed'\" timestamp = msg . inner awaitables = [ self . _output_senders [ channel_name ] . send ( sample ) for channel_name , sample in self . _resampler . resample ( timestamp ) ] await asyncio . gather ( * awaitables ) if msg := select . component_data_receiver : if msg . inner is None : # When this happens, then DataSourcingActor has closed the channel # for sending data for a specific `ComponentMetricRequest`, # which may need to be handled properly here, e.g. unsubscribe continue channel_name , sample = msg . inner if self . is_sample_valid ( sample = sample ): self . _resampler . add_sample ( time_series_id = channel_name , sample = sample , ) if msg := select . subscription_receiver : if msg . inner is None : raise ConnectionError ( \"Subscription channel connection has been closed!\" ) await self . subscribe ( request = msg . inner ) # Breaking out from the loop is required to regenerate # component_data_receivers to be able to fulfil this # subscription (later can be optimized by checking if # an output channel already existed in the `subscribe()` method) break","title":"ComponentMetricsResamplingActor"},{"location":"reference/frequenz/sdk/actor/resampling/#frequenz.sdk.actor.resampling.ComponentMetricsResamplingActor-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/actor/resampling/#frequenz.sdk.actor.resampling.ComponentMetricsResamplingActor.__init__","text":"Initialize the ComponentMetricsResamplingActor. PARAMETER DESCRIPTION channel_registry global channel registry used for receiving component data from DataSource and for sending resampled samples downstream TYPE: ChannelRegistry subscription_sender channel for sending component metric requests to the DataSourcing actor TYPE: Sender [ ComponentMetricRequest ] subscription_receiver channel for receiving component metric requests TYPE: Receiver [ ComponentMetricRequest ] resampling_period_s value describing how often resampling should be performed, in seconds TYPE: float DEFAULT: 0.2 max_data_age_in_periods max age that samples shouldn't exceed in order to be used in the resampling function TYPE: float DEFAULT: 3.0 resampling_function function to be applied to a sequence of samples within a resampling period to produce a single output sample TYPE: ResamplingFunction DEFAULT: average Example async def run () -> None : await microgrid_api . initialize ( HOST , PORT ) channel_registry = ChannelRegistry ( name = \"Microgrid Channel Registry\" ) data_source_request_channel = Broadcast [ ComponentMetricRequest ]( \"Data Source Request Channel\" ) data_source_request_sender = data_source_request_channel . new_sender () data_source_request_receiver = data_source_request_channel . new_receiver () resampling_actor_request_channel = Broadcast [ ComponentMetricRequest ]( \"Resampling Actor Request Channel\" ) resampling_actor_request_sender = resampling_actor_request_channel . new_sender () resampling_actor_request_receiver = resampling_actor_request_channel . new_receiver () _data_sourcing_actor = DataSourcingActor ( request_receiver = data_source_request_receiver , registry = channel_registry ) _resampling_actor = ComponentMetricsResamplingActor ( channel_registry = channel_registry , subscription_sender = data_source_request_sender , subscription_receiver = resampling_actor_request_receiver , resampling_period_s = 1.0 , ) components = await microgrid_api . get () . microgrid_api_client . components () battery_ids = [ comp . component_id for comp in components if comp . category == ComponentCategory . BATTERY ] subscription_requests = [ ComponentMetricRequest ( namespace = \"Resampling\" , component_id = component_id , metric_id = ComponentMetricId . SOC , start_time = None , ) for component_id in battery_ids ] await asyncio . gather ( * [ resampling_actor_request_sender . send ( request ) for request in subscription_requests ] ) sample_receiver = MergeNamed ( ** { channel_name : channel_registry . new_receiver ( channel_name ) for channel_name in map ( lambda req : req . get_channel_name (), subscription_requests ) } ) async for channel_name , msg in sample_receiver : print ( msg ) asyncio . run ( run ()) Source code in frequenz/sdk/actor/resampling.py 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 def __init__ ( # pylint: disable=too-many-arguments self , channel_registry : ChannelRegistry , subscription_sender : Sender [ ComponentMetricRequest ], subscription_receiver : Receiver [ ComponentMetricRequest ], resampling_period_s : float = 0.2 , max_data_age_in_periods : float = 3.0 , resampling_function : ResamplingFunction = average , ) -> None : \"\"\"Initialize the ComponentMetricsResamplingActor. Args: channel_registry: global channel registry used for receiving component data from DataSource and for sending resampled samples downstream subscription_sender: channel for sending component metric requests to the DataSourcing actor subscription_receiver: channel for receiving component metric requests resampling_period_s: value describing how often resampling should be performed, in seconds max_data_age_in_periods: max age that samples shouldn't exceed in order to be used in the resampling function resampling_function: function to be applied to a sequence of samples within a resampling period to produce a single output sample Example: ```python async def run() -> None: await microgrid_api.initialize(HOST, PORT) channel_registry = ChannelRegistry(name=\"Microgrid Channel Registry\") data_source_request_channel = Broadcast[ComponentMetricRequest]( \"Data Source Request Channel\" ) data_source_request_sender = data_source_request_channel.new_sender() data_source_request_receiver = data_source_request_channel.new_receiver() resampling_actor_request_channel = Broadcast[ComponentMetricRequest]( \"Resampling Actor Request Channel\" ) resampling_actor_request_sender = resampling_actor_request_channel.new_sender() resampling_actor_request_receiver = resampling_actor_request_channel.new_receiver() _data_sourcing_actor = DataSourcingActor( request_receiver=data_source_request_receiver, registry=channel_registry ) _resampling_actor = ComponentMetricsResamplingActor( channel_registry=channel_registry, subscription_sender=data_source_request_sender, subscription_receiver=resampling_actor_request_receiver, resampling_period_s=1.0, ) components = await microgrid_api.get().microgrid_api_client.components() battery_ids = [ comp.component_id for comp in components if comp.category == ComponentCategory.BATTERY ] subscription_requests = [ ComponentMetricRequest( namespace=\"Resampling\", component_id=component_id, metric_id=ComponentMetricId.SOC, start_time=None, ) for component_id in battery_ids ] await asyncio.gather( *[ resampling_actor_request_sender.send(request) for request in subscription_requests ] ) sample_receiver = MergeNamed( **{ channel_name: channel_registry.new_receiver(channel_name) for channel_name in map( lambda req: req.get_channel_name(), subscription_requests ) } ) async for channel_name, msg in sample_receiver: print(msg) asyncio.run(run()) ``` \"\"\" self . _channel_registry = channel_registry self . _subscription_sender = subscription_sender self . _subscription_receiver = subscription_receiver self . _resampling_period_s = resampling_period_s self . _max_data_age_in_periods : float = max_data_age_in_periods self . _resampling_function : ResamplingFunction = resampling_function self . _resampler = GroupResampler ( resampling_period_s = resampling_period_s , max_data_age_in_periods = max_data_age_in_periods , initial_resampling_function = resampling_function , ) self . _input_receivers : Dict [ str , Receiver [ Sample ]] = {} self . _output_senders : Dict [ str , Sender [ Sample ]] = {} self . _resampling_timer = Timer ( interval = self . _resampling_period_s )","title":"__init__()"},{"location":"reference/frequenz/sdk/actor/resampling/#frequenz.sdk.actor.resampling.ComponentMetricsResamplingActor.is_sample_valid","text":"Check if the provided sample is valid. PARAMETER DESCRIPTION sample sample to be validated TYPE: Sample RETURNS DESCRIPTION bool True if the sample is valid, False otherwise Source code in frequenz/sdk/actor/resampling.py 185 186 187 188 189 190 191 192 193 194 195 196 def is_sample_valid ( self , sample : Sample ) -> bool : \"\"\"Check if the provided sample is valid. Args: sample: sample to be validated Returns: True if the sample is valid, False otherwise \"\"\" if sample . value is None or math . isnan ( sample . value ): return False return True","title":"is_sample_valid()"},{"location":"reference/frequenz/sdk/actor/resampling/#frequenz.sdk.actor.resampling.ComponentMetricsResamplingActor.run","text":"Run the actor. RAISES DESCRIPTION ConnectionError When the provider of the subscription channel closes the connection Source code in frequenz/sdk/actor/resampling.py 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 async def run ( self ) -> None : \"\"\"Run the actor. Raises: ConnectionError: When the provider of the subscription channel closes the connection \"\"\" while True : select = Select ( resampling_timer = self . _resampling_timer , subscription_receiver = self . _subscription_receiver , component_data_receiver = MergeNamed ( ** self . _input_receivers ), ) while await select . ready (): if msg := select . resampling_timer : assert msg . inner is not None , \"The timer should never be 'closed'\" timestamp = msg . inner awaitables = [ self . _output_senders [ channel_name ] . send ( sample ) for channel_name , sample in self . _resampler . resample ( timestamp ) ] await asyncio . gather ( * awaitables ) if msg := select . component_data_receiver : if msg . inner is None : # When this happens, then DataSourcingActor has closed the channel # for sending data for a specific `ComponentMetricRequest`, # which may need to be handled properly here, e.g. unsubscribe continue channel_name , sample = msg . inner if self . is_sample_valid ( sample = sample ): self . _resampler . add_sample ( time_series_id = channel_name , sample = sample , ) if msg := select . subscription_receiver : if msg . inner is None : raise ConnectionError ( \"Subscription channel connection has been closed!\" ) await self . subscribe ( request = msg . inner ) # Breaking out from the loop is required to regenerate # component_data_receivers to be able to fulfil this # subscription (later can be optimized by checking if # an output channel already existed in the `subscribe()` method) break","title":"run()"},{"location":"reference/frequenz/sdk/actor/resampling/#frequenz.sdk.actor.resampling.ComponentMetricsResamplingActor.subscribe","text":"Subscribe for data for a specific time series. PARAMETER DESCRIPTION request subscription request for a specific component metric TYPE: ComponentMetricRequest Source code in frequenz/sdk/actor/resampling.py 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 async def subscribe ( self , request : ComponentMetricRequest ) -> None : \"\"\"Subscribe for data for a specific time series. Args: request: subscription request for a specific component metric \"\"\" channel_name = request . get_channel_name () data_source_request = dataclasses . replace ( request , ** dict ( namespace = \"Source\" )) data_source_channel_name = data_source_request . get_channel_name () if channel_name not in self . _input_receivers : await self . _subscription_sender . send ( data_source_request ) receiver : Receiver [ Sample ] = self . _channel_registry . new_receiver ( data_source_channel_name ) self . _input_receivers [ data_source_channel_name ] = receiver self . _resampler . add_time_series ( time_series_id = data_source_channel_name ) if channel_name not in self . _output_senders : sender : Sender [ Sample ] = self . _channel_registry . new_sender ( channel_name ) # This means that the `sender` will be sending samples to the channel with # name `channel_name` based on samples collected from the channel named # `data_source_channel_name` self . _output_senders [ data_source_channel_name ] = sender","title":"subscribe()"},{"location":"reference/frequenz/sdk/actor/resampling/#frequenz.sdk.actor.resampling-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/actor/resampling/#frequenz.sdk.actor.resampling.average","text":"Calculate average of the provided values. PARAMETER DESCRIPTION samples sequences of samples to apply the average to. It must be non-empty. TYPE: Sequence [ Sample ] resampling_period_s value describing how often resampling should be performed, in seconds TYPE: float RETURNS DESCRIPTION float average of all the sample values Source code in frequenz/sdk/actor/resampling.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 def average ( samples : Sequence [ Sample ], resampling_period_s : float ) -> float : \"\"\"Calculate average of the provided values. Args: samples: sequences of samples to apply the average to. It must be non-empty. resampling_period_s: value describing how often resampling should be performed, in seconds Returns: average of all the sample values \"\"\" assert len ( samples ) > 0 , \"Average cannot be given an empty list of samples\" values = list ( sample . value for sample in samples if sample . value is not None ) return sum ( values ) / len ( values )","title":"average()"},{"location":"reference/frequenz/sdk/actor/data_sourcing/","text":"frequenz.sdk.actor.data_sourcing \u00a4 The DataSourcingActor. Classes \u00a4 frequenz.sdk.actor.data_sourcing.ComponentMetricId \u00a4 Bases: Enum An enum representing the various metrics available in the data pipeline. Source code in frequenz/sdk/actor/data_sourcing/types.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 class ComponentMetricId ( Enum ): \"\"\"An enum representing the various metrics available in the data pipeline.\"\"\" ACTIVE_POWER = \"active_power\" CURRENT_PHASE_1 = \"current_phase_1\" CURRENT_PHASE_2 = \"current_phase_2\" CURRENT_PHASE_3 = \"current_phase_3\" VOLTAGE_PHASE_1 = \"voltage_phase_1\" VOLTAGE_PHASE_2 = \"voltage_phase_2\" VOLTAGE_PHASE_3 = \"voltage_phase_3\" SOC = \"soc\" SOC_LOWER_BOUND = \"soc_lower_bound\" SOC_UPPER_BOUND = \"soc_upper_bound\" CAPACITY = \"capacity\" POWER_LOWER_BOUND = \"power_lower_bound\" POWER_UPPER_BOUND = \"power_upper_bound\" ACTIVE_POWER_LOWER_BOUND = \"active_power_lower_bound\" ACTIVE_POWER_UPPER_BOUND = \"active_power_upper_bound\" frequenz.sdk.actor.data_sourcing.ComponentMetricRequest dataclass \u00a4 A request object to start streaming a metric for a component. Source code in frequenz/sdk/actor/data_sourcing/types.py 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 @dataclass class ComponentMetricRequest : \"\"\"A request object to start streaming a metric for a component.\"\"\" # A namespace that this request belongs to. Metric requests with a shared # namespace enable the reuse of channels within that namespace. # # If for example, an actor making a multiple requests, uses the name of the # actor as the namespace, then requests from the actor will get reused when # possible. namespace : str # Id of the requested component component_id : int # `metric_name` would be attribute names on BatteryData, etc. Example # value: `soc`, `current_phase_1`, etc. For individual phase current and # voltage values, we need to add additional attributes to `MeterData` and # `EVChargerData`. metric_id : ComponentMetricId # The start time from which data is required. When None, we will stream # only live data. start_time : Optional [ datetime ] def get_channel_name ( self ) -> str : \"\"\"Return a channel name constructed from Self. This channel name can be used by the sending side and receiving sides to identify the right channel from the ChannelRegistry. Returns: A string denoting a channel name. \"\"\" return f \" { self . component_id } :: { self . metric_id . name } :: { self . start_time } :: { self . namespace } \" Functions \u00a4 get_channel_name () \u00a4 Return a channel name constructed from Self. This channel name can be used by the sending side and receiving sides to identify the right channel from the ChannelRegistry. RETURNS DESCRIPTION str A string denoting a channel name. Source code in frequenz/sdk/actor/data_sourcing/types.py 62 63 64 65 66 67 68 69 70 71 def get_channel_name ( self ) -> str : \"\"\"Return a channel name constructed from Self. This channel name can be used by the sending side and receiving sides to identify the right channel from the ChannelRegistry. Returns: A string denoting a channel name. \"\"\" return f \" { self . component_id } :: { self . metric_id . name } :: { self . start_time } :: { self . namespace } \" frequenz.sdk.actor.data_sourcing.DataSourcingActor \u00a4 An actor that provides data streams of metrics as time series. Source code in frequenz/sdk/actor/data_sourcing/data_sourcing.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 @actor class DataSourcingActor : \"\"\"An actor that provides data streams of metrics as time series.\"\"\" def __init__ ( self , request_receiver : Receiver [ ComponentMetricRequest ], registry : ChannelRegistry , ) -> None : \"\"\"Create a `DataSourcingActor` instance. Args: request_receiver: A channel receiver to accept metric requests from. registry: A channel registry. To be replaced by a singleton instance. \"\"\" self . _request_receiver = request_receiver self . _microgrid_api_source = MicrogridApiSource ( registry ) async def run ( self ) -> None : \"\"\"Run the actor.\"\"\" async for request in self . _request_receiver : await self . _microgrid_api_source . add_metric ( request ) Functions \u00a4 __init__ ( request_receiver , registry ) \u00a4 Create a DataSourcingActor instance. PARAMETER DESCRIPTION request_receiver A channel receiver to accept metric requests from. TYPE: Receiver [ ComponentMetricRequest ] registry A channel registry. To be replaced by a singleton instance. TYPE: ChannelRegistry Source code in frequenz/sdk/actor/data_sourcing/data_sourcing.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 def __init__ ( self , request_receiver : Receiver [ ComponentMetricRequest ], registry : ChannelRegistry , ) -> None : \"\"\"Create a `DataSourcingActor` instance. Args: request_receiver: A channel receiver to accept metric requests from. registry: A channel registry. To be replaced by a singleton instance. \"\"\" self . _request_receiver = request_receiver self . _microgrid_api_source = MicrogridApiSource ( registry ) run () async \u00a4 Run the actor. Source code in frequenz/sdk/actor/data_sourcing/data_sourcing.py 32 33 34 35 async def run ( self ) -> None : \"\"\"Run the actor.\"\"\" async for request in self . _request_receiver : await self . _microgrid_api_source . add_metric ( request )","title":"data_sourcing"},{"location":"reference/frequenz/sdk/actor/data_sourcing/#frequenz.sdk.actor.data_sourcing","text":"The DataSourcingActor.","title":"data_sourcing"},{"location":"reference/frequenz/sdk/actor/data_sourcing/#frequenz.sdk.actor.data_sourcing-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/actor/data_sourcing/#frequenz.sdk.actor.data_sourcing.ComponentMetricId","text":"Bases: Enum An enum representing the various metrics available in the data pipeline. Source code in frequenz/sdk/actor/data_sourcing/types.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 class ComponentMetricId ( Enum ): \"\"\"An enum representing the various metrics available in the data pipeline.\"\"\" ACTIVE_POWER = \"active_power\" CURRENT_PHASE_1 = \"current_phase_1\" CURRENT_PHASE_2 = \"current_phase_2\" CURRENT_PHASE_3 = \"current_phase_3\" VOLTAGE_PHASE_1 = \"voltage_phase_1\" VOLTAGE_PHASE_2 = \"voltage_phase_2\" VOLTAGE_PHASE_3 = \"voltage_phase_3\" SOC = \"soc\" SOC_LOWER_BOUND = \"soc_lower_bound\" SOC_UPPER_BOUND = \"soc_upper_bound\" CAPACITY = \"capacity\" POWER_LOWER_BOUND = \"power_lower_bound\" POWER_UPPER_BOUND = \"power_upper_bound\" ACTIVE_POWER_LOWER_BOUND = \"active_power_lower_bound\" ACTIVE_POWER_UPPER_BOUND = \"active_power_upper_bound\"","title":"ComponentMetricId"},{"location":"reference/frequenz/sdk/actor/data_sourcing/#frequenz.sdk.actor.data_sourcing.ComponentMetricRequest","text":"A request object to start streaming a metric for a component. Source code in frequenz/sdk/actor/data_sourcing/types.py 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 @dataclass class ComponentMetricRequest : \"\"\"A request object to start streaming a metric for a component.\"\"\" # A namespace that this request belongs to. Metric requests with a shared # namespace enable the reuse of channels within that namespace. # # If for example, an actor making a multiple requests, uses the name of the # actor as the namespace, then requests from the actor will get reused when # possible. namespace : str # Id of the requested component component_id : int # `metric_name` would be attribute names on BatteryData, etc. Example # value: `soc`, `current_phase_1`, etc. For individual phase current and # voltage values, we need to add additional attributes to `MeterData` and # `EVChargerData`. metric_id : ComponentMetricId # The start time from which data is required. When None, we will stream # only live data. start_time : Optional [ datetime ] def get_channel_name ( self ) -> str : \"\"\"Return a channel name constructed from Self. This channel name can be used by the sending side and receiving sides to identify the right channel from the ChannelRegistry. Returns: A string denoting a channel name. \"\"\" return f \" { self . component_id } :: { self . metric_id . name } :: { self . start_time } :: { self . namespace } \"","title":"ComponentMetricRequest"},{"location":"reference/frequenz/sdk/actor/data_sourcing/#frequenz.sdk.actor.data_sourcing.ComponentMetricRequest-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/actor/data_sourcing/#frequenz.sdk.actor.data_sourcing.types.ComponentMetricRequest.get_channel_name","text":"Return a channel name constructed from Self. This channel name can be used by the sending side and receiving sides to identify the right channel from the ChannelRegistry. RETURNS DESCRIPTION str A string denoting a channel name. Source code in frequenz/sdk/actor/data_sourcing/types.py 62 63 64 65 66 67 68 69 70 71 def get_channel_name ( self ) -> str : \"\"\"Return a channel name constructed from Self. This channel name can be used by the sending side and receiving sides to identify the right channel from the ChannelRegistry. Returns: A string denoting a channel name. \"\"\" return f \" { self . component_id } :: { self . metric_id . name } :: { self . start_time } :: { self . namespace } \"","title":"get_channel_name()"},{"location":"reference/frequenz/sdk/actor/data_sourcing/#frequenz.sdk.actor.data_sourcing.DataSourcingActor","text":"An actor that provides data streams of metrics as time series. Source code in frequenz/sdk/actor/data_sourcing/data_sourcing.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 @actor class DataSourcingActor : \"\"\"An actor that provides data streams of metrics as time series.\"\"\" def __init__ ( self , request_receiver : Receiver [ ComponentMetricRequest ], registry : ChannelRegistry , ) -> None : \"\"\"Create a `DataSourcingActor` instance. Args: request_receiver: A channel receiver to accept metric requests from. registry: A channel registry. To be replaced by a singleton instance. \"\"\" self . _request_receiver = request_receiver self . _microgrid_api_source = MicrogridApiSource ( registry ) async def run ( self ) -> None : \"\"\"Run the actor.\"\"\" async for request in self . _request_receiver : await self . _microgrid_api_source . add_metric ( request )","title":"DataSourcingActor"},{"location":"reference/frequenz/sdk/actor/data_sourcing/#frequenz.sdk.actor.data_sourcing.DataSourcingActor-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/actor/data_sourcing/#frequenz.sdk.actor.data_sourcing.data_sourcing.DataSourcingActor.__init__","text":"Create a DataSourcingActor instance. PARAMETER DESCRIPTION request_receiver A channel receiver to accept metric requests from. TYPE: Receiver [ ComponentMetricRequest ] registry A channel registry. To be replaced by a singleton instance. TYPE: ChannelRegistry Source code in frequenz/sdk/actor/data_sourcing/data_sourcing.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 def __init__ ( self , request_receiver : Receiver [ ComponentMetricRequest ], registry : ChannelRegistry , ) -> None : \"\"\"Create a `DataSourcingActor` instance. Args: request_receiver: A channel receiver to accept metric requests from. registry: A channel registry. To be replaced by a singleton instance. \"\"\" self . _request_receiver = request_receiver self . _microgrid_api_source = MicrogridApiSource ( registry )","title":"__init__()"},{"location":"reference/frequenz/sdk/actor/data_sourcing/#frequenz.sdk.actor.data_sourcing.data_sourcing.DataSourcingActor.run","text":"Run the actor. Source code in frequenz/sdk/actor/data_sourcing/data_sourcing.py 32 33 34 35 async def run ( self ) -> None : \"\"\"Run the actor.\"\"\" async for request in self . _request_receiver : await self . _microgrid_api_source . add_metric ( request )","title":"run()"},{"location":"reference/frequenz/sdk/actor/data_sourcing/data_sourcing/","text":"frequenz.sdk.actor.data_sourcing.data_sourcing \u00a4 The DataSourcing Actor. Classes \u00a4 frequenz.sdk.actor.data_sourcing.data_sourcing.DataSourcingActor \u00a4 An actor that provides data streams of metrics as time series. Source code in frequenz/sdk/actor/data_sourcing/data_sourcing.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 @actor class DataSourcingActor : \"\"\"An actor that provides data streams of metrics as time series.\"\"\" def __init__ ( self , request_receiver : Receiver [ ComponentMetricRequest ], registry : ChannelRegistry , ) -> None : \"\"\"Create a `DataSourcingActor` instance. Args: request_receiver: A channel receiver to accept metric requests from. registry: A channel registry. To be replaced by a singleton instance. \"\"\" self . _request_receiver = request_receiver self . _microgrid_api_source = MicrogridApiSource ( registry ) async def run ( self ) -> None : \"\"\"Run the actor.\"\"\" async for request in self . _request_receiver : await self . _microgrid_api_source . add_metric ( request ) Functions \u00a4 __init__ ( request_receiver , registry ) \u00a4 Create a DataSourcingActor instance. PARAMETER DESCRIPTION request_receiver A channel receiver to accept metric requests from. TYPE: Receiver [ ComponentMetricRequest ] registry A channel registry. To be replaced by a singleton instance. TYPE: ChannelRegistry Source code in frequenz/sdk/actor/data_sourcing/data_sourcing.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 def __init__ ( self , request_receiver : Receiver [ ComponentMetricRequest ], registry : ChannelRegistry , ) -> None : \"\"\"Create a `DataSourcingActor` instance. Args: request_receiver: A channel receiver to accept metric requests from. registry: A channel registry. To be replaced by a singleton instance. \"\"\" self . _request_receiver = request_receiver self . _microgrid_api_source = MicrogridApiSource ( registry ) run () async \u00a4 Run the actor. Source code in frequenz/sdk/actor/data_sourcing/data_sourcing.py 32 33 34 35 async def run ( self ) -> None : \"\"\"Run the actor.\"\"\" async for request in self . _request_receiver : await self . _microgrid_api_source . add_metric ( request ) Functions \u00a4","title":"data_sourcing"},{"location":"reference/frequenz/sdk/actor/data_sourcing/data_sourcing/#frequenz.sdk.actor.data_sourcing.data_sourcing","text":"The DataSourcing Actor.","title":"data_sourcing"},{"location":"reference/frequenz/sdk/actor/data_sourcing/data_sourcing/#frequenz.sdk.actor.data_sourcing.data_sourcing-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/actor/data_sourcing/data_sourcing/#frequenz.sdk.actor.data_sourcing.data_sourcing.DataSourcingActor","text":"An actor that provides data streams of metrics as time series. Source code in frequenz/sdk/actor/data_sourcing/data_sourcing.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 @actor class DataSourcingActor : \"\"\"An actor that provides data streams of metrics as time series.\"\"\" def __init__ ( self , request_receiver : Receiver [ ComponentMetricRequest ], registry : ChannelRegistry , ) -> None : \"\"\"Create a `DataSourcingActor` instance. Args: request_receiver: A channel receiver to accept metric requests from. registry: A channel registry. To be replaced by a singleton instance. \"\"\" self . _request_receiver = request_receiver self . _microgrid_api_source = MicrogridApiSource ( registry ) async def run ( self ) -> None : \"\"\"Run the actor.\"\"\" async for request in self . _request_receiver : await self . _microgrid_api_source . add_metric ( request )","title":"DataSourcingActor"},{"location":"reference/frequenz/sdk/actor/data_sourcing/data_sourcing/#frequenz.sdk.actor.data_sourcing.data_sourcing.DataSourcingActor-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/actor/data_sourcing/data_sourcing/#frequenz.sdk.actor.data_sourcing.data_sourcing.DataSourcingActor.__init__","text":"Create a DataSourcingActor instance. PARAMETER DESCRIPTION request_receiver A channel receiver to accept metric requests from. TYPE: Receiver [ ComponentMetricRequest ] registry A channel registry. To be replaced by a singleton instance. TYPE: ChannelRegistry Source code in frequenz/sdk/actor/data_sourcing/data_sourcing.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 def __init__ ( self , request_receiver : Receiver [ ComponentMetricRequest ], registry : ChannelRegistry , ) -> None : \"\"\"Create a `DataSourcingActor` instance. Args: request_receiver: A channel receiver to accept metric requests from. registry: A channel registry. To be replaced by a singleton instance. \"\"\" self . _request_receiver = request_receiver self . _microgrid_api_source = MicrogridApiSource ( registry )","title":"__init__()"},{"location":"reference/frequenz/sdk/actor/data_sourcing/data_sourcing/#frequenz.sdk.actor.data_sourcing.data_sourcing.DataSourcingActor.run","text":"Run the actor. Source code in frequenz/sdk/actor/data_sourcing/data_sourcing.py 32 33 34 35 async def run ( self ) -> None : \"\"\"Run the actor.\"\"\" async for request in self . _request_receiver : await self . _microgrid_api_source . add_metric ( request )","title":"run()"},{"location":"reference/frequenz/sdk/actor/data_sourcing/data_sourcing/#frequenz.sdk.actor.data_sourcing.data_sourcing-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/actor/data_sourcing/microgrid_api_source/","text":"frequenz.sdk.actor.data_sourcing.microgrid_api_source \u00a4 The Microgrid API data source for the DataSourcingActor. Classes \u00a4 frequenz.sdk.actor.data_sourcing.microgrid_api_source.MicrogridApiSource \u00a4 Fetches requested metrics from the Microgrid API. Used by the DataSourcingActor. Source code in frequenz/sdk/actor/data_sourcing/microgrid_api_source.py 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 class MicrogridApiSource : \"\"\"Fetches requested metrics from the Microgrid API. Used by the DataSourcingActor. \"\"\" def __init__ ( self , registry : ChannelRegistry , ) -> None : \"\"\"Create a `MicrogridApiSource` instance. Args: registry: A channel registry. To be replaced by a singleton instance. \"\"\" self . _comp_categories_cache : Dict [ int , ComponentCategory ] = {} self . comp_data_receivers : Dict [ int , Receiver [ Any ]] = {} self . comp_data_tasks : Dict [ int , asyncio . Task [ None ]] = {} self . _registry = registry self . _req_streaming_metrics : Dict [ int , Dict [ ComponentMetricId , List [ ComponentMetricRequest ]] ] = {} async def _get_component_category ( self , comp_id : int ) -> Optional [ ComponentCategory ]: \"\"\"Get the component category of the given component. Args: comp_id: Id of the requested component. Returns: The category of the given component, if it is a valid component, or None otherwise. \"\"\" if comp_id in self . _comp_categories_cache : return self . _comp_categories_cache [ comp_id ] api = microgrid_api . get () . microgrid_api_client for comp in await api . components (): self . _comp_categories_cache [ comp . component_id ] = comp . category if comp_id in self . _comp_categories_cache : return self . _comp_categories_cache [ comp_id ] return None async def _check_battery_request ( self , comp_id : int , requests : Dict [ ComponentMetricId , List [ ComponentMetricRequest ]], ) -> None : \"\"\"Check if the requests are valid Battery metrics. Raises: ValueError: if the requested metric is not available for batteries. Args: comp_id: The id of the requested component. requests: A list of metric requests received from external actors for the given battery. \"\"\" for metric in requests : if metric not in _BatteryDataMethods : raise ValueError ( f \"Unknown metric { metric } for Battery id { comp_id } \" ) if comp_id not in self . comp_data_receivers : self . comp_data_receivers [ comp_id ] = await microgrid_api . get () . microgrid_api_client . battery_data ( comp_id ) async def _check_ev_charger_request ( self , comp_id : int , requests : Dict [ ComponentMetricId , List [ ComponentMetricRequest ]], ) -> None : \"\"\"Check if the requests are valid EV Charger metrics. Raises: ValueError: if the requested metric is not available for ev charger. Args: comp_id: The id of the requested component. requests: A list of metric requests received from external actors for the given EV Charger. \"\"\" for metric in requests : if metric not in _EVChargerDataMethods : raise ValueError ( f \"Unknown metric { metric } for EvCharger id { comp_id } \" ) if comp_id not in self . comp_data_receivers : self . comp_data_receivers [ comp_id ] = await microgrid_api . get () . microgrid_api_client . ev_charger_data ( comp_id ) async def _check_inverter_request ( self , comp_id : int , requests : Dict [ ComponentMetricId , List [ ComponentMetricRequest ]], ) -> None : \"\"\"Check if the requests are valid Inverter metrics. Raises: ValueError: if the requested metric is not available for inverters. Args: comp_id: The id of the requested component. requests: A list of metric requests received from external actors for the given inverter. \"\"\" for metric in requests : if metric not in _InverterDataMethods : raise ValueError ( f \"Unknown metric { metric } for Inverter id { comp_id } \" ) if comp_id not in self . comp_data_receivers : self . comp_data_receivers [ comp_id ] = await microgrid_api . get () . microgrid_api_client . inverter_data ( comp_id ) async def _check_meter_request ( self , comp_id : int , requests : Dict [ ComponentMetricId , List [ ComponentMetricRequest ]], ) -> None : \"\"\"Check if the requests are valid Meter metrics. Raises: ValueError: if the requested metric is not available for meters. Args: comp_id: The id of the requested component. requests: A list of metric requests received from external actors for the given meter. \"\"\" for metric in requests : if metric not in _MeterDataMethods : raise ValueError ( f \"Unknown metric { metric } for Meter id { comp_id } \" ) if comp_id not in self . comp_data_receivers : self . comp_data_receivers [ comp_id ] = await microgrid_api . get () . microgrid_api_client . meter_data ( comp_id ) async def _check_requested_component_and_metrics ( self , comp_id : int , category : ComponentCategory , requests : Dict [ ComponentMetricId , List [ ComponentMetricRequest ]], ) -> None : \"\"\"Check if the requested component and metrics are valid. Raises: ValueError: if the category is unknown or if the requested metric is unavailable to the given category. Args: comp_id: The id of the requested component. category: The category of the requested component. requests: A list of metric requests received from external actors for the given component. \"\"\" if comp_id in self . comp_data_receivers : return if category == ComponentCategory . BATTERY : await self . _check_battery_request ( comp_id , requests ) elif category == ComponentCategory . EV_CHARGER : await self . _check_ev_charger_request ( comp_id , requests ) elif category == ComponentCategory . INVERTER : await self . _check_inverter_request ( comp_id , requests ) elif category == ComponentCategory . METER : await self . _check_meter_request ( comp_id , requests ) else : raise ValueError ( f \"Unknown component category { category } \" ) def _get_data_extraction_method ( self , category : ComponentCategory , metric : ComponentMetricId ) -> Callable [[ Any ], float ]: \"\"\"Get the data extraction method for the given metric. Raises: ValueError: if the category is unknown. Args: category: The category of the component. metric: The metric for which we need an extraction method. Returns: A method that accepts a `ComponentData` object and returns a float representing the given metric. \"\"\" if category == ComponentCategory . BATTERY : return _BatteryDataMethods [ metric ] if category == ComponentCategory . INVERTER : return _InverterDataMethods [ metric ] if category == ComponentCategory . METER : return _MeterDataMethods [ metric ] if category == ComponentCategory . EV_CHARGER : return _EVChargerDataMethods [ metric ] raise ValueError ( f \"Unknown component category { category } \" ) def _get_metric_senders ( self , category : ComponentCategory , requests : Dict [ ComponentMetricId , List [ ComponentMetricRequest ]], ) -> List [ Tuple [ Callable [[ Any ], float ], List [ Sender [ Sample ]]]]: \"\"\"Get channel senders from the channel registry for each requested metric. Args: category: The category of the component. requests: A list of metric requests received from external actors for a certain component. Returns: A dictionary of output metric names to channel senders from the channel registry. \"\"\" return [ ( self . _get_data_extraction_method ( category , metric ), [ self . _registry . new_sender ( request . get_channel_name ()) for request in reqlist ], ) for ( metric , reqlist ) in requests . items () ] async def _handle_data_stream ( self , comp_id : int , category : ComponentCategory , ) -> None : \"\"\"Stream component data and send the requested metrics out. Args: comp_id: Id of the requested component. category: The category of the component. \"\"\" stream_senders = [] if comp_id in self . _req_streaming_metrics : await self . _check_requested_component_and_metrics ( comp_id , category , self . _req_streaming_metrics [ comp_id ] ) stream_senders = self . _get_metric_senders ( category , self . _req_streaming_metrics [ comp_id ] ) api_data_receiver = self . comp_data_receivers [ comp_id ] def process_msg ( data : Any ) -> None : tasks = [] for ( extractor , senders ) in stream_senders : for sender in senders : tasks . append ( sender . send ( Sample ( data . timestamp , extractor ( data )))) asyncio . gather ( * tasks ) async for data in api_data_receiver : process_msg ( data ) async def _update_streams ( self , comp_id : int , category : ComponentCategory , ) -> None : \"\"\"Update the requested metric streams for the given component. Args: comp_id: Id of the requested component. category: Category of the requested component. \"\"\" if comp_id in self . comp_data_tasks : self . comp_data_tasks [ comp_id ] . cancel () self . comp_data_tasks [ comp_id ] = asyncio . create_task ( self . _handle_data_stream ( comp_id , category ) ) async def add_metric ( self , request : ComponentMetricRequest ) -> None : \"\"\"Add a metric to be streamed from the microgrid API. Args: request: A request object for a metric, received from a downstream actor. \"\"\" comp_id = request . component_id category = await self . _get_component_category ( comp_id ) if category is None : logging . error ( \"Unknown component ID: %d in request %s \" , comp_id , request ) return self . _req_streaming_metrics . setdefault ( comp_id , {}) . setdefault ( request . metric_id , [] ) for existing_request in self . _req_streaming_metrics [ comp_id ][ request . metric_id ]: if existing_request . get_channel_name () == request . get_channel_name (): # the requested metric is already being handled, so nothing to do. return self . _req_streaming_metrics [ comp_id ][ request . metric_id ] . append ( request ) await self . _update_streams ( comp_id , category , ) Functions \u00a4 __init__ ( registry ) \u00a4 Create a MicrogridApiSource instance. PARAMETER DESCRIPTION registry A channel registry. To be replaced by a singleton instance. TYPE: ChannelRegistry Source code in frequenz/sdk/actor/data_sourcing/microgrid_api_source.py 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 def __init__ ( self , registry : ChannelRegistry , ) -> None : \"\"\"Create a `MicrogridApiSource` instance. Args: registry: A channel registry. To be replaced by a singleton instance. \"\"\" self . _comp_categories_cache : Dict [ int , ComponentCategory ] = {} self . comp_data_receivers : Dict [ int , Receiver [ Any ]] = {} self . comp_data_tasks : Dict [ int , asyncio . Task [ None ]] = {} self . _registry = registry self . _req_streaming_metrics : Dict [ int , Dict [ ComponentMetricId , List [ ComponentMetricRequest ]] ] = {} add_metric ( request ) async \u00a4 Add a metric to be streamed from the microgrid API. PARAMETER DESCRIPTION request A request object for a metric, received from a downstream actor. TYPE: ComponentMetricRequest Source code in frequenz/sdk/actor/data_sourcing/microgrid_api_source.py 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 async def add_metric ( self , request : ComponentMetricRequest ) -> None : \"\"\"Add a metric to be streamed from the microgrid API. Args: request: A request object for a metric, received from a downstream actor. \"\"\" comp_id = request . component_id category = await self . _get_component_category ( comp_id ) if category is None : logging . error ( \"Unknown component ID: %d in request %s \" , comp_id , request ) return self . _req_streaming_metrics . setdefault ( comp_id , {}) . setdefault ( request . metric_id , [] ) for existing_request in self . _req_streaming_metrics [ comp_id ][ request . metric_id ]: if existing_request . get_channel_name () == request . get_channel_name (): # the requested metric is already being handled, so nothing to do. return self . _req_streaming_metrics [ comp_id ][ request . metric_id ] . append ( request ) await self . _update_streams ( comp_id , category , )","title":"microgrid_api_source"},{"location":"reference/frequenz/sdk/actor/data_sourcing/microgrid_api_source/#frequenz.sdk.actor.data_sourcing.microgrid_api_source","text":"The Microgrid API data source for the DataSourcingActor.","title":"microgrid_api_source"},{"location":"reference/frequenz/sdk/actor/data_sourcing/microgrid_api_source/#frequenz.sdk.actor.data_sourcing.microgrid_api_source-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/actor/data_sourcing/microgrid_api_source/#frequenz.sdk.actor.data_sourcing.microgrid_api_source.MicrogridApiSource","text":"Fetches requested metrics from the Microgrid API. Used by the DataSourcingActor. Source code in frequenz/sdk/actor/data_sourcing/microgrid_api_source.py 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 class MicrogridApiSource : \"\"\"Fetches requested metrics from the Microgrid API. Used by the DataSourcingActor. \"\"\" def __init__ ( self , registry : ChannelRegistry , ) -> None : \"\"\"Create a `MicrogridApiSource` instance. Args: registry: A channel registry. To be replaced by a singleton instance. \"\"\" self . _comp_categories_cache : Dict [ int , ComponentCategory ] = {} self . comp_data_receivers : Dict [ int , Receiver [ Any ]] = {} self . comp_data_tasks : Dict [ int , asyncio . Task [ None ]] = {} self . _registry = registry self . _req_streaming_metrics : Dict [ int , Dict [ ComponentMetricId , List [ ComponentMetricRequest ]] ] = {} async def _get_component_category ( self , comp_id : int ) -> Optional [ ComponentCategory ]: \"\"\"Get the component category of the given component. Args: comp_id: Id of the requested component. Returns: The category of the given component, if it is a valid component, or None otherwise. \"\"\" if comp_id in self . _comp_categories_cache : return self . _comp_categories_cache [ comp_id ] api = microgrid_api . get () . microgrid_api_client for comp in await api . components (): self . _comp_categories_cache [ comp . component_id ] = comp . category if comp_id in self . _comp_categories_cache : return self . _comp_categories_cache [ comp_id ] return None async def _check_battery_request ( self , comp_id : int , requests : Dict [ ComponentMetricId , List [ ComponentMetricRequest ]], ) -> None : \"\"\"Check if the requests are valid Battery metrics. Raises: ValueError: if the requested metric is not available for batteries. Args: comp_id: The id of the requested component. requests: A list of metric requests received from external actors for the given battery. \"\"\" for metric in requests : if metric not in _BatteryDataMethods : raise ValueError ( f \"Unknown metric { metric } for Battery id { comp_id } \" ) if comp_id not in self . comp_data_receivers : self . comp_data_receivers [ comp_id ] = await microgrid_api . get () . microgrid_api_client . battery_data ( comp_id ) async def _check_ev_charger_request ( self , comp_id : int , requests : Dict [ ComponentMetricId , List [ ComponentMetricRequest ]], ) -> None : \"\"\"Check if the requests are valid EV Charger metrics. Raises: ValueError: if the requested metric is not available for ev charger. Args: comp_id: The id of the requested component. requests: A list of metric requests received from external actors for the given EV Charger. \"\"\" for metric in requests : if metric not in _EVChargerDataMethods : raise ValueError ( f \"Unknown metric { metric } for EvCharger id { comp_id } \" ) if comp_id not in self . comp_data_receivers : self . comp_data_receivers [ comp_id ] = await microgrid_api . get () . microgrid_api_client . ev_charger_data ( comp_id ) async def _check_inverter_request ( self , comp_id : int , requests : Dict [ ComponentMetricId , List [ ComponentMetricRequest ]], ) -> None : \"\"\"Check if the requests are valid Inverter metrics. Raises: ValueError: if the requested metric is not available for inverters. Args: comp_id: The id of the requested component. requests: A list of metric requests received from external actors for the given inverter. \"\"\" for metric in requests : if metric not in _InverterDataMethods : raise ValueError ( f \"Unknown metric { metric } for Inverter id { comp_id } \" ) if comp_id not in self . comp_data_receivers : self . comp_data_receivers [ comp_id ] = await microgrid_api . get () . microgrid_api_client . inverter_data ( comp_id ) async def _check_meter_request ( self , comp_id : int , requests : Dict [ ComponentMetricId , List [ ComponentMetricRequest ]], ) -> None : \"\"\"Check if the requests are valid Meter metrics. Raises: ValueError: if the requested metric is not available for meters. Args: comp_id: The id of the requested component. requests: A list of metric requests received from external actors for the given meter. \"\"\" for metric in requests : if metric not in _MeterDataMethods : raise ValueError ( f \"Unknown metric { metric } for Meter id { comp_id } \" ) if comp_id not in self . comp_data_receivers : self . comp_data_receivers [ comp_id ] = await microgrid_api . get () . microgrid_api_client . meter_data ( comp_id ) async def _check_requested_component_and_metrics ( self , comp_id : int , category : ComponentCategory , requests : Dict [ ComponentMetricId , List [ ComponentMetricRequest ]], ) -> None : \"\"\"Check if the requested component and metrics are valid. Raises: ValueError: if the category is unknown or if the requested metric is unavailable to the given category. Args: comp_id: The id of the requested component. category: The category of the requested component. requests: A list of metric requests received from external actors for the given component. \"\"\" if comp_id in self . comp_data_receivers : return if category == ComponentCategory . BATTERY : await self . _check_battery_request ( comp_id , requests ) elif category == ComponentCategory . EV_CHARGER : await self . _check_ev_charger_request ( comp_id , requests ) elif category == ComponentCategory . INVERTER : await self . _check_inverter_request ( comp_id , requests ) elif category == ComponentCategory . METER : await self . _check_meter_request ( comp_id , requests ) else : raise ValueError ( f \"Unknown component category { category } \" ) def _get_data_extraction_method ( self , category : ComponentCategory , metric : ComponentMetricId ) -> Callable [[ Any ], float ]: \"\"\"Get the data extraction method for the given metric. Raises: ValueError: if the category is unknown. Args: category: The category of the component. metric: The metric for which we need an extraction method. Returns: A method that accepts a `ComponentData` object and returns a float representing the given metric. \"\"\" if category == ComponentCategory . BATTERY : return _BatteryDataMethods [ metric ] if category == ComponentCategory . INVERTER : return _InverterDataMethods [ metric ] if category == ComponentCategory . METER : return _MeterDataMethods [ metric ] if category == ComponentCategory . EV_CHARGER : return _EVChargerDataMethods [ metric ] raise ValueError ( f \"Unknown component category { category } \" ) def _get_metric_senders ( self , category : ComponentCategory , requests : Dict [ ComponentMetricId , List [ ComponentMetricRequest ]], ) -> List [ Tuple [ Callable [[ Any ], float ], List [ Sender [ Sample ]]]]: \"\"\"Get channel senders from the channel registry for each requested metric. Args: category: The category of the component. requests: A list of metric requests received from external actors for a certain component. Returns: A dictionary of output metric names to channel senders from the channel registry. \"\"\" return [ ( self . _get_data_extraction_method ( category , metric ), [ self . _registry . new_sender ( request . get_channel_name ()) for request in reqlist ], ) for ( metric , reqlist ) in requests . items () ] async def _handle_data_stream ( self , comp_id : int , category : ComponentCategory , ) -> None : \"\"\"Stream component data and send the requested metrics out. Args: comp_id: Id of the requested component. category: The category of the component. \"\"\" stream_senders = [] if comp_id in self . _req_streaming_metrics : await self . _check_requested_component_and_metrics ( comp_id , category , self . _req_streaming_metrics [ comp_id ] ) stream_senders = self . _get_metric_senders ( category , self . _req_streaming_metrics [ comp_id ] ) api_data_receiver = self . comp_data_receivers [ comp_id ] def process_msg ( data : Any ) -> None : tasks = [] for ( extractor , senders ) in stream_senders : for sender in senders : tasks . append ( sender . send ( Sample ( data . timestamp , extractor ( data )))) asyncio . gather ( * tasks ) async for data in api_data_receiver : process_msg ( data ) async def _update_streams ( self , comp_id : int , category : ComponentCategory , ) -> None : \"\"\"Update the requested metric streams for the given component. Args: comp_id: Id of the requested component. category: Category of the requested component. \"\"\" if comp_id in self . comp_data_tasks : self . comp_data_tasks [ comp_id ] . cancel () self . comp_data_tasks [ comp_id ] = asyncio . create_task ( self . _handle_data_stream ( comp_id , category ) ) async def add_metric ( self , request : ComponentMetricRequest ) -> None : \"\"\"Add a metric to be streamed from the microgrid API. Args: request: A request object for a metric, received from a downstream actor. \"\"\" comp_id = request . component_id category = await self . _get_component_category ( comp_id ) if category is None : logging . error ( \"Unknown component ID: %d in request %s \" , comp_id , request ) return self . _req_streaming_metrics . setdefault ( comp_id , {}) . setdefault ( request . metric_id , [] ) for existing_request in self . _req_streaming_metrics [ comp_id ][ request . metric_id ]: if existing_request . get_channel_name () == request . get_channel_name (): # the requested metric is already being handled, so nothing to do. return self . _req_streaming_metrics [ comp_id ][ request . metric_id ] . append ( request ) await self . _update_streams ( comp_id , category , )","title":"MicrogridApiSource"},{"location":"reference/frequenz/sdk/actor/data_sourcing/microgrid_api_source/#frequenz.sdk.actor.data_sourcing.microgrid_api_source.MicrogridApiSource-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/actor/data_sourcing/microgrid_api_source/#frequenz.sdk.actor.data_sourcing.microgrid_api_source.MicrogridApiSource.__init__","text":"Create a MicrogridApiSource instance. PARAMETER DESCRIPTION registry A channel registry. To be replaced by a singleton instance. TYPE: ChannelRegistry Source code in frequenz/sdk/actor/data_sourcing/microgrid_api_source.py 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 def __init__ ( self , registry : ChannelRegistry , ) -> None : \"\"\"Create a `MicrogridApiSource` instance. Args: registry: A channel registry. To be replaced by a singleton instance. \"\"\" self . _comp_categories_cache : Dict [ int , ComponentCategory ] = {} self . comp_data_receivers : Dict [ int , Receiver [ Any ]] = {} self . comp_data_tasks : Dict [ int , asyncio . Task [ None ]] = {} self . _registry = registry self . _req_streaming_metrics : Dict [ int , Dict [ ComponentMetricId , List [ ComponentMetricRequest ]] ] = {}","title":"__init__()"},{"location":"reference/frequenz/sdk/actor/data_sourcing/microgrid_api_source/#frequenz.sdk.actor.data_sourcing.microgrid_api_source.MicrogridApiSource.add_metric","text":"Add a metric to be streamed from the microgrid API. PARAMETER DESCRIPTION request A request object for a metric, received from a downstream actor. TYPE: ComponentMetricRequest Source code in frequenz/sdk/actor/data_sourcing/microgrid_api_source.py 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 async def add_metric ( self , request : ComponentMetricRequest ) -> None : \"\"\"Add a metric to be streamed from the microgrid API. Args: request: A request object for a metric, received from a downstream actor. \"\"\" comp_id = request . component_id category = await self . _get_component_category ( comp_id ) if category is None : logging . error ( \"Unknown component ID: %d in request %s \" , comp_id , request ) return self . _req_streaming_metrics . setdefault ( comp_id , {}) . setdefault ( request . metric_id , [] ) for existing_request in self . _req_streaming_metrics [ comp_id ][ request . metric_id ]: if existing_request . get_channel_name () == request . get_channel_name (): # the requested metric is already being handled, so nothing to do. return self . _req_streaming_metrics [ comp_id ][ request . metric_id ] . append ( request ) await self . _update_streams ( comp_id , category , )","title":"add_metric()"},{"location":"reference/frequenz/sdk/actor/data_sourcing/types/","text":"frequenz.sdk.actor.data_sourcing.types \u00a4 Common types for the Data Pipeline. Classes \u00a4 frequenz.sdk.actor.data_sourcing.types.ComponentMetricId \u00a4 Bases: Enum An enum representing the various metrics available in the data pipeline. Source code in frequenz/sdk/actor/data_sourcing/types.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 class ComponentMetricId ( Enum ): \"\"\"An enum representing the various metrics available in the data pipeline.\"\"\" ACTIVE_POWER = \"active_power\" CURRENT_PHASE_1 = \"current_phase_1\" CURRENT_PHASE_2 = \"current_phase_2\" CURRENT_PHASE_3 = \"current_phase_3\" VOLTAGE_PHASE_1 = \"voltage_phase_1\" VOLTAGE_PHASE_2 = \"voltage_phase_2\" VOLTAGE_PHASE_3 = \"voltage_phase_3\" SOC = \"soc\" SOC_LOWER_BOUND = \"soc_lower_bound\" SOC_UPPER_BOUND = \"soc_upper_bound\" CAPACITY = \"capacity\" POWER_LOWER_BOUND = \"power_lower_bound\" POWER_UPPER_BOUND = \"power_upper_bound\" ACTIVE_POWER_LOWER_BOUND = \"active_power_lower_bound\" ACTIVE_POWER_UPPER_BOUND = \"active_power_upper_bound\" frequenz.sdk.actor.data_sourcing.types.ComponentMetricRequest dataclass \u00a4 A request object to start streaming a metric for a component. Source code in frequenz/sdk/actor/data_sourcing/types.py 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 @dataclass class ComponentMetricRequest : \"\"\"A request object to start streaming a metric for a component.\"\"\" # A namespace that this request belongs to. Metric requests with a shared # namespace enable the reuse of channels within that namespace. # # If for example, an actor making a multiple requests, uses the name of the # actor as the namespace, then requests from the actor will get reused when # possible. namespace : str # Id of the requested component component_id : int # `metric_name` would be attribute names on BatteryData, etc. Example # value: `soc`, `current_phase_1`, etc. For individual phase current and # voltage values, we need to add additional attributes to `MeterData` and # `EVChargerData`. metric_id : ComponentMetricId # The start time from which data is required. When None, we will stream # only live data. start_time : Optional [ datetime ] def get_channel_name ( self ) -> str : \"\"\"Return a channel name constructed from Self. This channel name can be used by the sending side and receiving sides to identify the right channel from the ChannelRegistry. Returns: A string denoting a channel name. \"\"\" return f \" { self . component_id } :: { self . metric_id . name } :: { self . start_time } :: { self . namespace } \" Functions \u00a4 get_channel_name () \u00a4 Return a channel name constructed from Self. This channel name can be used by the sending side and receiving sides to identify the right channel from the ChannelRegistry. RETURNS DESCRIPTION str A string denoting a channel name. Source code in frequenz/sdk/actor/data_sourcing/types.py 62 63 64 65 66 67 68 69 70 71 def get_channel_name ( self ) -> str : \"\"\"Return a channel name constructed from Self. This channel name can be used by the sending side and receiving sides to identify the right channel from the ChannelRegistry. Returns: A string denoting a channel name. \"\"\" return f \" { self . component_id } :: { self . metric_id . name } :: { self . start_time } :: { self . namespace } \"","title":"types"},{"location":"reference/frequenz/sdk/actor/data_sourcing/types/#frequenz.sdk.actor.data_sourcing.types","text":"Common types for the Data Pipeline.","title":"types"},{"location":"reference/frequenz/sdk/actor/data_sourcing/types/#frequenz.sdk.actor.data_sourcing.types-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/actor/data_sourcing/types/#frequenz.sdk.actor.data_sourcing.types.ComponentMetricId","text":"Bases: Enum An enum representing the various metrics available in the data pipeline. Source code in frequenz/sdk/actor/data_sourcing/types.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 class ComponentMetricId ( Enum ): \"\"\"An enum representing the various metrics available in the data pipeline.\"\"\" ACTIVE_POWER = \"active_power\" CURRENT_PHASE_1 = \"current_phase_1\" CURRENT_PHASE_2 = \"current_phase_2\" CURRENT_PHASE_3 = \"current_phase_3\" VOLTAGE_PHASE_1 = \"voltage_phase_1\" VOLTAGE_PHASE_2 = \"voltage_phase_2\" VOLTAGE_PHASE_3 = \"voltage_phase_3\" SOC = \"soc\" SOC_LOWER_BOUND = \"soc_lower_bound\" SOC_UPPER_BOUND = \"soc_upper_bound\" CAPACITY = \"capacity\" POWER_LOWER_BOUND = \"power_lower_bound\" POWER_UPPER_BOUND = \"power_upper_bound\" ACTIVE_POWER_LOWER_BOUND = \"active_power_lower_bound\" ACTIVE_POWER_UPPER_BOUND = \"active_power_upper_bound\"","title":"ComponentMetricId"},{"location":"reference/frequenz/sdk/actor/data_sourcing/types/#frequenz.sdk.actor.data_sourcing.types.ComponentMetricRequest","text":"A request object to start streaming a metric for a component. Source code in frequenz/sdk/actor/data_sourcing/types.py 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 @dataclass class ComponentMetricRequest : \"\"\"A request object to start streaming a metric for a component.\"\"\" # A namespace that this request belongs to. Metric requests with a shared # namespace enable the reuse of channels within that namespace. # # If for example, an actor making a multiple requests, uses the name of the # actor as the namespace, then requests from the actor will get reused when # possible. namespace : str # Id of the requested component component_id : int # `metric_name` would be attribute names on BatteryData, etc. Example # value: `soc`, `current_phase_1`, etc. For individual phase current and # voltage values, we need to add additional attributes to `MeterData` and # `EVChargerData`. metric_id : ComponentMetricId # The start time from which data is required. When None, we will stream # only live data. start_time : Optional [ datetime ] def get_channel_name ( self ) -> str : \"\"\"Return a channel name constructed from Self. This channel name can be used by the sending side and receiving sides to identify the right channel from the ChannelRegistry. Returns: A string denoting a channel name. \"\"\" return f \" { self . component_id } :: { self . metric_id . name } :: { self . start_time } :: { self . namespace } \"","title":"ComponentMetricRequest"},{"location":"reference/frequenz/sdk/actor/data_sourcing/types/#frequenz.sdk.actor.data_sourcing.types.ComponentMetricRequest-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/actor/data_sourcing/types/#frequenz.sdk.actor.data_sourcing.types.ComponentMetricRequest.get_channel_name","text":"Return a channel name constructed from Self. This channel name can be used by the sending side and receiving sides to identify the right channel from the ChannelRegistry. RETURNS DESCRIPTION str A string denoting a channel name. Source code in frequenz/sdk/actor/data_sourcing/types.py 62 63 64 65 66 67 68 69 70 71 def get_channel_name ( self ) -> str : \"\"\"Return a channel name constructed from Self. This channel name can be used by the sending side and receiving sides to identify the right channel from the ChannelRegistry. Returns: A string denoting a channel name. \"\"\" return f \" { self . component_id } :: { self . metric_id . name } :: { self . start_time } :: { self . namespace } \"","title":"get_channel_name()"},{"location":"reference/frequenz/sdk/api_client/","text":"frequenz.sdk.api_client \u00a4 Common items to be shared across all API clients. Classes \u00a4 frequenz.sdk.api_client.ApiClient \u00a4 Bases: ABC An abstract API client, with general purpose functions that all APIs should implement. The methods defined here follow the principle that each client implementation should clearly and consistently specify the following information: a. which minimum version of the API it intends to target, b. what is the communication protocol. Source code in frequenz/sdk/api_client/api_client.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 class ApiClient ( ABC ): \"\"\"An abstract API client, with general purpose functions that all APIs should implement. The methods defined here follow the principle that each client implementation should clearly and consistently specify the following information: a. which minimum version of the API it intends to target, b. what is the communication protocol. \"\"\" @classmethod @abstractmethod def api_major_version ( cls ) -> int : \"\"\"Return the major version of the API supported by the client. Returns: The major version of the API supported by the client. \"\"\" @classmethod @abstractmethod def api_type ( cls ) -> ApiProtocol : \"\"\"Return the API type supported by the client. Returns: The ApiProtocol value representing the API type being targeted in a concrete implementation. \"\"\" Functions \u00a4 api_major_version () classmethod abstractmethod \u00a4 Return the major version of the API supported by the client. RETURNS DESCRIPTION int The major version of the API supported by the client. Source code in frequenz/sdk/api_client/api_client.py 28 29 30 31 32 33 34 35 @classmethod @abstractmethod def api_major_version ( cls ) -> int : \"\"\"Return the major version of the API supported by the client. Returns: The major version of the API supported by the client. \"\"\" api_type () classmethod abstractmethod \u00a4 Return the API type supported by the client. RETURNS DESCRIPTION ApiProtocol The ApiProtocol value representing the API type being targeted in a concrete implementation. Source code in frequenz/sdk/api_client/api_client.py 37 38 39 40 41 42 43 44 45 @classmethod @abstractmethod def api_type ( cls ) -> ApiProtocol : \"\"\"Return the API type supported by the client. Returns: The ApiProtocol value representing the API type being targeted in a concrete implementation. \"\"\" frequenz.sdk.api_client.ApiProtocol \u00a4 Bases: Enum Enumerated values of supported API types. Source code in frequenz/sdk/api_client/api_client.py 10 11 12 13 14 15 class ApiProtocol ( Enum ): \"\"\"Enumerated values of supported API types.\"\"\" GRPC = 1 REST = 2 FILESYSTEM = 3","title":"api_client"},{"location":"reference/frequenz/sdk/api_client/#frequenz.sdk.api_client","text":"Common items to be shared across all API clients.","title":"api_client"},{"location":"reference/frequenz/sdk/api_client/#frequenz.sdk.api_client-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/api_client/#frequenz.sdk.api_client.ApiClient","text":"Bases: ABC An abstract API client, with general purpose functions that all APIs should implement. The methods defined here follow the principle that each client implementation should clearly and consistently specify the following information: a. which minimum version of the API it intends to target, b. what is the communication protocol. Source code in frequenz/sdk/api_client/api_client.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 class ApiClient ( ABC ): \"\"\"An abstract API client, with general purpose functions that all APIs should implement. The methods defined here follow the principle that each client implementation should clearly and consistently specify the following information: a. which minimum version of the API it intends to target, b. what is the communication protocol. \"\"\" @classmethod @abstractmethod def api_major_version ( cls ) -> int : \"\"\"Return the major version of the API supported by the client. Returns: The major version of the API supported by the client. \"\"\" @classmethod @abstractmethod def api_type ( cls ) -> ApiProtocol : \"\"\"Return the API type supported by the client. Returns: The ApiProtocol value representing the API type being targeted in a concrete implementation. \"\"\"","title":"ApiClient"},{"location":"reference/frequenz/sdk/api_client/#frequenz.sdk.api_client.ApiClient-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/api_client/#frequenz.sdk.api_client.api_client.ApiClient.api_major_version","text":"Return the major version of the API supported by the client. RETURNS DESCRIPTION int The major version of the API supported by the client. Source code in frequenz/sdk/api_client/api_client.py 28 29 30 31 32 33 34 35 @classmethod @abstractmethod def api_major_version ( cls ) -> int : \"\"\"Return the major version of the API supported by the client. Returns: The major version of the API supported by the client. \"\"\"","title":"api_major_version()"},{"location":"reference/frequenz/sdk/api_client/#frequenz.sdk.api_client.api_client.ApiClient.api_type","text":"Return the API type supported by the client. RETURNS DESCRIPTION ApiProtocol The ApiProtocol value representing the API type being targeted in a concrete implementation. Source code in frequenz/sdk/api_client/api_client.py 37 38 39 40 41 42 43 44 45 @classmethod @abstractmethod def api_type ( cls ) -> ApiProtocol : \"\"\"Return the API type supported by the client. Returns: The ApiProtocol value representing the API type being targeted in a concrete implementation. \"\"\"","title":"api_type()"},{"location":"reference/frequenz/sdk/api_client/#frequenz.sdk.api_client.ApiProtocol","text":"Bases: Enum Enumerated values of supported API types. Source code in frequenz/sdk/api_client/api_client.py 10 11 12 13 14 15 class ApiProtocol ( Enum ): \"\"\"Enumerated values of supported API types.\"\"\" GRPC = 1 REST = 2 FILESYSTEM = 3","title":"ApiProtocol"},{"location":"reference/frequenz/sdk/api_client/api_client/","text":"frequenz.sdk.api_client.api_client \u00a4 An abstract API client. Classes \u00a4 frequenz.sdk.api_client.api_client.ApiClient \u00a4 Bases: ABC An abstract API client, with general purpose functions that all APIs should implement. The methods defined here follow the principle that each client implementation should clearly and consistently specify the following information: a. which minimum version of the API it intends to target, b. what is the communication protocol. Source code in frequenz/sdk/api_client/api_client.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 class ApiClient ( ABC ): \"\"\"An abstract API client, with general purpose functions that all APIs should implement. The methods defined here follow the principle that each client implementation should clearly and consistently specify the following information: a. which minimum version of the API it intends to target, b. what is the communication protocol. \"\"\" @classmethod @abstractmethod def api_major_version ( cls ) -> int : \"\"\"Return the major version of the API supported by the client. Returns: The major version of the API supported by the client. \"\"\" @classmethod @abstractmethod def api_type ( cls ) -> ApiProtocol : \"\"\"Return the API type supported by the client. Returns: The ApiProtocol value representing the API type being targeted in a concrete implementation. \"\"\" Functions \u00a4 api_major_version () classmethod abstractmethod \u00a4 Return the major version of the API supported by the client. RETURNS DESCRIPTION int The major version of the API supported by the client. Source code in frequenz/sdk/api_client/api_client.py 28 29 30 31 32 33 34 35 @classmethod @abstractmethod def api_major_version ( cls ) -> int : \"\"\"Return the major version of the API supported by the client. Returns: The major version of the API supported by the client. \"\"\" api_type () classmethod abstractmethod \u00a4 Return the API type supported by the client. RETURNS DESCRIPTION ApiProtocol The ApiProtocol value representing the API type being targeted in a concrete implementation. Source code in frequenz/sdk/api_client/api_client.py 37 38 39 40 41 42 43 44 45 @classmethod @abstractmethod def api_type ( cls ) -> ApiProtocol : \"\"\"Return the API type supported by the client. Returns: The ApiProtocol value representing the API type being targeted in a concrete implementation. \"\"\" frequenz.sdk.api_client.api_client.ApiProtocol \u00a4 Bases: Enum Enumerated values of supported API types. Source code in frequenz/sdk/api_client/api_client.py 10 11 12 13 14 15 class ApiProtocol ( Enum ): \"\"\"Enumerated values of supported API types.\"\"\" GRPC = 1 REST = 2 FILESYSTEM = 3","title":"api_client"},{"location":"reference/frequenz/sdk/api_client/api_client/#frequenz.sdk.api_client.api_client","text":"An abstract API client.","title":"api_client"},{"location":"reference/frequenz/sdk/api_client/api_client/#frequenz.sdk.api_client.api_client-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/api_client/api_client/#frequenz.sdk.api_client.api_client.ApiClient","text":"Bases: ABC An abstract API client, with general purpose functions that all APIs should implement. The methods defined here follow the principle that each client implementation should clearly and consistently specify the following information: a. which minimum version of the API it intends to target, b. what is the communication protocol. Source code in frequenz/sdk/api_client/api_client.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 class ApiClient ( ABC ): \"\"\"An abstract API client, with general purpose functions that all APIs should implement. The methods defined here follow the principle that each client implementation should clearly and consistently specify the following information: a. which minimum version of the API it intends to target, b. what is the communication protocol. \"\"\" @classmethod @abstractmethod def api_major_version ( cls ) -> int : \"\"\"Return the major version of the API supported by the client. Returns: The major version of the API supported by the client. \"\"\" @classmethod @abstractmethod def api_type ( cls ) -> ApiProtocol : \"\"\"Return the API type supported by the client. Returns: The ApiProtocol value representing the API type being targeted in a concrete implementation. \"\"\"","title":"ApiClient"},{"location":"reference/frequenz/sdk/api_client/api_client/#frequenz.sdk.api_client.api_client.ApiClient-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/api_client/api_client/#frequenz.sdk.api_client.api_client.ApiClient.api_major_version","text":"Return the major version of the API supported by the client. RETURNS DESCRIPTION int The major version of the API supported by the client. Source code in frequenz/sdk/api_client/api_client.py 28 29 30 31 32 33 34 35 @classmethod @abstractmethod def api_major_version ( cls ) -> int : \"\"\"Return the major version of the API supported by the client. Returns: The major version of the API supported by the client. \"\"\"","title":"api_major_version()"},{"location":"reference/frequenz/sdk/api_client/api_client/#frequenz.sdk.api_client.api_client.ApiClient.api_type","text":"Return the API type supported by the client. RETURNS DESCRIPTION ApiProtocol The ApiProtocol value representing the API type being targeted in a concrete implementation. Source code in frequenz/sdk/api_client/api_client.py 37 38 39 40 41 42 43 44 45 @classmethod @abstractmethod def api_type ( cls ) -> ApiProtocol : \"\"\"Return the API type supported by the client. Returns: The ApiProtocol value representing the API type being targeted in a concrete implementation. \"\"\"","title":"api_type()"},{"location":"reference/frequenz/sdk/api_client/api_client/#frequenz.sdk.api_client.api_client.ApiProtocol","text":"Bases: Enum Enumerated values of supported API types. Source code in frequenz/sdk/api_client/api_client.py 10 11 12 13 14 15 class ApiProtocol ( Enum ): \"\"\"Enumerated values of supported API types.\"\"\" GRPC = 1 REST = 2 FILESYSTEM = 3","title":"ApiProtocol"},{"location":"reference/frequenz/sdk/configs/","text":"frequenz.sdk.configs \u00a4 Config interface. Classes \u00a4 frequenz.sdk.configs.Config \u00a4 Stores config variables. Config variables are read from a file. Only single file can be read. If new file is read, then previous configs will be forgotten. Source code in frequenz/sdk/configs/config.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 class Config : \"\"\" Stores config variables. Config variables are read from a file. Only single file can be read. If new file is read, then previous configs will be forgotten. \"\"\" def __init__ ( self , conf_vars : Dict [ str , Any ]): \"\"\"Instantiate the config store and read config variables from the file. Args: conf_vars: Dict containing configuration variables \"\"\" self . _conf_store : Dict [ str , Any ] = conf_vars def get ( self , key : str , default : Any = None ) -> Any : \"\"\"Get the value for the specified key. If the key is not in the configs, then return default. Args: key: Key to be searched. default: Value to be returned if the key is not found. Defaults to None. Returns: value in str format or default. \"\"\" return self . _conf_store . get ( key , default ) def get_dict ( self , key_prefix : str , expected_values_type : Optional [ T ] ) -> Dict [ str , Any ]: \"\"\"Get a dictionary based on config key prefixes. For example, if key_prefix is \"my_dict\", then the following config store: { 'some_key': 'some_value', 'my_dict_key1': 'value1', 'my_dict_key2': 'value2', } Will return: { 'key1': 'value1', 'key2': 'value2', } Args: key_prefix: Only get configuration variables starting with this prefix. expected_values_type: If provided, the value will be validated against this type. Returns: A dictionary containing the keys prefixed with `key_prefix` as keys (but with the prefix removed) and the values as values. \"\"\" result : Dict [ str , Any ] = {} for key , value in self . _conf_store . items (): if key . startswith ( key_prefix ): new_key = key [ len ( key_prefix ) :] if expected_values_type is not None : value = self . get_as ( key , expected_values_type ) result [ new_key ] = value return result def get_as ( self , key : str , expected_type : Any ) -> Any : \"\"\"Get and convert the value to specified type. Check if type of the value is as expected. If type is correct, then return converted value. Otherwise Raise ValueError. Type can be: * Any typing module type. * Any pydantic strict types (e.g. pydantic.StrictInt) Args: key: Key to be search expected_type: type for the value Raises: ValueError: If can't convert value to the expected type. KeyError: If specified key is not in config. Returns: Value for the specified key, converted to specified type. Example: For `var1='[1, 2.0, 3.5]'`: * `get_as(\"var1\", List[int])` -> `[1,2,3]` * `get_as(\"var1\", List[float])` -> `[1.0,2.0,3.5]` * `get_as(\"var1\", List[pydantic.StrictInt])` -> [ValueError][] * `get_as(\"var1\", List[pydantic.StrictFloat])` -> [ValueError][] For `var1='[1,2,3]'`: * `get_as(\"var1\", List[pydantic.StrictInt])` -> `[1,2,3]` \"\"\" value = self [ key ] if str is expected_type : return value try : parsed_value : Any = parse_raw_as ( expected_type , value ) except ( ValidationError , ValueError ) as err : raise ValueError ( f \"Could not convert config variable: { key } = ' { value } ' \" f \"to type { str ( expected_type ) } , err:\" + str ( err ) ) from err return parsed_value def __getitem__ ( self , key : str ) -> Any : \"\"\"Get the value for the specified key. If the key is not in the configs, then raise KeyError. Args: key: key to be searched. Raises: KeyError: If key is not in found. Returns: Dictionary if the corresponding value is a subsection in the .toml file or a primitive type it is a simple value. \"\"\" value = self . _conf_store . get ( key , None ) if value is None : raise KeyError ( f \"Unknown config name { key } \" ) return value def __contains__ ( self , key : str ) -> bool : \"\"\"Return whether the specified key is in the storage. Args: key: Config variable name. Returns: True if key is in the storage, otherwise returns False. \"\"\" return key in self . _conf_store Functions \u00a4 __contains__ ( key ) \u00a4 Return whether the specified key is in the storage. PARAMETER DESCRIPTION key Config variable name. TYPE: str RETURNS DESCRIPTION bool True if key is in the storage, otherwise returns False. Source code in frequenz/sdk/configs/config.py 152 153 154 155 156 157 158 159 160 161 def __contains__ ( self , key : str ) -> bool : \"\"\"Return whether the specified key is in the storage. Args: key: Config variable name. Returns: True if key is in the storage, otherwise returns False. \"\"\" return key in self . _conf_store __getitem__ ( key ) \u00a4 Get the value for the specified key. If the key is not in the configs, then raise KeyError. PARAMETER DESCRIPTION key key to be searched. TYPE: str RAISES DESCRIPTION KeyError If key is not in found. RETURNS DESCRIPTION Any Dictionary if the corresponding value is a subsection in the .toml file or a primitive type it is a simple value. Source code in frequenz/sdk/configs/config.py 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 def __getitem__ ( self , key : str ) -> Any : \"\"\"Get the value for the specified key. If the key is not in the configs, then raise KeyError. Args: key: key to be searched. Raises: KeyError: If key is not in found. Returns: Dictionary if the corresponding value is a subsection in the .toml file or a primitive type it is a simple value. \"\"\" value = self . _conf_store . get ( key , None ) if value is None : raise KeyError ( f \"Unknown config name { key } \" ) return value __init__ ( conf_vars ) \u00a4 Instantiate the config store and read config variables from the file. PARAMETER DESCRIPTION conf_vars Dict containing configuration variables TYPE: Dict [ str , Any ] Source code in frequenz/sdk/configs/config.py 25 26 27 28 29 30 31 def __init__ ( self , conf_vars : Dict [ str , Any ]): \"\"\"Instantiate the config store and read config variables from the file. Args: conf_vars: Dict containing configuration variables \"\"\" self . _conf_store : Dict [ str , Any ] = conf_vars get ( key , default = None ) \u00a4 Get the value for the specified key. If the key is not in the configs, then return default. PARAMETER DESCRIPTION key Key to be searched. TYPE: str default Value to be returned if the key is not found. Defaults to None. TYPE: Any DEFAULT: None RETURNS DESCRIPTION Any value in str format or default. Source code in frequenz/sdk/configs/config.py 33 34 35 36 37 38 39 40 41 42 43 44 45 46 def get ( self , key : str , default : Any = None ) -> Any : \"\"\"Get the value for the specified key. If the key is not in the configs, then return default. Args: key: Key to be searched. default: Value to be returned if the key is not found. Defaults to None. Returns: value in str format or default. \"\"\" return self . _conf_store . get ( key , default ) get_as ( key , expected_type ) \u00a4 Get and convert the value to specified type. Check if type of the value is as expected. If type is correct, then return converted value. Otherwise Raise ValueError. Type can be Any typing module type. Any pydantic strict types (e.g. pydantic.StrictInt) PARAMETER DESCRIPTION key Key to be search TYPE: str expected_type type for the value TYPE: Any RAISES DESCRIPTION ValueError If can't convert value to the expected type. KeyError If specified key is not in config. RETURNS DESCRIPTION Any Value for the specified key, converted to specified type. Example For var1='[1, 2.0, 3.5]' : * get_as(\"var1\", List[int]) -> [1,2,3] * get_as(\"var1\", List[float]) -> [1.0,2.0,3.5] * get_as(\"var1\", List[pydantic.StrictInt]) -> ValueError * get_as(\"var1\", List[pydantic.StrictFloat]) -> ValueError For var1='[1,2,3]' : * get_as(\"var1\", List[pydantic.StrictInt]) -> [1,2,3] Source code in frequenz/sdk/configs/config.py 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 def get_as ( self , key : str , expected_type : Any ) -> Any : \"\"\"Get and convert the value to specified type. Check if type of the value is as expected. If type is correct, then return converted value. Otherwise Raise ValueError. Type can be: * Any typing module type. * Any pydantic strict types (e.g. pydantic.StrictInt) Args: key: Key to be search expected_type: type for the value Raises: ValueError: If can't convert value to the expected type. KeyError: If specified key is not in config. Returns: Value for the specified key, converted to specified type. Example: For `var1='[1, 2.0, 3.5]'`: * `get_as(\"var1\", List[int])` -> `[1,2,3]` * `get_as(\"var1\", List[float])` -> `[1.0,2.0,3.5]` * `get_as(\"var1\", List[pydantic.StrictInt])` -> [ValueError][] * `get_as(\"var1\", List[pydantic.StrictFloat])` -> [ValueError][] For `var1='[1,2,3]'`: * `get_as(\"var1\", List[pydantic.StrictInt])` -> `[1,2,3]` \"\"\" value = self [ key ] if str is expected_type : return value try : parsed_value : Any = parse_raw_as ( expected_type , value ) except ( ValidationError , ValueError ) as err : raise ValueError ( f \"Could not convert config variable: { key } = ' { value } ' \" f \"to type { str ( expected_type ) } , err:\" + str ( err ) ) from err return parsed_value get_dict ( key_prefix , expected_values_type ) \u00a4 Get a dictionary based on config key prefixes. For example, if key_prefix is \"my_dict\", then the following config store: { 'some_key': 'some_value', 'my_dict_key1': 'value1', 'my_dict_key2': 'value2', } Will return { 'key1': 'value1', 'key2': 'value2', } PARAMETER DESCRIPTION key_prefix Only get configuration variables starting with this prefix. TYPE: str expected_values_type If provided, the value will be validated against this type. TYPE: Optional [ T ] RETURNS DESCRIPTION Dict [ str , Any ] A dictionary containing the keys prefixed with key_prefix as keys (but with the prefix removed) and the values as values. Source code in frequenz/sdk/configs/config.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 def get_dict ( self , key_prefix : str , expected_values_type : Optional [ T ] ) -> Dict [ str , Any ]: \"\"\"Get a dictionary based on config key prefixes. For example, if key_prefix is \"my_dict\", then the following config store: { 'some_key': 'some_value', 'my_dict_key1': 'value1', 'my_dict_key2': 'value2', } Will return: { 'key1': 'value1', 'key2': 'value2', } Args: key_prefix: Only get configuration variables starting with this prefix. expected_values_type: If provided, the value will be validated against this type. Returns: A dictionary containing the keys prefixed with `key_prefix` as keys (but with the prefix removed) and the values as values. \"\"\" result : Dict [ str , Any ] = {} for key , value in self . _conf_store . items (): if key . startswith ( key_prefix ): new_key = key [ len ( key_prefix ) :] if expected_values_type is not None : value = self . get_as ( key , expected_values_type ) result [ new_key ] = value return result frequenz.sdk.configs.ConfigManager \u00a4 Manages config variables. Config variables are read from file. Only single file can be read. If new file is read, then previous configs will be forgotten. Source code in frequenz/sdk/configs/config_manager.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 @actor class ConfigManager : \"\"\" Manages config variables. Config variables are read from file. Only single file can be read. If new file is read, then previous configs will be forgotten. \"\"\" def __init__ ( self , conf_file : str , output : Sender [ Config ], event_types : Optional [ Set [ FileWatcher . EventType ]] = None , ) -> None : \"\"\"Read config variables from the file. Args: conf_file: Path to file with config variables. output: Channel to publish updates to. event_types: Which types of events should update the config and trigger a notification. \"\"\" self . _conf_file : str = conf_file self . _conf_dir : str = os . path . dirname ( conf_file ) self . _file_watcher = FileWatcher ( paths = [ self . _conf_dir ], event_types = event_types ) self . _output = output def _read_config ( self ) -> Dict [ str , Any ]: \"\"\"Read the contents of the config file. Raises: ValueError: if config file cannot be read. Returns: A dictionary containing configuration variables. \"\"\" try : return toml . load ( self . _conf_file ) except ValueError as err : logging . error ( \"Can't read config file, err: %s \" , err ) raise async def send_config ( self ) -> None : \"\"\"Send config file using a broadcast channel.\"\"\" conf_vars = self . _read_config () config = Config ( conf_vars ) await self . _output . send ( config ) async def run ( self ) -> None : \"\"\"Watch config file and update when modified. At startup, the Config Manager sends the current config so that it can be cache in the Broadcast channel and served to receivers even if there hasn't been any change to the config file itself. \"\"\" await self . send_config () async for path in self . _file_watcher : if str ( path ) == self . _conf_file : logger . info ( \"Update configs, because file %s was modified.\" , self . _conf_file , ) await self . send_config () logger . debug ( \"ConfigManager stopped.\" ) Functions \u00a4 __init__ ( conf_file , output , event_types = None ) \u00a4 Read config variables from the file. PARAMETER DESCRIPTION conf_file Path to file with config variables. TYPE: str output Channel to publish updates to. TYPE: Sender [ Config ] event_types Which types of events should update the config and trigger a notification. TYPE: Optional [ Set [ FileWatcher . EventType ]] DEFAULT: None Source code in frequenz/sdk/configs/config_manager.py 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def __init__ ( self , conf_file : str , output : Sender [ Config ], event_types : Optional [ Set [ FileWatcher . EventType ]] = None , ) -> None : \"\"\"Read config variables from the file. Args: conf_file: Path to file with config variables. output: Channel to publish updates to. event_types: Which types of events should update the config and trigger a notification. \"\"\" self . _conf_file : str = conf_file self . _conf_dir : str = os . path . dirname ( conf_file ) self . _file_watcher = FileWatcher ( paths = [ self . _conf_dir ], event_types = event_types ) self . _output = output run () async \u00a4 Watch config file and update when modified. At startup, the Config Manager sends the current config so that it can be cache in the Broadcast channel and served to receivers even if there hasn't been any change to the config file itself. Source code in frequenz/sdk/configs/config_manager.py 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 async def run ( self ) -> None : \"\"\"Watch config file and update when modified. At startup, the Config Manager sends the current config so that it can be cache in the Broadcast channel and served to receivers even if there hasn't been any change to the config file itself. \"\"\" await self . send_config () async for path in self . _file_watcher : if str ( path ) == self . _conf_file : logger . info ( \"Update configs, because file %s was modified.\" , self . _conf_file , ) await self . send_config () logger . debug ( \"ConfigManager stopped.\" ) send_config () async \u00a4 Send config file using a broadcast channel. Source code in frequenz/sdk/configs/config_manager.py 66 67 68 69 70 async def send_config ( self ) -> None : \"\"\"Send config file using a broadcast channel.\"\"\" conf_vars = self . _read_config () config = Config ( conf_vars ) await self . _output . send ( config )","title":"configs"},{"location":"reference/frequenz/sdk/configs/#frequenz.sdk.configs","text":"Config interface.","title":"configs"},{"location":"reference/frequenz/sdk/configs/#frequenz.sdk.configs-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/configs/#frequenz.sdk.configs.Config","text":"Stores config variables. Config variables are read from a file. Only single file can be read. If new file is read, then previous configs will be forgotten. Source code in frequenz/sdk/configs/config.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 class Config : \"\"\" Stores config variables. Config variables are read from a file. Only single file can be read. If new file is read, then previous configs will be forgotten. \"\"\" def __init__ ( self , conf_vars : Dict [ str , Any ]): \"\"\"Instantiate the config store and read config variables from the file. Args: conf_vars: Dict containing configuration variables \"\"\" self . _conf_store : Dict [ str , Any ] = conf_vars def get ( self , key : str , default : Any = None ) -> Any : \"\"\"Get the value for the specified key. If the key is not in the configs, then return default. Args: key: Key to be searched. default: Value to be returned if the key is not found. Defaults to None. Returns: value in str format or default. \"\"\" return self . _conf_store . get ( key , default ) def get_dict ( self , key_prefix : str , expected_values_type : Optional [ T ] ) -> Dict [ str , Any ]: \"\"\"Get a dictionary based on config key prefixes. For example, if key_prefix is \"my_dict\", then the following config store: { 'some_key': 'some_value', 'my_dict_key1': 'value1', 'my_dict_key2': 'value2', } Will return: { 'key1': 'value1', 'key2': 'value2', } Args: key_prefix: Only get configuration variables starting with this prefix. expected_values_type: If provided, the value will be validated against this type. Returns: A dictionary containing the keys prefixed with `key_prefix` as keys (but with the prefix removed) and the values as values. \"\"\" result : Dict [ str , Any ] = {} for key , value in self . _conf_store . items (): if key . startswith ( key_prefix ): new_key = key [ len ( key_prefix ) :] if expected_values_type is not None : value = self . get_as ( key , expected_values_type ) result [ new_key ] = value return result def get_as ( self , key : str , expected_type : Any ) -> Any : \"\"\"Get and convert the value to specified type. Check if type of the value is as expected. If type is correct, then return converted value. Otherwise Raise ValueError. Type can be: * Any typing module type. * Any pydantic strict types (e.g. pydantic.StrictInt) Args: key: Key to be search expected_type: type for the value Raises: ValueError: If can't convert value to the expected type. KeyError: If specified key is not in config. Returns: Value for the specified key, converted to specified type. Example: For `var1='[1, 2.0, 3.5]'`: * `get_as(\"var1\", List[int])` -> `[1,2,3]` * `get_as(\"var1\", List[float])` -> `[1.0,2.0,3.5]` * `get_as(\"var1\", List[pydantic.StrictInt])` -> [ValueError][] * `get_as(\"var1\", List[pydantic.StrictFloat])` -> [ValueError][] For `var1='[1,2,3]'`: * `get_as(\"var1\", List[pydantic.StrictInt])` -> `[1,2,3]` \"\"\" value = self [ key ] if str is expected_type : return value try : parsed_value : Any = parse_raw_as ( expected_type , value ) except ( ValidationError , ValueError ) as err : raise ValueError ( f \"Could not convert config variable: { key } = ' { value } ' \" f \"to type { str ( expected_type ) } , err:\" + str ( err ) ) from err return parsed_value def __getitem__ ( self , key : str ) -> Any : \"\"\"Get the value for the specified key. If the key is not in the configs, then raise KeyError. Args: key: key to be searched. Raises: KeyError: If key is not in found. Returns: Dictionary if the corresponding value is a subsection in the .toml file or a primitive type it is a simple value. \"\"\" value = self . _conf_store . get ( key , None ) if value is None : raise KeyError ( f \"Unknown config name { key } \" ) return value def __contains__ ( self , key : str ) -> bool : \"\"\"Return whether the specified key is in the storage. Args: key: Config variable name. Returns: True if key is in the storage, otherwise returns False. \"\"\" return key in self . _conf_store","title":"Config"},{"location":"reference/frequenz/sdk/configs/#frequenz.sdk.configs.Config-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/configs/#frequenz.sdk.configs.config.Config.__contains__","text":"Return whether the specified key is in the storage. PARAMETER DESCRIPTION key Config variable name. TYPE: str RETURNS DESCRIPTION bool True if key is in the storage, otherwise returns False. Source code in frequenz/sdk/configs/config.py 152 153 154 155 156 157 158 159 160 161 def __contains__ ( self , key : str ) -> bool : \"\"\"Return whether the specified key is in the storage. Args: key: Config variable name. Returns: True if key is in the storage, otherwise returns False. \"\"\" return key in self . _conf_store","title":"__contains__()"},{"location":"reference/frequenz/sdk/configs/#frequenz.sdk.configs.config.Config.__getitem__","text":"Get the value for the specified key. If the key is not in the configs, then raise KeyError. PARAMETER DESCRIPTION key key to be searched. TYPE: str RAISES DESCRIPTION KeyError If key is not in found. RETURNS DESCRIPTION Any Dictionary if the corresponding value is a subsection in the .toml file or a primitive type it is a simple value. Source code in frequenz/sdk/configs/config.py 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 def __getitem__ ( self , key : str ) -> Any : \"\"\"Get the value for the specified key. If the key is not in the configs, then raise KeyError. Args: key: key to be searched. Raises: KeyError: If key is not in found. Returns: Dictionary if the corresponding value is a subsection in the .toml file or a primitive type it is a simple value. \"\"\" value = self . _conf_store . get ( key , None ) if value is None : raise KeyError ( f \"Unknown config name { key } \" ) return value","title":"__getitem__()"},{"location":"reference/frequenz/sdk/configs/#frequenz.sdk.configs.config.Config.__init__","text":"Instantiate the config store and read config variables from the file. PARAMETER DESCRIPTION conf_vars Dict containing configuration variables TYPE: Dict [ str , Any ] Source code in frequenz/sdk/configs/config.py 25 26 27 28 29 30 31 def __init__ ( self , conf_vars : Dict [ str , Any ]): \"\"\"Instantiate the config store and read config variables from the file. Args: conf_vars: Dict containing configuration variables \"\"\" self . _conf_store : Dict [ str , Any ] = conf_vars","title":"__init__()"},{"location":"reference/frequenz/sdk/configs/#frequenz.sdk.configs.config.Config.get","text":"Get the value for the specified key. If the key is not in the configs, then return default. PARAMETER DESCRIPTION key Key to be searched. TYPE: str default Value to be returned if the key is not found. Defaults to None. TYPE: Any DEFAULT: None RETURNS DESCRIPTION Any value in str format or default. Source code in frequenz/sdk/configs/config.py 33 34 35 36 37 38 39 40 41 42 43 44 45 46 def get ( self , key : str , default : Any = None ) -> Any : \"\"\"Get the value for the specified key. If the key is not in the configs, then return default. Args: key: Key to be searched. default: Value to be returned if the key is not found. Defaults to None. Returns: value in str format or default. \"\"\" return self . _conf_store . get ( key , default )","title":"get()"},{"location":"reference/frequenz/sdk/configs/#frequenz.sdk.configs.config.Config.get_as","text":"Get and convert the value to specified type. Check if type of the value is as expected. If type is correct, then return converted value. Otherwise Raise ValueError. Type can be Any typing module type. Any pydantic strict types (e.g. pydantic.StrictInt) PARAMETER DESCRIPTION key Key to be search TYPE: str expected_type type for the value TYPE: Any RAISES DESCRIPTION ValueError If can't convert value to the expected type. KeyError If specified key is not in config. RETURNS DESCRIPTION Any Value for the specified key, converted to specified type. Example For var1='[1, 2.0, 3.5]' : * get_as(\"var1\", List[int]) -> [1,2,3] * get_as(\"var1\", List[float]) -> [1.0,2.0,3.5] * get_as(\"var1\", List[pydantic.StrictInt]) -> ValueError * get_as(\"var1\", List[pydantic.StrictFloat]) -> ValueError For var1='[1,2,3]' : * get_as(\"var1\", List[pydantic.StrictInt]) -> [1,2,3] Source code in frequenz/sdk/configs/config.py 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 def get_as ( self , key : str , expected_type : Any ) -> Any : \"\"\"Get and convert the value to specified type. Check if type of the value is as expected. If type is correct, then return converted value. Otherwise Raise ValueError. Type can be: * Any typing module type. * Any pydantic strict types (e.g. pydantic.StrictInt) Args: key: Key to be search expected_type: type for the value Raises: ValueError: If can't convert value to the expected type. KeyError: If specified key is not in config. Returns: Value for the specified key, converted to specified type. Example: For `var1='[1, 2.0, 3.5]'`: * `get_as(\"var1\", List[int])` -> `[1,2,3]` * `get_as(\"var1\", List[float])` -> `[1.0,2.0,3.5]` * `get_as(\"var1\", List[pydantic.StrictInt])` -> [ValueError][] * `get_as(\"var1\", List[pydantic.StrictFloat])` -> [ValueError][] For `var1='[1,2,3]'`: * `get_as(\"var1\", List[pydantic.StrictInt])` -> `[1,2,3]` \"\"\" value = self [ key ] if str is expected_type : return value try : parsed_value : Any = parse_raw_as ( expected_type , value ) except ( ValidationError , ValueError ) as err : raise ValueError ( f \"Could not convert config variable: { key } = ' { value } ' \" f \"to type { str ( expected_type ) } , err:\" + str ( err ) ) from err return parsed_value","title":"get_as()"},{"location":"reference/frequenz/sdk/configs/#frequenz.sdk.configs.config.Config.get_dict","text":"Get a dictionary based on config key prefixes. For example, if key_prefix is \"my_dict\", then the following config store: { 'some_key': 'some_value', 'my_dict_key1': 'value1', 'my_dict_key2': 'value2', } Will return { 'key1': 'value1', 'key2': 'value2', } PARAMETER DESCRIPTION key_prefix Only get configuration variables starting with this prefix. TYPE: str expected_values_type If provided, the value will be validated against this type. TYPE: Optional [ T ] RETURNS DESCRIPTION Dict [ str , Any ] A dictionary containing the keys prefixed with key_prefix as keys (but with the prefix removed) and the values as values. Source code in frequenz/sdk/configs/config.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 def get_dict ( self , key_prefix : str , expected_values_type : Optional [ T ] ) -> Dict [ str , Any ]: \"\"\"Get a dictionary based on config key prefixes. For example, if key_prefix is \"my_dict\", then the following config store: { 'some_key': 'some_value', 'my_dict_key1': 'value1', 'my_dict_key2': 'value2', } Will return: { 'key1': 'value1', 'key2': 'value2', } Args: key_prefix: Only get configuration variables starting with this prefix. expected_values_type: If provided, the value will be validated against this type. Returns: A dictionary containing the keys prefixed with `key_prefix` as keys (but with the prefix removed) and the values as values. \"\"\" result : Dict [ str , Any ] = {} for key , value in self . _conf_store . items (): if key . startswith ( key_prefix ): new_key = key [ len ( key_prefix ) :] if expected_values_type is not None : value = self . get_as ( key , expected_values_type ) result [ new_key ] = value return result","title":"get_dict()"},{"location":"reference/frequenz/sdk/configs/#frequenz.sdk.configs.ConfigManager","text":"Manages config variables. Config variables are read from file. Only single file can be read. If new file is read, then previous configs will be forgotten. Source code in frequenz/sdk/configs/config_manager.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 @actor class ConfigManager : \"\"\" Manages config variables. Config variables are read from file. Only single file can be read. If new file is read, then previous configs will be forgotten. \"\"\" def __init__ ( self , conf_file : str , output : Sender [ Config ], event_types : Optional [ Set [ FileWatcher . EventType ]] = None , ) -> None : \"\"\"Read config variables from the file. Args: conf_file: Path to file with config variables. output: Channel to publish updates to. event_types: Which types of events should update the config and trigger a notification. \"\"\" self . _conf_file : str = conf_file self . _conf_dir : str = os . path . dirname ( conf_file ) self . _file_watcher = FileWatcher ( paths = [ self . _conf_dir ], event_types = event_types ) self . _output = output def _read_config ( self ) -> Dict [ str , Any ]: \"\"\"Read the contents of the config file. Raises: ValueError: if config file cannot be read. Returns: A dictionary containing configuration variables. \"\"\" try : return toml . load ( self . _conf_file ) except ValueError as err : logging . error ( \"Can't read config file, err: %s \" , err ) raise async def send_config ( self ) -> None : \"\"\"Send config file using a broadcast channel.\"\"\" conf_vars = self . _read_config () config = Config ( conf_vars ) await self . _output . send ( config ) async def run ( self ) -> None : \"\"\"Watch config file and update when modified. At startup, the Config Manager sends the current config so that it can be cache in the Broadcast channel and served to receivers even if there hasn't been any change to the config file itself. \"\"\" await self . send_config () async for path in self . _file_watcher : if str ( path ) == self . _conf_file : logger . info ( \"Update configs, because file %s was modified.\" , self . _conf_file , ) await self . send_config () logger . debug ( \"ConfigManager stopped.\" )","title":"ConfigManager"},{"location":"reference/frequenz/sdk/configs/#frequenz.sdk.configs.ConfigManager-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/configs/#frequenz.sdk.configs.config_manager.ConfigManager.__init__","text":"Read config variables from the file. PARAMETER DESCRIPTION conf_file Path to file with config variables. TYPE: str output Channel to publish updates to. TYPE: Sender [ Config ] event_types Which types of events should update the config and trigger a notification. TYPE: Optional [ Set [ FileWatcher . EventType ]] DEFAULT: None Source code in frequenz/sdk/configs/config_manager.py 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def __init__ ( self , conf_file : str , output : Sender [ Config ], event_types : Optional [ Set [ FileWatcher . EventType ]] = None , ) -> None : \"\"\"Read config variables from the file. Args: conf_file: Path to file with config variables. output: Channel to publish updates to. event_types: Which types of events should update the config and trigger a notification. \"\"\" self . _conf_file : str = conf_file self . _conf_dir : str = os . path . dirname ( conf_file ) self . _file_watcher = FileWatcher ( paths = [ self . _conf_dir ], event_types = event_types ) self . _output = output","title":"__init__()"},{"location":"reference/frequenz/sdk/configs/#frequenz.sdk.configs.config_manager.ConfigManager.run","text":"Watch config file and update when modified. At startup, the Config Manager sends the current config so that it can be cache in the Broadcast channel and served to receivers even if there hasn't been any change to the config file itself. Source code in frequenz/sdk/configs/config_manager.py 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 async def run ( self ) -> None : \"\"\"Watch config file and update when modified. At startup, the Config Manager sends the current config so that it can be cache in the Broadcast channel and served to receivers even if there hasn't been any change to the config file itself. \"\"\" await self . send_config () async for path in self . _file_watcher : if str ( path ) == self . _conf_file : logger . info ( \"Update configs, because file %s was modified.\" , self . _conf_file , ) await self . send_config () logger . debug ( \"ConfigManager stopped.\" )","title":"run()"},{"location":"reference/frequenz/sdk/configs/#frequenz.sdk.configs.config_manager.ConfigManager.send_config","text":"Send config file using a broadcast channel. Source code in frequenz/sdk/configs/config_manager.py 66 67 68 69 70 async def send_config ( self ) -> None : \"\"\"Send config file using a broadcast channel.\"\"\" conf_vars = self . _read_config () config = Config ( conf_vars ) await self . _output . send ( config )","title":"send_config()"},{"location":"reference/frequenz/sdk/configs/config/","text":"frequenz.sdk.configs.config \u00a4 Read and update config variables. Classes \u00a4 frequenz.sdk.configs.config.Config \u00a4 Stores config variables. Config variables are read from a file. Only single file can be read. If new file is read, then previous configs will be forgotten. Source code in frequenz/sdk/configs/config.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 class Config : \"\"\" Stores config variables. Config variables are read from a file. Only single file can be read. If new file is read, then previous configs will be forgotten. \"\"\" def __init__ ( self , conf_vars : Dict [ str , Any ]): \"\"\"Instantiate the config store and read config variables from the file. Args: conf_vars: Dict containing configuration variables \"\"\" self . _conf_store : Dict [ str , Any ] = conf_vars def get ( self , key : str , default : Any = None ) -> Any : \"\"\"Get the value for the specified key. If the key is not in the configs, then return default. Args: key: Key to be searched. default: Value to be returned if the key is not found. Defaults to None. Returns: value in str format or default. \"\"\" return self . _conf_store . get ( key , default ) def get_dict ( self , key_prefix : str , expected_values_type : Optional [ T ] ) -> Dict [ str , Any ]: \"\"\"Get a dictionary based on config key prefixes. For example, if key_prefix is \"my_dict\", then the following config store: { 'some_key': 'some_value', 'my_dict_key1': 'value1', 'my_dict_key2': 'value2', } Will return: { 'key1': 'value1', 'key2': 'value2', } Args: key_prefix: Only get configuration variables starting with this prefix. expected_values_type: If provided, the value will be validated against this type. Returns: A dictionary containing the keys prefixed with `key_prefix` as keys (but with the prefix removed) and the values as values. \"\"\" result : Dict [ str , Any ] = {} for key , value in self . _conf_store . items (): if key . startswith ( key_prefix ): new_key = key [ len ( key_prefix ) :] if expected_values_type is not None : value = self . get_as ( key , expected_values_type ) result [ new_key ] = value return result def get_as ( self , key : str , expected_type : Any ) -> Any : \"\"\"Get and convert the value to specified type. Check if type of the value is as expected. If type is correct, then return converted value. Otherwise Raise ValueError. Type can be: * Any typing module type. * Any pydantic strict types (e.g. pydantic.StrictInt) Args: key: Key to be search expected_type: type for the value Raises: ValueError: If can't convert value to the expected type. KeyError: If specified key is not in config. Returns: Value for the specified key, converted to specified type. Example: For `var1='[1, 2.0, 3.5]'`: * `get_as(\"var1\", List[int])` -> `[1,2,3]` * `get_as(\"var1\", List[float])` -> `[1.0,2.0,3.5]` * `get_as(\"var1\", List[pydantic.StrictInt])` -> [ValueError][] * `get_as(\"var1\", List[pydantic.StrictFloat])` -> [ValueError][] For `var1='[1,2,3]'`: * `get_as(\"var1\", List[pydantic.StrictInt])` -> `[1,2,3]` \"\"\" value = self [ key ] if str is expected_type : return value try : parsed_value : Any = parse_raw_as ( expected_type , value ) except ( ValidationError , ValueError ) as err : raise ValueError ( f \"Could not convert config variable: { key } = ' { value } ' \" f \"to type { str ( expected_type ) } , err:\" + str ( err ) ) from err return parsed_value def __getitem__ ( self , key : str ) -> Any : \"\"\"Get the value for the specified key. If the key is not in the configs, then raise KeyError. Args: key: key to be searched. Raises: KeyError: If key is not in found. Returns: Dictionary if the corresponding value is a subsection in the .toml file or a primitive type it is a simple value. \"\"\" value = self . _conf_store . get ( key , None ) if value is None : raise KeyError ( f \"Unknown config name { key } \" ) return value def __contains__ ( self , key : str ) -> bool : \"\"\"Return whether the specified key is in the storage. Args: key: Config variable name. Returns: True if key is in the storage, otherwise returns False. \"\"\" return key in self . _conf_store Functions \u00a4 __contains__ ( key ) \u00a4 Return whether the specified key is in the storage. PARAMETER DESCRIPTION key Config variable name. TYPE: str RETURNS DESCRIPTION bool True if key is in the storage, otherwise returns False. Source code in frequenz/sdk/configs/config.py 152 153 154 155 156 157 158 159 160 161 def __contains__ ( self , key : str ) -> bool : \"\"\"Return whether the specified key is in the storage. Args: key: Config variable name. Returns: True if key is in the storage, otherwise returns False. \"\"\" return key in self . _conf_store __getitem__ ( key ) \u00a4 Get the value for the specified key. If the key is not in the configs, then raise KeyError. PARAMETER DESCRIPTION key key to be searched. TYPE: str RAISES DESCRIPTION KeyError If key is not in found. RETURNS DESCRIPTION Any Dictionary if the corresponding value is a subsection in the .toml file or a primitive type it is a simple value. Source code in frequenz/sdk/configs/config.py 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 def __getitem__ ( self , key : str ) -> Any : \"\"\"Get the value for the specified key. If the key is not in the configs, then raise KeyError. Args: key: key to be searched. Raises: KeyError: If key is not in found. Returns: Dictionary if the corresponding value is a subsection in the .toml file or a primitive type it is a simple value. \"\"\" value = self . _conf_store . get ( key , None ) if value is None : raise KeyError ( f \"Unknown config name { key } \" ) return value __init__ ( conf_vars ) \u00a4 Instantiate the config store and read config variables from the file. PARAMETER DESCRIPTION conf_vars Dict containing configuration variables TYPE: Dict [ str , Any ] Source code in frequenz/sdk/configs/config.py 25 26 27 28 29 30 31 def __init__ ( self , conf_vars : Dict [ str , Any ]): \"\"\"Instantiate the config store and read config variables from the file. Args: conf_vars: Dict containing configuration variables \"\"\" self . _conf_store : Dict [ str , Any ] = conf_vars get ( key , default = None ) \u00a4 Get the value for the specified key. If the key is not in the configs, then return default. PARAMETER DESCRIPTION key Key to be searched. TYPE: str default Value to be returned if the key is not found. Defaults to None. TYPE: Any DEFAULT: None RETURNS DESCRIPTION Any value in str format or default. Source code in frequenz/sdk/configs/config.py 33 34 35 36 37 38 39 40 41 42 43 44 45 46 def get ( self , key : str , default : Any = None ) -> Any : \"\"\"Get the value for the specified key. If the key is not in the configs, then return default. Args: key: Key to be searched. default: Value to be returned if the key is not found. Defaults to None. Returns: value in str format or default. \"\"\" return self . _conf_store . get ( key , default ) get_as ( key , expected_type ) \u00a4 Get and convert the value to specified type. Check if type of the value is as expected. If type is correct, then return converted value. Otherwise Raise ValueError. Type can be Any typing module type. Any pydantic strict types (e.g. pydantic.StrictInt) PARAMETER DESCRIPTION key Key to be search TYPE: str expected_type type for the value TYPE: Any RAISES DESCRIPTION ValueError If can't convert value to the expected type. KeyError If specified key is not in config. RETURNS DESCRIPTION Any Value for the specified key, converted to specified type. Example For var1='[1, 2.0, 3.5]' : * get_as(\"var1\", List[int]) -> [1,2,3] * get_as(\"var1\", List[float]) -> [1.0,2.0,3.5] * get_as(\"var1\", List[pydantic.StrictInt]) -> ValueError * get_as(\"var1\", List[pydantic.StrictFloat]) -> ValueError For var1='[1,2,3]' : * get_as(\"var1\", List[pydantic.StrictInt]) -> [1,2,3] Source code in frequenz/sdk/configs/config.py 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 def get_as ( self , key : str , expected_type : Any ) -> Any : \"\"\"Get and convert the value to specified type. Check if type of the value is as expected. If type is correct, then return converted value. Otherwise Raise ValueError. Type can be: * Any typing module type. * Any pydantic strict types (e.g. pydantic.StrictInt) Args: key: Key to be search expected_type: type for the value Raises: ValueError: If can't convert value to the expected type. KeyError: If specified key is not in config. Returns: Value for the specified key, converted to specified type. Example: For `var1='[1, 2.0, 3.5]'`: * `get_as(\"var1\", List[int])` -> `[1,2,3]` * `get_as(\"var1\", List[float])` -> `[1.0,2.0,3.5]` * `get_as(\"var1\", List[pydantic.StrictInt])` -> [ValueError][] * `get_as(\"var1\", List[pydantic.StrictFloat])` -> [ValueError][] For `var1='[1,2,3]'`: * `get_as(\"var1\", List[pydantic.StrictInt])` -> `[1,2,3]` \"\"\" value = self [ key ] if str is expected_type : return value try : parsed_value : Any = parse_raw_as ( expected_type , value ) except ( ValidationError , ValueError ) as err : raise ValueError ( f \"Could not convert config variable: { key } = ' { value } ' \" f \"to type { str ( expected_type ) } , err:\" + str ( err ) ) from err return parsed_value get_dict ( key_prefix , expected_values_type ) \u00a4 Get a dictionary based on config key prefixes. For example, if key_prefix is \"my_dict\", then the following config store: { 'some_key': 'some_value', 'my_dict_key1': 'value1', 'my_dict_key2': 'value2', } Will return { 'key1': 'value1', 'key2': 'value2', } PARAMETER DESCRIPTION key_prefix Only get configuration variables starting with this prefix. TYPE: str expected_values_type If provided, the value will be validated against this type. TYPE: Optional [ T ] RETURNS DESCRIPTION Dict [ str , Any ] A dictionary containing the keys prefixed with key_prefix as keys (but with the prefix removed) and the values as values. Source code in frequenz/sdk/configs/config.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 def get_dict ( self , key_prefix : str , expected_values_type : Optional [ T ] ) -> Dict [ str , Any ]: \"\"\"Get a dictionary based on config key prefixes. For example, if key_prefix is \"my_dict\", then the following config store: { 'some_key': 'some_value', 'my_dict_key1': 'value1', 'my_dict_key2': 'value2', } Will return: { 'key1': 'value1', 'key2': 'value2', } Args: key_prefix: Only get configuration variables starting with this prefix. expected_values_type: If provided, the value will be validated against this type. Returns: A dictionary containing the keys prefixed with `key_prefix` as keys (but with the prefix removed) and the values as values. \"\"\" result : Dict [ str , Any ] = {} for key , value in self . _conf_store . items (): if key . startswith ( key_prefix ): new_key = key [ len ( key_prefix ) :] if expected_values_type is not None : value = self . get_as ( key , expected_values_type ) result [ new_key ] = value return result","title":"config"},{"location":"reference/frequenz/sdk/configs/config/#frequenz.sdk.configs.config","text":"Read and update config variables.","title":"config"},{"location":"reference/frequenz/sdk/configs/config/#frequenz.sdk.configs.config-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/configs/config/#frequenz.sdk.configs.config.Config","text":"Stores config variables. Config variables are read from a file. Only single file can be read. If new file is read, then previous configs will be forgotten. Source code in frequenz/sdk/configs/config.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 class Config : \"\"\" Stores config variables. Config variables are read from a file. Only single file can be read. If new file is read, then previous configs will be forgotten. \"\"\" def __init__ ( self , conf_vars : Dict [ str , Any ]): \"\"\"Instantiate the config store and read config variables from the file. Args: conf_vars: Dict containing configuration variables \"\"\" self . _conf_store : Dict [ str , Any ] = conf_vars def get ( self , key : str , default : Any = None ) -> Any : \"\"\"Get the value for the specified key. If the key is not in the configs, then return default. Args: key: Key to be searched. default: Value to be returned if the key is not found. Defaults to None. Returns: value in str format or default. \"\"\" return self . _conf_store . get ( key , default ) def get_dict ( self , key_prefix : str , expected_values_type : Optional [ T ] ) -> Dict [ str , Any ]: \"\"\"Get a dictionary based on config key prefixes. For example, if key_prefix is \"my_dict\", then the following config store: { 'some_key': 'some_value', 'my_dict_key1': 'value1', 'my_dict_key2': 'value2', } Will return: { 'key1': 'value1', 'key2': 'value2', } Args: key_prefix: Only get configuration variables starting with this prefix. expected_values_type: If provided, the value will be validated against this type. Returns: A dictionary containing the keys prefixed with `key_prefix` as keys (but with the prefix removed) and the values as values. \"\"\" result : Dict [ str , Any ] = {} for key , value in self . _conf_store . items (): if key . startswith ( key_prefix ): new_key = key [ len ( key_prefix ) :] if expected_values_type is not None : value = self . get_as ( key , expected_values_type ) result [ new_key ] = value return result def get_as ( self , key : str , expected_type : Any ) -> Any : \"\"\"Get and convert the value to specified type. Check if type of the value is as expected. If type is correct, then return converted value. Otherwise Raise ValueError. Type can be: * Any typing module type. * Any pydantic strict types (e.g. pydantic.StrictInt) Args: key: Key to be search expected_type: type for the value Raises: ValueError: If can't convert value to the expected type. KeyError: If specified key is not in config. Returns: Value for the specified key, converted to specified type. Example: For `var1='[1, 2.0, 3.5]'`: * `get_as(\"var1\", List[int])` -> `[1,2,3]` * `get_as(\"var1\", List[float])` -> `[1.0,2.0,3.5]` * `get_as(\"var1\", List[pydantic.StrictInt])` -> [ValueError][] * `get_as(\"var1\", List[pydantic.StrictFloat])` -> [ValueError][] For `var1='[1,2,3]'`: * `get_as(\"var1\", List[pydantic.StrictInt])` -> `[1,2,3]` \"\"\" value = self [ key ] if str is expected_type : return value try : parsed_value : Any = parse_raw_as ( expected_type , value ) except ( ValidationError , ValueError ) as err : raise ValueError ( f \"Could not convert config variable: { key } = ' { value } ' \" f \"to type { str ( expected_type ) } , err:\" + str ( err ) ) from err return parsed_value def __getitem__ ( self , key : str ) -> Any : \"\"\"Get the value for the specified key. If the key is not in the configs, then raise KeyError. Args: key: key to be searched. Raises: KeyError: If key is not in found. Returns: Dictionary if the corresponding value is a subsection in the .toml file or a primitive type it is a simple value. \"\"\" value = self . _conf_store . get ( key , None ) if value is None : raise KeyError ( f \"Unknown config name { key } \" ) return value def __contains__ ( self , key : str ) -> bool : \"\"\"Return whether the specified key is in the storage. Args: key: Config variable name. Returns: True if key is in the storage, otherwise returns False. \"\"\" return key in self . _conf_store","title":"Config"},{"location":"reference/frequenz/sdk/configs/config/#frequenz.sdk.configs.config.Config-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/configs/config/#frequenz.sdk.configs.config.Config.__contains__","text":"Return whether the specified key is in the storage. PARAMETER DESCRIPTION key Config variable name. TYPE: str RETURNS DESCRIPTION bool True if key is in the storage, otherwise returns False. Source code in frequenz/sdk/configs/config.py 152 153 154 155 156 157 158 159 160 161 def __contains__ ( self , key : str ) -> bool : \"\"\"Return whether the specified key is in the storage. Args: key: Config variable name. Returns: True if key is in the storage, otherwise returns False. \"\"\" return key in self . _conf_store","title":"__contains__()"},{"location":"reference/frequenz/sdk/configs/config/#frequenz.sdk.configs.config.Config.__getitem__","text":"Get the value for the specified key. If the key is not in the configs, then raise KeyError. PARAMETER DESCRIPTION key key to be searched. TYPE: str RAISES DESCRIPTION KeyError If key is not in found. RETURNS DESCRIPTION Any Dictionary if the corresponding value is a subsection in the .toml file or a primitive type it is a simple value. Source code in frequenz/sdk/configs/config.py 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 def __getitem__ ( self , key : str ) -> Any : \"\"\"Get the value for the specified key. If the key is not in the configs, then raise KeyError. Args: key: key to be searched. Raises: KeyError: If key is not in found. Returns: Dictionary if the corresponding value is a subsection in the .toml file or a primitive type it is a simple value. \"\"\" value = self . _conf_store . get ( key , None ) if value is None : raise KeyError ( f \"Unknown config name { key } \" ) return value","title":"__getitem__()"},{"location":"reference/frequenz/sdk/configs/config/#frequenz.sdk.configs.config.Config.__init__","text":"Instantiate the config store and read config variables from the file. PARAMETER DESCRIPTION conf_vars Dict containing configuration variables TYPE: Dict [ str , Any ] Source code in frequenz/sdk/configs/config.py 25 26 27 28 29 30 31 def __init__ ( self , conf_vars : Dict [ str , Any ]): \"\"\"Instantiate the config store and read config variables from the file. Args: conf_vars: Dict containing configuration variables \"\"\" self . _conf_store : Dict [ str , Any ] = conf_vars","title":"__init__()"},{"location":"reference/frequenz/sdk/configs/config/#frequenz.sdk.configs.config.Config.get","text":"Get the value for the specified key. If the key is not in the configs, then return default. PARAMETER DESCRIPTION key Key to be searched. TYPE: str default Value to be returned if the key is not found. Defaults to None. TYPE: Any DEFAULT: None RETURNS DESCRIPTION Any value in str format or default. Source code in frequenz/sdk/configs/config.py 33 34 35 36 37 38 39 40 41 42 43 44 45 46 def get ( self , key : str , default : Any = None ) -> Any : \"\"\"Get the value for the specified key. If the key is not in the configs, then return default. Args: key: Key to be searched. default: Value to be returned if the key is not found. Defaults to None. Returns: value in str format or default. \"\"\" return self . _conf_store . get ( key , default )","title":"get()"},{"location":"reference/frequenz/sdk/configs/config/#frequenz.sdk.configs.config.Config.get_as","text":"Get and convert the value to specified type. Check if type of the value is as expected. If type is correct, then return converted value. Otherwise Raise ValueError. Type can be Any typing module type. Any pydantic strict types (e.g. pydantic.StrictInt) PARAMETER DESCRIPTION key Key to be search TYPE: str expected_type type for the value TYPE: Any RAISES DESCRIPTION ValueError If can't convert value to the expected type. KeyError If specified key is not in config. RETURNS DESCRIPTION Any Value for the specified key, converted to specified type. Example For var1='[1, 2.0, 3.5]' : * get_as(\"var1\", List[int]) -> [1,2,3] * get_as(\"var1\", List[float]) -> [1.0,2.0,3.5] * get_as(\"var1\", List[pydantic.StrictInt]) -> ValueError * get_as(\"var1\", List[pydantic.StrictFloat]) -> ValueError For var1='[1,2,3]' : * get_as(\"var1\", List[pydantic.StrictInt]) -> [1,2,3] Source code in frequenz/sdk/configs/config.py 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 def get_as ( self , key : str , expected_type : Any ) -> Any : \"\"\"Get and convert the value to specified type. Check if type of the value is as expected. If type is correct, then return converted value. Otherwise Raise ValueError. Type can be: * Any typing module type. * Any pydantic strict types (e.g. pydantic.StrictInt) Args: key: Key to be search expected_type: type for the value Raises: ValueError: If can't convert value to the expected type. KeyError: If specified key is not in config. Returns: Value for the specified key, converted to specified type. Example: For `var1='[1, 2.0, 3.5]'`: * `get_as(\"var1\", List[int])` -> `[1,2,3]` * `get_as(\"var1\", List[float])` -> `[1.0,2.0,3.5]` * `get_as(\"var1\", List[pydantic.StrictInt])` -> [ValueError][] * `get_as(\"var1\", List[pydantic.StrictFloat])` -> [ValueError][] For `var1='[1,2,3]'`: * `get_as(\"var1\", List[pydantic.StrictInt])` -> `[1,2,3]` \"\"\" value = self [ key ] if str is expected_type : return value try : parsed_value : Any = parse_raw_as ( expected_type , value ) except ( ValidationError , ValueError ) as err : raise ValueError ( f \"Could not convert config variable: { key } = ' { value } ' \" f \"to type { str ( expected_type ) } , err:\" + str ( err ) ) from err return parsed_value","title":"get_as()"},{"location":"reference/frequenz/sdk/configs/config/#frequenz.sdk.configs.config.Config.get_dict","text":"Get a dictionary based on config key prefixes. For example, if key_prefix is \"my_dict\", then the following config store: { 'some_key': 'some_value', 'my_dict_key1': 'value1', 'my_dict_key2': 'value2', } Will return { 'key1': 'value1', 'key2': 'value2', } PARAMETER DESCRIPTION key_prefix Only get configuration variables starting with this prefix. TYPE: str expected_values_type If provided, the value will be validated against this type. TYPE: Optional [ T ] RETURNS DESCRIPTION Dict [ str , Any ] A dictionary containing the keys prefixed with key_prefix as keys (but with the prefix removed) and the values as values. Source code in frequenz/sdk/configs/config.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 def get_dict ( self , key_prefix : str , expected_values_type : Optional [ T ] ) -> Dict [ str , Any ]: \"\"\"Get a dictionary based on config key prefixes. For example, if key_prefix is \"my_dict\", then the following config store: { 'some_key': 'some_value', 'my_dict_key1': 'value1', 'my_dict_key2': 'value2', } Will return: { 'key1': 'value1', 'key2': 'value2', } Args: key_prefix: Only get configuration variables starting with this prefix. expected_values_type: If provided, the value will be validated against this type. Returns: A dictionary containing the keys prefixed with `key_prefix` as keys (but with the prefix removed) and the values as values. \"\"\" result : Dict [ str , Any ] = {} for key , value in self . _conf_store . items (): if key . startswith ( key_prefix ): new_key = key [ len ( key_prefix ) :] if expected_values_type is not None : value = self . get_as ( key , expected_values_type ) result [ new_key ] = value return result","title":"get_dict()"},{"location":"reference/frequenz/sdk/configs/config_manager/","text":"frequenz.sdk.configs.config_manager \u00a4 Read and update config variables. Classes \u00a4 frequenz.sdk.configs.config_manager.ConfigManager \u00a4 Manages config variables. Config variables are read from file. Only single file can be read. If new file is read, then previous configs will be forgotten. Source code in frequenz/sdk/configs/config_manager.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 @actor class ConfigManager : \"\"\" Manages config variables. Config variables are read from file. Only single file can be read. If new file is read, then previous configs will be forgotten. \"\"\" def __init__ ( self , conf_file : str , output : Sender [ Config ], event_types : Optional [ Set [ FileWatcher . EventType ]] = None , ) -> None : \"\"\"Read config variables from the file. Args: conf_file: Path to file with config variables. output: Channel to publish updates to. event_types: Which types of events should update the config and trigger a notification. \"\"\" self . _conf_file : str = conf_file self . _conf_dir : str = os . path . dirname ( conf_file ) self . _file_watcher = FileWatcher ( paths = [ self . _conf_dir ], event_types = event_types ) self . _output = output def _read_config ( self ) -> Dict [ str , Any ]: \"\"\"Read the contents of the config file. Raises: ValueError: if config file cannot be read. Returns: A dictionary containing configuration variables. \"\"\" try : return toml . load ( self . _conf_file ) except ValueError as err : logging . error ( \"Can't read config file, err: %s \" , err ) raise async def send_config ( self ) -> None : \"\"\"Send config file using a broadcast channel.\"\"\" conf_vars = self . _read_config () config = Config ( conf_vars ) await self . _output . send ( config ) async def run ( self ) -> None : \"\"\"Watch config file and update when modified. At startup, the Config Manager sends the current config so that it can be cache in the Broadcast channel and served to receivers even if there hasn't been any change to the config file itself. \"\"\" await self . send_config () async for path in self . _file_watcher : if str ( path ) == self . _conf_file : logger . info ( \"Update configs, because file %s was modified.\" , self . _conf_file , ) await self . send_config () logger . debug ( \"ConfigManager stopped.\" ) Functions \u00a4 __init__ ( conf_file , output , event_types = None ) \u00a4 Read config variables from the file. PARAMETER DESCRIPTION conf_file Path to file with config variables. TYPE: str output Channel to publish updates to. TYPE: Sender [ Config ] event_types Which types of events should update the config and trigger a notification. TYPE: Optional [ Set [ FileWatcher . EventType ]] DEFAULT: None Source code in frequenz/sdk/configs/config_manager.py 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def __init__ ( self , conf_file : str , output : Sender [ Config ], event_types : Optional [ Set [ FileWatcher . EventType ]] = None , ) -> None : \"\"\"Read config variables from the file. Args: conf_file: Path to file with config variables. output: Channel to publish updates to. event_types: Which types of events should update the config and trigger a notification. \"\"\" self . _conf_file : str = conf_file self . _conf_dir : str = os . path . dirname ( conf_file ) self . _file_watcher = FileWatcher ( paths = [ self . _conf_dir ], event_types = event_types ) self . _output = output run () async \u00a4 Watch config file and update when modified. At startup, the Config Manager sends the current config so that it can be cache in the Broadcast channel and served to receivers even if there hasn't been any change to the config file itself. Source code in frequenz/sdk/configs/config_manager.py 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 async def run ( self ) -> None : \"\"\"Watch config file and update when modified. At startup, the Config Manager sends the current config so that it can be cache in the Broadcast channel and served to receivers even if there hasn't been any change to the config file itself. \"\"\" await self . send_config () async for path in self . _file_watcher : if str ( path ) == self . _conf_file : logger . info ( \"Update configs, because file %s was modified.\" , self . _conf_file , ) await self . send_config () logger . debug ( \"ConfigManager stopped.\" ) send_config () async \u00a4 Send config file using a broadcast channel. Source code in frequenz/sdk/configs/config_manager.py 66 67 68 69 70 async def send_config ( self ) -> None : \"\"\"Send config file using a broadcast channel.\"\"\" conf_vars = self . _read_config () config = Config ( conf_vars ) await self . _output . send ( config ) Functions \u00a4","title":"config_manager"},{"location":"reference/frequenz/sdk/configs/config_manager/#frequenz.sdk.configs.config_manager","text":"Read and update config variables.","title":"config_manager"},{"location":"reference/frequenz/sdk/configs/config_manager/#frequenz.sdk.configs.config_manager-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/configs/config_manager/#frequenz.sdk.configs.config_manager.ConfigManager","text":"Manages config variables. Config variables are read from file. Only single file can be read. If new file is read, then previous configs will be forgotten. Source code in frequenz/sdk/configs/config_manager.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 @actor class ConfigManager : \"\"\" Manages config variables. Config variables are read from file. Only single file can be read. If new file is read, then previous configs will be forgotten. \"\"\" def __init__ ( self , conf_file : str , output : Sender [ Config ], event_types : Optional [ Set [ FileWatcher . EventType ]] = None , ) -> None : \"\"\"Read config variables from the file. Args: conf_file: Path to file with config variables. output: Channel to publish updates to. event_types: Which types of events should update the config and trigger a notification. \"\"\" self . _conf_file : str = conf_file self . _conf_dir : str = os . path . dirname ( conf_file ) self . _file_watcher = FileWatcher ( paths = [ self . _conf_dir ], event_types = event_types ) self . _output = output def _read_config ( self ) -> Dict [ str , Any ]: \"\"\"Read the contents of the config file. Raises: ValueError: if config file cannot be read. Returns: A dictionary containing configuration variables. \"\"\" try : return toml . load ( self . _conf_file ) except ValueError as err : logging . error ( \"Can't read config file, err: %s \" , err ) raise async def send_config ( self ) -> None : \"\"\"Send config file using a broadcast channel.\"\"\" conf_vars = self . _read_config () config = Config ( conf_vars ) await self . _output . send ( config ) async def run ( self ) -> None : \"\"\"Watch config file and update when modified. At startup, the Config Manager sends the current config so that it can be cache in the Broadcast channel and served to receivers even if there hasn't been any change to the config file itself. \"\"\" await self . send_config () async for path in self . _file_watcher : if str ( path ) == self . _conf_file : logger . info ( \"Update configs, because file %s was modified.\" , self . _conf_file , ) await self . send_config () logger . debug ( \"ConfigManager stopped.\" )","title":"ConfigManager"},{"location":"reference/frequenz/sdk/configs/config_manager/#frequenz.sdk.configs.config_manager.ConfigManager-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/configs/config_manager/#frequenz.sdk.configs.config_manager.ConfigManager.__init__","text":"Read config variables from the file. PARAMETER DESCRIPTION conf_file Path to file with config variables. TYPE: str output Channel to publish updates to. TYPE: Sender [ Config ] event_types Which types of events should update the config and trigger a notification. TYPE: Optional [ Set [ FileWatcher . EventType ]] DEFAULT: None Source code in frequenz/sdk/configs/config_manager.py 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def __init__ ( self , conf_file : str , output : Sender [ Config ], event_types : Optional [ Set [ FileWatcher . EventType ]] = None , ) -> None : \"\"\"Read config variables from the file. Args: conf_file: Path to file with config variables. output: Channel to publish updates to. event_types: Which types of events should update the config and trigger a notification. \"\"\" self . _conf_file : str = conf_file self . _conf_dir : str = os . path . dirname ( conf_file ) self . _file_watcher = FileWatcher ( paths = [ self . _conf_dir ], event_types = event_types ) self . _output = output","title":"__init__()"},{"location":"reference/frequenz/sdk/configs/config_manager/#frequenz.sdk.configs.config_manager.ConfigManager.run","text":"Watch config file and update when modified. At startup, the Config Manager sends the current config so that it can be cache in the Broadcast channel and served to receivers even if there hasn't been any change to the config file itself. Source code in frequenz/sdk/configs/config_manager.py 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 async def run ( self ) -> None : \"\"\"Watch config file and update when modified. At startup, the Config Manager sends the current config so that it can be cache in the Broadcast channel and served to receivers even if there hasn't been any change to the config file itself. \"\"\" await self . send_config () async for path in self . _file_watcher : if str ( path ) == self . _conf_file : logger . info ( \"Update configs, because file %s was modified.\" , self . _conf_file , ) await self . send_config () logger . debug ( \"ConfigManager stopped.\" )","title":"run()"},{"location":"reference/frequenz/sdk/configs/config_manager/#frequenz.sdk.configs.config_manager.ConfigManager.send_config","text":"Send config file using a broadcast channel. Source code in frequenz/sdk/configs/config_manager.py 66 67 68 69 70 async def send_config ( self ) -> None : \"\"\"Send config file using a broadcast channel.\"\"\" conf_vars = self . _read_config () config = Config ( conf_vars ) await self . _output . send ( config )","title":"send_config()"},{"location":"reference/frequenz/sdk/configs/config_manager/#frequenz.sdk.configs.config_manager-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/data_handling/","text":"frequenz.sdk.data_handling \u00a4 Tools for handling historical data. Classes \u00a4 frequenz.sdk.data_handling.TimeSeriesEntry dataclass \u00a4 Bases: Generic [ Value ] Describes a single observed value (of arbitrary type) at a specific timestamp. Source code in frequenz/sdk/data_handling/time_series.py 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 @dataclass class TimeSeriesEntry ( Generic [ Value ]): \"\"\"Describes a single observed value (of arbitrary type) at a specific timestamp.\"\"\" class Status ( enum . Enum ): \"\"\"Possible status values of a `TimeSeriesEntry`.\"\"\" VALID = \"valid\" UNKNOWN = \"unknown\" ERROR = \"error\" timestamp : datetime value : Optional [ Value ] = None status : Status = Status . VALID broken_component_ids : Set [ int ] = field ( default_factory = set ) @staticmethod def create_error ( timestamp : datetime ) -> TimeSeriesEntry [ Value ]: \"\"\"Create a `TimeSeriesEntry` that contains an error. This can happen when the value would be NaN, e.g. TimeSeriesEntry(value=1 / 0) Args: timestamp: Timestamp Returns: A single observed value (of arbitrary type) at a specific timestamp. \"\"\" return TimeSeriesEntry ( timestamp = timestamp , value = None , status = TimeSeriesEntry . Status . ERROR ) @staticmethod def create_unknown ( timestamp : datetime , broken_component_ids : Optional [ Set [ int ]] = None ) -> TimeSeriesEntry [ Value ]: \"\"\"Create a `TimeSeriesEntry` that contains an unknown value. This can happen when the value cannot be determined, because a component is broken. Args: timestamp: Timestamp broken_component_ids: broken component ids Returns: A single observed value (of arbitrary type) at a specific timestamp. \"\"\" return TimeSeriesEntry ( timestamp = timestamp , value = None , status = TimeSeriesEntry . Status . UNKNOWN , broken_component_ids = broken_component_ids or set (), ) Classes \u00a4 Status \u00a4 Bases: enum . Enum Possible status values of a TimeSeriesEntry . Source code in frequenz/sdk/data_handling/time_series.py 93 94 95 96 97 98 class Status ( enum . Enum ): \"\"\"Possible status values of a `TimeSeriesEntry`.\"\"\" VALID = \"valid\" UNKNOWN = \"unknown\" ERROR = \"error\" Functions \u00a4 create_error ( timestamp ) staticmethod \u00a4 Create a TimeSeriesEntry that contains an error. This can happen when the value would be NaN, e.g. TimeSeriesEntry(value=1 / 0) PARAMETER DESCRIPTION timestamp Timestamp TYPE: datetime RETURNS DESCRIPTION TimeSeriesEntry [ Value ] A single observed value (of arbitrary type) at a specific timestamp. Source code in frequenz/sdk/data_handling/time_series.py 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 @staticmethod def create_error ( timestamp : datetime ) -> TimeSeriesEntry [ Value ]: \"\"\"Create a `TimeSeriesEntry` that contains an error. This can happen when the value would be NaN, e.g. TimeSeriesEntry(value=1 / 0) Args: timestamp: Timestamp Returns: A single observed value (of arbitrary type) at a specific timestamp. \"\"\" return TimeSeriesEntry ( timestamp = timestamp , value = None , status = TimeSeriesEntry . Status . ERROR ) create_unknown ( timestamp , broken_component_ids = None ) staticmethod \u00a4 Create a TimeSeriesEntry that contains an unknown value. This can happen when the value cannot be determined, because a component is broken. PARAMETER DESCRIPTION timestamp Timestamp TYPE: datetime broken_component_ids broken component ids TYPE: Optional [ Set [ int ]] DEFAULT: None RETURNS DESCRIPTION TimeSeriesEntry [ Value ] A single observed value (of arbitrary type) at a specific timestamp. Source code in frequenz/sdk/data_handling/time_series.py 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 @staticmethod def create_unknown ( timestamp : datetime , broken_component_ids : Optional [ Set [ int ]] = None ) -> TimeSeriesEntry [ Value ]: \"\"\"Create a `TimeSeriesEntry` that contains an unknown value. This can happen when the value cannot be determined, because a component is broken. Args: timestamp: Timestamp broken_component_ids: broken component ids Returns: A single observed value (of arbitrary type) at a specific timestamp. \"\"\" return TimeSeriesEntry ( timestamp = timestamp , value = None , status = TimeSeriesEntry . Status . UNKNOWN , broken_component_ids = broken_component_ids or set (), )","title":"data_handling"},{"location":"reference/frequenz/sdk/data_handling/#frequenz.sdk.data_handling","text":"Tools for handling historical data.","title":"data_handling"},{"location":"reference/frequenz/sdk/data_handling/#frequenz.sdk.data_handling-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/data_handling/#frequenz.sdk.data_handling.TimeSeriesEntry","text":"Bases: Generic [ Value ] Describes a single observed value (of arbitrary type) at a specific timestamp. Source code in frequenz/sdk/data_handling/time_series.py 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 @dataclass class TimeSeriesEntry ( Generic [ Value ]): \"\"\"Describes a single observed value (of arbitrary type) at a specific timestamp.\"\"\" class Status ( enum . Enum ): \"\"\"Possible status values of a `TimeSeriesEntry`.\"\"\" VALID = \"valid\" UNKNOWN = \"unknown\" ERROR = \"error\" timestamp : datetime value : Optional [ Value ] = None status : Status = Status . VALID broken_component_ids : Set [ int ] = field ( default_factory = set ) @staticmethod def create_error ( timestamp : datetime ) -> TimeSeriesEntry [ Value ]: \"\"\"Create a `TimeSeriesEntry` that contains an error. This can happen when the value would be NaN, e.g. TimeSeriesEntry(value=1 / 0) Args: timestamp: Timestamp Returns: A single observed value (of arbitrary type) at a specific timestamp. \"\"\" return TimeSeriesEntry ( timestamp = timestamp , value = None , status = TimeSeriesEntry . Status . ERROR ) @staticmethod def create_unknown ( timestamp : datetime , broken_component_ids : Optional [ Set [ int ]] = None ) -> TimeSeriesEntry [ Value ]: \"\"\"Create a `TimeSeriesEntry` that contains an unknown value. This can happen when the value cannot be determined, because a component is broken. Args: timestamp: Timestamp broken_component_ids: broken component ids Returns: A single observed value (of arbitrary type) at a specific timestamp. \"\"\" return TimeSeriesEntry ( timestamp = timestamp , value = None , status = TimeSeriesEntry . Status . UNKNOWN , broken_component_ids = broken_component_ids or set (), )","title":"TimeSeriesEntry"},{"location":"reference/frequenz/sdk/data_handling/#frequenz.sdk.data_handling.TimeSeriesEntry-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/data_handling/#frequenz.sdk.data_handling.time_series.TimeSeriesEntry.Status","text":"Bases: enum . Enum Possible status values of a TimeSeriesEntry . Source code in frequenz/sdk/data_handling/time_series.py 93 94 95 96 97 98 class Status ( enum . Enum ): \"\"\"Possible status values of a `TimeSeriesEntry`.\"\"\" VALID = \"valid\" UNKNOWN = \"unknown\" ERROR = \"error\"","title":"Status"},{"location":"reference/frequenz/sdk/data_handling/#frequenz.sdk.data_handling.TimeSeriesEntry-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/data_handling/#frequenz.sdk.data_handling.time_series.TimeSeriesEntry.create_error","text":"Create a TimeSeriesEntry that contains an error. This can happen when the value would be NaN, e.g. TimeSeriesEntry(value=1 / 0) PARAMETER DESCRIPTION timestamp Timestamp TYPE: datetime RETURNS DESCRIPTION TimeSeriesEntry [ Value ] A single observed value (of arbitrary type) at a specific timestamp. Source code in frequenz/sdk/data_handling/time_series.py 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 @staticmethod def create_error ( timestamp : datetime ) -> TimeSeriesEntry [ Value ]: \"\"\"Create a `TimeSeriesEntry` that contains an error. This can happen when the value would be NaN, e.g. TimeSeriesEntry(value=1 / 0) Args: timestamp: Timestamp Returns: A single observed value (of arbitrary type) at a specific timestamp. \"\"\" return TimeSeriesEntry ( timestamp = timestamp , value = None , status = TimeSeriesEntry . Status . ERROR )","title":"create_error()"},{"location":"reference/frequenz/sdk/data_handling/#frequenz.sdk.data_handling.time_series.TimeSeriesEntry.create_unknown","text":"Create a TimeSeriesEntry that contains an unknown value. This can happen when the value cannot be determined, because a component is broken. PARAMETER DESCRIPTION timestamp Timestamp TYPE: datetime broken_component_ids broken component ids TYPE: Optional [ Set [ int ]] DEFAULT: None RETURNS DESCRIPTION TimeSeriesEntry [ Value ] A single observed value (of arbitrary type) at a specific timestamp. Source code in frequenz/sdk/data_handling/time_series.py 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 @staticmethod def create_unknown ( timestamp : datetime , broken_component_ids : Optional [ Set [ int ]] = None ) -> TimeSeriesEntry [ Value ]: \"\"\"Create a `TimeSeriesEntry` that contains an unknown value. This can happen when the value cannot be determined, because a component is broken. Args: timestamp: Timestamp broken_component_ids: broken component ids Returns: A single observed value (of arbitrary type) at a specific timestamp. \"\"\" return TimeSeriesEntry ( timestamp = timestamp , value = None , status = TimeSeriesEntry . Status . UNKNOWN , broken_component_ids = broken_component_ids or set (), )","title":"create_unknown()"},{"location":"reference/frequenz/sdk/data_handling/formula/","text":"frequenz.sdk.data_handling.formula \u00a4 Helper class for creating custom algebraic formulas from strings or SymPy expressions. Classes \u00a4 frequenz.sdk.data_handling.formula.Formula \u00a4 Simple wrapper class for sympy algebraic expressions. This allows the user to define arbitrary algebraic formulas from string expressions such as \"x + y\" or \"3 * z1 + 0.9 * z2 + 5.0 / z3\". For example, if an application needs a custom formula per deployment (such as how to calculate the grid power from several different meters), this can be used to create that formula from app config. Source code in frequenz/sdk/data_handling/formula.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 class Formula : \"\"\"Simple wrapper class for `sympy` algebraic expressions. This allows the user to define arbitrary algebraic formulas from string expressions such as \"x + y\" or \"3 * z1 + 0.9 * z2 + 5.0 / z3\". For example, if an application needs a custom formula per deployment (such as how to calculate the grid power from several different meters), this can be used to create that formula from app config. \"\"\" def __init__ ( self , formula : Union [ str , sympy . Expr ]) -> None : \"\"\"Initialize the class. Args: formula: formula describing how to combine values from different time series (may be provided either as a string or as a ready-made SymPy expression) Raises: ValueError: if `formula` is not an instance of any of the following types `str`, `sympy.Expr`, `sympy.Tuple` TypeError: if formula symbols are not instances of `sympy.Symbol` or if symbol names are not of type `str` \"\"\" if isinstance ( formula , str ): formula = sympy . parse_expr ( formula ) if not isinstance ( formula , ( sympy . Expr , sympy . Tuple )): raise ValueError ( f \"formula must be provided as str, sympy.Expr or sympy.Tuple, not\" f \" { type ( formula ) } \" ) def symbol_name ( symbol : sympy . Basic ) -> str : if not isinstance ( symbol , sympy . Symbol ): raise TypeError ( f \"Symbol must be of type sympy.Symbol instead of { type ( symbol ) } \" ) if not isinstance ( symbol . name , str ): raise TypeError ( f \"Symbol name must be a string instead of { type ( symbol . name ) } \" ) return symbol . name self . _symbols = set ( map ( symbol_name , formula . free_symbols )) self . _evaluate_formula = sympy . lambdify ( list ( formula . free_symbols ), formula ) @property def symbols ( self ) -> Collection [ str ]: \"\"\"Get the names of all the variables used in the formula. Returns: All the unique symbol names used in the formula. \"\"\" return self . _symbols def __call__ ( self , ** kwargs : Any ) -> Any : \"\"\"Directly evaluate the formula with symbol values provided as `kwargs`. Args: **kwargs: key-value pairs corresponding to the names and values of symbols in the formula (e.g. if the formula is `x + y` then values for `x` and `y` must be provided) Returns: Result of the formula applied to the provided values. \"\"\" return self . _evaluate_formula ( ** kwargs ) Functions \u00a4 __call__ ( ** kwargs ) \u00a4 Directly evaluate the formula with symbol values provided as kwargs . PARAMETER DESCRIPTION **kwargs key-value pairs corresponding to the names and values of symbols in the formula (e.g. if the formula is x + y then values for x and y must be provided) TYPE: Any DEFAULT: {} RETURNS DESCRIPTION Any Result of the formula applied to the provided values. Source code in frequenz/sdk/data_handling/formula.py 67 68 69 70 71 72 73 74 75 76 77 78 def __call__ ( self , ** kwargs : Any ) -> Any : \"\"\"Directly evaluate the formula with symbol values provided as `kwargs`. Args: **kwargs: key-value pairs corresponding to the names and values of symbols in the formula (e.g. if the formula is `x + y` then values for `x` and `y` must be provided) Returns: Result of the formula applied to the provided values. \"\"\" return self . _evaluate_formula ( ** kwargs ) __init__ ( formula ) \u00a4 Initialize the class. PARAMETER DESCRIPTION formula formula describing how to combine values from different time series (may be provided either as a string or as a ready-made SymPy expression) TYPE: Union [ str , sympy . Expr ] RAISES DESCRIPTION ValueError if formula is not an instance of any of the following types str , sympy.Expr , sympy.Tuple TypeError if formula symbols are not instances of sympy.Symbol or if symbol names are not of type str Source code in frequenz/sdk/data_handling/formula.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 def __init__ ( self , formula : Union [ str , sympy . Expr ]) -> None : \"\"\"Initialize the class. Args: formula: formula describing how to combine values from different time series (may be provided either as a string or as a ready-made SymPy expression) Raises: ValueError: if `formula` is not an instance of any of the following types `str`, `sympy.Expr`, `sympy.Tuple` TypeError: if formula symbols are not instances of `sympy.Symbol` or if symbol names are not of type `str` \"\"\" if isinstance ( formula , str ): formula = sympy . parse_expr ( formula ) if not isinstance ( formula , ( sympy . Expr , sympy . Tuple )): raise ValueError ( f \"formula must be provided as str, sympy.Expr or sympy.Tuple, not\" f \" { type ( formula ) } \" ) def symbol_name ( symbol : sympy . Basic ) -> str : if not isinstance ( symbol , sympy . Symbol ): raise TypeError ( f \"Symbol must be of type sympy.Symbol instead of { type ( symbol ) } \" ) if not isinstance ( symbol . name , str ): raise TypeError ( f \"Symbol name must be a string instead of { type ( symbol . name ) } \" ) return symbol . name self . _symbols = set ( map ( symbol_name , formula . free_symbols )) self . _evaluate_formula = sympy . lambdify ( list ( formula . free_symbols ), formula ) symbols () property \u00a4 Get the names of all the variables used in the formula. RETURNS DESCRIPTION Collection [ str ] All the unique symbol names used in the formula. Source code in frequenz/sdk/data_handling/formula.py 58 59 60 61 62 63 64 65 @property def symbols ( self ) -> Collection [ str ]: \"\"\"Get the names of all the variables used in the formula. Returns: All the unique symbol names used in the formula. \"\"\" return self . _symbols","title":"formula"},{"location":"reference/frequenz/sdk/data_handling/formula/#frequenz.sdk.data_handling.formula","text":"Helper class for creating custom algebraic formulas from strings or SymPy expressions.","title":"formula"},{"location":"reference/frequenz/sdk/data_handling/formula/#frequenz.sdk.data_handling.formula-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/data_handling/formula/#frequenz.sdk.data_handling.formula.Formula","text":"Simple wrapper class for sympy algebraic expressions. This allows the user to define arbitrary algebraic formulas from string expressions such as \"x + y\" or \"3 * z1 + 0.9 * z2 + 5.0 / z3\". For example, if an application needs a custom formula per deployment (such as how to calculate the grid power from several different meters), this can be used to create that formula from app config. Source code in frequenz/sdk/data_handling/formula.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 class Formula : \"\"\"Simple wrapper class for `sympy` algebraic expressions. This allows the user to define arbitrary algebraic formulas from string expressions such as \"x + y\" or \"3 * z1 + 0.9 * z2 + 5.0 / z3\". For example, if an application needs a custom formula per deployment (such as how to calculate the grid power from several different meters), this can be used to create that formula from app config. \"\"\" def __init__ ( self , formula : Union [ str , sympy . Expr ]) -> None : \"\"\"Initialize the class. Args: formula: formula describing how to combine values from different time series (may be provided either as a string or as a ready-made SymPy expression) Raises: ValueError: if `formula` is not an instance of any of the following types `str`, `sympy.Expr`, `sympy.Tuple` TypeError: if formula symbols are not instances of `sympy.Symbol` or if symbol names are not of type `str` \"\"\" if isinstance ( formula , str ): formula = sympy . parse_expr ( formula ) if not isinstance ( formula , ( sympy . Expr , sympy . Tuple )): raise ValueError ( f \"formula must be provided as str, sympy.Expr or sympy.Tuple, not\" f \" { type ( formula ) } \" ) def symbol_name ( symbol : sympy . Basic ) -> str : if not isinstance ( symbol , sympy . Symbol ): raise TypeError ( f \"Symbol must be of type sympy.Symbol instead of { type ( symbol ) } \" ) if not isinstance ( symbol . name , str ): raise TypeError ( f \"Symbol name must be a string instead of { type ( symbol . name ) } \" ) return symbol . name self . _symbols = set ( map ( symbol_name , formula . free_symbols )) self . _evaluate_formula = sympy . lambdify ( list ( formula . free_symbols ), formula ) @property def symbols ( self ) -> Collection [ str ]: \"\"\"Get the names of all the variables used in the formula. Returns: All the unique symbol names used in the formula. \"\"\" return self . _symbols def __call__ ( self , ** kwargs : Any ) -> Any : \"\"\"Directly evaluate the formula with symbol values provided as `kwargs`. Args: **kwargs: key-value pairs corresponding to the names and values of symbols in the formula (e.g. if the formula is `x + y` then values for `x` and `y` must be provided) Returns: Result of the formula applied to the provided values. \"\"\" return self . _evaluate_formula ( ** kwargs )","title":"Formula"},{"location":"reference/frequenz/sdk/data_handling/formula/#frequenz.sdk.data_handling.formula.Formula-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/data_handling/formula/#frequenz.sdk.data_handling.formula.Formula.__call__","text":"Directly evaluate the formula with symbol values provided as kwargs . PARAMETER DESCRIPTION **kwargs key-value pairs corresponding to the names and values of symbols in the formula (e.g. if the formula is x + y then values for x and y must be provided) TYPE: Any DEFAULT: {} RETURNS DESCRIPTION Any Result of the formula applied to the provided values. Source code in frequenz/sdk/data_handling/formula.py 67 68 69 70 71 72 73 74 75 76 77 78 def __call__ ( self , ** kwargs : Any ) -> Any : \"\"\"Directly evaluate the formula with symbol values provided as `kwargs`. Args: **kwargs: key-value pairs corresponding to the names and values of symbols in the formula (e.g. if the formula is `x + y` then values for `x` and `y` must be provided) Returns: Result of the formula applied to the provided values. \"\"\" return self . _evaluate_formula ( ** kwargs )","title":"__call__()"},{"location":"reference/frequenz/sdk/data_handling/formula/#frequenz.sdk.data_handling.formula.Formula.__init__","text":"Initialize the class. PARAMETER DESCRIPTION formula formula describing how to combine values from different time series (may be provided either as a string or as a ready-made SymPy expression) TYPE: Union [ str , sympy . Expr ] RAISES DESCRIPTION ValueError if formula is not an instance of any of the following types str , sympy.Expr , sympy.Tuple TypeError if formula symbols are not instances of sympy.Symbol or if symbol names are not of type str Source code in frequenz/sdk/data_handling/formula.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 def __init__ ( self , formula : Union [ str , sympy . Expr ]) -> None : \"\"\"Initialize the class. Args: formula: formula describing how to combine values from different time series (may be provided either as a string or as a ready-made SymPy expression) Raises: ValueError: if `formula` is not an instance of any of the following types `str`, `sympy.Expr`, `sympy.Tuple` TypeError: if formula symbols are not instances of `sympy.Symbol` or if symbol names are not of type `str` \"\"\" if isinstance ( formula , str ): formula = sympy . parse_expr ( formula ) if not isinstance ( formula , ( sympy . Expr , sympy . Tuple )): raise ValueError ( f \"formula must be provided as str, sympy.Expr or sympy.Tuple, not\" f \" { type ( formula ) } \" ) def symbol_name ( symbol : sympy . Basic ) -> str : if not isinstance ( symbol , sympy . Symbol ): raise TypeError ( f \"Symbol must be of type sympy.Symbol instead of { type ( symbol ) } \" ) if not isinstance ( symbol . name , str ): raise TypeError ( f \"Symbol name must be a string instead of { type ( symbol . name ) } \" ) return symbol . name self . _symbols = set ( map ( symbol_name , formula . free_symbols )) self . _evaluate_formula = sympy . lambdify ( list ( formula . free_symbols ), formula )","title":"__init__()"},{"location":"reference/frequenz/sdk/data_handling/formula/#frequenz.sdk.data_handling.formula.Formula.symbols","text":"Get the names of all the variables used in the formula. RETURNS DESCRIPTION Collection [ str ] All the unique symbol names used in the formula. Source code in frequenz/sdk/data_handling/formula.py 58 59 60 61 62 63 64 65 @property def symbols ( self ) -> Collection [ str ]: \"\"\"Get the names of all the variables used in the formula. Returns: All the unique symbol names used in the formula. \"\"\" return self . _symbols","title":"symbols()"},{"location":"reference/frequenz/sdk/data_handling/gen_historic_data_features/","text":"frequenz.sdk.data_handling.gen_historic_data_features \u00a4 Auxiliary functions for generating features when loading historic data. Functions \u00a4 frequenz . sdk . data_handling . gen_historic_data_features . get_active_power ( ac_connection , passive_sign_convention = True ) \u00a4 Extract active power from ac_connection column dictionary. This is an example user-defined feature generating function. PARAMETER DESCRIPTION ac_connection the ac_connection column data read from the parquet files. TYPE: pd . DataFrame passive_sign_convention if True (the default), the active power value will follow the passive sign convention, where a positive value means net consumption, and a negative value means net supply of power; If False , the power value will follow the active sign convention, where a positive value corresponds to net supply, and negative to net consumption. TYPE: bool DEFAULT: True RETURNS DESCRIPTION pd . Series The calculated active power. Source code in frequenz/sdk/data_handling/gen_historic_data_features.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 def get_active_power ( ac_connection : pd . DataFrame , passive_sign_convention : bool = True ) -> pd . Series : \"\"\"Extract active power from ac_connection column dictionary. This is an example user-defined feature generating function. Args: ac_connection: the ac_connection column data read from the parquet files. passive_sign_convention: if `True` (the default), the active power value will follow the passive sign convention, where a positive value means net consumption, and a negative value means net supply of power; If `False`, the power value will follow the active sign convention, where a positive value corresponds to net supply, and negative to net consumption. Returns: The calculated active power. \"\"\" power_sign = 2 * int ( passive_sign_convention ) - 1 active_power = power_sign * ( ac_connection [ \"ac_connection.total_power_active.power_consumption.now\" ] - ac_connection [ \"ac_connection.total_power_active.power_supply.now\" ] ) return active_power frequenz . sdk . data_handling . gen_historic_data_features . get_day_sec ( timestamps ) \u00a4 Extract the second within the day from timestamps. This is an example user-defined feature generating function. PARAMETER DESCRIPTION timestamps the timestamp to extract the current day's seconds from. TYPE: dt . datetime RETURNS DESCRIPTION float Number of seconds since midnight in the given timestamp. Source code in frequenz/sdk/data_handling/gen_historic_data_features.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 def get_day_sec ( timestamps : dt . datetime ) -> float : \"\"\"Extract the second within the day from timestamps. This is an example user-defined feature generating function. Args: timestamps: the timestamp to extract the current day's seconds from. Returns: Number of seconds since midnight in the given timestamp. \"\"\" pd_ts : pd . Timestamp = pd . to_datetime ( timestamps ) day_sec : float = ( pd_ts . hour * 3600 + pd_ts . minute * 60 + pd_ts . second + pd_ts . microsecond / 1e6 ) return day_sec","title":"gen_historic_data_features"},{"location":"reference/frequenz/sdk/data_handling/gen_historic_data_features/#frequenz.sdk.data_handling.gen_historic_data_features","text":"Auxiliary functions for generating features when loading historic data.","title":"gen_historic_data_features"},{"location":"reference/frequenz/sdk/data_handling/gen_historic_data_features/#frequenz.sdk.data_handling.gen_historic_data_features-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/data_handling/gen_historic_data_features/#frequenz.sdk.data_handling.gen_historic_data_features.get_active_power","text":"Extract active power from ac_connection column dictionary. This is an example user-defined feature generating function. PARAMETER DESCRIPTION ac_connection the ac_connection column data read from the parquet files. TYPE: pd . DataFrame passive_sign_convention if True (the default), the active power value will follow the passive sign convention, where a positive value means net consumption, and a negative value means net supply of power; If False , the power value will follow the active sign convention, where a positive value corresponds to net supply, and negative to net consumption. TYPE: bool DEFAULT: True RETURNS DESCRIPTION pd . Series The calculated active power. Source code in frequenz/sdk/data_handling/gen_historic_data_features.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 def get_active_power ( ac_connection : pd . DataFrame , passive_sign_convention : bool = True ) -> pd . Series : \"\"\"Extract active power from ac_connection column dictionary. This is an example user-defined feature generating function. Args: ac_connection: the ac_connection column data read from the parquet files. passive_sign_convention: if `True` (the default), the active power value will follow the passive sign convention, where a positive value means net consumption, and a negative value means net supply of power; If `False`, the power value will follow the active sign convention, where a positive value corresponds to net supply, and negative to net consumption. Returns: The calculated active power. \"\"\" power_sign = 2 * int ( passive_sign_convention ) - 1 active_power = power_sign * ( ac_connection [ \"ac_connection.total_power_active.power_consumption.now\" ] - ac_connection [ \"ac_connection.total_power_active.power_supply.now\" ] ) return active_power","title":"get_active_power()"},{"location":"reference/frequenz/sdk/data_handling/gen_historic_data_features/#frequenz.sdk.data_handling.gen_historic_data_features.get_day_sec","text":"Extract the second within the day from timestamps. This is an example user-defined feature generating function. PARAMETER DESCRIPTION timestamps the timestamp to extract the current day's seconds from. TYPE: dt . datetime RETURNS DESCRIPTION float Number of seconds since midnight in the given timestamp. Source code in frequenz/sdk/data_handling/gen_historic_data_features.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 def get_day_sec ( timestamps : dt . datetime ) -> float : \"\"\"Extract the second within the day from timestamps. This is an example user-defined feature generating function. Args: timestamps: the timestamp to extract the current day's seconds from. Returns: Number of seconds since midnight in the given timestamp. \"\"\" pd_ts : pd . Timestamp = pd . to_datetime ( timestamps ) day_sec : float = ( pd_ts . hour * 3600 + pd_ts . minute * 60 + pd_ts . second + pd_ts . microsecond / 1e6 ) return day_sec","title":"get_day_sec()"},{"location":"reference/frequenz/sdk/data_handling/handle_historic_data/","text":"frequenz.sdk.data_handling.handle_historic_data \u00a4 Module for handling loaded historic data from different components. Object for computing aggregate quantities from multiple components as data are loaded. Classes \u00a4 frequenz.sdk.data_handling.handle_historic_data.HandleHistData \u00a4 Object for computing aggregate quantities from historic data of multiple components. Aggregation of multiple components are done through the Formula() implementation. Source code in frequenz/sdk/data_handling/handle_historic_data.py 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 class HandleHistData : \"\"\"Object for computing aggregate quantities from historic data of multiple components. Aggregation of multiple components are done through the Formula() implementation. \"\"\" def __init__ ( self , messstellen_id : int , hd_handler_settings : HandleHistDataSettings , ignore_faulty_files : bool = True , ) -> None : \"\"\"Initialise `HandleHistData` instance. Args: messstellen_id: id of site hd_handler_settings: settings for handling multi- component historic data. ignore_faulty_files: mode for handling faulty files. When True: individual faulty file will be ignored. The reader will print out an error message but continue to read other files within the specified time range. When False: once the reader encounters a faulty file, the whole reader will be stopped and an error will be raised. Raises: ValueError: when multiple loaders are specified for one component ValueError: when a symbol is defined multiple times in hd_handler_settings.symbol_mappings KeyError: when any symbol used in the formulas are not defined in hd_handler_settings.symbol_mappings \"\"\" self . hd_loaders = { hdl . component_info . component_id : hdl for hdl in hd_handler_settings . hd_loaders } if len ( self . hd_loaders . keys ()) < len ( hd_handler_settings . hd_loaders ): raise ValueError ( \"Use only one LoadHistoricDataSettings object for each component.\" ) self . hd_formulas = hd_handler_settings . hd_formulas symbols = [ hdf . symbols for hdf in self . hd_formulas . values ()] symbols = list ({ sym for syms in symbols for sym in syms }) shdm_symbols = [ shdm . symbol for shdm in hd_handler_settings . symbol_mappings ] if len ( set ( shdm_symbols )) < len ( shdm_symbols ): raise ValueError ( \"Each symbol should have an unique definition.\" ) sym_undefined = [ sym for sym in symbols if sym not in shdm_symbols ] if len ( sym_undefined ) > 0 : raise KeyError ( f \"Symbol(s) { sym_undefined } used in formula(s) not defined.\" ) self . symbol_mappings = hd_handler_settings . symbol_mappings self . load_historic_data = LoadHistoricData ( messstellen_id , ignore_faulty_files = ignore_faulty_files ) def load_compute_formula ( self , start_time : dt . datetime , end_time : dt . datetime , data_sampling_rate : str = \"1S\" , ) -> pd . DataFrame : \"\"\"Load necessary data to compute specified quantities in `hd_formulas`. Args: start_time: starting time of time period over which to load historic data. end_time: ending time of time period over which to load historic data. data_sampling_rate: the rate at which to resample the data; following pandas resampling convention. Returns: Resultant dataframe with columns timestamp and individual columns for each of the specified `Formula()`s between start_time and end_time. \"\"\" dfs_hist0 = [] for hdl in self . hd_loaders : df_hist = self . load_historic_data . read ( self . hd_loaders [ hdl ], start_time , end_time ) if len ( df_hist ) > 0 : dfs_hist0 . append ( df_hist . rename ( columns = { col : col + \"_\" + str ( hdl ) for col in df_hist . columns if col != \"timestamp\" } ) ) res = {} if len ( dfs_hist0 ) > 0 : df_hist0 = ( reduce ( lambda df1 , df2 : pd . merge ( df1 , df2 , on = \"timestamp\" , how = \"outer\" , ), dfs_hist0 , ) . drop_duplicates ( subset = [ \"timestamp\" ]) . set_index ( \"timestamp\" ) . resample ( data_sampling_rate ) . mean () . reset_index () ) df_hist0 = df_hist0 . rename ( columns = { shdm . field + \"_\" + str ( shdm . component_id ): shdm . symbol for shdm in self . symbol_mappings } ) res [ \"timestamp\" ] = df_hist0 . timestamp for hdf in self . hd_formulas : if all ( s in df_hist0 . columns for s in self . hd_formulas [ hdf ] . symbols ): args = { s : np . array ( df_hist0 [ s ]) for s in self . hd_formulas [ hdf ] . symbols } res [ hdf ] = self . hd_formulas [ hdf ]( ** args ) if len ( res . keys ()) > 1 : df_res = pd . DataFrame ( res ) else : df_res = pd . DataFrame () return df_res def compute ( self , start_time : dt . datetime , end_time : dt . datetime , data_sampling_rate : str = \"1S\" , read_freq : dt . timedelta = dt . timedelta ( days = 1 ), ) -> pd . DataFrame : \"\"\"Load and compute the specified quantities in the formulas. Args: start_time: starting time from which to load historic data. end_time: ending time up till which to load historic data. data_sampling_rate: the rate at which to resample the data; following pandas resampling convention. read_freq: load individual component data per this specified rate before computing the fomula. Returns: Result data frame with columns timestamp and individual columns for each of the specified quantities from the hd_formulas \"\"\" res : Dict [ str , Any ] = { \"timestamp\" : []} for hdf in self . hd_formulas : res [ hdf ] = [] df_res = pd . DataFrame ( res ) start_time0 = start_time end_time0 = min ( start_time0 + read_freq , end_time ) while start_time0 < end_time : df_res0 = self . load_compute_formula ( start_time0 , end_time0 , data_sampling_rate = data_sampling_rate ) df_res = df_res . append ( df_res0 ) start_time0 = end_time0 end_time0 = min ( start_time0 + read_freq , end_time ) df_res [ \"timestamp\" ] = pd . to_datetime ( df_res . timestamp , utc = True ) return df_res Functions \u00a4 __init__ ( messstellen_id , hd_handler_settings , ignore_faulty_files = True ) \u00a4 Initialise HandleHistData instance. PARAMETER DESCRIPTION messstellen_id id of site TYPE: int hd_handler_settings settings for handling multi- component historic data. TYPE: HandleHistDataSettings ignore_faulty_files mode for handling faulty files. When True: individual faulty file will be ignored. The reader will print out an error message but continue to read other files within the specified time range. When False: once the reader encounters a faulty file, the whole reader will be stopped and an error will be raised. TYPE: bool DEFAULT: True RAISES DESCRIPTION ValueError when multiple loaders are specified for one component ValueError when a symbol is defined multiple times in hd_handler_settings.symbol_mappings KeyError when any symbol used in the formulas are not defined in hd_handler_settings.symbol_mappings Source code in frequenz/sdk/data_handling/handle_historic_data.py 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 def __init__ ( self , messstellen_id : int , hd_handler_settings : HandleHistDataSettings , ignore_faulty_files : bool = True , ) -> None : \"\"\"Initialise `HandleHistData` instance. Args: messstellen_id: id of site hd_handler_settings: settings for handling multi- component historic data. ignore_faulty_files: mode for handling faulty files. When True: individual faulty file will be ignored. The reader will print out an error message but continue to read other files within the specified time range. When False: once the reader encounters a faulty file, the whole reader will be stopped and an error will be raised. Raises: ValueError: when multiple loaders are specified for one component ValueError: when a symbol is defined multiple times in hd_handler_settings.symbol_mappings KeyError: when any symbol used in the formulas are not defined in hd_handler_settings.symbol_mappings \"\"\" self . hd_loaders = { hdl . component_info . component_id : hdl for hdl in hd_handler_settings . hd_loaders } if len ( self . hd_loaders . keys ()) < len ( hd_handler_settings . hd_loaders ): raise ValueError ( \"Use only one LoadHistoricDataSettings object for each component.\" ) self . hd_formulas = hd_handler_settings . hd_formulas symbols = [ hdf . symbols for hdf in self . hd_formulas . values ()] symbols = list ({ sym for syms in symbols for sym in syms }) shdm_symbols = [ shdm . symbol for shdm in hd_handler_settings . symbol_mappings ] if len ( set ( shdm_symbols )) < len ( shdm_symbols ): raise ValueError ( \"Each symbol should have an unique definition.\" ) sym_undefined = [ sym for sym in symbols if sym not in shdm_symbols ] if len ( sym_undefined ) > 0 : raise KeyError ( f \"Symbol(s) { sym_undefined } used in formula(s) not defined.\" ) self . symbol_mappings = hd_handler_settings . symbol_mappings self . load_historic_data = LoadHistoricData ( messstellen_id , ignore_faulty_files = ignore_faulty_files ) compute ( start_time , end_time , data_sampling_rate = '1S' , read_freq = dt . timedelta ( days = 1 )) \u00a4 Load and compute the specified quantities in the formulas. PARAMETER DESCRIPTION start_time starting time from which to load historic data. TYPE: dt . datetime end_time ending time up till which to load historic data. TYPE: dt . datetime data_sampling_rate the rate at which to resample the data; following pandas resampling convention. TYPE: str DEFAULT: '1S' read_freq load individual component data per this specified rate before computing the fomula. TYPE: dt . timedelta DEFAULT: dt.timedelta(days=1) RETURNS DESCRIPTION pd . DataFrame Result data frame with columns timestamp and individual columns for each of the specified quantities from the hd_formulas Source code in frequenz/sdk/data_handling/handle_historic_data.py 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 def compute ( self , start_time : dt . datetime , end_time : dt . datetime , data_sampling_rate : str = \"1S\" , read_freq : dt . timedelta = dt . timedelta ( days = 1 ), ) -> pd . DataFrame : \"\"\"Load and compute the specified quantities in the formulas. Args: start_time: starting time from which to load historic data. end_time: ending time up till which to load historic data. data_sampling_rate: the rate at which to resample the data; following pandas resampling convention. read_freq: load individual component data per this specified rate before computing the fomula. Returns: Result data frame with columns timestamp and individual columns for each of the specified quantities from the hd_formulas \"\"\" res : Dict [ str , Any ] = { \"timestamp\" : []} for hdf in self . hd_formulas : res [ hdf ] = [] df_res = pd . DataFrame ( res ) start_time0 = start_time end_time0 = min ( start_time0 + read_freq , end_time ) while start_time0 < end_time : df_res0 = self . load_compute_formula ( start_time0 , end_time0 , data_sampling_rate = data_sampling_rate ) df_res = df_res . append ( df_res0 ) start_time0 = end_time0 end_time0 = min ( start_time0 + read_freq , end_time ) df_res [ \"timestamp\" ] = pd . to_datetime ( df_res . timestamp , utc = True ) return df_res load_compute_formula ( start_time , end_time , data_sampling_rate = '1S' ) \u00a4 Load necessary data to compute specified quantities in hd_formulas . PARAMETER DESCRIPTION start_time starting time of time period over which to load historic data. TYPE: dt . datetime end_time ending time of time period over which to load historic data. TYPE: dt . datetime data_sampling_rate the rate at which to resample the data; following pandas resampling convention. TYPE: str DEFAULT: '1S' RETURNS DESCRIPTION pd . DataFrame Resultant dataframe with columns timestamp and individual columns for each of the specified Formula() s between start_time and end_time. Source code in frequenz/sdk/data_handling/handle_historic_data.py 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 def load_compute_formula ( self , start_time : dt . datetime , end_time : dt . datetime , data_sampling_rate : str = \"1S\" , ) -> pd . DataFrame : \"\"\"Load necessary data to compute specified quantities in `hd_formulas`. Args: start_time: starting time of time period over which to load historic data. end_time: ending time of time period over which to load historic data. data_sampling_rate: the rate at which to resample the data; following pandas resampling convention. Returns: Resultant dataframe with columns timestamp and individual columns for each of the specified `Formula()`s between start_time and end_time. \"\"\" dfs_hist0 = [] for hdl in self . hd_loaders : df_hist = self . load_historic_data . read ( self . hd_loaders [ hdl ], start_time , end_time ) if len ( df_hist ) > 0 : dfs_hist0 . append ( df_hist . rename ( columns = { col : col + \"_\" + str ( hdl ) for col in df_hist . columns if col != \"timestamp\" } ) ) res = {} if len ( dfs_hist0 ) > 0 : df_hist0 = ( reduce ( lambda df1 , df2 : pd . merge ( df1 , df2 , on = \"timestamp\" , how = \"outer\" , ), dfs_hist0 , ) . drop_duplicates ( subset = [ \"timestamp\" ]) . set_index ( \"timestamp\" ) . resample ( data_sampling_rate ) . mean () . reset_index () ) df_hist0 = df_hist0 . rename ( columns = { shdm . field + \"_\" + str ( shdm . component_id ): shdm . symbol for shdm in self . symbol_mappings } ) res [ \"timestamp\" ] = df_hist0 . timestamp for hdf in self . hd_formulas : if all ( s in df_hist0 . columns for s in self . hd_formulas [ hdf ] . symbols ): args = { s : np . array ( df_hist0 [ s ]) for s in self . hd_formulas [ hdf ] . symbols } res [ hdf ] = self . hd_formulas [ hdf ]( ** args ) if len ( res . keys ()) > 1 : df_res = pd . DataFrame ( res ) else : df_res = pd . DataFrame () return df_res frequenz.sdk.data_handling.handle_historic_data.HandleHistDataSettings \u00a4 Bases: NamedTuple Settings for handling multi-component historic data. Source code in frequenz/sdk/data_handling/handle_historic_data.py 34 35 36 37 38 39 40 41 42 43 class HandleHistDataSettings ( NamedTuple ): \"\"\"Settings for handling multi-component historic data.\"\"\" # loaders of historic data, specifying which component and which columns of # the parquet files to load hd_loaders : List [ LoadHistoricDataSettings ] # formulas with which to calculate the aggregated quantities with hd_formulas : Dict [ str , Formula ] # mappings between fomula symbols and loaded historic data symbol_mappings : List [ SymbolMapping ] frequenz.sdk.data_handling.handle_historic_data.SymbolMapping \u00a4 Bases: NamedTuple Mappings between fomula symbols and loaded historic data. Source code in frequenz/sdk/data_handling/handle_historic_data.py 23 24 25 26 27 28 29 30 31 class SymbolMapping ( NamedTuple ): \"\"\"Mappings between fomula symbols and loaded historic data.\"\"\" # name of the symbol for which the mapping is defined for symbol : str # component id component_id : int # name of column of the loaded historic dataframe corresponding to the symbol field : str","title":"handle_historic_data"},{"location":"reference/frequenz/sdk/data_handling/handle_historic_data/#frequenz.sdk.data_handling.handle_historic_data","text":"Module for handling loaded historic data from different components. Object for computing aggregate quantities from multiple components as data are loaded.","title":"handle_historic_data"},{"location":"reference/frequenz/sdk/data_handling/handle_historic_data/#frequenz.sdk.data_handling.handle_historic_data-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/data_handling/handle_historic_data/#frequenz.sdk.data_handling.handle_historic_data.HandleHistData","text":"Object for computing aggregate quantities from historic data of multiple components. Aggregation of multiple components are done through the Formula() implementation. Source code in frequenz/sdk/data_handling/handle_historic_data.py 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 class HandleHistData : \"\"\"Object for computing aggregate quantities from historic data of multiple components. Aggregation of multiple components are done through the Formula() implementation. \"\"\" def __init__ ( self , messstellen_id : int , hd_handler_settings : HandleHistDataSettings , ignore_faulty_files : bool = True , ) -> None : \"\"\"Initialise `HandleHistData` instance. Args: messstellen_id: id of site hd_handler_settings: settings for handling multi- component historic data. ignore_faulty_files: mode for handling faulty files. When True: individual faulty file will be ignored. The reader will print out an error message but continue to read other files within the specified time range. When False: once the reader encounters a faulty file, the whole reader will be stopped and an error will be raised. Raises: ValueError: when multiple loaders are specified for one component ValueError: when a symbol is defined multiple times in hd_handler_settings.symbol_mappings KeyError: when any symbol used in the formulas are not defined in hd_handler_settings.symbol_mappings \"\"\" self . hd_loaders = { hdl . component_info . component_id : hdl for hdl in hd_handler_settings . hd_loaders } if len ( self . hd_loaders . keys ()) < len ( hd_handler_settings . hd_loaders ): raise ValueError ( \"Use only one LoadHistoricDataSettings object for each component.\" ) self . hd_formulas = hd_handler_settings . hd_formulas symbols = [ hdf . symbols for hdf in self . hd_formulas . values ()] symbols = list ({ sym for syms in symbols for sym in syms }) shdm_symbols = [ shdm . symbol for shdm in hd_handler_settings . symbol_mappings ] if len ( set ( shdm_symbols )) < len ( shdm_symbols ): raise ValueError ( \"Each symbol should have an unique definition.\" ) sym_undefined = [ sym for sym in symbols if sym not in shdm_symbols ] if len ( sym_undefined ) > 0 : raise KeyError ( f \"Symbol(s) { sym_undefined } used in formula(s) not defined.\" ) self . symbol_mappings = hd_handler_settings . symbol_mappings self . load_historic_data = LoadHistoricData ( messstellen_id , ignore_faulty_files = ignore_faulty_files ) def load_compute_formula ( self , start_time : dt . datetime , end_time : dt . datetime , data_sampling_rate : str = \"1S\" , ) -> pd . DataFrame : \"\"\"Load necessary data to compute specified quantities in `hd_formulas`. Args: start_time: starting time of time period over which to load historic data. end_time: ending time of time period over which to load historic data. data_sampling_rate: the rate at which to resample the data; following pandas resampling convention. Returns: Resultant dataframe with columns timestamp and individual columns for each of the specified `Formula()`s between start_time and end_time. \"\"\" dfs_hist0 = [] for hdl in self . hd_loaders : df_hist = self . load_historic_data . read ( self . hd_loaders [ hdl ], start_time , end_time ) if len ( df_hist ) > 0 : dfs_hist0 . append ( df_hist . rename ( columns = { col : col + \"_\" + str ( hdl ) for col in df_hist . columns if col != \"timestamp\" } ) ) res = {} if len ( dfs_hist0 ) > 0 : df_hist0 = ( reduce ( lambda df1 , df2 : pd . merge ( df1 , df2 , on = \"timestamp\" , how = \"outer\" , ), dfs_hist0 , ) . drop_duplicates ( subset = [ \"timestamp\" ]) . set_index ( \"timestamp\" ) . resample ( data_sampling_rate ) . mean () . reset_index () ) df_hist0 = df_hist0 . rename ( columns = { shdm . field + \"_\" + str ( shdm . component_id ): shdm . symbol for shdm in self . symbol_mappings } ) res [ \"timestamp\" ] = df_hist0 . timestamp for hdf in self . hd_formulas : if all ( s in df_hist0 . columns for s in self . hd_formulas [ hdf ] . symbols ): args = { s : np . array ( df_hist0 [ s ]) for s in self . hd_formulas [ hdf ] . symbols } res [ hdf ] = self . hd_formulas [ hdf ]( ** args ) if len ( res . keys ()) > 1 : df_res = pd . DataFrame ( res ) else : df_res = pd . DataFrame () return df_res def compute ( self , start_time : dt . datetime , end_time : dt . datetime , data_sampling_rate : str = \"1S\" , read_freq : dt . timedelta = dt . timedelta ( days = 1 ), ) -> pd . DataFrame : \"\"\"Load and compute the specified quantities in the formulas. Args: start_time: starting time from which to load historic data. end_time: ending time up till which to load historic data. data_sampling_rate: the rate at which to resample the data; following pandas resampling convention. read_freq: load individual component data per this specified rate before computing the fomula. Returns: Result data frame with columns timestamp and individual columns for each of the specified quantities from the hd_formulas \"\"\" res : Dict [ str , Any ] = { \"timestamp\" : []} for hdf in self . hd_formulas : res [ hdf ] = [] df_res = pd . DataFrame ( res ) start_time0 = start_time end_time0 = min ( start_time0 + read_freq , end_time ) while start_time0 < end_time : df_res0 = self . load_compute_formula ( start_time0 , end_time0 , data_sampling_rate = data_sampling_rate ) df_res = df_res . append ( df_res0 ) start_time0 = end_time0 end_time0 = min ( start_time0 + read_freq , end_time ) df_res [ \"timestamp\" ] = pd . to_datetime ( df_res . timestamp , utc = True ) return df_res","title":"HandleHistData"},{"location":"reference/frequenz/sdk/data_handling/handle_historic_data/#frequenz.sdk.data_handling.handle_historic_data.HandleHistData-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/data_handling/handle_historic_data/#frequenz.sdk.data_handling.handle_historic_data.HandleHistData.__init__","text":"Initialise HandleHistData instance. PARAMETER DESCRIPTION messstellen_id id of site TYPE: int hd_handler_settings settings for handling multi- component historic data. TYPE: HandleHistDataSettings ignore_faulty_files mode for handling faulty files. When True: individual faulty file will be ignored. The reader will print out an error message but continue to read other files within the specified time range. When False: once the reader encounters a faulty file, the whole reader will be stopped and an error will be raised. TYPE: bool DEFAULT: True RAISES DESCRIPTION ValueError when multiple loaders are specified for one component ValueError when a symbol is defined multiple times in hd_handler_settings.symbol_mappings KeyError when any symbol used in the formulas are not defined in hd_handler_settings.symbol_mappings Source code in frequenz/sdk/data_handling/handle_historic_data.py 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 def __init__ ( self , messstellen_id : int , hd_handler_settings : HandleHistDataSettings , ignore_faulty_files : bool = True , ) -> None : \"\"\"Initialise `HandleHistData` instance. Args: messstellen_id: id of site hd_handler_settings: settings for handling multi- component historic data. ignore_faulty_files: mode for handling faulty files. When True: individual faulty file will be ignored. The reader will print out an error message but continue to read other files within the specified time range. When False: once the reader encounters a faulty file, the whole reader will be stopped and an error will be raised. Raises: ValueError: when multiple loaders are specified for one component ValueError: when a symbol is defined multiple times in hd_handler_settings.symbol_mappings KeyError: when any symbol used in the formulas are not defined in hd_handler_settings.symbol_mappings \"\"\" self . hd_loaders = { hdl . component_info . component_id : hdl for hdl in hd_handler_settings . hd_loaders } if len ( self . hd_loaders . keys ()) < len ( hd_handler_settings . hd_loaders ): raise ValueError ( \"Use only one LoadHistoricDataSettings object for each component.\" ) self . hd_formulas = hd_handler_settings . hd_formulas symbols = [ hdf . symbols for hdf in self . hd_formulas . values ()] symbols = list ({ sym for syms in symbols for sym in syms }) shdm_symbols = [ shdm . symbol for shdm in hd_handler_settings . symbol_mappings ] if len ( set ( shdm_symbols )) < len ( shdm_symbols ): raise ValueError ( \"Each symbol should have an unique definition.\" ) sym_undefined = [ sym for sym in symbols if sym not in shdm_symbols ] if len ( sym_undefined ) > 0 : raise KeyError ( f \"Symbol(s) { sym_undefined } used in formula(s) not defined.\" ) self . symbol_mappings = hd_handler_settings . symbol_mappings self . load_historic_data = LoadHistoricData ( messstellen_id , ignore_faulty_files = ignore_faulty_files )","title":"__init__()"},{"location":"reference/frequenz/sdk/data_handling/handle_historic_data/#frequenz.sdk.data_handling.handle_historic_data.HandleHistData.compute","text":"Load and compute the specified quantities in the formulas. PARAMETER DESCRIPTION start_time starting time from which to load historic data. TYPE: dt . datetime end_time ending time up till which to load historic data. TYPE: dt . datetime data_sampling_rate the rate at which to resample the data; following pandas resampling convention. TYPE: str DEFAULT: '1S' read_freq load individual component data per this specified rate before computing the fomula. TYPE: dt . timedelta DEFAULT: dt.timedelta(days=1) RETURNS DESCRIPTION pd . DataFrame Result data frame with columns timestamp and individual columns for each of the specified quantities from the hd_formulas Source code in frequenz/sdk/data_handling/handle_historic_data.py 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 def compute ( self , start_time : dt . datetime , end_time : dt . datetime , data_sampling_rate : str = \"1S\" , read_freq : dt . timedelta = dt . timedelta ( days = 1 ), ) -> pd . DataFrame : \"\"\"Load and compute the specified quantities in the formulas. Args: start_time: starting time from which to load historic data. end_time: ending time up till which to load historic data. data_sampling_rate: the rate at which to resample the data; following pandas resampling convention. read_freq: load individual component data per this specified rate before computing the fomula. Returns: Result data frame with columns timestamp and individual columns for each of the specified quantities from the hd_formulas \"\"\" res : Dict [ str , Any ] = { \"timestamp\" : []} for hdf in self . hd_formulas : res [ hdf ] = [] df_res = pd . DataFrame ( res ) start_time0 = start_time end_time0 = min ( start_time0 + read_freq , end_time ) while start_time0 < end_time : df_res0 = self . load_compute_formula ( start_time0 , end_time0 , data_sampling_rate = data_sampling_rate ) df_res = df_res . append ( df_res0 ) start_time0 = end_time0 end_time0 = min ( start_time0 + read_freq , end_time ) df_res [ \"timestamp\" ] = pd . to_datetime ( df_res . timestamp , utc = True ) return df_res","title":"compute()"},{"location":"reference/frequenz/sdk/data_handling/handle_historic_data/#frequenz.sdk.data_handling.handle_historic_data.HandleHistData.load_compute_formula","text":"Load necessary data to compute specified quantities in hd_formulas . PARAMETER DESCRIPTION start_time starting time of time period over which to load historic data. TYPE: dt . datetime end_time ending time of time period over which to load historic data. TYPE: dt . datetime data_sampling_rate the rate at which to resample the data; following pandas resampling convention. TYPE: str DEFAULT: '1S' RETURNS DESCRIPTION pd . DataFrame Resultant dataframe with columns timestamp and individual columns for each of the specified Formula() s between start_time and end_time. Source code in frequenz/sdk/data_handling/handle_historic_data.py 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 def load_compute_formula ( self , start_time : dt . datetime , end_time : dt . datetime , data_sampling_rate : str = \"1S\" , ) -> pd . DataFrame : \"\"\"Load necessary data to compute specified quantities in `hd_formulas`. Args: start_time: starting time of time period over which to load historic data. end_time: ending time of time period over which to load historic data. data_sampling_rate: the rate at which to resample the data; following pandas resampling convention. Returns: Resultant dataframe with columns timestamp and individual columns for each of the specified `Formula()`s between start_time and end_time. \"\"\" dfs_hist0 = [] for hdl in self . hd_loaders : df_hist = self . load_historic_data . read ( self . hd_loaders [ hdl ], start_time , end_time ) if len ( df_hist ) > 0 : dfs_hist0 . append ( df_hist . rename ( columns = { col : col + \"_\" + str ( hdl ) for col in df_hist . columns if col != \"timestamp\" } ) ) res = {} if len ( dfs_hist0 ) > 0 : df_hist0 = ( reduce ( lambda df1 , df2 : pd . merge ( df1 , df2 , on = \"timestamp\" , how = \"outer\" , ), dfs_hist0 , ) . drop_duplicates ( subset = [ \"timestamp\" ]) . set_index ( \"timestamp\" ) . resample ( data_sampling_rate ) . mean () . reset_index () ) df_hist0 = df_hist0 . rename ( columns = { shdm . field + \"_\" + str ( shdm . component_id ): shdm . symbol for shdm in self . symbol_mappings } ) res [ \"timestamp\" ] = df_hist0 . timestamp for hdf in self . hd_formulas : if all ( s in df_hist0 . columns for s in self . hd_formulas [ hdf ] . symbols ): args = { s : np . array ( df_hist0 [ s ]) for s in self . hd_formulas [ hdf ] . symbols } res [ hdf ] = self . hd_formulas [ hdf ]( ** args ) if len ( res . keys ()) > 1 : df_res = pd . DataFrame ( res ) else : df_res = pd . DataFrame () return df_res","title":"load_compute_formula()"},{"location":"reference/frequenz/sdk/data_handling/handle_historic_data/#frequenz.sdk.data_handling.handle_historic_data.HandleHistDataSettings","text":"Bases: NamedTuple Settings for handling multi-component historic data. Source code in frequenz/sdk/data_handling/handle_historic_data.py 34 35 36 37 38 39 40 41 42 43 class HandleHistDataSettings ( NamedTuple ): \"\"\"Settings for handling multi-component historic data.\"\"\" # loaders of historic data, specifying which component and which columns of # the parquet files to load hd_loaders : List [ LoadHistoricDataSettings ] # formulas with which to calculate the aggregated quantities with hd_formulas : Dict [ str , Formula ] # mappings between fomula symbols and loaded historic data symbol_mappings : List [ SymbolMapping ]","title":"HandleHistDataSettings"},{"location":"reference/frequenz/sdk/data_handling/handle_historic_data/#frequenz.sdk.data_handling.handle_historic_data.SymbolMapping","text":"Bases: NamedTuple Mappings between fomula symbols and loaded historic data. Source code in frequenz/sdk/data_handling/handle_historic_data.py 23 24 25 26 27 28 29 30 31 class SymbolMapping ( NamedTuple ): \"\"\"Mappings between fomula symbols and loaded historic data.\"\"\" # name of the symbol for which the mapping is defined for symbol : str # component id component_id : int # name of column of the loaded historic dataframe corresponding to the symbol field : str","title":"SymbolMapping"},{"location":"reference/frequenz/sdk/data_handling/power/","text":"frequenz.sdk.data_handling.power \u00a4 Provides support for processing power measurements from different microgrid components. Classes \u00a4 frequenz.sdk.data_handling.power.ComplexPower \u00a4 Describes the flow of AC power through a microgrid component or connection. The complex power represents both active and reactive power in a single complex number of the form S = P + jQ where P is the active power and Q the reactive power. It is expected that these values follow the passive sign convention, where positive and negative values of P correspond to consumption and supply respectively, while positive and negative values of Q correspond to inductive and capacitive loads. For details, see: https://en.wikipedia.org/wiki/Passive_sign_convention Source code in frequenz/sdk/data_handling/power.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 class ComplexPower : \"\"\"Describes the flow of AC power through a microgrid component or connection. The complex power represents both active and reactive power in a single complex number of the form S = P + jQ where P is the active power and Q the reactive power. It is expected that these values follow the passive sign convention, where positive and negative values of P correspond to consumption and supply respectively, while positive and negative values of Q correspond to inductive and capacitive loads. For details, see: https://en.wikipedia.org/wiki/Passive_sign_convention \"\"\" def __init__ ( self , complex_power : complex ) -> None : \"\"\"Instantiate a ComplexPower value from a built-in Python complex number. Args: complex_power: complex number from which to instantiate the power value, following the passive sign convention that a positive/negative real part corresponds to consumption/supply respectively, and a positive/negative imaginary part similarly corresponds to inductive/capacitive load \"\"\" self . _complex_power = complex_power @classmethod def from_protobuf ( cls , ac_message : AC ) -> ComplexPower : \"\"\"Create a ComplexPower value from the AC type of the microgrid gRPC API. Args: ac_message: protobuf message describing the AC power of a component Returns: Complex power value whose real (active) part is equal to the difference between consumption and supply in the `AC` message, and whose imaginary (reactive) part is equal to the difference between the message's inductive and capacitive power. \"\"\" active = ac_message . power_active . value reactive = ac_message . power_reactive . value return cls ( complex ( active , reactive )) @classmethod def from_active_power ( cls , active_power : float ) -> ComplexPower : \"\"\"Create a ComplexPower value from a numerical active power value. Args: active_power: value of active power, following the passive sign convention (positive => consumption, negative => supply) Returns: Value with real (active) part equal to the provided active power value, and zero imaginary (reactive) part. \"\"\" return cls ( complex ( active_power , 0 )) @classmethod def from_reactive_power ( cls , reactive_power : float ) -> ComplexPower : \"\"\"Create a ComplexPower value from a numerical reactive power value. Args: reactive_power: value of reactive power, following the passive sign convention (positive => inductive, negative => capacitive) Returns: value with zero real (active) part and imaginary (reactive) part equal to the provided reactive power value \"\"\" return cls ( complex ( 0 , reactive_power )) @property def real ( self ) -> float : \"\"\"Get the active component of the complex power value. Returns: Value of the real component, following the passive sign convention (positive => consumption, negative => supply) \"\"\" return self . _complex_power . real @property def active ( self ) -> float : \"\"\"Get the real component of the complex power value. Returns: Value of the real component, following the passive sign convention (positive => consumption, negative => supply) \"\"\" return self . real @property def consumption ( self ) -> float : \"\"\"Get the power consumption. Returns: Value of the real (active) component of the complex power value if it is positive, or zero otherwise \"\"\" return max ( self . real , 0 ) @property def supply ( self ) -> float : \"\"\"Get the power supply. Returns: Absolute value of the real (active) component of the complex power value if the latter is negative, or zero otherwise \"\"\" return max ( - self . real , 0 ) @property def imag ( self ) -> float : \"\"\"Get the reactive component of the complex power value. Returns: Value of the imaginary component, following the passive sign convention (positive => inductive, negative => capacitive) \"\"\" return self . _complex_power . imag @property def reactive ( self ) -> float : \"\"\"Get the imaginary component of the complex power value. Returns: Value of the imaginary component, following the passive sign convention (positive => inductive, negative => capacitive) \"\"\" return self . imag @property def inductive ( self ) -> float : \"\"\"Get the inductive power. Returns: Value of the imaginary (reactive) component of the complex power value if it is positive, or zero otherwise \"\"\" return max ( self . imag , 0 ) @property def capacitive ( self ) -> float : \"\"\"Get the capacitive power. Returns: Absolute value of the imaginary (reactive) component of the complex power value if the latter is negative, or zero otherwise \"\"\" return max ( - self . imag , 0 ) def __neg__ ( self ) -> ComplexPower : \"\"\"Generate the negative of this value. Returns: Value whose real and imaginary parts are the negative of this instance's \"\"\" return ComplexPower ( - self . _complex_power ) def __add__ ( self , other : object ) -> ComplexPower : \"\"\"Add this complex power value to the provided `other`. Args: other: `ComplexPower` value to add Returns: Sum of the this value and the provided `other` \"\"\" if not isinstance ( other , ComplexPower ): return NotImplemented return ComplexPower ( self . _complex_power + other . _complex_power ) def __sub__ ( self , other : object ) -> ComplexPower : \"\"\"Subtract the provided `other` from this complex power value. Args: other: `ComplexPower` value to subtract Returns: Difference between this value and the provided `other` \"\"\" if not isinstance ( other , ComplexPower ): return NotImplemented return ComplexPower ( self . _complex_power - other . _complex_power ) def __mul__ ( self , other : object ) -> ComplexPower : \"\"\"Multiply this complex power value by the provided scalar. Args: other: `Real` value by which to multiply Returns: Product of this value and the provided `other` \"\"\" if not isinstance ( other , Real ): return NotImplemented return ComplexPower ( self . _complex_power * other ) __rmul__ = __mul__ def __truediv__ ( self , other : object ) -> ComplexPower : \"\"\"Divide this complex power value by the provided scalar. Args: other: `Real` value by which to divide Returns: This value divided by the provided `other` \"\"\" if not isinstance ( other , Real ): return NotImplemented return ComplexPower ( self . _complex_power / other ) def __eq__ ( self , other : object ) -> bool : \"\"\"Check if this complex power value is equal to the provided `other`. Args: other: `ComplexPower` value to compare this one to. Returns: `True` if the underlying complex numbers are equal, `False` otherwise \"\"\" if not isinstance ( other , ComplexPower ): return NotImplemented return self . _complex_power == other . _complex_power Functions \u00a4 __add__ ( other ) \u00a4 Add this complex power value to the provided other . PARAMETER DESCRIPTION other ComplexPower value to add TYPE: object RETURNS DESCRIPTION ComplexPower Sum of the this value and the provided other Source code in frequenz/sdk/data_handling/power.py 174 175 176 177 178 179 180 181 182 183 184 185 186 def __add__ ( self , other : object ) -> ComplexPower : \"\"\"Add this complex power value to the provided `other`. Args: other: `ComplexPower` value to add Returns: Sum of the this value and the provided `other` \"\"\" if not isinstance ( other , ComplexPower ): return NotImplemented return ComplexPower ( self . _complex_power + other . _complex_power ) __eq__ ( other ) \u00a4 Check if this complex power value is equal to the provided other . PARAMETER DESCRIPTION other ComplexPower value to compare this one to. TYPE: object RETURNS DESCRIPTION bool True if the underlying complex numbers are equal, False otherwise Source code in frequenz/sdk/data_handling/power.py 232 233 234 235 236 237 238 239 240 241 242 243 244 def __eq__ ( self , other : object ) -> bool : \"\"\"Check if this complex power value is equal to the provided `other`. Args: other: `ComplexPower` value to compare this one to. Returns: `True` if the underlying complex numbers are equal, `False` otherwise \"\"\" if not isinstance ( other , ComplexPower ): return NotImplemented return self . _complex_power == other . _complex_power __init__ ( complex_power ) \u00a4 Instantiate a ComplexPower value from a built-in Python complex number. PARAMETER DESCRIPTION complex_power complex number from which to instantiate the power value, following the passive sign convention that a positive/negative real part corresponds to consumption/supply respectively, and a positive/negative imaginary part similarly corresponds to inductive/capacitive load TYPE: complex Source code in frequenz/sdk/data_handling/power.py 28 29 30 31 32 33 34 35 36 37 38 def __init__ ( self , complex_power : complex ) -> None : \"\"\"Instantiate a ComplexPower value from a built-in Python complex number. Args: complex_power: complex number from which to instantiate the power value, following the passive sign convention that a positive/negative real part corresponds to consumption/supply respectively, and a positive/negative imaginary part similarly corresponds to inductive/capacitive load \"\"\" self . _complex_power = complex_power __mul__ ( other ) \u00a4 Multiply this complex power value by the provided scalar. PARAMETER DESCRIPTION other Real value by which to multiply TYPE: object RETURNS DESCRIPTION ComplexPower Product of this value and the provided other Source code in frequenz/sdk/data_handling/power.py 202 203 204 205 206 207 208 209 210 211 212 213 214 def __mul__ ( self , other : object ) -> ComplexPower : \"\"\"Multiply this complex power value by the provided scalar. Args: other: `Real` value by which to multiply Returns: Product of this value and the provided `other` \"\"\" if not isinstance ( other , Real ): return NotImplemented return ComplexPower ( self . _complex_power * other ) __neg__ () \u00a4 Generate the negative of this value. RETURNS DESCRIPTION ComplexPower Value whose real and imaginary parts are the negative of this instance's Source code in frequenz/sdk/data_handling/power.py 166 167 168 169 170 171 172 def __neg__ ( self ) -> ComplexPower : \"\"\"Generate the negative of this value. Returns: Value whose real and imaginary parts are the negative of this instance's \"\"\" return ComplexPower ( - self . _complex_power ) __sub__ ( other ) \u00a4 Subtract the provided other from this complex power value. PARAMETER DESCRIPTION other ComplexPower value to subtract TYPE: object RETURNS DESCRIPTION ComplexPower Difference between this value and the provided other Source code in frequenz/sdk/data_handling/power.py 188 189 190 191 192 193 194 195 196 197 198 199 200 def __sub__ ( self , other : object ) -> ComplexPower : \"\"\"Subtract the provided `other` from this complex power value. Args: other: `ComplexPower` value to subtract Returns: Difference between this value and the provided `other` \"\"\" if not isinstance ( other , ComplexPower ): return NotImplemented return ComplexPower ( self . _complex_power - other . _complex_power ) __truediv__ ( other ) \u00a4 Divide this complex power value by the provided scalar. PARAMETER DESCRIPTION other Real value by which to divide TYPE: object RETURNS DESCRIPTION ComplexPower This value divided by the provided other Source code in frequenz/sdk/data_handling/power.py 218 219 220 221 222 223 224 225 226 227 228 229 230 def __truediv__ ( self , other : object ) -> ComplexPower : \"\"\"Divide this complex power value by the provided scalar. Args: other: `Real` value by which to divide Returns: This value divided by the provided `other` \"\"\" if not isinstance ( other , Real ): return NotImplemented return ComplexPower ( self . _complex_power / other ) active () property \u00a4 Get the real component of the complex power value. RETURNS DESCRIPTION float Value of the real component, following the passive sign convention (positive => consumption, negative => supply) Source code in frequenz/sdk/data_handling/power.py 96 97 98 99 100 101 102 103 104 @property def active ( self ) -> float : \"\"\"Get the real component of the complex power value. Returns: Value of the real component, following the passive sign convention (positive => consumption, negative => supply) \"\"\" return self . real capacitive () property \u00a4 Get the capacitive power. RETURNS DESCRIPTION float Absolute value of the imaginary (reactive) component of the complex power value if the latter is negative, or zero otherwise Source code in frequenz/sdk/data_handling/power.py 156 157 158 159 160 161 162 163 164 @property def capacitive ( self ) -> float : \"\"\"Get the capacitive power. Returns: Absolute value of the imaginary (reactive) component of the complex power value if the latter is negative, or zero otherwise \"\"\" return max ( - self . imag , 0 ) consumption () property \u00a4 Get the power consumption. RETURNS DESCRIPTION float Value of the real (active) component of the complex power value if it is positive, or zero otherwise Source code in frequenz/sdk/data_handling/power.py 106 107 108 109 110 111 112 113 114 @property def consumption ( self ) -> float : \"\"\"Get the power consumption. Returns: Value of the real (active) component of the complex power value if it is positive, or zero otherwise \"\"\" return max ( self . real , 0 ) from_active_power ( active_power ) classmethod \u00a4 Create a ComplexPower value from a numerical active power value. PARAMETER DESCRIPTION active_power value of active power, following the passive sign convention (positive => consumption, negative => supply) TYPE: float RETURNS DESCRIPTION ComplexPower Value with real (active) part equal to the provided active power value, and zero imaginary (reactive) part. Source code in frequenz/sdk/data_handling/power.py 58 59 60 61 62 63 64 65 66 67 68 69 70 @classmethod def from_active_power ( cls , active_power : float ) -> ComplexPower : \"\"\"Create a ComplexPower value from a numerical active power value. Args: active_power: value of active power, following the passive sign convention (positive => consumption, negative => supply) Returns: Value with real (active) part equal to the provided active power value, and zero imaginary (reactive) part. \"\"\" return cls ( complex ( active_power , 0 )) from_protobuf ( ac_message ) classmethod \u00a4 Create a ComplexPower value from the AC type of the microgrid gRPC API. PARAMETER DESCRIPTION ac_message protobuf message describing the AC power of a component TYPE: AC RETURNS DESCRIPTION ComplexPower Complex power value whose real (active) part is equal to the difference between consumption and supply in the AC message, and whose imaginary (reactive) part is equal to the difference between the message's inductive and capacitive power. Source code in frequenz/sdk/data_handling/power.py 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 @classmethod def from_protobuf ( cls , ac_message : AC ) -> ComplexPower : \"\"\"Create a ComplexPower value from the AC type of the microgrid gRPC API. Args: ac_message: protobuf message describing the AC power of a component Returns: Complex power value whose real (active) part is equal to the difference between consumption and supply in the `AC` message, and whose imaginary (reactive) part is equal to the difference between the message's inductive and capacitive power. \"\"\" active = ac_message . power_active . value reactive = ac_message . power_reactive . value return cls ( complex ( active , reactive )) from_reactive_power ( reactive_power ) classmethod \u00a4 Create a ComplexPower value from a numerical reactive power value. PARAMETER DESCRIPTION reactive_power value of reactive power, following the passive sign convention (positive => inductive, negative => capacitive) TYPE: float RETURNS DESCRIPTION ComplexPower value with zero real (active) part and imaginary (reactive) part equal to the provided reactive power value Source code in frequenz/sdk/data_handling/power.py 72 73 74 75 76 77 78 79 80 81 82 83 84 @classmethod def from_reactive_power ( cls , reactive_power : float ) -> ComplexPower : \"\"\"Create a ComplexPower value from a numerical reactive power value. Args: reactive_power: value of reactive power, following the passive sign convention (positive => inductive, negative => capacitive) Returns: value with zero real (active) part and imaginary (reactive) part equal to the provided reactive power value \"\"\" return cls ( complex ( 0 , reactive_power )) imag () property \u00a4 Get the reactive component of the complex power value. RETURNS DESCRIPTION float Value of the imaginary component, following the passive sign convention (positive => inductive, negative => capacitive) Source code in frequenz/sdk/data_handling/power.py 126 127 128 129 130 131 132 133 134 @property def imag ( self ) -> float : \"\"\"Get the reactive component of the complex power value. Returns: Value of the imaginary component, following the passive sign convention (positive => inductive, negative => capacitive) \"\"\" return self . _complex_power . imag inductive () property \u00a4 Get the inductive power. RETURNS DESCRIPTION float Value of the imaginary (reactive) component of the complex power value if it is positive, or zero otherwise Source code in frequenz/sdk/data_handling/power.py 146 147 148 149 150 151 152 153 154 @property def inductive ( self ) -> float : \"\"\"Get the inductive power. Returns: Value of the imaginary (reactive) component of the complex power value if it is positive, or zero otherwise \"\"\" return max ( self . imag , 0 ) reactive () property \u00a4 Get the imaginary component of the complex power value. RETURNS DESCRIPTION float Value of the imaginary component, following the passive sign convention (positive => inductive, negative => capacitive) Source code in frequenz/sdk/data_handling/power.py 136 137 138 139 140 141 142 143 144 @property def reactive ( self ) -> float : \"\"\"Get the imaginary component of the complex power value. Returns: Value of the imaginary component, following the passive sign convention (positive => inductive, negative => capacitive) \"\"\" return self . imag real () property \u00a4 Get the active component of the complex power value. RETURNS DESCRIPTION float Value of the real component, following the passive sign convention (positive => consumption, negative => supply) Source code in frequenz/sdk/data_handling/power.py 86 87 88 89 90 91 92 93 94 @property def real ( self ) -> float : \"\"\"Get the active component of the complex power value. Returns: Value of the real component, following the passive sign convention (positive => consumption, negative => supply) \"\"\" return self . _complex_power . real supply () property \u00a4 Get the power supply. RETURNS DESCRIPTION float Absolute value of the real (active) component of the complex power value if the latter is negative, or zero otherwise Source code in frequenz/sdk/data_handling/power.py 116 117 118 119 120 121 122 123 124 @property def supply ( self ) -> float : \"\"\"Get the power supply. Returns: Absolute value of the real (active) component of the complex power value if the latter is negative, or zero otherwise \"\"\" return max ( - self . real , 0 )","title":"power"},{"location":"reference/frequenz/sdk/data_handling/power/#frequenz.sdk.data_handling.power","text":"Provides support for processing power measurements from different microgrid components.","title":"power"},{"location":"reference/frequenz/sdk/data_handling/power/#frequenz.sdk.data_handling.power-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/data_handling/power/#frequenz.sdk.data_handling.power.ComplexPower","text":"Describes the flow of AC power through a microgrid component or connection. The complex power represents both active and reactive power in a single complex number of the form S = P + jQ where P is the active power and Q the reactive power. It is expected that these values follow the passive sign convention, where positive and negative values of P correspond to consumption and supply respectively, while positive and negative values of Q correspond to inductive and capacitive loads. For details, see: https://en.wikipedia.org/wiki/Passive_sign_convention Source code in frequenz/sdk/data_handling/power.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 class ComplexPower : \"\"\"Describes the flow of AC power through a microgrid component or connection. The complex power represents both active and reactive power in a single complex number of the form S = P + jQ where P is the active power and Q the reactive power. It is expected that these values follow the passive sign convention, where positive and negative values of P correspond to consumption and supply respectively, while positive and negative values of Q correspond to inductive and capacitive loads. For details, see: https://en.wikipedia.org/wiki/Passive_sign_convention \"\"\" def __init__ ( self , complex_power : complex ) -> None : \"\"\"Instantiate a ComplexPower value from a built-in Python complex number. Args: complex_power: complex number from which to instantiate the power value, following the passive sign convention that a positive/negative real part corresponds to consumption/supply respectively, and a positive/negative imaginary part similarly corresponds to inductive/capacitive load \"\"\" self . _complex_power = complex_power @classmethod def from_protobuf ( cls , ac_message : AC ) -> ComplexPower : \"\"\"Create a ComplexPower value from the AC type of the microgrid gRPC API. Args: ac_message: protobuf message describing the AC power of a component Returns: Complex power value whose real (active) part is equal to the difference between consumption and supply in the `AC` message, and whose imaginary (reactive) part is equal to the difference between the message's inductive and capacitive power. \"\"\" active = ac_message . power_active . value reactive = ac_message . power_reactive . value return cls ( complex ( active , reactive )) @classmethod def from_active_power ( cls , active_power : float ) -> ComplexPower : \"\"\"Create a ComplexPower value from a numerical active power value. Args: active_power: value of active power, following the passive sign convention (positive => consumption, negative => supply) Returns: Value with real (active) part equal to the provided active power value, and zero imaginary (reactive) part. \"\"\" return cls ( complex ( active_power , 0 )) @classmethod def from_reactive_power ( cls , reactive_power : float ) -> ComplexPower : \"\"\"Create a ComplexPower value from a numerical reactive power value. Args: reactive_power: value of reactive power, following the passive sign convention (positive => inductive, negative => capacitive) Returns: value with zero real (active) part and imaginary (reactive) part equal to the provided reactive power value \"\"\" return cls ( complex ( 0 , reactive_power )) @property def real ( self ) -> float : \"\"\"Get the active component of the complex power value. Returns: Value of the real component, following the passive sign convention (positive => consumption, negative => supply) \"\"\" return self . _complex_power . real @property def active ( self ) -> float : \"\"\"Get the real component of the complex power value. Returns: Value of the real component, following the passive sign convention (positive => consumption, negative => supply) \"\"\" return self . real @property def consumption ( self ) -> float : \"\"\"Get the power consumption. Returns: Value of the real (active) component of the complex power value if it is positive, or zero otherwise \"\"\" return max ( self . real , 0 ) @property def supply ( self ) -> float : \"\"\"Get the power supply. Returns: Absolute value of the real (active) component of the complex power value if the latter is negative, or zero otherwise \"\"\" return max ( - self . real , 0 ) @property def imag ( self ) -> float : \"\"\"Get the reactive component of the complex power value. Returns: Value of the imaginary component, following the passive sign convention (positive => inductive, negative => capacitive) \"\"\" return self . _complex_power . imag @property def reactive ( self ) -> float : \"\"\"Get the imaginary component of the complex power value. Returns: Value of the imaginary component, following the passive sign convention (positive => inductive, negative => capacitive) \"\"\" return self . imag @property def inductive ( self ) -> float : \"\"\"Get the inductive power. Returns: Value of the imaginary (reactive) component of the complex power value if it is positive, or zero otherwise \"\"\" return max ( self . imag , 0 ) @property def capacitive ( self ) -> float : \"\"\"Get the capacitive power. Returns: Absolute value of the imaginary (reactive) component of the complex power value if the latter is negative, or zero otherwise \"\"\" return max ( - self . imag , 0 ) def __neg__ ( self ) -> ComplexPower : \"\"\"Generate the negative of this value. Returns: Value whose real and imaginary parts are the negative of this instance's \"\"\" return ComplexPower ( - self . _complex_power ) def __add__ ( self , other : object ) -> ComplexPower : \"\"\"Add this complex power value to the provided `other`. Args: other: `ComplexPower` value to add Returns: Sum of the this value and the provided `other` \"\"\" if not isinstance ( other , ComplexPower ): return NotImplemented return ComplexPower ( self . _complex_power + other . _complex_power ) def __sub__ ( self , other : object ) -> ComplexPower : \"\"\"Subtract the provided `other` from this complex power value. Args: other: `ComplexPower` value to subtract Returns: Difference between this value and the provided `other` \"\"\" if not isinstance ( other , ComplexPower ): return NotImplemented return ComplexPower ( self . _complex_power - other . _complex_power ) def __mul__ ( self , other : object ) -> ComplexPower : \"\"\"Multiply this complex power value by the provided scalar. Args: other: `Real` value by which to multiply Returns: Product of this value and the provided `other` \"\"\" if not isinstance ( other , Real ): return NotImplemented return ComplexPower ( self . _complex_power * other ) __rmul__ = __mul__ def __truediv__ ( self , other : object ) -> ComplexPower : \"\"\"Divide this complex power value by the provided scalar. Args: other: `Real` value by which to divide Returns: This value divided by the provided `other` \"\"\" if not isinstance ( other , Real ): return NotImplemented return ComplexPower ( self . _complex_power / other ) def __eq__ ( self , other : object ) -> bool : \"\"\"Check if this complex power value is equal to the provided `other`. Args: other: `ComplexPower` value to compare this one to. Returns: `True` if the underlying complex numbers are equal, `False` otherwise \"\"\" if not isinstance ( other , ComplexPower ): return NotImplemented return self . _complex_power == other . _complex_power","title":"ComplexPower"},{"location":"reference/frequenz/sdk/data_handling/power/#frequenz.sdk.data_handling.power.ComplexPower-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/data_handling/power/#frequenz.sdk.data_handling.power.ComplexPower.__add__","text":"Add this complex power value to the provided other . PARAMETER DESCRIPTION other ComplexPower value to add TYPE: object RETURNS DESCRIPTION ComplexPower Sum of the this value and the provided other Source code in frequenz/sdk/data_handling/power.py 174 175 176 177 178 179 180 181 182 183 184 185 186 def __add__ ( self , other : object ) -> ComplexPower : \"\"\"Add this complex power value to the provided `other`. Args: other: `ComplexPower` value to add Returns: Sum of the this value and the provided `other` \"\"\" if not isinstance ( other , ComplexPower ): return NotImplemented return ComplexPower ( self . _complex_power + other . _complex_power )","title":"__add__()"},{"location":"reference/frequenz/sdk/data_handling/power/#frequenz.sdk.data_handling.power.ComplexPower.__eq__","text":"Check if this complex power value is equal to the provided other . PARAMETER DESCRIPTION other ComplexPower value to compare this one to. TYPE: object RETURNS DESCRIPTION bool True if the underlying complex numbers are equal, False otherwise Source code in frequenz/sdk/data_handling/power.py 232 233 234 235 236 237 238 239 240 241 242 243 244 def __eq__ ( self , other : object ) -> bool : \"\"\"Check if this complex power value is equal to the provided `other`. Args: other: `ComplexPower` value to compare this one to. Returns: `True` if the underlying complex numbers are equal, `False` otherwise \"\"\" if not isinstance ( other , ComplexPower ): return NotImplemented return self . _complex_power == other . _complex_power","title":"__eq__()"},{"location":"reference/frequenz/sdk/data_handling/power/#frequenz.sdk.data_handling.power.ComplexPower.__init__","text":"Instantiate a ComplexPower value from a built-in Python complex number. PARAMETER DESCRIPTION complex_power complex number from which to instantiate the power value, following the passive sign convention that a positive/negative real part corresponds to consumption/supply respectively, and a positive/negative imaginary part similarly corresponds to inductive/capacitive load TYPE: complex Source code in frequenz/sdk/data_handling/power.py 28 29 30 31 32 33 34 35 36 37 38 def __init__ ( self , complex_power : complex ) -> None : \"\"\"Instantiate a ComplexPower value from a built-in Python complex number. Args: complex_power: complex number from which to instantiate the power value, following the passive sign convention that a positive/negative real part corresponds to consumption/supply respectively, and a positive/negative imaginary part similarly corresponds to inductive/capacitive load \"\"\" self . _complex_power = complex_power","title":"__init__()"},{"location":"reference/frequenz/sdk/data_handling/power/#frequenz.sdk.data_handling.power.ComplexPower.__mul__","text":"Multiply this complex power value by the provided scalar. PARAMETER DESCRIPTION other Real value by which to multiply TYPE: object RETURNS DESCRIPTION ComplexPower Product of this value and the provided other Source code in frequenz/sdk/data_handling/power.py 202 203 204 205 206 207 208 209 210 211 212 213 214 def __mul__ ( self , other : object ) -> ComplexPower : \"\"\"Multiply this complex power value by the provided scalar. Args: other: `Real` value by which to multiply Returns: Product of this value and the provided `other` \"\"\" if not isinstance ( other , Real ): return NotImplemented return ComplexPower ( self . _complex_power * other )","title":"__mul__()"},{"location":"reference/frequenz/sdk/data_handling/power/#frequenz.sdk.data_handling.power.ComplexPower.__neg__","text":"Generate the negative of this value. RETURNS DESCRIPTION ComplexPower Value whose real and imaginary parts are the negative of this instance's Source code in frequenz/sdk/data_handling/power.py 166 167 168 169 170 171 172 def __neg__ ( self ) -> ComplexPower : \"\"\"Generate the negative of this value. Returns: Value whose real and imaginary parts are the negative of this instance's \"\"\" return ComplexPower ( - self . _complex_power )","title":"__neg__()"},{"location":"reference/frequenz/sdk/data_handling/power/#frequenz.sdk.data_handling.power.ComplexPower.__sub__","text":"Subtract the provided other from this complex power value. PARAMETER DESCRIPTION other ComplexPower value to subtract TYPE: object RETURNS DESCRIPTION ComplexPower Difference between this value and the provided other Source code in frequenz/sdk/data_handling/power.py 188 189 190 191 192 193 194 195 196 197 198 199 200 def __sub__ ( self , other : object ) -> ComplexPower : \"\"\"Subtract the provided `other` from this complex power value. Args: other: `ComplexPower` value to subtract Returns: Difference between this value and the provided `other` \"\"\" if not isinstance ( other , ComplexPower ): return NotImplemented return ComplexPower ( self . _complex_power - other . _complex_power )","title":"__sub__()"},{"location":"reference/frequenz/sdk/data_handling/power/#frequenz.sdk.data_handling.power.ComplexPower.__truediv__","text":"Divide this complex power value by the provided scalar. PARAMETER DESCRIPTION other Real value by which to divide TYPE: object RETURNS DESCRIPTION ComplexPower This value divided by the provided other Source code in frequenz/sdk/data_handling/power.py 218 219 220 221 222 223 224 225 226 227 228 229 230 def __truediv__ ( self , other : object ) -> ComplexPower : \"\"\"Divide this complex power value by the provided scalar. Args: other: `Real` value by which to divide Returns: This value divided by the provided `other` \"\"\" if not isinstance ( other , Real ): return NotImplemented return ComplexPower ( self . _complex_power / other )","title":"__truediv__()"},{"location":"reference/frequenz/sdk/data_handling/power/#frequenz.sdk.data_handling.power.ComplexPower.active","text":"Get the real component of the complex power value. RETURNS DESCRIPTION float Value of the real component, following the passive sign convention (positive => consumption, negative => supply) Source code in frequenz/sdk/data_handling/power.py 96 97 98 99 100 101 102 103 104 @property def active ( self ) -> float : \"\"\"Get the real component of the complex power value. Returns: Value of the real component, following the passive sign convention (positive => consumption, negative => supply) \"\"\" return self . real","title":"active()"},{"location":"reference/frequenz/sdk/data_handling/power/#frequenz.sdk.data_handling.power.ComplexPower.capacitive","text":"Get the capacitive power. RETURNS DESCRIPTION float Absolute value of the imaginary (reactive) component of the complex power value if the latter is negative, or zero otherwise Source code in frequenz/sdk/data_handling/power.py 156 157 158 159 160 161 162 163 164 @property def capacitive ( self ) -> float : \"\"\"Get the capacitive power. Returns: Absolute value of the imaginary (reactive) component of the complex power value if the latter is negative, or zero otherwise \"\"\" return max ( - self . imag , 0 )","title":"capacitive()"},{"location":"reference/frequenz/sdk/data_handling/power/#frequenz.sdk.data_handling.power.ComplexPower.consumption","text":"Get the power consumption. RETURNS DESCRIPTION float Value of the real (active) component of the complex power value if it is positive, or zero otherwise Source code in frequenz/sdk/data_handling/power.py 106 107 108 109 110 111 112 113 114 @property def consumption ( self ) -> float : \"\"\"Get the power consumption. Returns: Value of the real (active) component of the complex power value if it is positive, or zero otherwise \"\"\" return max ( self . real , 0 )","title":"consumption()"},{"location":"reference/frequenz/sdk/data_handling/power/#frequenz.sdk.data_handling.power.ComplexPower.from_active_power","text":"Create a ComplexPower value from a numerical active power value. PARAMETER DESCRIPTION active_power value of active power, following the passive sign convention (positive => consumption, negative => supply) TYPE: float RETURNS DESCRIPTION ComplexPower Value with real (active) part equal to the provided active power value, and zero imaginary (reactive) part. Source code in frequenz/sdk/data_handling/power.py 58 59 60 61 62 63 64 65 66 67 68 69 70 @classmethod def from_active_power ( cls , active_power : float ) -> ComplexPower : \"\"\"Create a ComplexPower value from a numerical active power value. Args: active_power: value of active power, following the passive sign convention (positive => consumption, negative => supply) Returns: Value with real (active) part equal to the provided active power value, and zero imaginary (reactive) part. \"\"\" return cls ( complex ( active_power , 0 ))","title":"from_active_power()"},{"location":"reference/frequenz/sdk/data_handling/power/#frequenz.sdk.data_handling.power.ComplexPower.from_protobuf","text":"Create a ComplexPower value from the AC type of the microgrid gRPC API. PARAMETER DESCRIPTION ac_message protobuf message describing the AC power of a component TYPE: AC RETURNS DESCRIPTION ComplexPower Complex power value whose real (active) part is equal to the difference between consumption and supply in the AC message, and whose imaginary (reactive) part is equal to the difference between the message's inductive and capacitive power. Source code in frequenz/sdk/data_handling/power.py 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 @classmethod def from_protobuf ( cls , ac_message : AC ) -> ComplexPower : \"\"\"Create a ComplexPower value from the AC type of the microgrid gRPC API. Args: ac_message: protobuf message describing the AC power of a component Returns: Complex power value whose real (active) part is equal to the difference between consumption and supply in the `AC` message, and whose imaginary (reactive) part is equal to the difference between the message's inductive and capacitive power. \"\"\" active = ac_message . power_active . value reactive = ac_message . power_reactive . value return cls ( complex ( active , reactive ))","title":"from_protobuf()"},{"location":"reference/frequenz/sdk/data_handling/power/#frequenz.sdk.data_handling.power.ComplexPower.from_reactive_power","text":"Create a ComplexPower value from a numerical reactive power value. PARAMETER DESCRIPTION reactive_power value of reactive power, following the passive sign convention (positive => inductive, negative => capacitive) TYPE: float RETURNS DESCRIPTION ComplexPower value with zero real (active) part and imaginary (reactive) part equal to the provided reactive power value Source code in frequenz/sdk/data_handling/power.py 72 73 74 75 76 77 78 79 80 81 82 83 84 @classmethod def from_reactive_power ( cls , reactive_power : float ) -> ComplexPower : \"\"\"Create a ComplexPower value from a numerical reactive power value. Args: reactive_power: value of reactive power, following the passive sign convention (positive => inductive, negative => capacitive) Returns: value with zero real (active) part and imaginary (reactive) part equal to the provided reactive power value \"\"\" return cls ( complex ( 0 , reactive_power ))","title":"from_reactive_power()"},{"location":"reference/frequenz/sdk/data_handling/power/#frequenz.sdk.data_handling.power.ComplexPower.imag","text":"Get the reactive component of the complex power value. RETURNS DESCRIPTION float Value of the imaginary component, following the passive sign convention (positive => inductive, negative => capacitive) Source code in frequenz/sdk/data_handling/power.py 126 127 128 129 130 131 132 133 134 @property def imag ( self ) -> float : \"\"\"Get the reactive component of the complex power value. Returns: Value of the imaginary component, following the passive sign convention (positive => inductive, negative => capacitive) \"\"\" return self . _complex_power . imag","title":"imag()"},{"location":"reference/frequenz/sdk/data_handling/power/#frequenz.sdk.data_handling.power.ComplexPower.inductive","text":"Get the inductive power. RETURNS DESCRIPTION float Value of the imaginary (reactive) component of the complex power value if it is positive, or zero otherwise Source code in frequenz/sdk/data_handling/power.py 146 147 148 149 150 151 152 153 154 @property def inductive ( self ) -> float : \"\"\"Get the inductive power. Returns: Value of the imaginary (reactive) component of the complex power value if it is positive, or zero otherwise \"\"\" return max ( self . imag , 0 )","title":"inductive()"},{"location":"reference/frequenz/sdk/data_handling/power/#frequenz.sdk.data_handling.power.ComplexPower.reactive","text":"Get the imaginary component of the complex power value. RETURNS DESCRIPTION float Value of the imaginary component, following the passive sign convention (positive => inductive, negative => capacitive) Source code in frequenz/sdk/data_handling/power.py 136 137 138 139 140 141 142 143 144 @property def reactive ( self ) -> float : \"\"\"Get the imaginary component of the complex power value. Returns: Value of the imaginary component, following the passive sign convention (positive => inductive, negative => capacitive) \"\"\" return self . imag","title":"reactive()"},{"location":"reference/frequenz/sdk/data_handling/power/#frequenz.sdk.data_handling.power.ComplexPower.real","text":"Get the active component of the complex power value. RETURNS DESCRIPTION float Value of the real component, following the passive sign convention (positive => consumption, negative => supply) Source code in frequenz/sdk/data_handling/power.py 86 87 88 89 90 91 92 93 94 @property def real ( self ) -> float : \"\"\"Get the active component of the complex power value. Returns: Value of the real component, following the passive sign convention (positive => consumption, negative => supply) \"\"\" return self . _complex_power . real","title":"real()"},{"location":"reference/frequenz/sdk/data_handling/power/#frequenz.sdk.data_handling.power.ComplexPower.supply","text":"Get the power supply. RETURNS DESCRIPTION float Absolute value of the real (active) component of the complex power value if the latter is negative, or zero otherwise Source code in frequenz/sdk/data_handling/power.py 116 117 118 119 120 121 122 123 124 @property def supply ( self ) -> float : \"\"\"Get the power supply. Returns: Absolute value of the real (active) component of the complex power value if the latter is negative, or zero otherwise \"\"\" return max ( - self . real , 0 )","title":"supply()"},{"location":"reference/frequenz/sdk/data_handling/time_series/","text":"frequenz.sdk.data_handling.time_series \u00a4 Helper classes for tracking values from time-series data streams. Classes \u00a4 frequenz.sdk.data_handling.time_series.BatteryField \u00a4 Bases: ComponentField Name of the fields from streamed battery data. Source code in frequenz/sdk/data_handling/time_series.py 36 37 38 39 40 41 42 class BatteryField ( ComponentField ): \"\"\"Name of the fields from streamed battery data.\"\"\" SOC = \"soc\" CAPACITY = \"capacity\" POWER_UPPER_BOUND = \"power_upper_bound\" POWER_LOWER_BOUND = \"power_lower_bound\" frequenz.sdk.data_handling.time_series.CacheEntryLookupResult dataclass \u00a4 Bases: Generic [ Value ] Component ids and meter connections for components of a specific type. Source code in frequenz/sdk/data_handling/time_series.py 146 147 148 149 150 151 152 153 154 155 156 157 158 @dataclass ( frozen = True ) class CacheEntryLookupResult ( Generic [ Value ]): \"\"\"Component ids and meter connections for components of a specific type.\"\"\" class Status ( enum . Enum ): \"\"\"Possible outcomes of looking up a key in a cache.\"\"\" HIT = \"hit\" MISS = \"miss\" EXPIRED = \"expired\" status : Status entry : Optional [ TimeSeriesEntry [ Value ]] = None Classes \u00a4 Status \u00a4 Bases: enum . Enum Possible outcomes of looking up a key in a cache. Source code in frequenz/sdk/data_handling/time_series.py 150 151 152 153 154 155 class Status ( enum . Enum ): \"\"\"Possible outcomes of looking up a key in a cache.\"\"\" HIT = \"hit\" MISS = \"miss\" EXPIRED = \"expired\" frequenz.sdk.data_handling.time_series.ComponentField \u00a4 Bases: enum . Enum Name of the field from streamed component data. Source code in frequenz/sdk/data_handling/time_series.py 32 33 class ComponentField ( enum . Enum ): \"\"\"Name of the field from streamed component data.\"\"\" frequenz.sdk.data_handling.time_series.EVChargerField \u00a4 Bases: ComponentField Name of the fields from streamed ev charger data. Source code in frequenz/sdk/data_handling/time_series.py 59 60 61 62 class EVChargerField ( ComponentField ): \"\"\"Name of the fields from streamed ev charger data.\"\"\" ACTIVE_POWER = \"active_power\" frequenz.sdk.data_handling.time_series.InverterField \u00a4 Bases: ComponentField Name of the fields from streamed inverter data. Source code in frequenz/sdk/data_handling/time_series.py 45 46 47 48 49 50 class InverterField ( ComponentField ): \"\"\"Name of the fields from streamed inverter data.\"\"\" ACTIVE_POWER = \"active_power\" ACTIVE_POWER_UPPER_BOUND = \"active_power_upper_bound\" ACTIVE_POWER_LOWER_BOUND = \"active_power_lower_bound\" frequenz.sdk.data_handling.time_series.LatestEntryCache \u00a4 Bases: Generic [ Key , Value ] Cache of the most recent values observed in one or more time series. Each time series is identified in the cache via a unique Key , and it is expected that every time series will be of the same type of Value . Source code in frequenz/sdk/data_handling/time_series.py 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 class LatestEntryCache ( Generic [ Key , Value ]): \"\"\"Cache of the most recent values observed in one or more time series. Each time series is identified in the cache via a unique `Key`, and it is expected that every time series will be of the same type of `Value`. \"\"\" def __init__ ( self ) -> None : \"\"\"Initialize the class.\"\"\" self . _latest_timestamp = datetime . min . replace ( tzinfo = timezone . utc ) self . _entries : Dict [ Key , TimeSeriesEntry [ Value ]] = {} @property def latest_timestamp ( self ) -> datetime : \"\"\"Get the most recently observed timestamp across all keys in the cache. Returns: The highest timestamp out of all entries in the cache, or `datetime.min` if there are no cache entries. \"\"\" return self . _latest_timestamp def clear ( self ) -> None : \"\"\"Clear all entries from the cache. This will not affect `latest_timestamp`. If you want to restore the cache to its initial state, use the `reset` method instead. \"\"\" self . _entries . clear () def __contains__ ( self , key : Key ) -> bool : \"\"\"Check if a cache entry exists for the specified key. Args: key: key to search for. Returns: `True` if the cache contains an entry for `key`, `False` otherwise. \"\"\" return key in self . _entries def get ( self , key : Key , timedelta_tolerance : timedelta = timedelta . max , default : Optional [ TimeSeriesEntry [ Value ]] = None , ) -> CacheEntryLookupResult [ Value ]: \"\"\"Get the cached entry for the specified key, if any. Args: key: key for which to look up the cached entry timedelta_tolerance: maximum permitted time difference between `latest_timestamp` and the timestamp of the cached entry default: what to return if the `key` is not found in the cache, or if the cached entry is not within the limits of `timedelta_tolerance` Returns: The cached entry associated with the provided `key`, or `default` if either there is no entry for the `key`, or if the difference between the cached timestamp and `latest_timestamp` is greater than `timedelta_tolerance` Raises: ValueError: when either timedelta_tolerance is negative or an entry retrieved from the cache has a timestamp greater than the latest saved timestamp across all cache keys. \"\"\" if timedelta_tolerance < timedelta ( 0 ): raise ValueError ( f \"timedelta_tolerance cannot be less than 0, but \" f \" { timedelta_tolerance } was provided\" ) entry = self . _entries . get ( key , None ) if entry is None : logger . debug ( \"LatestEntryCache: missing data for key %s \" , key ) return CacheEntryLookupResult ( status = CacheEntryLookupResult . Status . MISS , entry = default ) if entry . timestamp > self . _latest_timestamp : raise ValueError ( \"Timestamp of single entry in the cache cannot be greater\" \" than the latest timestamp across entries for all keys.\" ) delta = self . _latest_timestamp - entry . timestamp if delta > timedelta_tolerance : logger . debug ( \"LatestEntryCache: data for key %s is outdated\" , key ) logger . debug ( \"latest timestamp: %s \" , self . _latest_timestamp ) logger . debug ( \"entry timestamp: %s \" , entry . timestamp ) logger . debug ( \"timedelta: %s \" , delta ) logger . debug ( \"tolerance: %s \" , timedelta_tolerance ) return CacheEntryLookupResult ( status = CacheEntryLookupResult . Status . EXPIRED , entry = default ) return CacheEntryLookupResult ( status = CacheEntryLookupResult . Status . HIT , entry = entry ) def keys ( self ) -> Collection [ Key ]: \"\"\"Get all the keys with entries in the cache. Returns: All the keys with an entry in the cache \"\"\" return self . _entries . keys () def __len__ ( self ) -> int : \"\"\"Get the total number of entries stored in the cache. Returns: The total number of keys with entries in the cache. \"\"\" return len ( self . _entries ) def pop ( self , key : Key , default : Optional [ TimeSeriesEntry [ Value ]] = None , ) -> CacheEntryLookupResult [ Value ]: \"\"\"Pop the entry for the specified key from the cache, if it exists. Note that this does not affect `latest_timestamp`, even if the removed entry was the only one in the cache. Use the `reset_latest_timestamp` method to eliminate the impact of timestamps from removed entries. Args: key: key whose cache entry to remove default: what to return if the `key` is not found in the cache Returns: Popped value if it exists, `None` otherwise \"\"\" entry = self . _entries . pop ( key , None ) if entry is None : return CacheEntryLookupResult ( status = CacheEntryLookupResult . Status . MISS , entry = default ) return CacheEntryLookupResult ( status = CacheEntryLookupResult . Status . HIT , entry = entry ) def reset ( self ) -> None : \"\"\"Reset the cache to its default initial state. This will clear out all cache entries and reset the `latest_timestamp` property to `datetime.min`. It is equivalent to separately calling the `clear` and `reset_latest_timestamp` methods in succession, but is very slightly more efficient. \"\"\" self . clear () self . _latest_timestamp = datetime . min . replace ( tzinfo = timezone . utc ) def reset_latest_timestamp ( self ) -> bool : \"\"\"Reset the `latest_timestamp` property to the lowest possible value. This will be equal to either the highest timestamp out of any entries remaining in the cache, or `datetime.min` if no entries remain. Note that this is an O(N) operation, so may be expensive. It is meant to be used only in order to correct an error introduced into the cache, e.g. after removing one or more entries with invalid timestamps. Returns: `True` if the latest timestamp was modified, `False` otherwise. Raises: ValueError: if the new latest timestamp is greater than the previous one \"\"\" previous = self . _latest_timestamp self . _latest_timestamp = max ( map ( lambda x : x . timestamp , self . _entries . values ()), default = datetime . min . replace ( tzinfo = timezone . utc ), ) if self . _latest_timestamp > previous : raise ValueError ( \"The new latest timestamp after reset cannot be greater \" \"than the latest timestamp before the reset.\" ) return previous != self . _latest_timestamp def update ( self , key : Key , entry : TimeSeriesEntry [ Value ]) -> bool : \"\"\"Insert or update an entry for a specific key. Args: key: key to associate with the entry entry: entry to add to the cache (will be accepted if `key` is new, or if the timestamp of the existing entry is older than `entry.timestamp`) Returns: `True` if `entry` was added to the cache, `False` otherwise Raises: AttributeError: if timestamps are not timezone-aware \"\"\" # sanity check that entry timestamp is valid if ( entry . timestamp . tzinfo is None or entry . timestamp . tzinfo . utcoffset ( entry . timestamp ) is None ): raise AttributeError ( \"Entry's timestamp must be timezone-aware.\" ) self . _latest_timestamp = max ( self . _latest_timestamp , entry . timestamp ) last = self . _entries . get ( key , None ) if last is None or entry . timestamp > last . timestamp : self . _entries [ key ] = entry return True logger . debug ( \"TimeSeriesEntryCache: entry for key %s is outdated\" , key ) logger . debug ( \"previously observed timestamp: %s \" , last . timestamp ) logger . debug ( \"entry timestamp: %s \" , entry . timestamp ) return False Functions \u00a4 __contains__ ( key ) \u00a4 Check if a cache entry exists for the specified key. PARAMETER DESCRIPTION key key to search for. TYPE: Key RETURNS DESCRIPTION bool True if the cache contains an entry for key , False otherwise. Source code in frequenz/sdk/data_handling/time_series.py 191 192 193 194 195 196 197 198 199 200 def __contains__ ( self , key : Key ) -> bool : \"\"\"Check if a cache entry exists for the specified key. Args: key: key to search for. Returns: `True` if the cache contains an entry for `key`, `False` otherwise. \"\"\" return key in self . _entries __init__ () \u00a4 Initialize the class. Source code in frequenz/sdk/data_handling/time_series.py 168 169 170 171 def __init__ ( self ) -> None : \"\"\"Initialize the class.\"\"\" self . _latest_timestamp = datetime . min . replace ( tzinfo = timezone . utc ) self . _entries : Dict [ Key , TimeSeriesEntry [ Value ]] = {} __len__ () \u00a4 Get the total number of entries stored in the cache. RETURNS DESCRIPTION int The total number of keys with entries in the cache. Source code in frequenz/sdk/data_handling/time_series.py 272 273 274 275 276 277 278 def __len__ ( self ) -> int : \"\"\"Get the total number of entries stored in the cache. Returns: The total number of keys with entries in the cache. \"\"\" return len ( self . _entries ) clear () \u00a4 Clear all entries from the cache. This will not affect latest_timestamp . If you want to restore the cache to its initial state, use the reset method instead. Source code in frequenz/sdk/data_handling/time_series.py 183 184 185 186 187 188 189 def clear ( self ) -> None : \"\"\"Clear all entries from the cache. This will not affect `latest_timestamp`. If you want to restore the cache to its initial state, use the `reset` method instead. \"\"\" self . _entries . clear () get ( key , timedelta_tolerance = timedelta . max , default = None ) \u00a4 Get the cached entry for the specified key, if any. PARAMETER DESCRIPTION key key for which to look up the cached entry TYPE: Key timedelta_tolerance maximum permitted time difference between latest_timestamp and the timestamp of the cached entry TYPE: timedelta DEFAULT: timedelta.max default what to return if the key is not found in the cache, or if the cached entry is not within the limits of timedelta_tolerance TYPE: Optional [ TimeSeriesEntry [ Value ]] DEFAULT: None RETURNS DESCRIPTION CacheEntryLookupResult [ Value ] The cached entry associated with the provided key , or default if either there is no entry for the key , or if the difference between the cached timestamp and latest_timestamp is greater than timedelta_tolerance RAISES DESCRIPTION ValueError when either timedelta_tolerance is negative or an entry retrieved from the cache has a timestamp greater than the latest saved timestamp across all cache keys. Source code in frequenz/sdk/data_handling/time_series.py 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 def get ( self , key : Key , timedelta_tolerance : timedelta = timedelta . max , default : Optional [ TimeSeriesEntry [ Value ]] = None , ) -> CacheEntryLookupResult [ Value ]: \"\"\"Get the cached entry for the specified key, if any. Args: key: key for which to look up the cached entry timedelta_tolerance: maximum permitted time difference between `latest_timestamp` and the timestamp of the cached entry default: what to return if the `key` is not found in the cache, or if the cached entry is not within the limits of `timedelta_tolerance` Returns: The cached entry associated with the provided `key`, or `default` if either there is no entry for the `key`, or if the difference between the cached timestamp and `latest_timestamp` is greater than `timedelta_tolerance` Raises: ValueError: when either timedelta_tolerance is negative or an entry retrieved from the cache has a timestamp greater than the latest saved timestamp across all cache keys. \"\"\" if timedelta_tolerance < timedelta ( 0 ): raise ValueError ( f \"timedelta_tolerance cannot be less than 0, but \" f \" { timedelta_tolerance } was provided\" ) entry = self . _entries . get ( key , None ) if entry is None : logger . debug ( \"LatestEntryCache: missing data for key %s \" , key ) return CacheEntryLookupResult ( status = CacheEntryLookupResult . Status . MISS , entry = default ) if entry . timestamp > self . _latest_timestamp : raise ValueError ( \"Timestamp of single entry in the cache cannot be greater\" \" than the latest timestamp across entries for all keys.\" ) delta = self . _latest_timestamp - entry . timestamp if delta > timedelta_tolerance : logger . debug ( \"LatestEntryCache: data for key %s is outdated\" , key ) logger . debug ( \"latest timestamp: %s \" , self . _latest_timestamp ) logger . debug ( \"entry timestamp: %s \" , entry . timestamp ) logger . debug ( \"timedelta: %s \" , delta ) logger . debug ( \"tolerance: %s \" , timedelta_tolerance ) return CacheEntryLookupResult ( status = CacheEntryLookupResult . Status . EXPIRED , entry = default ) return CacheEntryLookupResult ( status = CacheEntryLookupResult . Status . HIT , entry = entry ) keys () \u00a4 Get all the keys with entries in the cache. RETURNS DESCRIPTION Collection [ Key ] All the keys with an entry in the cache Source code in frequenz/sdk/data_handling/time_series.py 264 265 266 267 268 269 270 def keys ( self ) -> Collection [ Key ]: \"\"\"Get all the keys with entries in the cache. Returns: All the keys with an entry in the cache \"\"\" return self . _entries . keys () latest_timestamp () property \u00a4 Get the most recently observed timestamp across all keys in the cache. RETURNS DESCRIPTION datetime The highest timestamp out of all entries in the cache, or datetime.min if there are no cache entries. Source code in frequenz/sdk/data_handling/time_series.py 173 174 175 176 177 178 179 180 181 @property def latest_timestamp ( self ) -> datetime : \"\"\"Get the most recently observed timestamp across all keys in the cache. Returns: The highest timestamp out of all entries in the cache, or `datetime.min` if there are no cache entries. \"\"\" return self . _latest_timestamp pop ( key , default = None ) \u00a4 Pop the entry for the specified key from the cache, if it exists. Note that this does not affect latest_timestamp , even if the removed entry was the only one in the cache. Use the reset_latest_timestamp method to eliminate the impact of timestamps from removed entries. PARAMETER DESCRIPTION key key whose cache entry to remove TYPE: Key default what to return if the key is not found in the cache TYPE: Optional [ TimeSeriesEntry [ Value ]] DEFAULT: None RETURNS DESCRIPTION CacheEntryLookupResult [ Value ] Popped value if it exists, None otherwise Source code in frequenz/sdk/data_handling/time_series.py 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 def pop ( self , key : Key , default : Optional [ TimeSeriesEntry [ Value ]] = None , ) -> CacheEntryLookupResult [ Value ]: \"\"\"Pop the entry for the specified key from the cache, if it exists. Note that this does not affect `latest_timestamp`, even if the removed entry was the only one in the cache. Use the `reset_latest_timestamp` method to eliminate the impact of timestamps from removed entries. Args: key: key whose cache entry to remove default: what to return if the `key` is not found in the cache Returns: Popped value if it exists, `None` otherwise \"\"\" entry = self . _entries . pop ( key , None ) if entry is None : return CacheEntryLookupResult ( status = CacheEntryLookupResult . Status . MISS , entry = default ) return CacheEntryLookupResult ( status = CacheEntryLookupResult . Status . HIT , entry = entry ) reset () \u00a4 Reset the cache to its default initial state. This will clear out all cache entries and reset the latest_timestamp property to datetime.min . It is equivalent to separately calling the clear and reset_latest_timestamp methods in succession, but is very slightly more efficient. Source code in frequenz/sdk/data_handling/time_series.py 307 308 309 310 311 312 313 314 315 316 def reset ( self ) -> None : \"\"\"Reset the cache to its default initial state. This will clear out all cache entries and reset the `latest_timestamp` property to `datetime.min`. It is equivalent to separately calling the `clear` and `reset_latest_timestamp` methods in succession, but is very slightly more efficient. \"\"\" self . clear () self . _latest_timestamp = datetime . min . replace ( tzinfo = timezone . utc ) reset_latest_timestamp () \u00a4 Reset the latest_timestamp property to the lowest possible value. This will be equal to either the highest timestamp out of any entries remaining in the cache, or datetime.min if no entries remain. Note that this is an O(N) operation, so may be expensive. It is meant to be used only in order to correct an error introduced into the cache, e.g. after removing one or more entries with invalid timestamps. RETURNS DESCRIPTION bool True if the latest timestamp was modified, False otherwise. RAISES DESCRIPTION ValueError if the new latest timestamp is greater than the previous one Source code in frequenz/sdk/data_handling/time_series.py 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 def reset_latest_timestamp ( self ) -> bool : \"\"\"Reset the `latest_timestamp` property to the lowest possible value. This will be equal to either the highest timestamp out of any entries remaining in the cache, or `datetime.min` if no entries remain. Note that this is an O(N) operation, so may be expensive. It is meant to be used only in order to correct an error introduced into the cache, e.g. after removing one or more entries with invalid timestamps. Returns: `True` if the latest timestamp was modified, `False` otherwise. Raises: ValueError: if the new latest timestamp is greater than the previous one \"\"\" previous = self . _latest_timestamp self . _latest_timestamp = max ( map ( lambda x : x . timestamp , self . _entries . values ()), default = datetime . min . replace ( tzinfo = timezone . utc ), ) if self . _latest_timestamp > previous : raise ValueError ( \"The new latest timestamp after reset cannot be greater \" \"than the latest timestamp before the reset.\" ) return previous != self . _latest_timestamp update ( key , entry ) \u00a4 Insert or update an entry for a specific key. PARAMETER DESCRIPTION key key to associate with the entry TYPE: Key entry entry to add to the cache (will be accepted if key is new, or if the timestamp of the existing entry is older than entry.timestamp ) TYPE: TimeSeriesEntry [ Value ] RETURNS DESCRIPTION bool True if entry was added to the cache, False otherwise RAISES DESCRIPTION AttributeError if timestamps are not timezone-aware Source code in frequenz/sdk/data_handling/time_series.py 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 def update ( self , key : Key , entry : TimeSeriesEntry [ Value ]) -> bool : \"\"\"Insert or update an entry for a specific key. Args: key: key to associate with the entry entry: entry to add to the cache (will be accepted if `key` is new, or if the timestamp of the existing entry is older than `entry.timestamp`) Returns: `True` if `entry` was added to the cache, `False` otherwise Raises: AttributeError: if timestamps are not timezone-aware \"\"\" # sanity check that entry timestamp is valid if ( entry . timestamp . tzinfo is None or entry . timestamp . tzinfo . utcoffset ( entry . timestamp ) is None ): raise AttributeError ( \"Entry's timestamp must be timezone-aware.\" ) self . _latest_timestamp = max ( self . _latest_timestamp , entry . timestamp ) last = self . _entries . get ( key , None ) if last is None or entry . timestamp > last . timestamp : self . _entries [ key ] = entry return True logger . debug ( \"TimeSeriesEntryCache: entry for key %s is outdated\" , key ) logger . debug ( \"previously observed timestamp: %s \" , last . timestamp ) logger . debug ( \"entry timestamp: %s \" , entry . timestamp ) return False frequenz.sdk.data_handling.time_series.MeterField \u00a4 Bases: ComponentField Name of the fields from streamed meter data. Source code in frequenz/sdk/data_handling/time_series.py 53 54 55 56 class MeterField ( ComponentField ): \"\"\"Name of the fields from streamed meter data.\"\"\" ACTIVE_POWER = \"active_power\" frequenz.sdk.data_handling.time_series.SymbolComponentCategory \u00a4 Bases: enum . Enum Allowed component categories used in symbols for formula calculations. Source code in frequenz/sdk/data_handling/time_series.py 23 24 25 26 27 28 29 class SymbolComponentCategory ( enum . Enum ): \"\"\"Allowed component categories used in symbols for formula calculations.\"\"\" INVERTER = \"inverter\" BATTERY = \"battery\" EV_CHARGER = \"ev_charger\" METER = \"meter\" frequenz.sdk.data_handling.time_series.SymbolMapping dataclass \u00a4 Mappings between formula symbols and streamed component data. Source code in frequenz/sdk/data_handling/time_series.py 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 @dataclass ( frozen = True ) class SymbolMapping : \"\"\"Mappings between formula symbols and streamed component data.\"\"\" category : SymbolComponentCategory component_id : int field : ComponentField @property def symbol ( self ) -> str : \"\"\"Create a sympy-compatible symbol from a symbol mapping. For instance, SymbolMapping(SymbolComponentCategory.METER, 5, ComponentField.ACTIVE_POWER) becomes \"meter_5_active_power\". Returns: sympy-compatible symbol mapping encoded as a string \"\"\" return SYMBOL_SEGMENT_SEPARATOR . join ( [ self . category . value , str ( self . component_id ), self . field . value ] ) Functions \u00a4 symbol () property \u00a4 Create a sympy-compatible symbol from a symbol mapping. For instance, SymbolMapping(SymbolComponentCategory.METER, 5, ComponentField.ACTIVE_POWER) becomes \"meter_5_active_power\". RETURNS DESCRIPTION str sympy-compatible symbol mapping encoded as a string Source code in frequenz/sdk/data_handling/time_series.py 73 74 75 76 77 78 79 80 81 82 83 84 85 86 @property def symbol ( self ) -> str : \"\"\"Create a sympy-compatible symbol from a symbol mapping. For instance, SymbolMapping(SymbolComponentCategory.METER, 5, ComponentField.ACTIVE_POWER) becomes \"meter_5_active_power\". Returns: sympy-compatible symbol mapping encoded as a string \"\"\" return SYMBOL_SEGMENT_SEPARATOR . join ( [ self . category . value , str ( self . component_id ), self . field . value ] ) frequenz.sdk.data_handling.time_series.TimeSeriesEntry dataclass \u00a4 Bases: Generic [ Value ] Describes a single observed value (of arbitrary type) at a specific timestamp. Source code in frequenz/sdk/data_handling/time_series.py 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 @dataclass class TimeSeriesEntry ( Generic [ Value ]): \"\"\"Describes a single observed value (of arbitrary type) at a specific timestamp.\"\"\" class Status ( enum . Enum ): \"\"\"Possible status values of a `TimeSeriesEntry`.\"\"\" VALID = \"valid\" UNKNOWN = \"unknown\" ERROR = \"error\" timestamp : datetime value : Optional [ Value ] = None status : Status = Status . VALID broken_component_ids : Set [ int ] = field ( default_factory = set ) @staticmethod def create_error ( timestamp : datetime ) -> TimeSeriesEntry [ Value ]: \"\"\"Create a `TimeSeriesEntry` that contains an error. This can happen when the value would be NaN, e.g. TimeSeriesEntry(value=1 / 0) Args: timestamp: Timestamp Returns: A single observed value (of arbitrary type) at a specific timestamp. \"\"\" return TimeSeriesEntry ( timestamp = timestamp , value = None , status = TimeSeriesEntry . Status . ERROR ) @staticmethod def create_unknown ( timestamp : datetime , broken_component_ids : Optional [ Set [ int ]] = None ) -> TimeSeriesEntry [ Value ]: \"\"\"Create a `TimeSeriesEntry` that contains an unknown value. This can happen when the value cannot be determined, because a component is broken. Args: timestamp: Timestamp broken_component_ids: broken component ids Returns: A single observed value (of arbitrary type) at a specific timestamp. \"\"\" return TimeSeriesEntry ( timestamp = timestamp , value = None , status = TimeSeriesEntry . Status . UNKNOWN , broken_component_ids = broken_component_ids or set (), ) Classes \u00a4 Status \u00a4 Bases: enum . Enum Possible status values of a TimeSeriesEntry . Source code in frequenz/sdk/data_handling/time_series.py 93 94 95 96 97 98 class Status ( enum . Enum ): \"\"\"Possible status values of a `TimeSeriesEntry`.\"\"\" VALID = \"valid\" UNKNOWN = \"unknown\" ERROR = \"error\" Functions \u00a4 create_error ( timestamp ) staticmethod \u00a4 Create a TimeSeriesEntry that contains an error. This can happen when the value would be NaN, e.g. TimeSeriesEntry(value=1 / 0) PARAMETER DESCRIPTION timestamp Timestamp TYPE: datetime RETURNS DESCRIPTION TimeSeriesEntry [ Value ] A single observed value (of arbitrary type) at a specific timestamp. Source code in frequenz/sdk/data_handling/time_series.py 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 @staticmethod def create_error ( timestamp : datetime ) -> TimeSeriesEntry [ Value ]: \"\"\"Create a `TimeSeriesEntry` that contains an error. This can happen when the value would be NaN, e.g. TimeSeriesEntry(value=1 / 0) Args: timestamp: Timestamp Returns: A single observed value (of arbitrary type) at a specific timestamp. \"\"\" return TimeSeriesEntry ( timestamp = timestamp , value = None , status = TimeSeriesEntry . Status . ERROR ) create_unknown ( timestamp , broken_component_ids = None ) staticmethod \u00a4 Create a TimeSeriesEntry that contains an unknown value. This can happen when the value cannot be determined, because a component is broken. PARAMETER DESCRIPTION timestamp Timestamp TYPE: datetime broken_component_ids broken component ids TYPE: Optional [ Set [ int ]] DEFAULT: None RETURNS DESCRIPTION TimeSeriesEntry [ Value ] A single observed value (of arbitrary type) at a specific timestamp. Source code in frequenz/sdk/data_handling/time_series.py 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 @staticmethod def create_unknown ( timestamp : datetime , broken_component_ids : Optional [ Set [ int ]] = None ) -> TimeSeriesEntry [ Value ]: \"\"\"Create a `TimeSeriesEntry` that contains an unknown value. This can happen when the value cannot be determined, because a component is broken. Args: timestamp: Timestamp broken_component_ids: broken component ids Returns: A single observed value (of arbitrary type) at a specific timestamp. \"\"\" return TimeSeriesEntry ( timestamp = timestamp , value = None , status = TimeSeriesEntry . Status . UNKNOWN , broken_component_ids = broken_component_ids or set (), ) frequenz.sdk.data_handling.time_series.TimeSeriesFormula \u00a4 Bases: Formula , Generic [ Value ] Combines values from multiple time series via a specified algebraic formula. Formulas are handled using the sympy library for symbolic mathematics. It is expected that each individual time series will have the same underlying type of Value , and that this Value supports all the operations the formula requires (for example, if the formula is x / 7 and Value does not support division, then the formula cannot be applied). Source code in frequenz/sdk/data_handling/time_series.py 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 class TimeSeriesFormula ( Formula , Generic [ Value ]): \"\"\"Combines values from multiple time series via a specified algebraic formula. Formulas are handled using the `sympy` library for symbolic mathematics. It is expected that each individual time series will have the same underlying type of `Value`, and that this `Value` supports all the operations the formula requires (for example, if the formula is `x / 7` and `Value` does not support division, then the formula cannot be applied). \"\"\" @staticmethod def _is_component_broken ( cache_lookup_result : CacheEntryLookupResult . Status , ) -> bool : \"\"\"Check if a component is broken. Args: cache_lookup_result: an enum saying if data from component with `component_id` was found in the cache or not Returns: `True` if component is broken and `False` otherwise \"\"\" return cache_lookup_result in { CacheEntryLookupResult . Status . MISS , CacheEntryLookupResult . Status . EXPIRED , } # pylint:disable=too-many-arguments def evaluate ( self , cache : LatestEntryCache [ str , Value ], formula_name : str = \"\" , symbol_to_symbol_mapping : Optional [ Dict [ str , SymbolMapping ]] = None , timedelta_tolerance : timedelta = timedelta . max , default_entry : Optional [ TimeSeriesEntry [ Value ]] = None , ) -> Optional [ TimeSeriesEntry [ Value ]]: \"\"\"Evaluate the formula using time-series values from the provided cache. The underlying assumption of the evaluation process is that measurements from each time series will be offset slightly in time, but may still be combined if that offset is small enough. By default the permitted offset is the maximum possible `timedelta`, in which case the mere existence of a value in each time series will be enough. This is probably not desirable for real-world use case so users should take care to always set the `timedelta_tolerance` parameter to a value that matches their use-case (for example, if the rate of update of time series is 0.2 sec, a `timedelta_tolerance` of 0.2 sec is recommended). Args: cache: cache of the most recent time series values, where the key should match the variable name in the formula (so e.g. if the formula is `x + y` then the cache should contain keys `\"x\"` and `\"y\"`) formula_name: user-defined name for the formula symbol_to_symbol_mapping: mapping of symbols in string representation to symbol mappings timedelta_tolerance: maximum permitted time difference between `cache.latest_timestamp` and the timestamp of any cached entry (if this is violated, the result will be the same as if an entry for the given key does not exist) default_entry: what entry to use if the entry for a given symbol is not found in the cache, or if the cached entry is not within the limits of `timedelta_tolerance`. If None, then formula won't be evaluated and None will be returned. Returns: Result of the formula, with a `timestamp` equal to the highest timestamp among all of the combined time series entries, and a `value` that equals the formula result, or `None` if any of the required time series variables are not present in `cache` or are older than `timedelta_tolerance` \"\"\" kwargs : Dict [ str , Optional [ Value ]] = {} timestamp = datetime . min . replace ( tzinfo = timezone . utc ) symbol_to_symbol_mapping = symbol_to_symbol_mapping or {} formula_broken_component_ids : Set [ int ] = set () broken_meter_found = False for symbol in self . _symbols : symbol_mapping = symbol_to_symbol_mapping . get ( symbol ) cache_lookup_result = cache . get ( symbol , timedelta_tolerance , default = default_entry ) # If the value wasn't found in the cache and no symbol mapping was provided # for this symbol (meaning it cannot be determined what component category # it refers to), then return `default_entry` if it was provided, otherwise # the formula cannot be evaluated and `None` will be returned # if cache_lookup_result.entry is None: # return default_entry if default_entry is not None else None # Symbol metadata is not available, e.g. component category if symbol_mapping is None : # Component data is available and up to date if cache_lookup_result . entry is not None : kwargs [ symbol ] = cache_lookup_result . entry . value timestamp = max ( timestamp , cache_lookup_result . entry . timestamp ) # Otherwise, apply the default entry if it was provided, and if it # wasn't return `None` as the formula result as it cannot be evaluated else : if default_entry is None : return None kwargs [ symbol ] = default_entry . value timestamp = max ( timestamp , default_entry . timestamp ) # Symbol metadata is available, e.g. component category else : # When a component is broken, keep collecting ids of broken components # that this formula relies on, and if there's any meter among these, # return `UNKNOWN` as the formula result, otherwise fill in the values # of broken components with the `default_entry` and evaluate the formula if self . _is_component_broken ( cache_lookup_result . status ): formula_broken_component_ids . add ( symbol_mapping . component_id ) # If a meter is broken the formula cannot be evaluated if symbol_mapping . category == SymbolComponentCategory . METER : broken_meter_found = True continue # For component categories different than meter, apply the # default entry if default_entry is None : return None kwargs [ symbol ] = default_entry . value timestamp = max ( timestamp , default_entry . timestamp ) # Component data is available and up to date if cache_lookup_result . entry is not None : kwargs [ symbol ] = cache_lookup_result . entry . value timestamp = max ( timestamp , cache_lookup_result . entry . timestamp ) if broken_meter_found : return TimeSeriesEntry . create_unknown ( timestamp = timestamp , broken_component_ids = formula_broken_component_ids , ) try : return TimeSeriesEntry ( timestamp = timestamp , value = self ( ** kwargs )) except Exception : # pylint:disable=broad-except logger . exception ( 'Formula \" %s \" raised an unexpected Exception' , formula_name ) return TimeSeriesEntry . create_error ( timestamp = timestamp ) Functions \u00a4 evaluate ( cache , formula_name = '' , symbol_to_symbol_mapping = None , timedelta_tolerance = timedelta . max , default_entry = None ) \u00a4 Evaluate the formula using time-series values from the provided cache. The underlying assumption of the evaluation process is that measurements from each time series will be offset slightly in time, but may still be combined if that offset is small enough. By default the permitted offset is the maximum possible timedelta , in which case the mere existence of a value in each time series will be enough. This is probably not desirable for real-world use case so users should take care to always set the timedelta_tolerance parameter to a value that matches their use-case (for example, if the rate of update of time series is 0.2 sec, a timedelta_tolerance of 0.2 sec is recommended). PARAMETER DESCRIPTION cache cache of the most recent time series values, where the key should match the variable name in the formula (so e.g. if the formula is x + y then the cache should contain keys \"x\" and \"y\" ) TYPE: LatestEntryCache [ str , Value ] formula_name user-defined name for the formula TYPE: str DEFAULT: '' symbol_to_symbol_mapping mapping of symbols in string representation to symbol mappings TYPE: Optional [ Dict [ str , SymbolMapping ]] DEFAULT: None timedelta_tolerance maximum permitted time difference between cache.latest_timestamp and the timestamp of any cached entry (if this is violated, the result will be the same as if an entry for the given key does not exist) TYPE: timedelta DEFAULT: timedelta.max default_entry what entry to use if the entry for a given symbol is not found in the cache, or if the cached entry is not within the limits of timedelta_tolerance . If None, then formula won't be evaluated and None will be returned. TYPE: Optional [ TimeSeriesEntry [ Value ]] DEFAULT: None RETURNS DESCRIPTION Optional [ TimeSeriesEntry [ Value ]] Result of the formula, with a timestamp equal to the highest timestamp among all of the combined time series entries, and a value that equals the formula result, or None if any of the required time series variables are not present in cache or are older than timedelta_tolerance Source code in frequenz/sdk/data_handling/time_series.py 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 def evaluate ( self , cache : LatestEntryCache [ str , Value ], formula_name : str = \"\" , symbol_to_symbol_mapping : Optional [ Dict [ str , SymbolMapping ]] = None , timedelta_tolerance : timedelta = timedelta . max , default_entry : Optional [ TimeSeriesEntry [ Value ]] = None , ) -> Optional [ TimeSeriesEntry [ Value ]]: \"\"\"Evaluate the formula using time-series values from the provided cache. The underlying assumption of the evaluation process is that measurements from each time series will be offset slightly in time, but may still be combined if that offset is small enough. By default the permitted offset is the maximum possible `timedelta`, in which case the mere existence of a value in each time series will be enough. This is probably not desirable for real-world use case so users should take care to always set the `timedelta_tolerance` parameter to a value that matches their use-case (for example, if the rate of update of time series is 0.2 sec, a `timedelta_tolerance` of 0.2 sec is recommended). Args: cache: cache of the most recent time series values, where the key should match the variable name in the formula (so e.g. if the formula is `x + y` then the cache should contain keys `\"x\"` and `\"y\"`) formula_name: user-defined name for the formula symbol_to_symbol_mapping: mapping of symbols in string representation to symbol mappings timedelta_tolerance: maximum permitted time difference between `cache.latest_timestamp` and the timestamp of any cached entry (if this is violated, the result will be the same as if an entry for the given key does not exist) default_entry: what entry to use if the entry for a given symbol is not found in the cache, or if the cached entry is not within the limits of `timedelta_tolerance`. If None, then formula won't be evaluated and None will be returned. Returns: Result of the formula, with a `timestamp` equal to the highest timestamp among all of the combined time series entries, and a `value` that equals the formula result, or `None` if any of the required time series variables are not present in `cache` or are older than `timedelta_tolerance` \"\"\" kwargs : Dict [ str , Optional [ Value ]] = {} timestamp = datetime . min . replace ( tzinfo = timezone . utc ) symbol_to_symbol_mapping = symbol_to_symbol_mapping or {} formula_broken_component_ids : Set [ int ] = set () broken_meter_found = False for symbol in self . _symbols : symbol_mapping = symbol_to_symbol_mapping . get ( symbol ) cache_lookup_result = cache . get ( symbol , timedelta_tolerance , default = default_entry ) # If the value wasn't found in the cache and no symbol mapping was provided # for this symbol (meaning it cannot be determined what component category # it refers to), then return `default_entry` if it was provided, otherwise # the formula cannot be evaluated and `None` will be returned # if cache_lookup_result.entry is None: # return default_entry if default_entry is not None else None # Symbol metadata is not available, e.g. component category if symbol_mapping is None : # Component data is available and up to date if cache_lookup_result . entry is not None : kwargs [ symbol ] = cache_lookup_result . entry . value timestamp = max ( timestamp , cache_lookup_result . entry . timestamp ) # Otherwise, apply the default entry if it was provided, and if it # wasn't return `None` as the formula result as it cannot be evaluated else : if default_entry is None : return None kwargs [ symbol ] = default_entry . value timestamp = max ( timestamp , default_entry . timestamp ) # Symbol metadata is available, e.g. component category else : # When a component is broken, keep collecting ids of broken components # that this formula relies on, and if there's any meter among these, # return `UNKNOWN` as the formula result, otherwise fill in the values # of broken components with the `default_entry` and evaluate the formula if self . _is_component_broken ( cache_lookup_result . status ): formula_broken_component_ids . add ( symbol_mapping . component_id ) # If a meter is broken the formula cannot be evaluated if symbol_mapping . category == SymbolComponentCategory . METER : broken_meter_found = True continue # For component categories different than meter, apply the # default entry if default_entry is None : return None kwargs [ symbol ] = default_entry . value timestamp = max ( timestamp , default_entry . timestamp ) # Component data is available and up to date if cache_lookup_result . entry is not None : kwargs [ symbol ] = cache_lookup_result . entry . value timestamp = max ( timestamp , cache_lookup_result . entry . timestamp ) if broken_meter_found : return TimeSeriesEntry . create_unknown ( timestamp = timestamp , broken_component_ids = formula_broken_component_ids , ) try : return TimeSeriesEntry ( timestamp = timestamp , value = self ( ** kwargs )) except Exception : # pylint:disable=broad-except logger . exception ( 'Formula \" %s \" raised an unexpected Exception' , formula_name ) return TimeSeriesEntry . create_error ( timestamp = timestamp )","title":"time_series"},{"location":"reference/frequenz/sdk/data_handling/time_series/#frequenz.sdk.data_handling.time_series","text":"Helper classes for tracking values from time-series data streams.","title":"time_series"},{"location":"reference/frequenz/sdk/data_handling/time_series/#frequenz.sdk.data_handling.time_series-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/data_handling/time_series/#frequenz.sdk.data_handling.time_series.BatteryField","text":"Bases: ComponentField Name of the fields from streamed battery data. Source code in frequenz/sdk/data_handling/time_series.py 36 37 38 39 40 41 42 class BatteryField ( ComponentField ): \"\"\"Name of the fields from streamed battery data.\"\"\" SOC = \"soc\" CAPACITY = \"capacity\" POWER_UPPER_BOUND = \"power_upper_bound\" POWER_LOWER_BOUND = \"power_lower_bound\"","title":"BatteryField"},{"location":"reference/frequenz/sdk/data_handling/time_series/#frequenz.sdk.data_handling.time_series.CacheEntryLookupResult","text":"Bases: Generic [ Value ] Component ids and meter connections for components of a specific type. Source code in frequenz/sdk/data_handling/time_series.py 146 147 148 149 150 151 152 153 154 155 156 157 158 @dataclass ( frozen = True ) class CacheEntryLookupResult ( Generic [ Value ]): \"\"\"Component ids and meter connections for components of a specific type.\"\"\" class Status ( enum . Enum ): \"\"\"Possible outcomes of looking up a key in a cache.\"\"\" HIT = \"hit\" MISS = \"miss\" EXPIRED = \"expired\" status : Status entry : Optional [ TimeSeriesEntry [ Value ]] = None","title":"CacheEntryLookupResult"},{"location":"reference/frequenz/sdk/data_handling/time_series/#frequenz.sdk.data_handling.time_series.CacheEntryLookupResult-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/data_handling/time_series/#frequenz.sdk.data_handling.time_series.CacheEntryLookupResult.Status","text":"Bases: enum . Enum Possible outcomes of looking up a key in a cache. Source code in frequenz/sdk/data_handling/time_series.py 150 151 152 153 154 155 class Status ( enum . Enum ): \"\"\"Possible outcomes of looking up a key in a cache.\"\"\" HIT = \"hit\" MISS = \"miss\" EXPIRED = \"expired\"","title":"Status"},{"location":"reference/frequenz/sdk/data_handling/time_series/#frequenz.sdk.data_handling.time_series.ComponentField","text":"Bases: enum . Enum Name of the field from streamed component data. Source code in frequenz/sdk/data_handling/time_series.py 32 33 class ComponentField ( enum . Enum ): \"\"\"Name of the field from streamed component data.\"\"\"","title":"ComponentField"},{"location":"reference/frequenz/sdk/data_handling/time_series/#frequenz.sdk.data_handling.time_series.EVChargerField","text":"Bases: ComponentField Name of the fields from streamed ev charger data. Source code in frequenz/sdk/data_handling/time_series.py 59 60 61 62 class EVChargerField ( ComponentField ): \"\"\"Name of the fields from streamed ev charger data.\"\"\" ACTIVE_POWER = \"active_power\"","title":"EVChargerField"},{"location":"reference/frequenz/sdk/data_handling/time_series/#frequenz.sdk.data_handling.time_series.InverterField","text":"Bases: ComponentField Name of the fields from streamed inverter data. Source code in frequenz/sdk/data_handling/time_series.py 45 46 47 48 49 50 class InverterField ( ComponentField ): \"\"\"Name of the fields from streamed inverter data.\"\"\" ACTIVE_POWER = \"active_power\" ACTIVE_POWER_UPPER_BOUND = \"active_power_upper_bound\" ACTIVE_POWER_LOWER_BOUND = \"active_power_lower_bound\"","title":"InverterField"},{"location":"reference/frequenz/sdk/data_handling/time_series/#frequenz.sdk.data_handling.time_series.LatestEntryCache","text":"Bases: Generic [ Key , Value ] Cache of the most recent values observed in one or more time series. Each time series is identified in the cache via a unique Key , and it is expected that every time series will be of the same type of Value . Source code in frequenz/sdk/data_handling/time_series.py 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 class LatestEntryCache ( Generic [ Key , Value ]): \"\"\"Cache of the most recent values observed in one or more time series. Each time series is identified in the cache via a unique `Key`, and it is expected that every time series will be of the same type of `Value`. \"\"\" def __init__ ( self ) -> None : \"\"\"Initialize the class.\"\"\" self . _latest_timestamp = datetime . min . replace ( tzinfo = timezone . utc ) self . _entries : Dict [ Key , TimeSeriesEntry [ Value ]] = {} @property def latest_timestamp ( self ) -> datetime : \"\"\"Get the most recently observed timestamp across all keys in the cache. Returns: The highest timestamp out of all entries in the cache, or `datetime.min` if there are no cache entries. \"\"\" return self . _latest_timestamp def clear ( self ) -> None : \"\"\"Clear all entries from the cache. This will not affect `latest_timestamp`. If you want to restore the cache to its initial state, use the `reset` method instead. \"\"\" self . _entries . clear () def __contains__ ( self , key : Key ) -> bool : \"\"\"Check if a cache entry exists for the specified key. Args: key: key to search for. Returns: `True` if the cache contains an entry for `key`, `False` otherwise. \"\"\" return key in self . _entries def get ( self , key : Key , timedelta_tolerance : timedelta = timedelta . max , default : Optional [ TimeSeriesEntry [ Value ]] = None , ) -> CacheEntryLookupResult [ Value ]: \"\"\"Get the cached entry for the specified key, if any. Args: key: key for which to look up the cached entry timedelta_tolerance: maximum permitted time difference between `latest_timestamp` and the timestamp of the cached entry default: what to return if the `key` is not found in the cache, or if the cached entry is not within the limits of `timedelta_tolerance` Returns: The cached entry associated with the provided `key`, or `default` if either there is no entry for the `key`, or if the difference between the cached timestamp and `latest_timestamp` is greater than `timedelta_tolerance` Raises: ValueError: when either timedelta_tolerance is negative or an entry retrieved from the cache has a timestamp greater than the latest saved timestamp across all cache keys. \"\"\" if timedelta_tolerance < timedelta ( 0 ): raise ValueError ( f \"timedelta_tolerance cannot be less than 0, but \" f \" { timedelta_tolerance } was provided\" ) entry = self . _entries . get ( key , None ) if entry is None : logger . debug ( \"LatestEntryCache: missing data for key %s \" , key ) return CacheEntryLookupResult ( status = CacheEntryLookupResult . Status . MISS , entry = default ) if entry . timestamp > self . _latest_timestamp : raise ValueError ( \"Timestamp of single entry in the cache cannot be greater\" \" than the latest timestamp across entries for all keys.\" ) delta = self . _latest_timestamp - entry . timestamp if delta > timedelta_tolerance : logger . debug ( \"LatestEntryCache: data for key %s is outdated\" , key ) logger . debug ( \"latest timestamp: %s \" , self . _latest_timestamp ) logger . debug ( \"entry timestamp: %s \" , entry . timestamp ) logger . debug ( \"timedelta: %s \" , delta ) logger . debug ( \"tolerance: %s \" , timedelta_tolerance ) return CacheEntryLookupResult ( status = CacheEntryLookupResult . Status . EXPIRED , entry = default ) return CacheEntryLookupResult ( status = CacheEntryLookupResult . Status . HIT , entry = entry ) def keys ( self ) -> Collection [ Key ]: \"\"\"Get all the keys with entries in the cache. Returns: All the keys with an entry in the cache \"\"\" return self . _entries . keys () def __len__ ( self ) -> int : \"\"\"Get the total number of entries stored in the cache. Returns: The total number of keys with entries in the cache. \"\"\" return len ( self . _entries ) def pop ( self , key : Key , default : Optional [ TimeSeriesEntry [ Value ]] = None , ) -> CacheEntryLookupResult [ Value ]: \"\"\"Pop the entry for the specified key from the cache, if it exists. Note that this does not affect `latest_timestamp`, even if the removed entry was the only one in the cache. Use the `reset_latest_timestamp` method to eliminate the impact of timestamps from removed entries. Args: key: key whose cache entry to remove default: what to return if the `key` is not found in the cache Returns: Popped value if it exists, `None` otherwise \"\"\" entry = self . _entries . pop ( key , None ) if entry is None : return CacheEntryLookupResult ( status = CacheEntryLookupResult . Status . MISS , entry = default ) return CacheEntryLookupResult ( status = CacheEntryLookupResult . Status . HIT , entry = entry ) def reset ( self ) -> None : \"\"\"Reset the cache to its default initial state. This will clear out all cache entries and reset the `latest_timestamp` property to `datetime.min`. It is equivalent to separately calling the `clear` and `reset_latest_timestamp` methods in succession, but is very slightly more efficient. \"\"\" self . clear () self . _latest_timestamp = datetime . min . replace ( tzinfo = timezone . utc ) def reset_latest_timestamp ( self ) -> bool : \"\"\"Reset the `latest_timestamp` property to the lowest possible value. This will be equal to either the highest timestamp out of any entries remaining in the cache, or `datetime.min` if no entries remain. Note that this is an O(N) operation, so may be expensive. It is meant to be used only in order to correct an error introduced into the cache, e.g. after removing one or more entries with invalid timestamps. Returns: `True` if the latest timestamp was modified, `False` otherwise. Raises: ValueError: if the new latest timestamp is greater than the previous one \"\"\" previous = self . _latest_timestamp self . _latest_timestamp = max ( map ( lambda x : x . timestamp , self . _entries . values ()), default = datetime . min . replace ( tzinfo = timezone . utc ), ) if self . _latest_timestamp > previous : raise ValueError ( \"The new latest timestamp after reset cannot be greater \" \"than the latest timestamp before the reset.\" ) return previous != self . _latest_timestamp def update ( self , key : Key , entry : TimeSeriesEntry [ Value ]) -> bool : \"\"\"Insert or update an entry for a specific key. Args: key: key to associate with the entry entry: entry to add to the cache (will be accepted if `key` is new, or if the timestamp of the existing entry is older than `entry.timestamp`) Returns: `True` if `entry` was added to the cache, `False` otherwise Raises: AttributeError: if timestamps are not timezone-aware \"\"\" # sanity check that entry timestamp is valid if ( entry . timestamp . tzinfo is None or entry . timestamp . tzinfo . utcoffset ( entry . timestamp ) is None ): raise AttributeError ( \"Entry's timestamp must be timezone-aware.\" ) self . _latest_timestamp = max ( self . _latest_timestamp , entry . timestamp ) last = self . _entries . get ( key , None ) if last is None or entry . timestamp > last . timestamp : self . _entries [ key ] = entry return True logger . debug ( \"TimeSeriesEntryCache: entry for key %s is outdated\" , key ) logger . debug ( \"previously observed timestamp: %s \" , last . timestamp ) logger . debug ( \"entry timestamp: %s \" , entry . timestamp ) return False","title":"LatestEntryCache"},{"location":"reference/frequenz/sdk/data_handling/time_series/#frequenz.sdk.data_handling.time_series.LatestEntryCache-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/data_handling/time_series/#frequenz.sdk.data_handling.time_series.LatestEntryCache.__contains__","text":"Check if a cache entry exists for the specified key. PARAMETER DESCRIPTION key key to search for. TYPE: Key RETURNS DESCRIPTION bool True if the cache contains an entry for key , False otherwise. Source code in frequenz/sdk/data_handling/time_series.py 191 192 193 194 195 196 197 198 199 200 def __contains__ ( self , key : Key ) -> bool : \"\"\"Check if a cache entry exists for the specified key. Args: key: key to search for. Returns: `True` if the cache contains an entry for `key`, `False` otherwise. \"\"\" return key in self . _entries","title":"__contains__()"},{"location":"reference/frequenz/sdk/data_handling/time_series/#frequenz.sdk.data_handling.time_series.LatestEntryCache.__init__","text":"Initialize the class. Source code in frequenz/sdk/data_handling/time_series.py 168 169 170 171 def __init__ ( self ) -> None : \"\"\"Initialize the class.\"\"\" self . _latest_timestamp = datetime . min . replace ( tzinfo = timezone . utc ) self . _entries : Dict [ Key , TimeSeriesEntry [ Value ]] = {}","title":"__init__()"},{"location":"reference/frequenz/sdk/data_handling/time_series/#frequenz.sdk.data_handling.time_series.LatestEntryCache.__len__","text":"Get the total number of entries stored in the cache. RETURNS DESCRIPTION int The total number of keys with entries in the cache. Source code in frequenz/sdk/data_handling/time_series.py 272 273 274 275 276 277 278 def __len__ ( self ) -> int : \"\"\"Get the total number of entries stored in the cache. Returns: The total number of keys with entries in the cache. \"\"\" return len ( self . _entries )","title":"__len__()"},{"location":"reference/frequenz/sdk/data_handling/time_series/#frequenz.sdk.data_handling.time_series.LatestEntryCache.clear","text":"Clear all entries from the cache. This will not affect latest_timestamp . If you want to restore the cache to its initial state, use the reset method instead. Source code in frequenz/sdk/data_handling/time_series.py 183 184 185 186 187 188 189 def clear ( self ) -> None : \"\"\"Clear all entries from the cache. This will not affect `latest_timestamp`. If you want to restore the cache to its initial state, use the `reset` method instead. \"\"\" self . _entries . clear ()","title":"clear()"},{"location":"reference/frequenz/sdk/data_handling/time_series/#frequenz.sdk.data_handling.time_series.LatestEntryCache.get","text":"Get the cached entry for the specified key, if any. PARAMETER DESCRIPTION key key for which to look up the cached entry TYPE: Key timedelta_tolerance maximum permitted time difference between latest_timestamp and the timestamp of the cached entry TYPE: timedelta DEFAULT: timedelta.max default what to return if the key is not found in the cache, or if the cached entry is not within the limits of timedelta_tolerance TYPE: Optional [ TimeSeriesEntry [ Value ]] DEFAULT: None RETURNS DESCRIPTION CacheEntryLookupResult [ Value ] The cached entry associated with the provided key , or default if either there is no entry for the key , or if the difference between the cached timestamp and latest_timestamp is greater than timedelta_tolerance RAISES DESCRIPTION ValueError when either timedelta_tolerance is negative or an entry retrieved from the cache has a timestamp greater than the latest saved timestamp across all cache keys. Source code in frequenz/sdk/data_handling/time_series.py 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 def get ( self , key : Key , timedelta_tolerance : timedelta = timedelta . max , default : Optional [ TimeSeriesEntry [ Value ]] = None , ) -> CacheEntryLookupResult [ Value ]: \"\"\"Get the cached entry for the specified key, if any. Args: key: key for which to look up the cached entry timedelta_tolerance: maximum permitted time difference between `latest_timestamp` and the timestamp of the cached entry default: what to return if the `key` is not found in the cache, or if the cached entry is not within the limits of `timedelta_tolerance` Returns: The cached entry associated with the provided `key`, or `default` if either there is no entry for the `key`, or if the difference between the cached timestamp and `latest_timestamp` is greater than `timedelta_tolerance` Raises: ValueError: when either timedelta_tolerance is negative or an entry retrieved from the cache has a timestamp greater than the latest saved timestamp across all cache keys. \"\"\" if timedelta_tolerance < timedelta ( 0 ): raise ValueError ( f \"timedelta_tolerance cannot be less than 0, but \" f \" { timedelta_tolerance } was provided\" ) entry = self . _entries . get ( key , None ) if entry is None : logger . debug ( \"LatestEntryCache: missing data for key %s \" , key ) return CacheEntryLookupResult ( status = CacheEntryLookupResult . Status . MISS , entry = default ) if entry . timestamp > self . _latest_timestamp : raise ValueError ( \"Timestamp of single entry in the cache cannot be greater\" \" than the latest timestamp across entries for all keys.\" ) delta = self . _latest_timestamp - entry . timestamp if delta > timedelta_tolerance : logger . debug ( \"LatestEntryCache: data for key %s is outdated\" , key ) logger . debug ( \"latest timestamp: %s \" , self . _latest_timestamp ) logger . debug ( \"entry timestamp: %s \" , entry . timestamp ) logger . debug ( \"timedelta: %s \" , delta ) logger . debug ( \"tolerance: %s \" , timedelta_tolerance ) return CacheEntryLookupResult ( status = CacheEntryLookupResult . Status . EXPIRED , entry = default ) return CacheEntryLookupResult ( status = CacheEntryLookupResult . Status . HIT , entry = entry )","title":"get()"},{"location":"reference/frequenz/sdk/data_handling/time_series/#frequenz.sdk.data_handling.time_series.LatestEntryCache.keys","text":"Get all the keys with entries in the cache. RETURNS DESCRIPTION Collection [ Key ] All the keys with an entry in the cache Source code in frequenz/sdk/data_handling/time_series.py 264 265 266 267 268 269 270 def keys ( self ) -> Collection [ Key ]: \"\"\"Get all the keys with entries in the cache. Returns: All the keys with an entry in the cache \"\"\" return self . _entries . keys ()","title":"keys()"},{"location":"reference/frequenz/sdk/data_handling/time_series/#frequenz.sdk.data_handling.time_series.LatestEntryCache.latest_timestamp","text":"Get the most recently observed timestamp across all keys in the cache. RETURNS DESCRIPTION datetime The highest timestamp out of all entries in the cache, or datetime.min if there are no cache entries. Source code in frequenz/sdk/data_handling/time_series.py 173 174 175 176 177 178 179 180 181 @property def latest_timestamp ( self ) -> datetime : \"\"\"Get the most recently observed timestamp across all keys in the cache. Returns: The highest timestamp out of all entries in the cache, or `datetime.min` if there are no cache entries. \"\"\" return self . _latest_timestamp","title":"latest_timestamp()"},{"location":"reference/frequenz/sdk/data_handling/time_series/#frequenz.sdk.data_handling.time_series.LatestEntryCache.pop","text":"Pop the entry for the specified key from the cache, if it exists. Note that this does not affect latest_timestamp , even if the removed entry was the only one in the cache. Use the reset_latest_timestamp method to eliminate the impact of timestamps from removed entries. PARAMETER DESCRIPTION key key whose cache entry to remove TYPE: Key default what to return if the key is not found in the cache TYPE: Optional [ TimeSeriesEntry [ Value ]] DEFAULT: None RETURNS DESCRIPTION CacheEntryLookupResult [ Value ] Popped value if it exists, None otherwise Source code in frequenz/sdk/data_handling/time_series.py 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 def pop ( self , key : Key , default : Optional [ TimeSeriesEntry [ Value ]] = None , ) -> CacheEntryLookupResult [ Value ]: \"\"\"Pop the entry for the specified key from the cache, if it exists. Note that this does not affect `latest_timestamp`, even if the removed entry was the only one in the cache. Use the `reset_latest_timestamp` method to eliminate the impact of timestamps from removed entries. Args: key: key whose cache entry to remove default: what to return if the `key` is not found in the cache Returns: Popped value if it exists, `None` otherwise \"\"\" entry = self . _entries . pop ( key , None ) if entry is None : return CacheEntryLookupResult ( status = CacheEntryLookupResult . Status . MISS , entry = default ) return CacheEntryLookupResult ( status = CacheEntryLookupResult . Status . HIT , entry = entry )","title":"pop()"},{"location":"reference/frequenz/sdk/data_handling/time_series/#frequenz.sdk.data_handling.time_series.LatestEntryCache.reset","text":"Reset the cache to its default initial state. This will clear out all cache entries and reset the latest_timestamp property to datetime.min . It is equivalent to separately calling the clear and reset_latest_timestamp methods in succession, but is very slightly more efficient. Source code in frequenz/sdk/data_handling/time_series.py 307 308 309 310 311 312 313 314 315 316 def reset ( self ) -> None : \"\"\"Reset the cache to its default initial state. This will clear out all cache entries and reset the `latest_timestamp` property to `datetime.min`. It is equivalent to separately calling the `clear` and `reset_latest_timestamp` methods in succession, but is very slightly more efficient. \"\"\" self . clear () self . _latest_timestamp = datetime . min . replace ( tzinfo = timezone . utc )","title":"reset()"},{"location":"reference/frequenz/sdk/data_handling/time_series/#frequenz.sdk.data_handling.time_series.LatestEntryCache.reset_latest_timestamp","text":"Reset the latest_timestamp property to the lowest possible value. This will be equal to either the highest timestamp out of any entries remaining in the cache, or datetime.min if no entries remain. Note that this is an O(N) operation, so may be expensive. It is meant to be used only in order to correct an error introduced into the cache, e.g. after removing one or more entries with invalid timestamps. RETURNS DESCRIPTION bool True if the latest timestamp was modified, False otherwise. RAISES DESCRIPTION ValueError if the new latest timestamp is greater than the previous one Source code in frequenz/sdk/data_handling/time_series.py 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 def reset_latest_timestamp ( self ) -> bool : \"\"\"Reset the `latest_timestamp` property to the lowest possible value. This will be equal to either the highest timestamp out of any entries remaining in the cache, or `datetime.min` if no entries remain. Note that this is an O(N) operation, so may be expensive. It is meant to be used only in order to correct an error introduced into the cache, e.g. after removing one or more entries with invalid timestamps. Returns: `True` if the latest timestamp was modified, `False` otherwise. Raises: ValueError: if the new latest timestamp is greater than the previous one \"\"\" previous = self . _latest_timestamp self . _latest_timestamp = max ( map ( lambda x : x . timestamp , self . _entries . values ()), default = datetime . min . replace ( tzinfo = timezone . utc ), ) if self . _latest_timestamp > previous : raise ValueError ( \"The new latest timestamp after reset cannot be greater \" \"than the latest timestamp before the reset.\" ) return previous != self . _latest_timestamp","title":"reset_latest_timestamp()"},{"location":"reference/frequenz/sdk/data_handling/time_series/#frequenz.sdk.data_handling.time_series.LatestEntryCache.update","text":"Insert or update an entry for a specific key. PARAMETER DESCRIPTION key key to associate with the entry TYPE: Key entry entry to add to the cache (will be accepted if key is new, or if the timestamp of the existing entry is older than entry.timestamp ) TYPE: TimeSeriesEntry [ Value ] RETURNS DESCRIPTION bool True if entry was added to the cache, False otherwise RAISES DESCRIPTION AttributeError if timestamps are not timezone-aware Source code in frequenz/sdk/data_handling/time_series.py 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 def update ( self , key : Key , entry : TimeSeriesEntry [ Value ]) -> bool : \"\"\"Insert or update an entry for a specific key. Args: key: key to associate with the entry entry: entry to add to the cache (will be accepted if `key` is new, or if the timestamp of the existing entry is older than `entry.timestamp`) Returns: `True` if `entry` was added to the cache, `False` otherwise Raises: AttributeError: if timestamps are not timezone-aware \"\"\" # sanity check that entry timestamp is valid if ( entry . timestamp . tzinfo is None or entry . timestamp . tzinfo . utcoffset ( entry . timestamp ) is None ): raise AttributeError ( \"Entry's timestamp must be timezone-aware.\" ) self . _latest_timestamp = max ( self . _latest_timestamp , entry . timestamp ) last = self . _entries . get ( key , None ) if last is None or entry . timestamp > last . timestamp : self . _entries [ key ] = entry return True logger . debug ( \"TimeSeriesEntryCache: entry for key %s is outdated\" , key ) logger . debug ( \"previously observed timestamp: %s \" , last . timestamp ) logger . debug ( \"entry timestamp: %s \" , entry . timestamp ) return False","title":"update()"},{"location":"reference/frequenz/sdk/data_handling/time_series/#frequenz.sdk.data_handling.time_series.MeterField","text":"Bases: ComponentField Name of the fields from streamed meter data. Source code in frequenz/sdk/data_handling/time_series.py 53 54 55 56 class MeterField ( ComponentField ): \"\"\"Name of the fields from streamed meter data.\"\"\" ACTIVE_POWER = \"active_power\"","title":"MeterField"},{"location":"reference/frequenz/sdk/data_handling/time_series/#frequenz.sdk.data_handling.time_series.SymbolComponentCategory","text":"Bases: enum . Enum Allowed component categories used in symbols for formula calculations. Source code in frequenz/sdk/data_handling/time_series.py 23 24 25 26 27 28 29 class SymbolComponentCategory ( enum . Enum ): \"\"\"Allowed component categories used in symbols for formula calculations.\"\"\" INVERTER = \"inverter\" BATTERY = \"battery\" EV_CHARGER = \"ev_charger\" METER = \"meter\"","title":"SymbolComponentCategory"},{"location":"reference/frequenz/sdk/data_handling/time_series/#frequenz.sdk.data_handling.time_series.SymbolMapping","text":"Mappings between formula symbols and streamed component data. Source code in frequenz/sdk/data_handling/time_series.py 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 @dataclass ( frozen = True ) class SymbolMapping : \"\"\"Mappings between formula symbols and streamed component data.\"\"\" category : SymbolComponentCategory component_id : int field : ComponentField @property def symbol ( self ) -> str : \"\"\"Create a sympy-compatible symbol from a symbol mapping. For instance, SymbolMapping(SymbolComponentCategory.METER, 5, ComponentField.ACTIVE_POWER) becomes \"meter_5_active_power\". Returns: sympy-compatible symbol mapping encoded as a string \"\"\" return SYMBOL_SEGMENT_SEPARATOR . join ( [ self . category . value , str ( self . component_id ), self . field . value ] )","title":"SymbolMapping"},{"location":"reference/frequenz/sdk/data_handling/time_series/#frequenz.sdk.data_handling.time_series.SymbolMapping-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/data_handling/time_series/#frequenz.sdk.data_handling.time_series.SymbolMapping.symbol","text":"Create a sympy-compatible symbol from a symbol mapping. For instance, SymbolMapping(SymbolComponentCategory.METER, 5, ComponentField.ACTIVE_POWER) becomes \"meter_5_active_power\". RETURNS DESCRIPTION str sympy-compatible symbol mapping encoded as a string Source code in frequenz/sdk/data_handling/time_series.py 73 74 75 76 77 78 79 80 81 82 83 84 85 86 @property def symbol ( self ) -> str : \"\"\"Create a sympy-compatible symbol from a symbol mapping. For instance, SymbolMapping(SymbolComponentCategory.METER, 5, ComponentField.ACTIVE_POWER) becomes \"meter_5_active_power\". Returns: sympy-compatible symbol mapping encoded as a string \"\"\" return SYMBOL_SEGMENT_SEPARATOR . join ( [ self . category . value , str ( self . component_id ), self . field . value ] )","title":"symbol()"},{"location":"reference/frequenz/sdk/data_handling/time_series/#frequenz.sdk.data_handling.time_series.TimeSeriesEntry","text":"Bases: Generic [ Value ] Describes a single observed value (of arbitrary type) at a specific timestamp. Source code in frequenz/sdk/data_handling/time_series.py 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 @dataclass class TimeSeriesEntry ( Generic [ Value ]): \"\"\"Describes a single observed value (of arbitrary type) at a specific timestamp.\"\"\" class Status ( enum . Enum ): \"\"\"Possible status values of a `TimeSeriesEntry`.\"\"\" VALID = \"valid\" UNKNOWN = \"unknown\" ERROR = \"error\" timestamp : datetime value : Optional [ Value ] = None status : Status = Status . VALID broken_component_ids : Set [ int ] = field ( default_factory = set ) @staticmethod def create_error ( timestamp : datetime ) -> TimeSeriesEntry [ Value ]: \"\"\"Create a `TimeSeriesEntry` that contains an error. This can happen when the value would be NaN, e.g. TimeSeriesEntry(value=1 / 0) Args: timestamp: Timestamp Returns: A single observed value (of arbitrary type) at a specific timestamp. \"\"\" return TimeSeriesEntry ( timestamp = timestamp , value = None , status = TimeSeriesEntry . Status . ERROR ) @staticmethod def create_unknown ( timestamp : datetime , broken_component_ids : Optional [ Set [ int ]] = None ) -> TimeSeriesEntry [ Value ]: \"\"\"Create a `TimeSeriesEntry` that contains an unknown value. This can happen when the value cannot be determined, because a component is broken. Args: timestamp: Timestamp broken_component_ids: broken component ids Returns: A single observed value (of arbitrary type) at a specific timestamp. \"\"\" return TimeSeriesEntry ( timestamp = timestamp , value = None , status = TimeSeriesEntry . Status . UNKNOWN , broken_component_ids = broken_component_ids or set (), )","title":"TimeSeriesEntry"},{"location":"reference/frequenz/sdk/data_handling/time_series/#frequenz.sdk.data_handling.time_series.TimeSeriesEntry-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/data_handling/time_series/#frequenz.sdk.data_handling.time_series.TimeSeriesEntry.Status","text":"Bases: enum . Enum Possible status values of a TimeSeriesEntry . Source code in frequenz/sdk/data_handling/time_series.py 93 94 95 96 97 98 class Status ( enum . Enum ): \"\"\"Possible status values of a `TimeSeriesEntry`.\"\"\" VALID = \"valid\" UNKNOWN = \"unknown\" ERROR = \"error\"","title":"Status"},{"location":"reference/frequenz/sdk/data_handling/time_series/#frequenz.sdk.data_handling.time_series.TimeSeriesEntry-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/data_handling/time_series/#frequenz.sdk.data_handling.time_series.TimeSeriesEntry.create_error","text":"Create a TimeSeriesEntry that contains an error. This can happen when the value would be NaN, e.g. TimeSeriesEntry(value=1 / 0) PARAMETER DESCRIPTION timestamp Timestamp TYPE: datetime RETURNS DESCRIPTION TimeSeriesEntry [ Value ] A single observed value (of arbitrary type) at a specific timestamp. Source code in frequenz/sdk/data_handling/time_series.py 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 @staticmethod def create_error ( timestamp : datetime ) -> TimeSeriesEntry [ Value ]: \"\"\"Create a `TimeSeriesEntry` that contains an error. This can happen when the value would be NaN, e.g. TimeSeriesEntry(value=1 / 0) Args: timestamp: Timestamp Returns: A single observed value (of arbitrary type) at a specific timestamp. \"\"\" return TimeSeriesEntry ( timestamp = timestamp , value = None , status = TimeSeriesEntry . Status . ERROR )","title":"create_error()"},{"location":"reference/frequenz/sdk/data_handling/time_series/#frequenz.sdk.data_handling.time_series.TimeSeriesEntry.create_unknown","text":"Create a TimeSeriesEntry that contains an unknown value. This can happen when the value cannot be determined, because a component is broken. PARAMETER DESCRIPTION timestamp Timestamp TYPE: datetime broken_component_ids broken component ids TYPE: Optional [ Set [ int ]] DEFAULT: None RETURNS DESCRIPTION TimeSeriesEntry [ Value ] A single observed value (of arbitrary type) at a specific timestamp. Source code in frequenz/sdk/data_handling/time_series.py 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 @staticmethod def create_unknown ( timestamp : datetime , broken_component_ids : Optional [ Set [ int ]] = None ) -> TimeSeriesEntry [ Value ]: \"\"\"Create a `TimeSeriesEntry` that contains an unknown value. This can happen when the value cannot be determined, because a component is broken. Args: timestamp: Timestamp broken_component_ids: broken component ids Returns: A single observed value (of arbitrary type) at a specific timestamp. \"\"\" return TimeSeriesEntry ( timestamp = timestamp , value = None , status = TimeSeriesEntry . Status . UNKNOWN , broken_component_ids = broken_component_ids or set (), )","title":"create_unknown()"},{"location":"reference/frequenz/sdk/data_handling/time_series/#frequenz.sdk.data_handling.time_series.TimeSeriesFormula","text":"Bases: Formula , Generic [ Value ] Combines values from multiple time series via a specified algebraic formula. Formulas are handled using the sympy library for symbolic mathematics. It is expected that each individual time series will have the same underlying type of Value , and that this Value supports all the operations the formula requires (for example, if the formula is x / 7 and Value does not support division, then the formula cannot be applied). Source code in frequenz/sdk/data_handling/time_series.py 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 class TimeSeriesFormula ( Formula , Generic [ Value ]): \"\"\"Combines values from multiple time series via a specified algebraic formula. Formulas are handled using the `sympy` library for symbolic mathematics. It is expected that each individual time series will have the same underlying type of `Value`, and that this `Value` supports all the operations the formula requires (for example, if the formula is `x / 7` and `Value` does not support division, then the formula cannot be applied). \"\"\" @staticmethod def _is_component_broken ( cache_lookup_result : CacheEntryLookupResult . Status , ) -> bool : \"\"\"Check if a component is broken. Args: cache_lookup_result: an enum saying if data from component with `component_id` was found in the cache or not Returns: `True` if component is broken and `False` otherwise \"\"\" return cache_lookup_result in { CacheEntryLookupResult . Status . MISS , CacheEntryLookupResult . Status . EXPIRED , } # pylint:disable=too-many-arguments def evaluate ( self , cache : LatestEntryCache [ str , Value ], formula_name : str = \"\" , symbol_to_symbol_mapping : Optional [ Dict [ str , SymbolMapping ]] = None , timedelta_tolerance : timedelta = timedelta . max , default_entry : Optional [ TimeSeriesEntry [ Value ]] = None , ) -> Optional [ TimeSeriesEntry [ Value ]]: \"\"\"Evaluate the formula using time-series values from the provided cache. The underlying assumption of the evaluation process is that measurements from each time series will be offset slightly in time, but may still be combined if that offset is small enough. By default the permitted offset is the maximum possible `timedelta`, in which case the mere existence of a value in each time series will be enough. This is probably not desirable for real-world use case so users should take care to always set the `timedelta_tolerance` parameter to a value that matches their use-case (for example, if the rate of update of time series is 0.2 sec, a `timedelta_tolerance` of 0.2 sec is recommended). Args: cache: cache of the most recent time series values, where the key should match the variable name in the formula (so e.g. if the formula is `x + y` then the cache should contain keys `\"x\"` and `\"y\"`) formula_name: user-defined name for the formula symbol_to_symbol_mapping: mapping of symbols in string representation to symbol mappings timedelta_tolerance: maximum permitted time difference between `cache.latest_timestamp` and the timestamp of any cached entry (if this is violated, the result will be the same as if an entry for the given key does not exist) default_entry: what entry to use if the entry for a given symbol is not found in the cache, or if the cached entry is not within the limits of `timedelta_tolerance`. If None, then formula won't be evaluated and None will be returned. Returns: Result of the formula, with a `timestamp` equal to the highest timestamp among all of the combined time series entries, and a `value` that equals the formula result, or `None` if any of the required time series variables are not present in `cache` or are older than `timedelta_tolerance` \"\"\" kwargs : Dict [ str , Optional [ Value ]] = {} timestamp = datetime . min . replace ( tzinfo = timezone . utc ) symbol_to_symbol_mapping = symbol_to_symbol_mapping or {} formula_broken_component_ids : Set [ int ] = set () broken_meter_found = False for symbol in self . _symbols : symbol_mapping = symbol_to_symbol_mapping . get ( symbol ) cache_lookup_result = cache . get ( symbol , timedelta_tolerance , default = default_entry ) # If the value wasn't found in the cache and no symbol mapping was provided # for this symbol (meaning it cannot be determined what component category # it refers to), then return `default_entry` if it was provided, otherwise # the formula cannot be evaluated and `None` will be returned # if cache_lookup_result.entry is None: # return default_entry if default_entry is not None else None # Symbol metadata is not available, e.g. component category if symbol_mapping is None : # Component data is available and up to date if cache_lookup_result . entry is not None : kwargs [ symbol ] = cache_lookup_result . entry . value timestamp = max ( timestamp , cache_lookup_result . entry . timestamp ) # Otherwise, apply the default entry if it was provided, and if it # wasn't return `None` as the formula result as it cannot be evaluated else : if default_entry is None : return None kwargs [ symbol ] = default_entry . value timestamp = max ( timestamp , default_entry . timestamp ) # Symbol metadata is available, e.g. component category else : # When a component is broken, keep collecting ids of broken components # that this formula relies on, and if there's any meter among these, # return `UNKNOWN` as the formula result, otherwise fill in the values # of broken components with the `default_entry` and evaluate the formula if self . _is_component_broken ( cache_lookup_result . status ): formula_broken_component_ids . add ( symbol_mapping . component_id ) # If a meter is broken the formula cannot be evaluated if symbol_mapping . category == SymbolComponentCategory . METER : broken_meter_found = True continue # For component categories different than meter, apply the # default entry if default_entry is None : return None kwargs [ symbol ] = default_entry . value timestamp = max ( timestamp , default_entry . timestamp ) # Component data is available and up to date if cache_lookup_result . entry is not None : kwargs [ symbol ] = cache_lookup_result . entry . value timestamp = max ( timestamp , cache_lookup_result . entry . timestamp ) if broken_meter_found : return TimeSeriesEntry . create_unknown ( timestamp = timestamp , broken_component_ids = formula_broken_component_ids , ) try : return TimeSeriesEntry ( timestamp = timestamp , value = self ( ** kwargs )) except Exception : # pylint:disable=broad-except logger . exception ( 'Formula \" %s \" raised an unexpected Exception' , formula_name ) return TimeSeriesEntry . create_error ( timestamp = timestamp )","title":"TimeSeriesFormula"},{"location":"reference/frequenz/sdk/data_handling/time_series/#frequenz.sdk.data_handling.time_series.TimeSeriesFormula-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/data_handling/time_series/#frequenz.sdk.data_handling.time_series.TimeSeriesFormula.evaluate","text":"Evaluate the formula using time-series values from the provided cache. The underlying assumption of the evaluation process is that measurements from each time series will be offset slightly in time, but may still be combined if that offset is small enough. By default the permitted offset is the maximum possible timedelta , in which case the mere existence of a value in each time series will be enough. This is probably not desirable for real-world use case so users should take care to always set the timedelta_tolerance parameter to a value that matches their use-case (for example, if the rate of update of time series is 0.2 sec, a timedelta_tolerance of 0.2 sec is recommended). PARAMETER DESCRIPTION cache cache of the most recent time series values, where the key should match the variable name in the formula (so e.g. if the formula is x + y then the cache should contain keys \"x\" and \"y\" ) TYPE: LatestEntryCache [ str , Value ] formula_name user-defined name for the formula TYPE: str DEFAULT: '' symbol_to_symbol_mapping mapping of symbols in string representation to symbol mappings TYPE: Optional [ Dict [ str , SymbolMapping ]] DEFAULT: None timedelta_tolerance maximum permitted time difference between cache.latest_timestamp and the timestamp of any cached entry (if this is violated, the result will be the same as if an entry for the given key does not exist) TYPE: timedelta DEFAULT: timedelta.max default_entry what entry to use if the entry for a given symbol is not found in the cache, or if the cached entry is not within the limits of timedelta_tolerance . If None, then formula won't be evaluated and None will be returned. TYPE: Optional [ TimeSeriesEntry [ Value ]] DEFAULT: None RETURNS DESCRIPTION Optional [ TimeSeriesEntry [ Value ]] Result of the formula, with a timestamp equal to the highest timestamp among all of the combined time series entries, and a value that equals the formula result, or None if any of the required time series variables are not present in cache or are older than timedelta_tolerance Source code in frequenz/sdk/data_handling/time_series.py 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 def evaluate ( self , cache : LatestEntryCache [ str , Value ], formula_name : str = \"\" , symbol_to_symbol_mapping : Optional [ Dict [ str , SymbolMapping ]] = None , timedelta_tolerance : timedelta = timedelta . max , default_entry : Optional [ TimeSeriesEntry [ Value ]] = None , ) -> Optional [ TimeSeriesEntry [ Value ]]: \"\"\"Evaluate the formula using time-series values from the provided cache. The underlying assumption of the evaluation process is that measurements from each time series will be offset slightly in time, but may still be combined if that offset is small enough. By default the permitted offset is the maximum possible `timedelta`, in which case the mere existence of a value in each time series will be enough. This is probably not desirable for real-world use case so users should take care to always set the `timedelta_tolerance` parameter to a value that matches their use-case (for example, if the rate of update of time series is 0.2 sec, a `timedelta_tolerance` of 0.2 sec is recommended). Args: cache: cache of the most recent time series values, where the key should match the variable name in the formula (so e.g. if the formula is `x + y` then the cache should contain keys `\"x\"` and `\"y\"`) formula_name: user-defined name for the formula symbol_to_symbol_mapping: mapping of symbols in string representation to symbol mappings timedelta_tolerance: maximum permitted time difference between `cache.latest_timestamp` and the timestamp of any cached entry (if this is violated, the result will be the same as if an entry for the given key does not exist) default_entry: what entry to use if the entry for a given symbol is not found in the cache, or if the cached entry is not within the limits of `timedelta_tolerance`. If None, then formula won't be evaluated and None will be returned. Returns: Result of the formula, with a `timestamp` equal to the highest timestamp among all of the combined time series entries, and a `value` that equals the formula result, or `None` if any of the required time series variables are not present in `cache` or are older than `timedelta_tolerance` \"\"\" kwargs : Dict [ str , Optional [ Value ]] = {} timestamp = datetime . min . replace ( tzinfo = timezone . utc ) symbol_to_symbol_mapping = symbol_to_symbol_mapping or {} formula_broken_component_ids : Set [ int ] = set () broken_meter_found = False for symbol in self . _symbols : symbol_mapping = symbol_to_symbol_mapping . get ( symbol ) cache_lookup_result = cache . get ( symbol , timedelta_tolerance , default = default_entry ) # If the value wasn't found in the cache and no symbol mapping was provided # for this symbol (meaning it cannot be determined what component category # it refers to), then return `default_entry` if it was provided, otherwise # the formula cannot be evaluated and `None` will be returned # if cache_lookup_result.entry is None: # return default_entry if default_entry is not None else None # Symbol metadata is not available, e.g. component category if symbol_mapping is None : # Component data is available and up to date if cache_lookup_result . entry is not None : kwargs [ symbol ] = cache_lookup_result . entry . value timestamp = max ( timestamp , cache_lookup_result . entry . timestamp ) # Otherwise, apply the default entry if it was provided, and if it # wasn't return `None` as the formula result as it cannot be evaluated else : if default_entry is None : return None kwargs [ symbol ] = default_entry . value timestamp = max ( timestamp , default_entry . timestamp ) # Symbol metadata is available, e.g. component category else : # When a component is broken, keep collecting ids of broken components # that this formula relies on, and if there's any meter among these, # return `UNKNOWN` as the formula result, otherwise fill in the values # of broken components with the `default_entry` and evaluate the formula if self . _is_component_broken ( cache_lookup_result . status ): formula_broken_component_ids . add ( symbol_mapping . component_id ) # If a meter is broken the formula cannot be evaluated if symbol_mapping . category == SymbolComponentCategory . METER : broken_meter_found = True continue # For component categories different than meter, apply the # default entry if default_entry is None : return None kwargs [ symbol ] = default_entry . value timestamp = max ( timestamp , default_entry . timestamp ) # Component data is available and up to date if cache_lookup_result . entry is not None : kwargs [ symbol ] = cache_lookup_result . entry . value timestamp = max ( timestamp , cache_lookup_result . entry . timestamp ) if broken_meter_found : return TimeSeriesEntry . create_unknown ( timestamp = timestamp , broken_component_ids = formula_broken_component_ids , ) try : return TimeSeriesEntry ( timestamp = timestamp , value = self ( ** kwargs )) except Exception : # pylint:disable=broad-except logger . exception ( 'Formula \" %s \" raised an unexpected Exception' , formula_name ) return TimeSeriesEntry . create_error ( timestamp = timestamp )","title":"evaluate()"},{"location":"reference/frequenz/sdk/data_ingestion/","text":"frequenz.sdk.data_ingestion \u00a4 Tools for data ingestion. Classes \u00a4 frequenz.sdk.data_ingestion.MicrogridData \u00a4 Actor for receiving component data, calculating formulas and sending results. Source code in frequenz/sdk/data_ingestion/microgrid_data.py 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 @actor class MicrogridData : # pylint: disable=too-many-instance-attributes \"\"\"Actor for receiving component data, calculating formulas and sending results.\"\"\" # current number of arguments already minimum for purpose of MicrogridData # (client, component graph, output channels, additional formula and symbols) def __init__ ( # pylint: disable=too-many-arguments self , microgrid_client : MicrogridApiClient , component_graph : ComponentGraph , outputs : Dict [ str , Sender [ TimeSeriesEntry [ Any ]]], formula_calculator : FormulaCalculator , config_update_receiver : Optional [ Receiver [ Config ]] = None , wait_for_data_sec : float = 2 , formula_update_interval_sec : float = 0.5 , ) -> None : \"\"\"Initialise MicrogridData actor. Args: microgrid_client: microgrid client component_graph: component graph of microgrid outputs: senders for output to channel formula_calculator: an instance of FormulaCalculator responsible for managing symbols and evaluating formulas config_update_receiver: receiver for receiving config file updates wait_for_data_sec: how long actor should wait before processing first request. It is a time needed to collect first components data. formula_update_interval_sec: how frequently send formula results. With this frequency all results from formulas will be send. Raises: ValueError: if a sender corresponding to any of the microgrid_formulas is not provided \"\"\" component_infos , battery_inverter_mappings = infer_microgrid_config ( component_graph ) self . component_graph = component_graph self . component_infos = component_infos self . battery_inverter_mappings = battery_inverter_mappings self . microgrid_client = microgrid_client self . _outputs = outputs # Fallback to an empty receiver so that `Select` doesn't raise `KeyError`s if config_update_receiver is not None : self . _config_update_receiver = config_update_receiver else : self . _config_update_receiver = Broadcast [ Config ]( \"microgrid_data_config_update_channel\" ) . new_receiver () self . _formula_update_interval_sec : float = formula_update_interval_sec self . _wait_for_data_sec = wait_for_data_sec self . formula_calculator = formula_calculator self . microgrid_formula_overrides : Dict [ str , Set [ int ]] = {} for output_channel_name in outputs . keys (): if output_channel_name not in self . formula_calculator . microgrid_formulas : raise ValueError ( f \"No formula defined for output channel { output_channel_name } .\" ) async def resend_formulas ( self ) -> None : \"\"\"Send formulas results with some period.\"\"\" # Sleep first to collect initial data from all component await asyncio . sleep ( self . _wait_for_data_sec ) tasks : List [ asyncio . Task [ bool ]] = [] while True : start_time = datetime . now ( timezone . utc ) # For every formula that was updated at least once, send that formula. for name , formula_result in self . formula_calculator . results . items (): if name not in self . _outputs : # If formula was computed but there is not output channel in # MicrogridData then it is bug in MicrogridData. logger . error ( \"MicrogridData: No channel for formula %s .\" , name , ) else : task = asyncio . create_task ( self . _outputs [ name ] . send ( formula_result )) tasks . append ( task ) await asyncio . gather ( * tasks , return_exceptions = True ) diff : float = ( datetime . now ( timezone . utc ) - start_time ) . total_seconds () if diff >= self . _formula_update_interval_sec : logger . error ( \"Sending results of formulas took too long: %f , \" \"expected sending interval: %f \" , diff , self . _formula_update_interval_sec , ) else : await asyncio . sleep ( self . _formula_update_interval_sec - diff ) def parse_formula_overrides ( self , config : Config ) -> Dict [ str , Set [ int ]]: \"\"\"Parse formula overrides from the config file. The following format of the config file is expected: ... formula_grid_load = \"[1,3,4]\" formula_batteries_remaining_power = \"[75,123,1]\" ... \"formula_\" is a configurable prefix defined in `CONFIG_FILE_FORMULA_PREFIX`. Args: config: contents of the recently updated config file. Returns: mapping of formula names to list of battery ids to be taken into account when evaluating the formula Raises: ValueError: if value provided refers to a formula that wasn't defined in formula calculator AttributeError: if value provided for a formula name doesn't have `split` method TypeError: if battery ids to be taken into account for a formula are not integers \"\"\" formula_overrides : Dict [ str , Set [ int ]] = {} try : formula_config = config . get_dict ( CONFIG_FILE_FORMULA_PREFIX , expected_values_type = Set [ int ] ) except ValueError as err : logger . error ( \"Formula overrides (config variables starting with %s \" \" are expected to be str -> Set[int] mappings: %s \" , CONFIG_FILE_FORMULA_PREFIX , err , ) raise for formula_name , battery_ids in formula_config . items (): if formula_name not in self . formula_calculator . microgrid_formulas : logger . error ( \"Formula %s cannot be updated, because it does not exist.\" , formula_name , ) continue formula_overrides [ formula_name ] = battery_ids return formula_overrides # pylint: disable=unused-argument async def _reinitialize ( self , config : Config , resend_formulas_task : asyncio . Task [ None ] ) -> None : \"\"\"Reinitialize MicrogridData with updated config. To be implemented once the config file scheme for updating formulas is known. This function will: - reinitialize formula calculator based on the new config - change and apply settings like `formula_update_interval_sec` or `wait_for_data_sec` Args: config: contents of the recently updated config file. resend_formulas_task: task for sending formula results Raises: Exception: when an error occurred either while parsing the new config or when creating a new instance of FormulaCalculator \"\"\" try : new_overrides = self . parse_formula_overrides ( config ) except Exception as err : # pylint: disable=broad-except # This is an error, because it shouldn't happen, but in general we don't need # to log a stack trace too because it should be just bad user input logger . error ( \"An error occurred while applying the new configuration: %s \" , err ) raise try : new_formula_calculator = FormulaCalculator ( self . component_graph , battery_ids_overrides = new_overrides , ) except Exception : # pylint: disable=broad-except # If this fails, there is a bug for sure, so we print the stack track. logger . exception ( \"An error occurred while creating the new formula calculator\" ) raise resend_formulas_task . cancel () self . microgrid_formula_overrides = new_overrides self . formula_calculator = new_formula_calculator async def run ( self ) -> None : \"\"\"Run the actor.\"\"\" while True : receivers = await gen_component_receivers ( self . component_infos , self . microgrid_client ) # Create a task that will periodically send formula results. resend_formulas_task = asyncio . create_task ( self . resend_formulas ()) select = Select ( component_data_receiver = Merge ( * receivers . values ()), config_update_receiver = self . _config_update_receiver , ) while await select . ready (): if msg := select . component_data_receiver : # Update symbols and recalculate formulas. updated_symbols = self . formula_calculator . update_symbol_values ( msg . inner ) self . formula_calculator . compute ( updated_symbols , only_formula_names = set ( self . _outputs . keys ()) ) elif msg := select . config_update_receiver : try : await self . _reinitialize ( msg . inner , resend_formulas_task ) except Exception as err : # pylint: disable=broad-except logger . error ( \"Reinitialization failed, because an error occurred \" \"while applying the new configuration: %s \" , err , ) else : # Break from the inner loop to regenerate component receivers break Functions \u00a4 __init__ ( microgrid_client , component_graph , outputs , formula_calculator , config_update_receiver = None , wait_for_data_sec = 2 , formula_update_interval_sec = 0.5 ) \u00a4 Initialise MicrogridData actor. PARAMETER DESCRIPTION microgrid_client microgrid client TYPE: MicrogridApiClient component_graph component graph of microgrid TYPE: ComponentGraph outputs senders for output to channel TYPE: Dict [ str , Sender [ TimeSeriesEntry [ Any ]]] formula_calculator an instance of FormulaCalculator responsible for managing symbols and evaluating formulas TYPE: FormulaCalculator config_update_receiver receiver for receiving config file updates TYPE: Optional [ Receiver [ Config ]] DEFAULT: None wait_for_data_sec how long actor should wait before processing first request. It is a time needed to collect first components data. TYPE: float DEFAULT: 2 formula_update_interval_sec how frequently send formula results. With this frequency all results from formulas will be send. TYPE: float DEFAULT: 0.5 RAISES DESCRIPTION ValueError if a sender corresponding to any of the microgrid_formulas is not provided Source code in frequenz/sdk/data_ingestion/microgrid_data.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 def __init__ ( # pylint: disable=too-many-arguments self , microgrid_client : MicrogridApiClient , component_graph : ComponentGraph , outputs : Dict [ str , Sender [ TimeSeriesEntry [ Any ]]], formula_calculator : FormulaCalculator , config_update_receiver : Optional [ Receiver [ Config ]] = None , wait_for_data_sec : float = 2 , formula_update_interval_sec : float = 0.5 , ) -> None : \"\"\"Initialise MicrogridData actor. Args: microgrid_client: microgrid client component_graph: component graph of microgrid outputs: senders for output to channel formula_calculator: an instance of FormulaCalculator responsible for managing symbols and evaluating formulas config_update_receiver: receiver for receiving config file updates wait_for_data_sec: how long actor should wait before processing first request. It is a time needed to collect first components data. formula_update_interval_sec: how frequently send formula results. With this frequency all results from formulas will be send. Raises: ValueError: if a sender corresponding to any of the microgrid_formulas is not provided \"\"\" component_infos , battery_inverter_mappings = infer_microgrid_config ( component_graph ) self . component_graph = component_graph self . component_infos = component_infos self . battery_inverter_mappings = battery_inverter_mappings self . microgrid_client = microgrid_client self . _outputs = outputs # Fallback to an empty receiver so that `Select` doesn't raise `KeyError`s if config_update_receiver is not None : self . _config_update_receiver = config_update_receiver else : self . _config_update_receiver = Broadcast [ Config ]( \"microgrid_data_config_update_channel\" ) . new_receiver () self . _formula_update_interval_sec : float = formula_update_interval_sec self . _wait_for_data_sec = wait_for_data_sec self . formula_calculator = formula_calculator self . microgrid_formula_overrides : Dict [ str , Set [ int ]] = {} for output_channel_name in outputs . keys (): if output_channel_name not in self . formula_calculator . microgrid_formulas : raise ValueError ( f \"No formula defined for output channel { output_channel_name } .\" ) parse_formula_overrides ( config ) \u00a4 Parse formula overrides from the config file. The following format of the config file is expected: ... formula_grid_load = \"[1,3,4]\" formula_batteries_remaining_power = \"[75,123,1]\" ... \"formula_\" is a configurable prefix defined in CONFIG_FILE_FORMULA_PREFIX . PARAMETER DESCRIPTION config contents of the recently updated config file. TYPE: Config RETURNS DESCRIPTION Dict [ str , Set [ int ]] mapping of formula names to list of battery ids to be taken into account when evaluating the formula RAISES DESCRIPTION ValueError if value provided refers to a formula that wasn't defined in formula calculator AttributeError if value provided for a formula name doesn't have split method TypeError if battery ids to be taken into account for a formula are not integers Source code in frequenz/sdk/data_ingestion/microgrid_data.py 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 def parse_formula_overrides ( self , config : Config ) -> Dict [ str , Set [ int ]]: \"\"\"Parse formula overrides from the config file. The following format of the config file is expected: ... formula_grid_load = \"[1,3,4]\" formula_batteries_remaining_power = \"[75,123,1]\" ... \"formula_\" is a configurable prefix defined in `CONFIG_FILE_FORMULA_PREFIX`. Args: config: contents of the recently updated config file. Returns: mapping of formula names to list of battery ids to be taken into account when evaluating the formula Raises: ValueError: if value provided refers to a formula that wasn't defined in formula calculator AttributeError: if value provided for a formula name doesn't have `split` method TypeError: if battery ids to be taken into account for a formula are not integers \"\"\" formula_overrides : Dict [ str , Set [ int ]] = {} try : formula_config = config . get_dict ( CONFIG_FILE_FORMULA_PREFIX , expected_values_type = Set [ int ] ) except ValueError as err : logger . error ( \"Formula overrides (config variables starting with %s \" \" are expected to be str -> Set[int] mappings: %s \" , CONFIG_FILE_FORMULA_PREFIX , err , ) raise for formula_name , battery_ids in formula_config . items (): if formula_name not in self . formula_calculator . microgrid_formulas : logger . error ( \"Formula %s cannot be updated, because it does not exist.\" , formula_name , ) continue formula_overrides [ formula_name ] = battery_ids return formula_overrides resend_formulas () async \u00a4 Send formulas results with some period. Source code in frequenz/sdk/data_ingestion/microgrid_data.py 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 async def resend_formulas ( self ) -> None : \"\"\"Send formulas results with some period.\"\"\" # Sleep first to collect initial data from all component await asyncio . sleep ( self . _wait_for_data_sec ) tasks : List [ asyncio . Task [ bool ]] = [] while True : start_time = datetime . now ( timezone . utc ) # For every formula that was updated at least once, send that formula. for name , formula_result in self . formula_calculator . results . items (): if name not in self . _outputs : # If formula was computed but there is not output channel in # MicrogridData then it is bug in MicrogridData. logger . error ( \"MicrogridData: No channel for formula %s .\" , name , ) else : task = asyncio . create_task ( self . _outputs [ name ] . send ( formula_result )) tasks . append ( task ) await asyncio . gather ( * tasks , return_exceptions = True ) diff : float = ( datetime . now ( timezone . utc ) - start_time ) . total_seconds () if diff >= self . _formula_update_interval_sec : logger . error ( \"Sending results of formulas took too long: %f , \" \"expected sending interval: %f \" , diff , self . _formula_update_interval_sec , ) else : await asyncio . sleep ( self . _formula_update_interval_sec - diff ) run () async \u00a4 Run the actor. Source code in frequenz/sdk/data_ingestion/microgrid_data.py 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 async def run ( self ) -> None : \"\"\"Run the actor.\"\"\" while True : receivers = await gen_component_receivers ( self . component_infos , self . microgrid_client ) # Create a task that will periodically send formula results. resend_formulas_task = asyncio . create_task ( self . resend_formulas ()) select = Select ( component_data_receiver = Merge ( * receivers . values ()), config_update_receiver = self . _config_update_receiver , ) while await select . ready (): if msg := select . component_data_receiver : # Update symbols and recalculate formulas. updated_symbols = self . formula_calculator . update_symbol_values ( msg . inner ) self . formula_calculator . compute ( updated_symbols , only_formula_names = set ( self . _outputs . keys ()) ) elif msg := select . config_update_receiver : try : await self . _reinitialize ( msg . inner , resend_formulas_task ) except Exception as err : # pylint: disable=broad-except logger . error ( \"Reinitialization failed, because an error occurred \" \"while applying the new configuration: %s \" , err , ) else : # Break from the inner loop to regenerate component receivers break","title":"data_ingestion"},{"location":"reference/frequenz/sdk/data_ingestion/#frequenz.sdk.data_ingestion","text":"Tools for data ingestion.","title":"data_ingestion"},{"location":"reference/frequenz/sdk/data_ingestion/#frequenz.sdk.data_ingestion-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/data_ingestion/#frequenz.sdk.data_ingestion.MicrogridData","text":"Actor for receiving component data, calculating formulas and sending results. Source code in frequenz/sdk/data_ingestion/microgrid_data.py 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 @actor class MicrogridData : # pylint: disable=too-many-instance-attributes \"\"\"Actor for receiving component data, calculating formulas and sending results.\"\"\" # current number of arguments already minimum for purpose of MicrogridData # (client, component graph, output channels, additional formula and symbols) def __init__ ( # pylint: disable=too-many-arguments self , microgrid_client : MicrogridApiClient , component_graph : ComponentGraph , outputs : Dict [ str , Sender [ TimeSeriesEntry [ Any ]]], formula_calculator : FormulaCalculator , config_update_receiver : Optional [ Receiver [ Config ]] = None , wait_for_data_sec : float = 2 , formula_update_interval_sec : float = 0.5 , ) -> None : \"\"\"Initialise MicrogridData actor. Args: microgrid_client: microgrid client component_graph: component graph of microgrid outputs: senders for output to channel formula_calculator: an instance of FormulaCalculator responsible for managing symbols and evaluating formulas config_update_receiver: receiver for receiving config file updates wait_for_data_sec: how long actor should wait before processing first request. It is a time needed to collect first components data. formula_update_interval_sec: how frequently send formula results. With this frequency all results from formulas will be send. Raises: ValueError: if a sender corresponding to any of the microgrid_formulas is not provided \"\"\" component_infos , battery_inverter_mappings = infer_microgrid_config ( component_graph ) self . component_graph = component_graph self . component_infos = component_infos self . battery_inverter_mappings = battery_inverter_mappings self . microgrid_client = microgrid_client self . _outputs = outputs # Fallback to an empty receiver so that `Select` doesn't raise `KeyError`s if config_update_receiver is not None : self . _config_update_receiver = config_update_receiver else : self . _config_update_receiver = Broadcast [ Config ]( \"microgrid_data_config_update_channel\" ) . new_receiver () self . _formula_update_interval_sec : float = formula_update_interval_sec self . _wait_for_data_sec = wait_for_data_sec self . formula_calculator = formula_calculator self . microgrid_formula_overrides : Dict [ str , Set [ int ]] = {} for output_channel_name in outputs . keys (): if output_channel_name not in self . formula_calculator . microgrid_formulas : raise ValueError ( f \"No formula defined for output channel { output_channel_name } .\" ) async def resend_formulas ( self ) -> None : \"\"\"Send formulas results with some period.\"\"\" # Sleep first to collect initial data from all component await asyncio . sleep ( self . _wait_for_data_sec ) tasks : List [ asyncio . Task [ bool ]] = [] while True : start_time = datetime . now ( timezone . utc ) # For every formula that was updated at least once, send that formula. for name , formula_result in self . formula_calculator . results . items (): if name not in self . _outputs : # If formula was computed but there is not output channel in # MicrogridData then it is bug in MicrogridData. logger . error ( \"MicrogridData: No channel for formula %s .\" , name , ) else : task = asyncio . create_task ( self . _outputs [ name ] . send ( formula_result )) tasks . append ( task ) await asyncio . gather ( * tasks , return_exceptions = True ) diff : float = ( datetime . now ( timezone . utc ) - start_time ) . total_seconds () if diff >= self . _formula_update_interval_sec : logger . error ( \"Sending results of formulas took too long: %f , \" \"expected sending interval: %f \" , diff , self . _formula_update_interval_sec , ) else : await asyncio . sleep ( self . _formula_update_interval_sec - diff ) def parse_formula_overrides ( self , config : Config ) -> Dict [ str , Set [ int ]]: \"\"\"Parse formula overrides from the config file. The following format of the config file is expected: ... formula_grid_load = \"[1,3,4]\" formula_batteries_remaining_power = \"[75,123,1]\" ... \"formula_\" is a configurable prefix defined in `CONFIG_FILE_FORMULA_PREFIX`. Args: config: contents of the recently updated config file. Returns: mapping of formula names to list of battery ids to be taken into account when evaluating the formula Raises: ValueError: if value provided refers to a formula that wasn't defined in formula calculator AttributeError: if value provided for a formula name doesn't have `split` method TypeError: if battery ids to be taken into account for a formula are not integers \"\"\" formula_overrides : Dict [ str , Set [ int ]] = {} try : formula_config = config . get_dict ( CONFIG_FILE_FORMULA_PREFIX , expected_values_type = Set [ int ] ) except ValueError as err : logger . error ( \"Formula overrides (config variables starting with %s \" \" are expected to be str -> Set[int] mappings: %s \" , CONFIG_FILE_FORMULA_PREFIX , err , ) raise for formula_name , battery_ids in formula_config . items (): if formula_name not in self . formula_calculator . microgrid_formulas : logger . error ( \"Formula %s cannot be updated, because it does not exist.\" , formula_name , ) continue formula_overrides [ formula_name ] = battery_ids return formula_overrides # pylint: disable=unused-argument async def _reinitialize ( self , config : Config , resend_formulas_task : asyncio . Task [ None ] ) -> None : \"\"\"Reinitialize MicrogridData with updated config. To be implemented once the config file scheme for updating formulas is known. This function will: - reinitialize formula calculator based on the new config - change and apply settings like `formula_update_interval_sec` or `wait_for_data_sec` Args: config: contents of the recently updated config file. resend_formulas_task: task for sending formula results Raises: Exception: when an error occurred either while parsing the new config or when creating a new instance of FormulaCalculator \"\"\" try : new_overrides = self . parse_formula_overrides ( config ) except Exception as err : # pylint: disable=broad-except # This is an error, because it shouldn't happen, but in general we don't need # to log a stack trace too because it should be just bad user input logger . error ( \"An error occurred while applying the new configuration: %s \" , err ) raise try : new_formula_calculator = FormulaCalculator ( self . component_graph , battery_ids_overrides = new_overrides , ) except Exception : # pylint: disable=broad-except # If this fails, there is a bug for sure, so we print the stack track. logger . exception ( \"An error occurred while creating the new formula calculator\" ) raise resend_formulas_task . cancel () self . microgrid_formula_overrides = new_overrides self . formula_calculator = new_formula_calculator async def run ( self ) -> None : \"\"\"Run the actor.\"\"\" while True : receivers = await gen_component_receivers ( self . component_infos , self . microgrid_client ) # Create a task that will periodically send formula results. resend_formulas_task = asyncio . create_task ( self . resend_formulas ()) select = Select ( component_data_receiver = Merge ( * receivers . values ()), config_update_receiver = self . _config_update_receiver , ) while await select . ready (): if msg := select . component_data_receiver : # Update symbols and recalculate formulas. updated_symbols = self . formula_calculator . update_symbol_values ( msg . inner ) self . formula_calculator . compute ( updated_symbols , only_formula_names = set ( self . _outputs . keys ()) ) elif msg := select . config_update_receiver : try : await self . _reinitialize ( msg . inner , resend_formulas_task ) except Exception as err : # pylint: disable=broad-except logger . error ( \"Reinitialization failed, because an error occurred \" \"while applying the new configuration: %s \" , err , ) else : # Break from the inner loop to regenerate component receivers break","title":"MicrogridData"},{"location":"reference/frequenz/sdk/data_ingestion/#frequenz.sdk.data_ingestion.MicrogridData-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/data_ingestion/#frequenz.sdk.data_ingestion.microgrid_data.MicrogridData.__init__","text":"Initialise MicrogridData actor. PARAMETER DESCRIPTION microgrid_client microgrid client TYPE: MicrogridApiClient component_graph component graph of microgrid TYPE: ComponentGraph outputs senders for output to channel TYPE: Dict [ str , Sender [ TimeSeriesEntry [ Any ]]] formula_calculator an instance of FormulaCalculator responsible for managing symbols and evaluating formulas TYPE: FormulaCalculator config_update_receiver receiver for receiving config file updates TYPE: Optional [ Receiver [ Config ]] DEFAULT: None wait_for_data_sec how long actor should wait before processing first request. It is a time needed to collect first components data. TYPE: float DEFAULT: 2 formula_update_interval_sec how frequently send formula results. With this frequency all results from formulas will be send. TYPE: float DEFAULT: 0.5 RAISES DESCRIPTION ValueError if a sender corresponding to any of the microgrid_formulas is not provided Source code in frequenz/sdk/data_ingestion/microgrid_data.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 def __init__ ( # pylint: disable=too-many-arguments self , microgrid_client : MicrogridApiClient , component_graph : ComponentGraph , outputs : Dict [ str , Sender [ TimeSeriesEntry [ Any ]]], formula_calculator : FormulaCalculator , config_update_receiver : Optional [ Receiver [ Config ]] = None , wait_for_data_sec : float = 2 , formula_update_interval_sec : float = 0.5 , ) -> None : \"\"\"Initialise MicrogridData actor. Args: microgrid_client: microgrid client component_graph: component graph of microgrid outputs: senders for output to channel formula_calculator: an instance of FormulaCalculator responsible for managing symbols and evaluating formulas config_update_receiver: receiver for receiving config file updates wait_for_data_sec: how long actor should wait before processing first request. It is a time needed to collect first components data. formula_update_interval_sec: how frequently send formula results. With this frequency all results from formulas will be send. Raises: ValueError: if a sender corresponding to any of the microgrid_formulas is not provided \"\"\" component_infos , battery_inverter_mappings = infer_microgrid_config ( component_graph ) self . component_graph = component_graph self . component_infos = component_infos self . battery_inverter_mappings = battery_inverter_mappings self . microgrid_client = microgrid_client self . _outputs = outputs # Fallback to an empty receiver so that `Select` doesn't raise `KeyError`s if config_update_receiver is not None : self . _config_update_receiver = config_update_receiver else : self . _config_update_receiver = Broadcast [ Config ]( \"microgrid_data_config_update_channel\" ) . new_receiver () self . _formula_update_interval_sec : float = formula_update_interval_sec self . _wait_for_data_sec = wait_for_data_sec self . formula_calculator = formula_calculator self . microgrid_formula_overrides : Dict [ str , Set [ int ]] = {} for output_channel_name in outputs . keys (): if output_channel_name not in self . formula_calculator . microgrid_formulas : raise ValueError ( f \"No formula defined for output channel { output_channel_name } .\" )","title":"__init__()"},{"location":"reference/frequenz/sdk/data_ingestion/#frequenz.sdk.data_ingestion.microgrid_data.MicrogridData.parse_formula_overrides","text":"Parse formula overrides from the config file. The following format of the config file is expected: ... formula_grid_load = \"[1,3,4]\" formula_batteries_remaining_power = \"[75,123,1]\" ... \"formula_\" is a configurable prefix defined in CONFIG_FILE_FORMULA_PREFIX . PARAMETER DESCRIPTION config contents of the recently updated config file. TYPE: Config RETURNS DESCRIPTION Dict [ str , Set [ int ]] mapping of formula names to list of battery ids to be taken into account when evaluating the formula RAISES DESCRIPTION ValueError if value provided refers to a formula that wasn't defined in formula calculator AttributeError if value provided for a formula name doesn't have split method TypeError if battery ids to be taken into account for a formula are not integers Source code in frequenz/sdk/data_ingestion/microgrid_data.py 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 def parse_formula_overrides ( self , config : Config ) -> Dict [ str , Set [ int ]]: \"\"\"Parse formula overrides from the config file. The following format of the config file is expected: ... formula_grid_load = \"[1,3,4]\" formula_batteries_remaining_power = \"[75,123,1]\" ... \"formula_\" is a configurable prefix defined in `CONFIG_FILE_FORMULA_PREFIX`. Args: config: contents of the recently updated config file. Returns: mapping of formula names to list of battery ids to be taken into account when evaluating the formula Raises: ValueError: if value provided refers to a formula that wasn't defined in formula calculator AttributeError: if value provided for a formula name doesn't have `split` method TypeError: if battery ids to be taken into account for a formula are not integers \"\"\" formula_overrides : Dict [ str , Set [ int ]] = {} try : formula_config = config . get_dict ( CONFIG_FILE_FORMULA_PREFIX , expected_values_type = Set [ int ] ) except ValueError as err : logger . error ( \"Formula overrides (config variables starting with %s \" \" are expected to be str -> Set[int] mappings: %s \" , CONFIG_FILE_FORMULA_PREFIX , err , ) raise for formula_name , battery_ids in formula_config . items (): if formula_name not in self . formula_calculator . microgrid_formulas : logger . error ( \"Formula %s cannot be updated, because it does not exist.\" , formula_name , ) continue formula_overrides [ formula_name ] = battery_ids return formula_overrides","title":"parse_formula_overrides()"},{"location":"reference/frequenz/sdk/data_ingestion/#frequenz.sdk.data_ingestion.microgrid_data.MicrogridData.resend_formulas","text":"Send formulas results with some period. Source code in frequenz/sdk/data_ingestion/microgrid_data.py 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 async def resend_formulas ( self ) -> None : \"\"\"Send formulas results with some period.\"\"\" # Sleep first to collect initial data from all component await asyncio . sleep ( self . _wait_for_data_sec ) tasks : List [ asyncio . Task [ bool ]] = [] while True : start_time = datetime . now ( timezone . utc ) # For every formula that was updated at least once, send that formula. for name , formula_result in self . formula_calculator . results . items (): if name not in self . _outputs : # If formula was computed but there is not output channel in # MicrogridData then it is bug in MicrogridData. logger . error ( \"MicrogridData: No channel for formula %s .\" , name , ) else : task = asyncio . create_task ( self . _outputs [ name ] . send ( formula_result )) tasks . append ( task ) await asyncio . gather ( * tasks , return_exceptions = True ) diff : float = ( datetime . now ( timezone . utc ) - start_time ) . total_seconds () if diff >= self . _formula_update_interval_sec : logger . error ( \"Sending results of formulas took too long: %f , \" \"expected sending interval: %f \" , diff , self . _formula_update_interval_sec , ) else : await asyncio . sleep ( self . _formula_update_interval_sec - diff )","title":"resend_formulas()"},{"location":"reference/frequenz/sdk/data_ingestion/#frequenz.sdk.data_ingestion.microgrid_data.MicrogridData.run","text":"Run the actor. Source code in frequenz/sdk/data_ingestion/microgrid_data.py 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 async def run ( self ) -> None : \"\"\"Run the actor.\"\"\" while True : receivers = await gen_component_receivers ( self . component_infos , self . microgrid_client ) # Create a task that will periodically send formula results. resend_formulas_task = asyncio . create_task ( self . resend_formulas ()) select = Select ( component_data_receiver = Merge ( * receivers . values ()), config_update_receiver = self . _config_update_receiver , ) while await select . ready (): if msg := select . component_data_receiver : # Update symbols and recalculate formulas. updated_symbols = self . formula_calculator . update_symbol_values ( msg . inner ) self . formula_calculator . compute ( updated_symbols , only_formula_names = set ( self . _outputs . keys ()) ) elif msg := select . config_update_receiver : try : await self . _reinitialize ( msg . inner , resend_formulas_task ) except Exception as err : # pylint: disable=broad-except logger . error ( \"Reinitialization failed, because an error occurred \" \"while applying the new configuration: %s \" , err , ) else : # Break from the inner loop to regenerate component receivers break","title":"run()"},{"location":"reference/frequenz/sdk/data_ingestion/component_info/","text":"frequenz.sdk.data_ingestion.component_info \u00a4 Definition of component infos. Classes \u00a4 frequenz.sdk.data_ingestion.component_info.ComponentInfo dataclass \u00a4 Object containing component information. Source code in frequenz/sdk/data_ingestion/component_info.py 16 17 18 19 20 21 22 23 24 25 @dataclass class ComponentInfo : \"\"\"Object containing component information.\"\"\" # component id component_id : int # category of component category : ComponentCategory # type of meter; \"pv\"/\"market\"/\"grid\"/None (when component_category != \"Meter\") meter_connection : Optional [ ComponentCategory ] = None Functions \u00a4 frequenz . sdk . data_ingestion . component_info . infer_microgrid_config ( graph ) \u00a4 Infer microgrid configuration from component graph. PARAMETER DESCRIPTION graph component graph of microgrid TYPE: ComponentGraph RETURNS DESCRIPTION Tuple [ List [ ComponentInfo ], Dict [ int , int ]] Tuple containing 1) list of components relevant for calculation of microgrid data. 2) mappings between batteries and battery inverters. Source code in frequenz/sdk/data_ingestion/component_info.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 def infer_microgrid_config ( graph : ComponentGraph , ) -> Tuple [ List [ ComponentInfo ], Dict [ int , int ]]: \"\"\"Infer microgrid configuration from component graph. Args: graph: component graph of microgrid Returns: Tuple containing 1) list of components relevant for calculation of microgrid data. 2) mappings between batteries and battery inverters. \"\"\" component_infos = [] bat_inv_mappings = {} component_category_mappings = { component . component_id : component . category for component in graph . components () } for component in graph . components (): meter_connection = None predecessors = graph . predecessors ( component . component_id ) successors = graph . successors ( component . component_id ) if component . category == ComponentCategory . METER : connections = [ comp for comp in predecessors | successors if component_category_mappings [ comp . component_id ] != ComponentCategory . JUNCTION ] if len ( connections ) == 1 : meter_connection = component_category_mappings [ connections [ 0 ] . component_id ] if meter_connection not in { ComponentCategory . INVERTER , ComponentCategory . EV_CHARGER , }: component_infos . append ( ComponentInfo ( component . component_id , component . category , meter_connection = meter_connection , ) ) elif component . category == ComponentCategory . BATTERY : if len ( predecessors ) == 0 : logger . warning ( \"Battery %d doesn't have any predecessors!\" , component . component_id , ) continue if len ( predecessors ) > 1 : inverter_ids = [ comp . component_id for comp in predecessors if comp . category == ComponentCategory . INVERTER ] logger . warning ( \"Configurations with a single battery %d \" \"and multiple inverters %s are not supported!\" , component . component_id , inverter_ids , ) if len ( predecessors ) >= 1 : predecessor = predecessors . pop () bat_inv_mappings [ component . component_id ] = predecessor . component_id component_infos . append ( ComponentInfo ( component . component_id , component . category , meter_connection = meter_connection , ) ) elif component . category == ComponentCategory . INVERTER : if len ( successors ) > 1 : battery_ids = [ comp . component_id for comp in successors if comp . category == ComponentCategory . BATTERY ] logger . warning ( \"Configurations with a single inverter %d \" \"and multiple batteries %s are not supported!\" , component . component_id , battery_ids , ) if len ( successors ) >= 1 : successor = successors . pop () if ( component_category_mappings [ successor . component_id ] == ComponentCategory . BATTERY ): component_infos . append ( ComponentInfo ( component . component_id , component . category , meter_connection = meter_connection , ) ) elif component . category == ComponentCategory . EV_CHARGER : component_infos . append ( ComponentInfo ( component . component_id , component . category , meter_connection = meter_connection , ) ) return component_infos , bat_inv_mappings","title":"component_info"},{"location":"reference/frequenz/sdk/data_ingestion/component_info/#frequenz.sdk.data_ingestion.component_info","text":"Definition of component infos.","title":"component_info"},{"location":"reference/frequenz/sdk/data_ingestion/component_info/#frequenz.sdk.data_ingestion.component_info-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/data_ingestion/component_info/#frequenz.sdk.data_ingestion.component_info.ComponentInfo","text":"Object containing component information. Source code in frequenz/sdk/data_ingestion/component_info.py 16 17 18 19 20 21 22 23 24 25 @dataclass class ComponentInfo : \"\"\"Object containing component information.\"\"\" # component id component_id : int # category of component category : ComponentCategory # type of meter; \"pv\"/\"market\"/\"grid\"/None (when component_category != \"Meter\") meter_connection : Optional [ ComponentCategory ] = None","title":"ComponentInfo"},{"location":"reference/frequenz/sdk/data_ingestion/component_info/#frequenz.sdk.data_ingestion.component_info-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/data_ingestion/component_info/#frequenz.sdk.data_ingestion.component_info.infer_microgrid_config","text":"Infer microgrid configuration from component graph. PARAMETER DESCRIPTION graph component graph of microgrid TYPE: ComponentGraph RETURNS DESCRIPTION Tuple [ List [ ComponentInfo ], Dict [ int , int ]] Tuple containing 1) list of components relevant for calculation of microgrid data. 2) mappings between batteries and battery inverters. Source code in frequenz/sdk/data_ingestion/component_info.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 def infer_microgrid_config ( graph : ComponentGraph , ) -> Tuple [ List [ ComponentInfo ], Dict [ int , int ]]: \"\"\"Infer microgrid configuration from component graph. Args: graph: component graph of microgrid Returns: Tuple containing 1) list of components relevant for calculation of microgrid data. 2) mappings between batteries and battery inverters. \"\"\" component_infos = [] bat_inv_mappings = {} component_category_mappings = { component . component_id : component . category for component in graph . components () } for component in graph . components (): meter_connection = None predecessors = graph . predecessors ( component . component_id ) successors = graph . successors ( component . component_id ) if component . category == ComponentCategory . METER : connections = [ comp for comp in predecessors | successors if component_category_mappings [ comp . component_id ] != ComponentCategory . JUNCTION ] if len ( connections ) == 1 : meter_connection = component_category_mappings [ connections [ 0 ] . component_id ] if meter_connection not in { ComponentCategory . INVERTER , ComponentCategory . EV_CHARGER , }: component_infos . append ( ComponentInfo ( component . component_id , component . category , meter_connection = meter_connection , ) ) elif component . category == ComponentCategory . BATTERY : if len ( predecessors ) == 0 : logger . warning ( \"Battery %d doesn't have any predecessors!\" , component . component_id , ) continue if len ( predecessors ) > 1 : inverter_ids = [ comp . component_id for comp in predecessors if comp . category == ComponentCategory . INVERTER ] logger . warning ( \"Configurations with a single battery %d \" \"and multiple inverters %s are not supported!\" , component . component_id , inverter_ids , ) if len ( predecessors ) >= 1 : predecessor = predecessors . pop () bat_inv_mappings [ component . component_id ] = predecessor . component_id component_infos . append ( ComponentInfo ( component . component_id , component . category , meter_connection = meter_connection , ) ) elif component . category == ComponentCategory . INVERTER : if len ( successors ) > 1 : battery_ids = [ comp . component_id for comp in successors if comp . category == ComponentCategory . BATTERY ] logger . warning ( \"Configurations with a single inverter %d \" \"and multiple batteries %s are not supported!\" , component . component_id , battery_ids , ) if len ( successors ) >= 1 : successor = successors . pop () if ( component_category_mappings [ successor . component_id ] == ComponentCategory . BATTERY ): component_infos . append ( ComponentInfo ( component . component_id , component . category , meter_connection = meter_connection , ) ) elif component . category == ComponentCategory . EV_CHARGER : component_infos . append ( ComponentInfo ( component . component_id , component . category , meter_connection = meter_connection , ) ) return component_infos , bat_inv_mappings","title":"infer_microgrid_config()"},{"location":"reference/frequenz/sdk/data_ingestion/constants/","text":"frequenz.sdk.data_ingestion.constants \u00a4 Functions for generating DataColletor with necessary fields from ComponentInfo.","title":"constants"},{"location":"reference/frequenz/sdk/data_ingestion/constants/#frequenz.sdk.data_ingestion.constants","text":"Functions for generating DataColletor with necessary fields from ComponentInfo.","title":"constants"},{"location":"reference/frequenz/sdk/data_ingestion/formula_calculator/","text":"frequenz.sdk.data_ingestion.formula_calculator \u00a4 Class for evaluating formulas. Classes \u00a4 frequenz.sdk.data_ingestion.formula_calculator.ComponentGroupInfo dataclass \u00a4 Component ids and meter connections for components of a specific type. Source code in frequenz/sdk/data_ingestion/formula_calculator.py 41 42 43 44 45 46 @dataclass ( frozen = True ) class ComponentGroupInfo : \"\"\"Component ids and meter connections for components of a specific type.\"\"\" ids : List [ int ] connections : List [ Optional [ ComponentCategory ]] frequenz.sdk.data_ingestion.formula_calculator.FormulaCalculator \u00a4 Class for evaluating formulas based on streamed component data. Default formulas are hardcoded in code and it is not possible to change them. Default formulas use always all possible components. If one component is broken, then 0 will be put in place of missing component data. For example, lets say we have 2 batteries: B1, B2 B1:energy =100 B2:energy=200 If B2 suddenly stops working then total_energy should be 100. The total energy will be back 300 as soon as broken component will start sending data. The default set of formulas includes client_load : site consumption grid_load : grid consumption pv_prod : total PV production (if one or more pv arrays exist) ev_chargers_consumption : total ev charging rate (if one or more ev chargers exist) total_energy : total energy (in Wh) in all batteries batteries_active_power : active_power of all battery inverters batteries_active_power_bounds : active_power_bounds of all battery inverters batteries_capacity : total capacity of all batteries Source code in frequenz/sdk/data_ingestion/formula_calculator.py 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 class FormulaCalculator : # pylint: disable=too-many-instance-attributes \"\"\"Class for evaluating formulas based on streamed component data. Default formulas are hardcoded in code and it is not possible to change them. Default formulas use always all possible components. If one component is broken, then 0 will be put in place of missing component data. For example, lets say we have 2 batteries: B1, B2 B1:energy =100 B2:energy=200 If B2 suddenly stops working then total_energy should be 100. The total energy will be back 300 as soon as broken component will start sending data. The default set of formulas includes: `client_load`: site consumption `grid_load`: grid consumption `pv_prod`: total PV production (if one or more pv arrays exist) `ev_chargers_consumption`: total ev charging rate (if one or more ev chargers exist) `total_energy`: total energy (in Wh) in all batteries `batteries_active_power`: active_power of all battery inverters `batteries_active_power_bounds`: active_power_bounds of all battery inverters `batteries_capacity`: total capacity of all batteries \"\"\" def __init__ ( self , component_graph : ComponentGraph , additional_formulas : Optional [ Dict [ str , TimeSeriesFormula [ Any ]]] = None , battery_ids_overrides : Optional [ Dict [ str , Set [ int ]]] = None , symbol_mappings : Optional [ List [ SymbolMapping ]] = None , ) -> None : \"\"\"Initialize FormulaCalculator. Args: component_graph: component graph of microgrid additional_formulas: a dictionary of additional formulas not included in the default set, with key specifying names for these formulas battery_ids_overrides: mapping of formula names to list of battery ids to be taken into account when evaluating the formula symbol_mappings: list of additional symbol definitions, necessary if the additional user-defined formulas contains extra symbols that are not included in the default set Raises: KeyError: if there are missing symbols or duplicated formula names \"\"\" component_infos , battery_inverter_mappings = infer_microgrid_config ( component_graph ) self . component_infos = component_infos self . battery_inverter_mappings = battery_inverter_mappings self . battery_ids_overrides = battery_ids_overrides self . microgrid_formulas : Dict [ str , TimeSeriesFormula [ Any ]] = ( {} if additional_formulas is None else additional_formulas ) custom_symbol_mappings : List [ SymbolMapping ] = symbol_mappings or [] default_symbol_mappings = self . _create_default_symbol_mappings () self . symbol_mappings : Dict [ str , SymbolMapping ] = { symbol_mapping . symbol : symbol_mapping for symbol_mapping in custom_symbol_mappings + default_symbol_mappings } self . set_microgrid_formulas () self . _check_symbol_definitions_exist () self . symbol_values : LatestEntryCache [ str , Any ] = LatestEntryCache () self . results : Dict [ str , TimeSeriesEntry [ Any ]] = {} # Max permitted time when the component should send any information. # After that timeout the component will be treated as not existing. # Formulas will put 0 in place of data from this components. # This will happen until component starts sending data. self . component_data_timeout_sec = 60 def _create_client_load_formula ( self , meter_group_info : ComponentGroupInfo , ev_charger_group_info : ComponentGroupInfo , inverter_group_info : ComponentGroupInfo , ) -> TimeSeriesFormula [ float ]: \"\"\"Create formula for client_load. Args: meter_group_info: ids and meter connections of all meters ev_charger_group_info: ids of all ev chargers inverter_group_info: ids of all inverters Returns: Formula for calculating client_load. Raises: ValueError: when there is neither market nor grid meters \"\"\" if None in meter_group_info . connections : return TimeSeriesFormula ( \" + \" . join ( [ f \"meter_ { meter_group_info . ids [ i ] } _active_power\" for i in range ( len ( meter_group_info . ids )) if meter_group_info . connections [ i ] is None ] ) ) if ComponentCategory . GRID in meter_group_info . connections : return TimeSeriesFormula ( \" + \" . join ( [ f \"meter_ { meter_group_info . ids [ i ] } _active_power\" for i in range ( len ( meter_group_info . ids )) if meter_group_info . connections [ i ] == ComponentCategory . GRID ] + [ f \"meter_ { meter_group_info . ids [ i ] } _active_power\" for i in range ( len ( meter_group_info . ids )) if meter_group_info . connections [ i ] == ComponentCategory . PV_ARRAY ] + [ f \"meter_ { meter_group_info . ids [ i ] } _active_power\" for i in range ( len ( meter_group_info . ids )) if meter_group_info . connections [ i ] == ComponentCategory . CHP ] + [ f \"ev_charger_ { ev_charger_group_info . ids [ i ] } _active_power\" for i in range ( len ( ev_charger_group_info . ids )) ] + [ f \"inverter_ { inverter_id } _active_power\" for inverter_id in inverter_group_info . ids ] ) ) raise ValueError ( \"Either `market` or `grid` component must be present\" ) def _create_grid_load_formula ( self , meter_group_info : ComponentGroupInfo , ev_charger_group_info : ComponentGroupInfo , inverter_group_info : ComponentGroupInfo , ) -> TimeSeriesFormula [ float ]: \"\"\"Create formula for grid_load. Args: meter_group_info: ids and meter connections of all meters ev_charger_group_info: ids of all ev chargers inverter_group_info: ids of all inverters Returns: Formula for calculating grid_load. Raises: ValueError: when there is neither market nor grid meters \"\"\" if None in meter_group_info . connections : return TimeSeriesFormula ( \" + \" . join ( [ f \"meter_ { meter_group_info . ids [ i ] } _active_power\" for i in range ( len ( meter_group_info . ids )) if meter_group_info . connections [ i ] is None ] + [ f \"meter_ { meter_group_info . ids [ i ] } _active_power\" for i in range ( len ( meter_group_info . ids )) if meter_group_info . connections [ i ] == ComponentCategory . PV_ARRAY ] + [ f \"meter_ { meter_group_info . ids [ i ] } _active_power\" for i in range ( len ( meter_group_info . ids )) if meter_group_info . connections [ i ] == ComponentCategory . CHP ] + [ f \"ev_charger_ { ev_charger_group_info . ids [ i ] } _active_power\" for i in range ( len ( ev_charger_group_info . ids )) ] + [ f \"inverter_ { inverter_id } _active_power\" for inverter_id in inverter_group_info . ids ] ) ) if ComponentCategory . GRID in meter_group_info . connections : return TimeSeriesFormula ( \" + \" . join ( [ f \"meter_ { meter_group_info . ids [ i ] } _active_power\" for i in range ( len ( meter_group_info . ids )) if meter_group_info . connections [ i ] == ComponentCategory . GRID ] ) ) raise ValueError ( \"Either `market` or `grid` component must be present\" ) def _create_batteries_capacity_formula ( self , battery_ids : List [ int ] ) -> TimeSeriesFormula [ float ]: \"\"\"Create formula for total capacity of all batteries. Args: battery_ids: battery ids Returns: Formula for calculating total capacity of all batteries. \"\"\" if len ( battery_ids ) > 0 : return TimeSeriesFormula ( \" + \" . join ( [ f \"battery_ { battery_id } _capacity\" for battery_id in battery_ids ] ) ) return TimeSeriesFormula ( \"0\" ) def _create_pv_prod_formula ( self , meter_group_info : ComponentGroupInfo ) -> TimeSeriesFormula [ float ]: \"\"\"Create formula for pv_prod. Computes total active power of all meters that measures pv systems. Args: meter_group_info: ids and meter connections of all meters Returns: Formula for calculating pv_prod. \"\"\" if ComponentCategory . PV_ARRAY in meter_group_info . connections : return TimeSeriesFormula ( \" + \" . join ( [ f \"meter_ { meter_group_info . ids [ i ] } _active_power\" for i in range ( len ( meter_group_info . ids )) if meter_group_info . connections [ i ] == ComponentCategory . PV_ARRAY ] ) ) return TimeSeriesFormula ( \"0\" ) def _create_ev_active_power_consumption_formula ( self , ev_charger_ids : List [ int ] ) -> TimeSeriesFormula [ float ]: \"\"\"Create formula for ev_active_power_consumption. SUM(current_consumption_power[i] for i in all_ev_chargers) where current_consumption_power = METRIC_EV_ACTIVE_POWER Args: ev_charger_ids: ev charger ids Returns: Formula for calculating ev_active_power_consumption. \"\"\" if len ( ev_charger_ids ) > 0 : return TimeSeriesFormula ( \" + \" . join ( [ f \"ev_charger_ { ev_charger_id } _active_power\" for ev_charger_id in ev_charger_ids ] ) ) return TimeSeriesFormula ( \"0\" ) def _create_active_power_formula ( self , inverter_ids : List [ int ] ) -> TimeSeriesFormula [ float ]: \"\"\"Create formula for active_power. SUM(active_power[i] for i in all_inverters) where active_power = METRIC_ACTIVE_POWER Args: inverter_ids: inverter ids Returns: Formula for calculating active_power. \"\"\" return TimeSeriesFormula ( \" + \" . join ( [ f \"inverter_ { inverter_id } _active_power\" for inverter_id in inverter_ids ] ) ) def _create_batteries_active_power_bounds_formula ( self , battery_ids : List [ int ], battery_inverter_mappings : Dict [ int , int ] ) -> TimeSeriesFormula [ Tuple [ float , float ]]: \"\"\"Create formula for batteries_active_power_bounds. batteries_active_power_bounds is total upper and lower bound for active power read from battery-inverter pairs. Battery-inverter pair is pair of battery and adjacent inverter. It returns a tuple with upper and lower bound, where: lower - sum of lower bound for each battery-inverter pair. Lower bound of battery-inverter pair is max(battery.active_power_lower_bound, inverter.active_power_lower_bound) upper - sum of upper bound for each battery-inverter pair. Upper bound of battery-inverter pair is min(battery.power_upper_bound, inverter.active_power_upper_bound), Args: battery_ids: battery ids battery_inverter_mappings: mappings between batteries and battery inverters Returns: Formula for calculating batteries_active_power_bounds. \"\"\" lower_bound_formula = \" + \" . join ( [ f \"max(battery_ { bid } _power_lower_bound, \" f \"inverter_ { battery_inverter_mappings [ bid ] } _active_power_lower_bound)\" for bid in battery_ids ] ) upper_bound_formula = \" + \" . join ( [ f \"min(battery_ { bid } _power_upper_bound, \" f \"inverter_ { battery_inverter_mappings [ bid ] } _active_power_upper_bound)\" for bid in battery_ids ] ) str_formula = sympy . Tuple ( lower_bound_formula , upper_bound_formula ) # type: ignore expression = sympy . sympify ( str_formula ) # type: ignore return TimeSeriesFormula ( expression ) def _create_total_energy_formula ( self , battery_ids : List [ int ] ) -> TimeSeriesFormula [ float ]: \"\"\"Create formula for total_energy. SUM(Soc[i]*capacity[i] for in in all_batteries) Args: battery_ids: battery ids Returns: Formula for calculating total_energy. \"\"\" return TimeSeriesFormula ( \" + \" . join ( [ f \"battery_ { bid } _soc * battery_ { bid } _capacity\" for bid in battery_ids ] ) ) def filter_selected_batteries ( self , battery_ids : List [ int ], formula_name : str , ) -> List [ int ]: \"\"\"Filter selected batteries from all batteries in the component graph. Batteries to be used for an individual formula can be overridden via config file in the UI. Args: battery_ids: list of ids of all the batteries in the component graph formula_name: name of the formula to apply the override for Returns: list of battery ids selected by the user in the UI for a given formula \"\"\" if ( self . battery_ids_overrides is None or formula_name not in self . battery_ids_overrides ): return battery_ids selected_battery_ids = self . battery_ids_overrides [ formula_name ] return list ( set ( battery_ids ) & selected_battery_ids ) def set_microgrid_formulas ( self , ) -> None : \"\"\"Set formulas associated with the components specified for the microgrid. Raises: ValueError: when there is neither market nor grid meters \"\"\" components_by_type = self . _group_components () client_load_formula = self . _create_client_load_formula ( meter_group_info = components_by_type [ ComponentCategory . METER ], ev_charger_group_info = components_by_type [ ComponentCategory . EV_CHARGER ], inverter_group_info = components_by_type [ ComponentCategory . INVERTER ], ) self . _add_formula ( METRIC_CLIENT_LOAD , client_load_formula ) grid_load_formula = self . _create_grid_load_formula ( meter_group_info = components_by_type [ ComponentCategory . METER ], ev_charger_group_info = components_by_type [ ComponentCategory . EV_CHARGER ], inverter_group_info = components_by_type [ ComponentCategory . INVERTER ], ) self . _add_formula ( METRIC_GRID_LOAD , grid_load_formula ) pv_prod_formula = self . _create_pv_prod_formula ( meter_group_info = components_by_type [ ComponentCategory . METER ] ) self . _add_formula ( METRIC_PV_PROD , pv_prod_formula ) ev_active_power_consumption_formula = ( self . _create_ev_active_power_consumption_formula ( ev_charger_ids = components_by_type [ ComponentCategory . EV_CHARGER ] . ids ) ) self . _add_formula ( METRIC_EV_CHARGERS_CONSUMPTION , ev_active_power_consumption_formula ) active_power_formula = self . _create_active_power_formula ( inverter_ids = components_by_type [ ComponentCategory . INVERTER ] . ids ) self . _add_formula ( METRIC_BATTERIES_ACTIVE_POWER , active_power_formula ) batteries_active_power_bounds_formula = ( self . _create_batteries_active_power_bounds_formula ( battery_ids = self . filter_selected_batteries ( battery_ids = components_by_type [ ComponentCategory . BATTERY ] . ids , formula_name = METRIC_BATTERIES_ACTIVE_POWER_BOUNDS , ), battery_inverter_mappings = self . battery_inverter_mappings , ) ) self . _add_formula ( METRIC_BATTERIES_ACTIVE_POWER_BOUNDS , batteries_active_power_bounds_formula ) total_energy_formula = self . _create_total_energy_formula ( battery_ids = self . filter_selected_batteries ( battery_ids = components_by_type [ ComponentCategory . BATTERY ] . ids , formula_name = METRIC_BATTERIES_REMAINING_ENERGY , ), ) self . _add_formula ( METRIC_BATTERIES_REMAINING_ENERGY , total_energy_formula ) batteries_capacity_formula = self . _create_batteries_capacity_formula ( battery_ids = self . filter_selected_batteries ( battery_ids = components_by_type [ ComponentCategory . BATTERY ] . ids , formula_name = METRIC_BATTERIES_CAPACITY , ), ) self . _add_formula ( METRIC_BATTERIES_CAPACITY , batteries_capacity_formula ) def _make_group ( self , component_category : ComponentCategory , attr : str ) -> List [ Any ]: \"\"\"Filter components by type and return a single attribute for all of them. Args: component_category: components of which type to include in the result. attr: attribute to return for all components of type `component_category`. Returns: Single attribute of all components of type `component_category`. \"\"\" return [ getattr ( info , attr ) for info in self . component_infos if info . category == component_category ] def _group_components ( self ) -> Dict [ ComponentCategory , ComponentGroupInfo ]: \"\"\"Group components by component category. Returns: Components grouped by type, where groups hold information about component IDs and meter connections. \"\"\" meter_connections = self . _make_group ( ComponentCategory . METER , \"meter_connection\" ) meter_ids = self . _make_group ( ComponentCategory . METER , \"component_id\" ) battery_ids = self . _make_group ( ComponentCategory . BATTERY , \"component_id\" ) inverter_ids = self . _make_group ( ComponentCategory . INVERTER , \"component_id\" ) ev_charger_ids = self . _make_group ( ComponentCategory . EV_CHARGER , \"component_id\" ) components_by_type = { ComponentCategory . METER : ComponentGroupInfo ( ids = meter_ids , connections = meter_connections ), ComponentCategory . INVERTER : ComponentGroupInfo ( ids = inverter_ids , connections = [] ), ComponentCategory . BATTERY : ComponentGroupInfo ( ids = battery_ids , connections = [] ), ComponentCategory . EV_CHARGER : ComponentGroupInfo ( ids = ev_charger_ids , connections = [] ), } return components_by_type def _create_default_inverter_symbol_mappings ( self , inverter_ids : List [ int ] ) -> List [ SymbolMapping ]: \"\"\"Create default symbol mappings for inverters. Args: inverter_ids: list of ids of inverters Returns: list of default symbol mappings for inverters \"\"\" symbol_mappings : List [ SymbolMapping ] = [] for iid in inverter_ids : symbol_mappings . append ( SymbolMapping ( SymbolComponentCategory . INVERTER , iid , InverterField . ACTIVE_POWER ) ) symbol_mappings . append ( SymbolMapping ( SymbolComponentCategory . INVERTER , iid , InverterField . ACTIVE_POWER_UPPER_BOUND , ) ) symbol_mappings . append ( SymbolMapping ( SymbolComponentCategory . INVERTER , iid , InverterField . ACTIVE_POWER_LOWER_BOUND , ) ) return symbol_mappings def _create_default_battery_symbol_mappings ( self , battery_ids : List [ int ] ) -> List [ SymbolMapping ]: \"\"\"Create default symbol mappings for batteries. Args: battery_ids: list of ids of batteries Returns: list of default symbol mappings for batteries \"\"\" symbol_mappings : List [ SymbolMapping ] = [] for bid in battery_ids : symbol_mappings . append ( SymbolMapping ( SymbolComponentCategory . BATTERY , bid , BatteryField . SOC ) ) symbol_mappings . append ( SymbolMapping ( SymbolComponentCategory . BATTERY , bid , BatteryField . POWER_UPPER_BOUND , ) ) symbol_mappings . append ( SymbolMapping ( SymbolComponentCategory . BATTERY , bid , BatteryField . POWER_LOWER_BOUND , ) ) symbol_mappings . append ( SymbolMapping ( SymbolComponentCategory . BATTERY , bid , BatteryField . CAPACITY ) ) return symbol_mappings def _create_default_ev_charger_symbol_mappings ( self , ev_charger_ids : List [ int ] ) -> List [ SymbolMapping ]: \"\"\"Create default symbol mappings for EV chargers. Args: ev_charger_ids: list of ids of EV chargers Returns: list of default symbol mappings for EV chargers \"\"\" symbol_mappings : List [ SymbolMapping ] = [] for evid in ev_charger_ids : symbol_mappings . append ( SymbolMapping ( SymbolComponentCategory . EV_CHARGER , evid , EVChargerField . ACTIVE_POWER , ) ) return symbol_mappings def _create_default_meter_symbol_mappings ( self , meter_ids : List [ int ] ) -> List [ SymbolMapping ]: \"\"\"Create default symbol mappings for meters. Args: meter_ids: list of ids of meters Returns: list of default symbol mappings for meters \"\"\" symbol_mappings : List [ SymbolMapping ] = [] for mid in meter_ids : symbol_mappings . append ( SymbolMapping ( SymbolComponentCategory . METER , mid , MeterField . ACTIVE_POWER ) ) return symbol_mappings def _create_default_symbol_mappings ( self ) -> List [ SymbolMapping ]: \"\"\"Create default symbol mappings for all component categories. Returns: list of default symbol mappings for all component categories \"\"\" component_groups = self . _group_components () symbol_mappings : List [ SymbolMapping ] = [] meter_symbol_mappings = self . _create_default_meter_symbol_mappings ( meter_ids = component_groups [ ComponentCategory . METER ] . ids , ) symbol_mappings . extend ( meter_symbol_mappings ) inverter_symbol_mappings = self . _create_default_inverter_symbol_mappings ( inverter_ids = component_groups [ ComponentCategory . INVERTER ] . ids ) symbol_mappings . extend ( inverter_symbol_mappings ) ev_charger_symbol_mappings = self . _create_default_ev_charger_symbol_mappings ( ev_charger_ids = component_groups [ ComponentCategory . EV_CHARGER ] . ids ) symbol_mappings . extend ( ev_charger_symbol_mappings ) battery_symbol_mappings = self . _create_default_battery_symbol_mappings ( battery_ids = component_groups [ ComponentCategory . BATTERY ] . ids ) symbol_mappings . extend ( battery_symbol_mappings ) return symbol_mappings def _add_formula ( self , formula_name : str , formula : TimeSeriesFormula [ Any ]) -> None : \"\"\"Add a default formula. If the formula is not already supplied by user upon initialization of the actor and that an output channel is provided. Args: formula_name: name of formula formula: definition of the time series formula Raises: KeyError: when formula is already defined \"\"\" if formula_name in self . microgrid_formulas : raise KeyError ( f \"Formula { formula_name } is already defined!\" ) self . microgrid_formulas [ formula_name ] = formula def _check_symbol_definitions_exist ( self , ) -> None : \"\"\"Check that all the symbols used in `microgrid_formulas` are defined. Raises: KeyError: when used symbols do not exist \"\"\" required_symbols = [ self . microgrid_formulas [ formula_name ] . symbols for formula_name in self . microgrid_formulas ] unique_required_symbols = set ( chain ( * required_symbols )) defined_symbols = list ( self . symbol_mappings . keys ()) missing_symbols = [] for symbol in unique_required_symbols : if symbol not in defined_symbols : missing_symbols . append ( symbol ) if len ( missing_symbols ) > 0 : raise KeyError ( f \"Symbol(s) { missing_symbols } used in `microgrid_formulas` not defined.\" ) def update_symbol_values ( self , component_data : Dict [ str , Any ]) -> Set [ str ]: \"\"\"Update all the symbol values with latest streamed component data. In order to have the formulas computed, the user has to provide symbol mappings, which map symbols to attributes from protobuf messages. When a single component sends data, the values of the corresponding symbols will be updated, e.g. when an inverter with id=8 sends the following data: { 'active_power': 255.0, 'active_power_lower_bound': -999.0, 'active_power_upper_bound': 1000.0, 'id': 8, 'timestamp': datetime.datetime(2022, 9, 1, 16, 36, 42, 575424, tzinfo=<UTC>) } values of the declared symbols related to that component id will be updated as follows: TimeSeriesEntry( 'inverter_8_active_power', datetime.datetime(2022, 9, 1, 16, 36, 42, 575424, tzinfo=<UTC>), 255.0 ) TimeSeriesEntry( 'inverter_8_active_power_lower_bound', datetime.datetime(2022, 9, 1, 16, 36, 42, 575424, tzinfo=<UTC>), -999.0 ) TimeSeriesEntry( 'inverter_8_active_power_upper_bound', datetime.datetime(2022, 9, 1, 16, 36, 42, 575424, tzinfo=<UTC>), 1000.0 ) If a symbol for a given component hasn't been declared, its value will not be updated, even if that component sends some data. Args: component_data: latest streamed component data from a single device Returns: The set of updated symbols. \"\"\" updated_symbol_mappings = [ symbol_mapping for symbol_mapping in self . symbol_mappings . values () if symbol_mapping . component_id == component_data [ \"id\" ] ] for symbol_mapping in updated_symbol_mappings : self . symbol_values . update ( key = symbol_mapping . symbol , entry = TimeSeriesEntry ( timestamp = component_data [ \"timestamp\" ], value = component_data [ symbol_mapping . field . value ], ), ) return set ( symbol_mapping . symbol for symbol_mapping in updated_symbol_mappings ) def compute ( self , symbols : Set [ str ], only_formula_names : Optional [ Set [ str ]] = None ) -> List [ str ]: \"\"\"Compute all the formulas that depend on the provided symbols. Whenever Microgrid devices send data, it is then mapped to symbols that are used by the formulas. The provided `symbols` will cause the formulas relying on them to be computed. If a formula doesn't depend on the symbols that were recently updated, it will not be computed and if the provided `symbols` aren't used for any formula, no computation will be done. Some formulas might rely on multiple symbols, out of which not all might be available at a given point of time. In this case, the values for missing symbols will be replaced with a default value (0.0), which is passed to the `evaluate` method as the `default_entry` parameter. Args: symbols: the set of recently updated symbols from a single device only_formula_names: optional set of formula names that need to be evaluated. If no names are provided, all formulas relying on the provided `symbols` will be evaluated. Returns: Names of the computed formulas. \"\"\" formulas_to_compute : Set [ str ] = { formula_name for formula_name in self . microgrid_formulas if len ( symbols & set ( self . microgrid_formulas [ formula_name ] . symbols )) > 0 } if only_formula_names is not None : formulas_to_compute = formulas_to_compute . intersection ( only_formula_names ) computed_formula_names = [] for formula_name in formulas_to_compute : res = self . microgrid_formulas [ formula_name ] . evaluate ( cache = self . symbol_values , formula_name = formula_name , symbol_to_symbol_mapping = self . symbol_mappings , timedelta_tolerance = timedelta ( seconds = self . component_data_timeout_sec ), default_entry = TimeSeriesEntry [ Any ]( timestamp = datetime . now ( timezone . utc ), value = 0.0 ), ) if res is not None : self . results [ formula_name ] = res computed_formula_names . append ( formula_name ) return computed_formula_names Functions \u00a4 __init__ ( component_graph , additional_formulas = None , battery_ids_overrides = None , symbol_mappings = None ) \u00a4 Initialize FormulaCalculator. PARAMETER DESCRIPTION component_graph component graph of microgrid TYPE: ComponentGraph additional_formulas a dictionary of additional formulas not included in the default set, with key specifying names for these formulas TYPE: Optional [ Dict [ str , TimeSeriesFormula [ Any ]]] DEFAULT: None battery_ids_overrides mapping of formula names to list of battery ids to be taken into account when evaluating the formula TYPE: Optional [ Dict [ str , Set [ int ]]] DEFAULT: None symbol_mappings list of additional symbol definitions, necessary if the additional user-defined formulas contains extra symbols that are not included in the default set TYPE: Optional [ List [ SymbolMapping ]] DEFAULT: None RAISES DESCRIPTION KeyError if there are missing symbols or duplicated formula names Source code in frequenz/sdk/data_ingestion/formula_calculator.py 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 def __init__ ( self , component_graph : ComponentGraph , additional_formulas : Optional [ Dict [ str , TimeSeriesFormula [ Any ]]] = None , battery_ids_overrides : Optional [ Dict [ str , Set [ int ]]] = None , symbol_mappings : Optional [ List [ SymbolMapping ]] = None , ) -> None : \"\"\"Initialize FormulaCalculator. Args: component_graph: component graph of microgrid additional_formulas: a dictionary of additional formulas not included in the default set, with key specifying names for these formulas battery_ids_overrides: mapping of formula names to list of battery ids to be taken into account when evaluating the formula symbol_mappings: list of additional symbol definitions, necessary if the additional user-defined formulas contains extra symbols that are not included in the default set Raises: KeyError: if there are missing symbols or duplicated formula names \"\"\" component_infos , battery_inverter_mappings = infer_microgrid_config ( component_graph ) self . component_infos = component_infos self . battery_inverter_mappings = battery_inverter_mappings self . battery_ids_overrides = battery_ids_overrides self . microgrid_formulas : Dict [ str , TimeSeriesFormula [ Any ]] = ( {} if additional_formulas is None else additional_formulas ) custom_symbol_mappings : List [ SymbolMapping ] = symbol_mappings or [] default_symbol_mappings = self . _create_default_symbol_mappings () self . symbol_mappings : Dict [ str , SymbolMapping ] = { symbol_mapping . symbol : symbol_mapping for symbol_mapping in custom_symbol_mappings + default_symbol_mappings } self . set_microgrid_formulas () self . _check_symbol_definitions_exist () self . symbol_values : LatestEntryCache [ str , Any ] = LatestEntryCache () self . results : Dict [ str , TimeSeriesEntry [ Any ]] = {} # Max permitted time when the component should send any information. # After that timeout the component will be treated as not existing. # Formulas will put 0 in place of data from this components. # This will happen until component starts sending data. self . component_data_timeout_sec = 60 compute ( symbols , only_formula_names = None ) \u00a4 Compute all the formulas that depend on the provided symbols. Whenever Microgrid devices send data, it is then mapped to symbols that are used by the formulas. The provided symbols will cause the formulas relying on them to be computed. If a formula doesn't depend on the symbols that were recently updated, it will not be computed and if the provided symbols aren't used for any formula, no computation will be done. Some formulas might rely on multiple symbols, out of which not all might be available at a given point of time. In this case, the values for missing symbols will be replaced with a default value (0.0), which is passed to the evaluate method as the default_entry parameter. PARAMETER DESCRIPTION symbols the set of recently updated symbols from a single device TYPE: Set [ str ] only_formula_names optional set of formula names that need to be evaluated. If no names are provided, all formulas relying on the provided symbols will be evaluated. TYPE: Optional [ Set [ str ]] DEFAULT: None RETURNS DESCRIPTION List [ str ] Names of the computed formulas. Source code in frequenz/sdk/data_ingestion/formula_calculator.py 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 def compute ( self , symbols : Set [ str ], only_formula_names : Optional [ Set [ str ]] = None ) -> List [ str ]: \"\"\"Compute all the formulas that depend on the provided symbols. Whenever Microgrid devices send data, it is then mapped to symbols that are used by the formulas. The provided `symbols` will cause the formulas relying on them to be computed. If a formula doesn't depend on the symbols that were recently updated, it will not be computed and if the provided `symbols` aren't used for any formula, no computation will be done. Some formulas might rely on multiple symbols, out of which not all might be available at a given point of time. In this case, the values for missing symbols will be replaced with a default value (0.0), which is passed to the `evaluate` method as the `default_entry` parameter. Args: symbols: the set of recently updated symbols from a single device only_formula_names: optional set of formula names that need to be evaluated. If no names are provided, all formulas relying on the provided `symbols` will be evaluated. Returns: Names of the computed formulas. \"\"\" formulas_to_compute : Set [ str ] = { formula_name for formula_name in self . microgrid_formulas if len ( symbols & set ( self . microgrid_formulas [ formula_name ] . symbols )) > 0 } if only_formula_names is not None : formulas_to_compute = formulas_to_compute . intersection ( only_formula_names ) computed_formula_names = [] for formula_name in formulas_to_compute : res = self . microgrid_formulas [ formula_name ] . evaluate ( cache = self . symbol_values , formula_name = formula_name , symbol_to_symbol_mapping = self . symbol_mappings , timedelta_tolerance = timedelta ( seconds = self . component_data_timeout_sec ), default_entry = TimeSeriesEntry [ Any ]( timestamp = datetime . now ( timezone . utc ), value = 0.0 ), ) if res is not None : self . results [ formula_name ] = res computed_formula_names . append ( formula_name ) return computed_formula_names filter_selected_batteries ( battery_ids , formula_name ) \u00a4 Filter selected batteries from all batteries in the component graph. Batteries to be used for an individual formula can be overridden via config file in the UI. PARAMETER DESCRIPTION battery_ids list of ids of all the batteries in the component graph TYPE: List [ int ] formula_name name of the formula to apply the override for TYPE: str RETURNS DESCRIPTION List [ int ] list of battery ids selected by the user in the UI for a given formula Source code in frequenz/sdk/data_ingestion/formula_calculator.py 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 def filter_selected_batteries ( self , battery_ids : List [ int ], formula_name : str , ) -> List [ int ]: \"\"\"Filter selected batteries from all batteries in the component graph. Batteries to be used for an individual formula can be overridden via config file in the UI. Args: battery_ids: list of ids of all the batteries in the component graph formula_name: name of the formula to apply the override for Returns: list of battery ids selected by the user in the UI for a given formula \"\"\" if ( self . battery_ids_overrides is None or formula_name not in self . battery_ids_overrides ): return battery_ids selected_battery_ids = self . battery_ids_overrides [ formula_name ] return list ( set ( battery_ids ) & selected_battery_ids ) set_microgrid_formulas () \u00a4 Set formulas associated with the components specified for the microgrid. RAISES DESCRIPTION ValueError when there is neither market nor grid meters Source code in frequenz/sdk/data_ingestion/formula_calculator.py 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 def set_microgrid_formulas ( self , ) -> None : \"\"\"Set formulas associated with the components specified for the microgrid. Raises: ValueError: when there is neither market nor grid meters \"\"\" components_by_type = self . _group_components () client_load_formula = self . _create_client_load_formula ( meter_group_info = components_by_type [ ComponentCategory . METER ], ev_charger_group_info = components_by_type [ ComponentCategory . EV_CHARGER ], inverter_group_info = components_by_type [ ComponentCategory . INVERTER ], ) self . _add_formula ( METRIC_CLIENT_LOAD , client_load_formula ) grid_load_formula = self . _create_grid_load_formula ( meter_group_info = components_by_type [ ComponentCategory . METER ], ev_charger_group_info = components_by_type [ ComponentCategory . EV_CHARGER ], inverter_group_info = components_by_type [ ComponentCategory . INVERTER ], ) self . _add_formula ( METRIC_GRID_LOAD , grid_load_formula ) pv_prod_formula = self . _create_pv_prod_formula ( meter_group_info = components_by_type [ ComponentCategory . METER ] ) self . _add_formula ( METRIC_PV_PROD , pv_prod_formula ) ev_active_power_consumption_formula = ( self . _create_ev_active_power_consumption_formula ( ev_charger_ids = components_by_type [ ComponentCategory . EV_CHARGER ] . ids ) ) self . _add_formula ( METRIC_EV_CHARGERS_CONSUMPTION , ev_active_power_consumption_formula ) active_power_formula = self . _create_active_power_formula ( inverter_ids = components_by_type [ ComponentCategory . INVERTER ] . ids ) self . _add_formula ( METRIC_BATTERIES_ACTIVE_POWER , active_power_formula ) batteries_active_power_bounds_formula = ( self . _create_batteries_active_power_bounds_formula ( battery_ids = self . filter_selected_batteries ( battery_ids = components_by_type [ ComponentCategory . BATTERY ] . ids , formula_name = METRIC_BATTERIES_ACTIVE_POWER_BOUNDS , ), battery_inverter_mappings = self . battery_inverter_mappings , ) ) self . _add_formula ( METRIC_BATTERIES_ACTIVE_POWER_BOUNDS , batteries_active_power_bounds_formula ) total_energy_formula = self . _create_total_energy_formula ( battery_ids = self . filter_selected_batteries ( battery_ids = components_by_type [ ComponentCategory . BATTERY ] . ids , formula_name = METRIC_BATTERIES_REMAINING_ENERGY , ), ) self . _add_formula ( METRIC_BATTERIES_REMAINING_ENERGY , total_energy_formula ) batteries_capacity_formula = self . _create_batteries_capacity_formula ( battery_ids = self . filter_selected_batteries ( battery_ids = components_by_type [ ComponentCategory . BATTERY ] . ids , formula_name = METRIC_BATTERIES_CAPACITY , ), ) self . _add_formula ( METRIC_BATTERIES_CAPACITY , batteries_capacity_formula ) update_symbol_values ( component_data ) \u00a4 Update all the symbol values with latest streamed component data. In order to have the formulas computed, the user has to provide symbol mappings, which map symbols to attributes from protobuf messages. When a single component sends data, the values of the corresponding symbols will be updated, e.g. when an inverter with id=8 sends the following data: { 'active_power': 255.0, 'active_power_lower_bound': -999.0, 'active_power_upper_bound': 1000.0, 'id': 8, 'timestamp': datetime.datetime(2022, 9, 1, 16, 36, 42, 575424, tzinfo= ) } values of the declared symbols related to that component id will be updated as follows: TimeSeriesEntry( 'inverter_8_active_power', datetime.datetime(2022, 9, 1, 16, 36, 42, 575424, tzinfo= ), 255.0 ) TimeSeriesEntry( 'inverter_8_active_power_lower_bound', datetime.datetime(2022, 9, 1, 16, 36, 42, 575424, tzinfo= ), -999.0 ) TimeSeriesEntry( 'inverter_8_active_power_upper_bound', datetime.datetime(2022, 9, 1, 16, 36, 42, 575424, tzinfo= ), 1000.0 ) If a symbol for a given component hasn't been declared, its value will not be updated, even if that component sends some data. PARAMETER DESCRIPTION component_data latest streamed component data from a single device TYPE: Dict [ str , Any ] RETURNS DESCRIPTION Set [ str ] The set of updated symbols. Source code in frequenz/sdk/data_ingestion/formula_calculator.py 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 def update_symbol_values ( self , component_data : Dict [ str , Any ]) -> Set [ str ]: \"\"\"Update all the symbol values with latest streamed component data. In order to have the formulas computed, the user has to provide symbol mappings, which map symbols to attributes from protobuf messages. When a single component sends data, the values of the corresponding symbols will be updated, e.g. when an inverter with id=8 sends the following data: { 'active_power': 255.0, 'active_power_lower_bound': -999.0, 'active_power_upper_bound': 1000.0, 'id': 8, 'timestamp': datetime.datetime(2022, 9, 1, 16, 36, 42, 575424, tzinfo=<UTC>) } values of the declared symbols related to that component id will be updated as follows: TimeSeriesEntry( 'inverter_8_active_power', datetime.datetime(2022, 9, 1, 16, 36, 42, 575424, tzinfo=<UTC>), 255.0 ) TimeSeriesEntry( 'inverter_8_active_power_lower_bound', datetime.datetime(2022, 9, 1, 16, 36, 42, 575424, tzinfo=<UTC>), -999.0 ) TimeSeriesEntry( 'inverter_8_active_power_upper_bound', datetime.datetime(2022, 9, 1, 16, 36, 42, 575424, tzinfo=<UTC>), 1000.0 ) If a symbol for a given component hasn't been declared, its value will not be updated, even if that component sends some data. Args: component_data: latest streamed component data from a single device Returns: The set of updated symbols. \"\"\" updated_symbol_mappings = [ symbol_mapping for symbol_mapping in self . symbol_mappings . values () if symbol_mapping . component_id == component_data [ \"id\" ] ] for symbol_mapping in updated_symbol_mappings : self . symbol_values . update ( key = symbol_mapping . symbol , entry = TimeSeriesEntry ( timestamp = component_data [ \"timestamp\" ], value = component_data [ symbol_mapping . field . value ], ), ) return set ( symbol_mapping . symbol for symbol_mapping in updated_symbol_mappings ) Functions \u00a4","title":"formula_calculator"},{"location":"reference/frequenz/sdk/data_ingestion/formula_calculator/#frequenz.sdk.data_ingestion.formula_calculator","text":"Class for evaluating formulas.","title":"formula_calculator"},{"location":"reference/frequenz/sdk/data_ingestion/formula_calculator/#frequenz.sdk.data_ingestion.formula_calculator-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/data_ingestion/formula_calculator/#frequenz.sdk.data_ingestion.formula_calculator.ComponentGroupInfo","text":"Component ids and meter connections for components of a specific type. Source code in frequenz/sdk/data_ingestion/formula_calculator.py 41 42 43 44 45 46 @dataclass ( frozen = True ) class ComponentGroupInfo : \"\"\"Component ids and meter connections for components of a specific type.\"\"\" ids : List [ int ] connections : List [ Optional [ ComponentCategory ]]","title":"ComponentGroupInfo"},{"location":"reference/frequenz/sdk/data_ingestion/formula_calculator/#frequenz.sdk.data_ingestion.formula_calculator.FormulaCalculator","text":"Class for evaluating formulas based on streamed component data. Default formulas are hardcoded in code and it is not possible to change them. Default formulas use always all possible components. If one component is broken, then 0 will be put in place of missing component data. For example, lets say we have 2 batteries: B1, B2 B1:energy =100 B2:energy=200 If B2 suddenly stops working then total_energy should be 100. The total energy will be back 300 as soon as broken component will start sending data. The default set of formulas includes client_load : site consumption grid_load : grid consumption pv_prod : total PV production (if one or more pv arrays exist) ev_chargers_consumption : total ev charging rate (if one or more ev chargers exist) total_energy : total energy (in Wh) in all batteries batteries_active_power : active_power of all battery inverters batteries_active_power_bounds : active_power_bounds of all battery inverters batteries_capacity : total capacity of all batteries Source code in frequenz/sdk/data_ingestion/formula_calculator.py 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 class FormulaCalculator : # pylint: disable=too-many-instance-attributes \"\"\"Class for evaluating formulas based on streamed component data. Default formulas are hardcoded in code and it is not possible to change them. Default formulas use always all possible components. If one component is broken, then 0 will be put in place of missing component data. For example, lets say we have 2 batteries: B1, B2 B1:energy =100 B2:energy=200 If B2 suddenly stops working then total_energy should be 100. The total energy will be back 300 as soon as broken component will start sending data. The default set of formulas includes: `client_load`: site consumption `grid_load`: grid consumption `pv_prod`: total PV production (if one or more pv arrays exist) `ev_chargers_consumption`: total ev charging rate (if one or more ev chargers exist) `total_energy`: total energy (in Wh) in all batteries `batteries_active_power`: active_power of all battery inverters `batteries_active_power_bounds`: active_power_bounds of all battery inverters `batteries_capacity`: total capacity of all batteries \"\"\" def __init__ ( self , component_graph : ComponentGraph , additional_formulas : Optional [ Dict [ str , TimeSeriesFormula [ Any ]]] = None , battery_ids_overrides : Optional [ Dict [ str , Set [ int ]]] = None , symbol_mappings : Optional [ List [ SymbolMapping ]] = None , ) -> None : \"\"\"Initialize FormulaCalculator. Args: component_graph: component graph of microgrid additional_formulas: a dictionary of additional formulas not included in the default set, with key specifying names for these formulas battery_ids_overrides: mapping of formula names to list of battery ids to be taken into account when evaluating the formula symbol_mappings: list of additional symbol definitions, necessary if the additional user-defined formulas contains extra symbols that are not included in the default set Raises: KeyError: if there are missing symbols or duplicated formula names \"\"\" component_infos , battery_inverter_mappings = infer_microgrid_config ( component_graph ) self . component_infos = component_infos self . battery_inverter_mappings = battery_inverter_mappings self . battery_ids_overrides = battery_ids_overrides self . microgrid_formulas : Dict [ str , TimeSeriesFormula [ Any ]] = ( {} if additional_formulas is None else additional_formulas ) custom_symbol_mappings : List [ SymbolMapping ] = symbol_mappings or [] default_symbol_mappings = self . _create_default_symbol_mappings () self . symbol_mappings : Dict [ str , SymbolMapping ] = { symbol_mapping . symbol : symbol_mapping for symbol_mapping in custom_symbol_mappings + default_symbol_mappings } self . set_microgrid_formulas () self . _check_symbol_definitions_exist () self . symbol_values : LatestEntryCache [ str , Any ] = LatestEntryCache () self . results : Dict [ str , TimeSeriesEntry [ Any ]] = {} # Max permitted time when the component should send any information. # After that timeout the component will be treated as not existing. # Formulas will put 0 in place of data from this components. # This will happen until component starts sending data. self . component_data_timeout_sec = 60 def _create_client_load_formula ( self , meter_group_info : ComponentGroupInfo , ev_charger_group_info : ComponentGroupInfo , inverter_group_info : ComponentGroupInfo , ) -> TimeSeriesFormula [ float ]: \"\"\"Create formula for client_load. Args: meter_group_info: ids and meter connections of all meters ev_charger_group_info: ids of all ev chargers inverter_group_info: ids of all inverters Returns: Formula for calculating client_load. Raises: ValueError: when there is neither market nor grid meters \"\"\" if None in meter_group_info . connections : return TimeSeriesFormula ( \" + \" . join ( [ f \"meter_ { meter_group_info . ids [ i ] } _active_power\" for i in range ( len ( meter_group_info . ids )) if meter_group_info . connections [ i ] is None ] ) ) if ComponentCategory . GRID in meter_group_info . connections : return TimeSeriesFormula ( \" + \" . join ( [ f \"meter_ { meter_group_info . ids [ i ] } _active_power\" for i in range ( len ( meter_group_info . ids )) if meter_group_info . connections [ i ] == ComponentCategory . GRID ] + [ f \"meter_ { meter_group_info . ids [ i ] } _active_power\" for i in range ( len ( meter_group_info . ids )) if meter_group_info . connections [ i ] == ComponentCategory . PV_ARRAY ] + [ f \"meter_ { meter_group_info . ids [ i ] } _active_power\" for i in range ( len ( meter_group_info . ids )) if meter_group_info . connections [ i ] == ComponentCategory . CHP ] + [ f \"ev_charger_ { ev_charger_group_info . ids [ i ] } _active_power\" for i in range ( len ( ev_charger_group_info . ids )) ] + [ f \"inverter_ { inverter_id } _active_power\" for inverter_id in inverter_group_info . ids ] ) ) raise ValueError ( \"Either `market` or `grid` component must be present\" ) def _create_grid_load_formula ( self , meter_group_info : ComponentGroupInfo , ev_charger_group_info : ComponentGroupInfo , inverter_group_info : ComponentGroupInfo , ) -> TimeSeriesFormula [ float ]: \"\"\"Create formula for grid_load. Args: meter_group_info: ids and meter connections of all meters ev_charger_group_info: ids of all ev chargers inverter_group_info: ids of all inverters Returns: Formula for calculating grid_load. Raises: ValueError: when there is neither market nor grid meters \"\"\" if None in meter_group_info . connections : return TimeSeriesFormula ( \" + \" . join ( [ f \"meter_ { meter_group_info . ids [ i ] } _active_power\" for i in range ( len ( meter_group_info . ids )) if meter_group_info . connections [ i ] is None ] + [ f \"meter_ { meter_group_info . ids [ i ] } _active_power\" for i in range ( len ( meter_group_info . ids )) if meter_group_info . connections [ i ] == ComponentCategory . PV_ARRAY ] + [ f \"meter_ { meter_group_info . ids [ i ] } _active_power\" for i in range ( len ( meter_group_info . ids )) if meter_group_info . connections [ i ] == ComponentCategory . CHP ] + [ f \"ev_charger_ { ev_charger_group_info . ids [ i ] } _active_power\" for i in range ( len ( ev_charger_group_info . ids )) ] + [ f \"inverter_ { inverter_id } _active_power\" for inverter_id in inverter_group_info . ids ] ) ) if ComponentCategory . GRID in meter_group_info . connections : return TimeSeriesFormula ( \" + \" . join ( [ f \"meter_ { meter_group_info . ids [ i ] } _active_power\" for i in range ( len ( meter_group_info . ids )) if meter_group_info . connections [ i ] == ComponentCategory . GRID ] ) ) raise ValueError ( \"Either `market` or `grid` component must be present\" ) def _create_batteries_capacity_formula ( self , battery_ids : List [ int ] ) -> TimeSeriesFormula [ float ]: \"\"\"Create formula for total capacity of all batteries. Args: battery_ids: battery ids Returns: Formula for calculating total capacity of all batteries. \"\"\" if len ( battery_ids ) > 0 : return TimeSeriesFormula ( \" + \" . join ( [ f \"battery_ { battery_id } _capacity\" for battery_id in battery_ids ] ) ) return TimeSeriesFormula ( \"0\" ) def _create_pv_prod_formula ( self , meter_group_info : ComponentGroupInfo ) -> TimeSeriesFormula [ float ]: \"\"\"Create formula for pv_prod. Computes total active power of all meters that measures pv systems. Args: meter_group_info: ids and meter connections of all meters Returns: Formula for calculating pv_prod. \"\"\" if ComponentCategory . PV_ARRAY in meter_group_info . connections : return TimeSeriesFormula ( \" + \" . join ( [ f \"meter_ { meter_group_info . ids [ i ] } _active_power\" for i in range ( len ( meter_group_info . ids )) if meter_group_info . connections [ i ] == ComponentCategory . PV_ARRAY ] ) ) return TimeSeriesFormula ( \"0\" ) def _create_ev_active_power_consumption_formula ( self , ev_charger_ids : List [ int ] ) -> TimeSeriesFormula [ float ]: \"\"\"Create formula for ev_active_power_consumption. SUM(current_consumption_power[i] for i in all_ev_chargers) where current_consumption_power = METRIC_EV_ACTIVE_POWER Args: ev_charger_ids: ev charger ids Returns: Formula for calculating ev_active_power_consumption. \"\"\" if len ( ev_charger_ids ) > 0 : return TimeSeriesFormula ( \" + \" . join ( [ f \"ev_charger_ { ev_charger_id } _active_power\" for ev_charger_id in ev_charger_ids ] ) ) return TimeSeriesFormula ( \"0\" ) def _create_active_power_formula ( self , inverter_ids : List [ int ] ) -> TimeSeriesFormula [ float ]: \"\"\"Create formula for active_power. SUM(active_power[i] for i in all_inverters) where active_power = METRIC_ACTIVE_POWER Args: inverter_ids: inverter ids Returns: Formula for calculating active_power. \"\"\" return TimeSeriesFormula ( \" + \" . join ( [ f \"inverter_ { inverter_id } _active_power\" for inverter_id in inverter_ids ] ) ) def _create_batteries_active_power_bounds_formula ( self , battery_ids : List [ int ], battery_inverter_mappings : Dict [ int , int ] ) -> TimeSeriesFormula [ Tuple [ float , float ]]: \"\"\"Create formula for batteries_active_power_bounds. batteries_active_power_bounds is total upper and lower bound for active power read from battery-inverter pairs. Battery-inverter pair is pair of battery and adjacent inverter. It returns a tuple with upper and lower bound, where: lower - sum of lower bound for each battery-inverter pair. Lower bound of battery-inverter pair is max(battery.active_power_lower_bound, inverter.active_power_lower_bound) upper - sum of upper bound for each battery-inverter pair. Upper bound of battery-inverter pair is min(battery.power_upper_bound, inverter.active_power_upper_bound), Args: battery_ids: battery ids battery_inverter_mappings: mappings between batteries and battery inverters Returns: Formula for calculating batteries_active_power_bounds. \"\"\" lower_bound_formula = \" + \" . join ( [ f \"max(battery_ { bid } _power_lower_bound, \" f \"inverter_ { battery_inverter_mappings [ bid ] } _active_power_lower_bound)\" for bid in battery_ids ] ) upper_bound_formula = \" + \" . join ( [ f \"min(battery_ { bid } _power_upper_bound, \" f \"inverter_ { battery_inverter_mappings [ bid ] } _active_power_upper_bound)\" for bid in battery_ids ] ) str_formula = sympy . Tuple ( lower_bound_formula , upper_bound_formula ) # type: ignore expression = sympy . sympify ( str_formula ) # type: ignore return TimeSeriesFormula ( expression ) def _create_total_energy_formula ( self , battery_ids : List [ int ] ) -> TimeSeriesFormula [ float ]: \"\"\"Create formula for total_energy. SUM(Soc[i]*capacity[i] for in in all_batteries) Args: battery_ids: battery ids Returns: Formula for calculating total_energy. \"\"\" return TimeSeriesFormula ( \" + \" . join ( [ f \"battery_ { bid } _soc * battery_ { bid } _capacity\" for bid in battery_ids ] ) ) def filter_selected_batteries ( self , battery_ids : List [ int ], formula_name : str , ) -> List [ int ]: \"\"\"Filter selected batteries from all batteries in the component graph. Batteries to be used for an individual formula can be overridden via config file in the UI. Args: battery_ids: list of ids of all the batteries in the component graph formula_name: name of the formula to apply the override for Returns: list of battery ids selected by the user in the UI for a given formula \"\"\" if ( self . battery_ids_overrides is None or formula_name not in self . battery_ids_overrides ): return battery_ids selected_battery_ids = self . battery_ids_overrides [ formula_name ] return list ( set ( battery_ids ) & selected_battery_ids ) def set_microgrid_formulas ( self , ) -> None : \"\"\"Set formulas associated with the components specified for the microgrid. Raises: ValueError: when there is neither market nor grid meters \"\"\" components_by_type = self . _group_components () client_load_formula = self . _create_client_load_formula ( meter_group_info = components_by_type [ ComponentCategory . METER ], ev_charger_group_info = components_by_type [ ComponentCategory . EV_CHARGER ], inverter_group_info = components_by_type [ ComponentCategory . INVERTER ], ) self . _add_formula ( METRIC_CLIENT_LOAD , client_load_formula ) grid_load_formula = self . _create_grid_load_formula ( meter_group_info = components_by_type [ ComponentCategory . METER ], ev_charger_group_info = components_by_type [ ComponentCategory . EV_CHARGER ], inverter_group_info = components_by_type [ ComponentCategory . INVERTER ], ) self . _add_formula ( METRIC_GRID_LOAD , grid_load_formula ) pv_prod_formula = self . _create_pv_prod_formula ( meter_group_info = components_by_type [ ComponentCategory . METER ] ) self . _add_formula ( METRIC_PV_PROD , pv_prod_formula ) ev_active_power_consumption_formula = ( self . _create_ev_active_power_consumption_formula ( ev_charger_ids = components_by_type [ ComponentCategory . EV_CHARGER ] . ids ) ) self . _add_formula ( METRIC_EV_CHARGERS_CONSUMPTION , ev_active_power_consumption_formula ) active_power_formula = self . _create_active_power_formula ( inverter_ids = components_by_type [ ComponentCategory . INVERTER ] . ids ) self . _add_formula ( METRIC_BATTERIES_ACTIVE_POWER , active_power_formula ) batteries_active_power_bounds_formula = ( self . _create_batteries_active_power_bounds_formula ( battery_ids = self . filter_selected_batteries ( battery_ids = components_by_type [ ComponentCategory . BATTERY ] . ids , formula_name = METRIC_BATTERIES_ACTIVE_POWER_BOUNDS , ), battery_inverter_mappings = self . battery_inverter_mappings , ) ) self . _add_formula ( METRIC_BATTERIES_ACTIVE_POWER_BOUNDS , batteries_active_power_bounds_formula ) total_energy_formula = self . _create_total_energy_formula ( battery_ids = self . filter_selected_batteries ( battery_ids = components_by_type [ ComponentCategory . BATTERY ] . ids , formula_name = METRIC_BATTERIES_REMAINING_ENERGY , ), ) self . _add_formula ( METRIC_BATTERIES_REMAINING_ENERGY , total_energy_formula ) batteries_capacity_formula = self . _create_batteries_capacity_formula ( battery_ids = self . filter_selected_batteries ( battery_ids = components_by_type [ ComponentCategory . BATTERY ] . ids , formula_name = METRIC_BATTERIES_CAPACITY , ), ) self . _add_formula ( METRIC_BATTERIES_CAPACITY , batteries_capacity_formula ) def _make_group ( self , component_category : ComponentCategory , attr : str ) -> List [ Any ]: \"\"\"Filter components by type and return a single attribute for all of them. Args: component_category: components of which type to include in the result. attr: attribute to return for all components of type `component_category`. Returns: Single attribute of all components of type `component_category`. \"\"\" return [ getattr ( info , attr ) for info in self . component_infos if info . category == component_category ] def _group_components ( self ) -> Dict [ ComponentCategory , ComponentGroupInfo ]: \"\"\"Group components by component category. Returns: Components grouped by type, where groups hold information about component IDs and meter connections. \"\"\" meter_connections = self . _make_group ( ComponentCategory . METER , \"meter_connection\" ) meter_ids = self . _make_group ( ComponentCategory . METER , \"component_id\" ) battery_ids = self . _make_group ( ComponentCategory . BATTERY , \"component_id\" ) inverter_ids = self . _make_group ( ComponentCategory . INVERTER , \"component_id\" ) ev_charger_ids = self . _make_group ( ComponentCategory . EV_CHARGER , \"component_id\" ) components_by_type = { ComponentCategory . METER : ComponentGroupInfo ( ids = meter_ids , connections = meter_connections ), ComponentCategory . INVERTER : ComponentGroupInfo ( ids = inverter_ids , connections = [] ), ComponentCategory . BATTERY : ComponentGroupInfo ( ids = battery_ids , connections = [] ), ComponentCategory . EV_CHARGER : ComponentGroupInfo ( ids = ev_charger_ids , connections = [] ), } return components_by_type def _create_default_inverter_symbol_mappings ( self , inverter_ids : List [ int ] ) -> List [ SymbolMapping ]: \"\"\"Create default symbol mappings for inverters. Args: inverter_ids: list of ids of inverters Returns: list of default symbol mappings for inverters \"\"\" symbol_mappings : List [ SymbolMapping ] = [] for iid in inverter_ids : symbol_mappings . append ( SymbolMapping ( SymbolComponentCategory . INVERTER , iid , InverterField . ACTIVE_POWER ) ) symbol_mappings . append ( SymbolMapping ( SymbolComponentCategory . INVERTER , iid , InverterField . ACTIVE_POWER_UPPER_BOUND , ) ) symbol_mappings . append ( SymbolMapping ( SymbolComponentCategory . INVERTER , iid , InverterField . ACTIVE_POWER_LOWER_BOUND , ) ) return symbol_mappings def _create_default_battery_symbol_mappings ( self , battery_ids : List [ int ] ) -> List [ SymbolMapping ]: \"\"\"Create default symbol mappings for batteries. Args: battery_ids: list of ids of batteries Returns: list of default symbol mappings for batteries \"\"\" symbol_mappings : List [ SymbolMapping ] = [] for bid in battery_ids : symbol_mappings . append ( SymbolMapping ( SymbolComponentCategory . BATTERY , bid , BatteryField . SOC ) ) symbol_mappings . append ( SymbolMapping ( SymbolComponentCategory . BATTERY , bid , BatteryField . POWER_UPPER_BOUND , ) ) symbol_mappings . append ( SymbolMapping ( SymbolComponentCategory . BATTERY , bid , BatteryField . POWER_LOWER_BOUND , ) ) symbol_mappings . append ( SymbolMapping ( SymbolComponentCategory . BATTERY , bid , BatteryField . CAPACITY ) ) return symbol_mappings def _create_default_ev_charger_symbol_mappings ( self , ev_charger_ids : List [ int ] ) -> List [ SymbolMapping ]: \"\"\"Create default symbol mappings for EV chargers. Args: ev_charger_ids: list of ids of EV chargers Returns: list of default symbol mappings for EV chargers \"\"\" symbol_mappings : List [ SymbolMapping ] = [] for evid in ev_charger_ids : symbol_mappings . append ( SymbolMapping ( SymbolComponentCategory . EV_CHARGER , evid , EVChargerField . ACTIVE_POWER , ) ) return symbol_mappings def _create_default_meter_symbol_mappings ( self , meter_ids : List [ int ] ) -> List [ SymbolMapping ]: \"\"\"Create default symbol mappings for meters. Args: meter_ids: list of ids of meters Returns: list of default symbol mappings for meters \"\"\" symbol_mappings : List [ SymbolMapping ] = [] for mid in meter_ids : symbol_mappings . append ( SymbolMapping ( SymbolComponentCategory . METER , mid , MeterField . ACTIVE_POWER ) ) return symbol_mappings def _create_default_symbol_mappings ( self ) -> List [ SymbolMapping ]: \"\"\"Create default symbol mappings for all component categories. Returns: list of default symbol mappings for all component categories \"\"\" component_groups = self . _group_components () symbol_mappings : List [ SymbolMapping ] = [] meter_symbol_mappings = self . _create_default_meter_symbol_mappings ( meter_ids = component_groups [ ComponentCategory . METER ] . ids , ) symbol_mappings . extend ( meter_symbol_mappings ) inverter_symbol_mappings = self . _create_default_inverter_symbol_mappings ( inverter_ids = component_groups [ ComponentCategory . INVERTER ] . ids ) symbol_mappings . extend ( inverter_symbol_mappings ) ev_charger_symbol_mappings = self . _create_default_ev_charger_symbol_mappings ( ev_charger_ids = component_groups [ ComponentCategory . EV_CHARGER ] . ids ) symbol_mappings . extend ( ev_charger_symbol_mappings ) battery_symbol_mappings = self . _create_default_battery_symbol_mappings ( battery_ids = component_groups [ ComponentCategory . BATTERY ] . ids ) symbol_mappings . extend ( battery_symbol_mappings ) return symbol_mappings def _add_formula ( self , formula_name : str , formula : TimeSeriesFormula [ Any ]) -> None : \"\"\"Add a default formula. If the formula is not already supplied by user upon initialization of the actor and that an output channel is provided. Args: formula_name: name of formula formula: definition of the time series formula Raises: KeyError: when formula is already defined \"\"\" if formula_name in self . microgrid_formulas : raise KeyError ( f \"Formula { formula_name } is already defined!\" ) self . microgrid_formulas [ formula_name ] = formula def _check_symbol_definitions_exist ( self , ) -> None : \"\"\"Check that all the symbols used in `microgrid_formulas` are defined. Raises: KeyError: when used symbols do not exist \"\"\" required_symbols = [ self . microgrid_formulas [ formula_name ] . symbols for formula_name in self . microgrid_formulas ] unique_required_symbols = set ( chain ( * required_symbols )) defined_symbols = list ( self . symbol_mappings . keys ()) missing_symbols = [] for symbol in unique_required_symbols : if symbol not in defined_symbols : missing_symbols . append ( symbol ) if len ( missing_symbols ) > 0 : raise KeyError ( f \"Symbol(s) { missing_symbols } used in `microgrid_formulas` not defined.\" ) def update_symbol_values ( self , component_data : Dict [ str , Any ]) -> Set [ str ]: \"\"\"Update all the symbol values with latest streamed component data. In order to have the formulas computed, the user has to provide symbol mappings, which map symbols to attributes from protobuf messages. When a single component sends data, the values of the corresponding symbols will be updated, e.g. when an inverter with id=8 sends the following data: { 'active_power': 255.0, 'active_power_lower_bound': -999.0, 'active_power_upper_bound': 1000.0, 'id': 8, 'timestamp': datetime.datetime(2022, 9, 1, 16, 36, 42, 575424, tzinfo=<UTC>) } values of the declared symbols related to that component id will be updated as follows: TimeSeriesEntry( 'inverter_8_active_power', datetime.datetime(2022, 9, 1, 16, 36, 42, 575424, tzinfo=<UTC>), 255.0 ) TimeSeriesEntry( 'inverter_8_active_power_lower_bound', datetime.datetime(2022, 9, 1, 16, 36, 42, 575424, tzinfo=<UTC>), -999.0 ) TimeSeriesEntry( 'inverter_8_active_power_upper_bound', datetime.datetime(2022, 9, 1, 16, 36, 42, 575424, tzinfo=<UTC>), 1000.0 ) If a symbol for a given component hasn't been declared, its value will not be updated, even if that component sends some data. Args: component_data: latest streamed component data from a single device Returns: The set of updated symbols. \"\"\" updated_symbol_mappings = [ symbol_mapping for symbol_mapping in self . symbol_mappings . values () if symbol_mapping . component_id == component_data [ \"id\" ] ] for symbol_mapping in updated_symbol_mappings : self . symbol_values . update ( key = symbol_mapping . symbol , entry = TimeSeriesEntry ( timestamp = component_data [ \"timestamp\" ], value = component_data [ symbol_mapping . field . value ], ), ) return set ( symbol_mapping . symbol for symbol_mapping in updated_symbol_mappings ) def compute ( self , symbols : Set [ str ], only_formula_names : Optional [ Set [ str ]] = None ) -> List [ str ]: \"\"\"Compute all the formulas that depend on the provided symbols. Whenever Microgrid devices send data, it is then mapped to symbols that are used by the formulas. The provided `symbols` will cause the formulas relying on them to be computed. If a formula doesn't depend on the symbols that were recently updated, it will not be computed and if the provided `symbols` aren't used for any formula, no computation will be done. Some formulas might rely on multiple symbols, out of which not all might be available at a given point of time. In this case, the values for missing symbols will be replaced with a default value (0.0), which is passed to the `evaluate` method as the `default_entry` parameter. Args: symbols: the set of recently updated symbols from a single device only_formula_names: optional set of formula names that need to be evaluated. If no names are provided, all formulas relying on the provided `symbols` will be evaluated. Returns: Names of the computed formulas. \"\"\" formulas_to_compute : Set [ str ] = { formula_name for formula_name in self . microgrid_formulas if len ( symbols & set ( self . microgrid_formulas [ formula_name ] . symbols )) > 0 } if only_formula_names is not None : formulas_to_compute = formulas_to_compute . intersection ( only_formula_names ) computed_formula_names = [] for formula_name in formulas_to_compute : res = self . microgrid_formulas [ formula_name ] . evaluate ( cache = self . symbol_values , formula_name = formula_name , symbol_to_symbol_mapping = self . symbol_mappings , timedelta_tolerance = timedelta ( seconds = self . component_data_timeout_sec ), default_entry = TimeSeriesEntry [ Any ]( timestamp = datetime . now ( timezone . utc ), value = 0.0 ), ) if res is not None : self . results [ formula_name ] = res computed_formula_names . append ( formula_name ) return computed_formula_names","title":"FormulaCalculator"},{"location":"reference/frequenz/sdk/data_ingestion/formula_calculator/#frequenz.sdk.data_ingestion.formula_calculator.FormulaCalculator-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/data_ingestion/formula_calculator/#frequenz.sdk.data_ingestion.formula_calculator.FormulaCalculator.__init__","text":"Initialize FormulaCalculator. PARAMETER DESCRIPTION component_graph component graph of microgrid TYPE: ComponentGraph additional_formulas a dictionary of additional formulas not included in the default set, with key specifying names for these formulas TYPE: Optional [ Dict [ str , TimeSeriesFormula [ Any ]]] DEFAULT: None battery_ids_overrides mapping of formula names to list of battery ids to be taken into account when evaluating the formula TYPE: Optional [ Dict [ str , Set [ int ]]] DEFAULT: None symbol_mappings list of additional symbol definitions, necessary if the additional user-defined formulas contains extra symbols that are not included in the default set TYPE: Optional [ List [ SymbolMapping ]] DEFAULT: None RAISES DESCRIPTION KeyError if there are missing symbols or duplicated formula names Source code in frequenz/sdk/data_ingestion/formula_calculator.py 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 def __init__ ( self , component_graph : ComponentGraph , additional_formulas : Optional [ Dict [ str , TimeSeriesFormula [ Any ]]] = None , battery_ids_overrides : Optional [ Dict [ str , Set [ int ]]] = None , symbol_mappings : Optional [ List [ SymbolMapping ]] = None , ) -> None : \"\"\"Initialize FormulaCalculator. Args: component_graph: component graph of microgrid additional_formulas: a dictionary of additional formulas not included in the default set, with key specifying names for these formulas battery_ids_overrides: mapping of formula names to list of battery ids to be taken into account when evaluating the formula symbol_mappings: list of additional symbol definitions, necessary if the additional user-defined formulas contains extra symbols that are not included in the default set Raises: KeyError: if there are missing symbols or duplicated formula names \"\"\" component_infos , battery_inverter_mappings = infer_microgrid_config ( component_graph ) self . component_infos = component_infos self . battery_inverter_mappings = battery_inverter_mappings self . battery_ids_overrides = battery_ids_overrides self . microgrid_formulas : Dict [ str , TimeSeriesFormula [ Any ]] = ( {} if additional_formulas is None else additional_formulas ) custom_symbol_mappings : List [ SymbolMapping ] = symbol_mappings or [] default_symbol_mappings = self . _create_default_symbol_mappings () self . symbol_mappings : Dict [ str , SymbolMapping ] = { symbol_mapping . symbol : symbol_mapping for symbol_mapping in custom_symbol_mappings + default_symbol_mappings } self . set_microgrid_formulas () self . _check_symbol_definitions_exist () self . symbol_values : LatestEntryCache [ str , Any ] = LatestEntryCache () self . results : Dict [ str , TimeSeriesEntry [ Any ]] = {} # Max permitted time when the component should send any information. # After that timeout the component will be treated as not existing. # Formulas will put 0 in place of data from this components. # This will happen until component starts sending data. self . component_data_timeout_sec = 60","title":"__init__()"},{"location":"reference/frequenz/sdk/data_ingestion/formula_calculator/#frequenz.sdk.data_ingestion.formula_calculator.FormulaCalculator.compute","text":"Compute all the formulas that depend on the provided symbols. Whenever Microgrid devices send data, it is then mapped to symbols that are used by the formulas. The provided symbols will cause the formulas relying on them to be computed. If a formula doesn't depend on the symbols that were recently updated, it will not be computed and if the provided symbols aren't used for any formula, no computation will be done. Some formulas might rely on multiple symbols, out of which not all might be available at a given point of time. In this case, the values for missing symbols will be replaced with a default value (0.0), which is passed to the evaluate method as the default_entry parameter. PARAMETER DESCRIPTION symbols the set of recently updated symbols from a single device TYPE: Set [ str ] only_formula_names optional set of formula names that need to be evaluated. If no names are provided, all formulas relying on the provided symbols will be evaluated. TYPE: Optional [ Set [ str ]] DEFAULT: None RETURNS DESCRIPTION List [ str ] Names of the computed formulas. Source code in frequenz/sdk/data_ingestion/formula_calculator.py 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 def compute ( self , symbols : Set [ str ], only_formula_names : Optional [ Set [ str ]] = None ) -> List [ str ]: \"\"\"Compute all the formulas that depend on the provided symbols. Whenever Microgrid devices send data, it is then mapped to symbols that are used by the formulas. The provided `symbols` will cause the formulas relying on them to be computed. If a formula doesn't depend on the symbols that were recently updated, it will not be computed and if the provided `symbols` aren't used for any formula, no computation will be done. Some formulas might rely on multiple symbols, out of which not all might be available at a given point of time. In this case, the values for missing symbols will be replaced with a default value (0.0), which is passed to the `evaluate` method as the `default_entry` parameter. Args: symbols: the set of recently updated symbols from a single device only_formula_names: optional set of formula names that need to be evaluated. If no names are provided, all formulas relying on the provided `symbols` will be evaluated. Returns: Names of the computed formulas. \"\"\" formulas_to_compute : Set [ str ] = { formula_name for formula_name in self . microgrid_formulas if len ( symbols & set ( self . microgrid_formulas [ formula_name ] . symbols )) > 0 } if only_formula_names is not None : formulas_to_compute = formulas_to_compute . intersection ( only_formula_names ) computed_formula_names = [] for formula_name in formulas_to_compute : res = self . microgrid_formulas [ formula_name ] . evaluate ( cache = self . symbol_values , formula_name = formula_name , symbol_to_symbol_mapping = self . symbol_mappings , timedelta_tolerance = timedelta ( seconds = self . component_data_timeout_sec ), default_entry = TimeSeriesEntry [ Any ]( timestamp = datetime . now ( timezone . utc ), value = 0.0 ), ) if res is not None : self . results [ formula_name ] = res computed_formula_names . append ( formula_name ) return computed_formula_names","title":"compute()"},{"location":"reference/frequenz/sdk/data_ingestion/formula_calculator/#frequenz.sdk.data_ingestion.formula_calculator.FormulaCalculator.filter_selected_batteries","text":"Filter selected batteries from all batteries in the component graph. Batteries to be used for an individual formula can be overridden via config file in the UI. PARAMETER DESCRIPTION battery_ids list of ids of all the batteries in the component graph TYPE: List [ int ] formula_name name of the formula to apply the override for TYPE: str RETURNS DESCRIPTION List [ int ] list of battery ids selected by the user in the UI for a given formula Source code in frequenz/sdk/data_ingestion/formula_calculator.py 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 def filter_selected_batteries ( self , battery_ids : List [ int ], formula_name : str , ) -> List [ int ]: \"\"\"Filter selected batteries from all batteries in the component graph. Batteries to be used for an individual formula can be overridden via config file in the UI. Args: battery_ids: list of ids of all the batteries in the component graph formula_name: name of the formula to apply the override for Returns: list of battery ids selected by the user in the UI for a given formula \"\"\" if ( self . battery_ids_overrides is None or formula_name not in self . battery_ids_overrides ): return battery_ids selected_battery_ids = self . battery_ids_overrides [ formula_name ] return list ( set ( battery_ids ) & selected_battery_ids )","title":"filter_selected_batteries()"},{"location":"reference/frequenz/sdk/data_ingestion/formula_calculator/#frequenz.sdk.data_ingestion.formula_calculator.FormulaCalculator.set_microgrid_formulas","text":"Set formulas associated with the components specified for the microgrid. RAISES DESCRIPTION ValueError when there is neither market nor grid meters Source code in frequenz/sdk/data_ingestion/formula_calculator.py 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 def set_microgrid_formulas ( self , ) -> None : \"\"\"Set formulas associated with the components specified for the microgrid. Raises: ValueError: when there is neither market nor grid meters \"\"\" components_by_type = self . _group_components () client_load_formula = self . _create_client_load_formula ( meter_group_info = components_by_type [ ComponentCategory . METER ], ev_charger_group_info = components_by_type [ ComponentCategory . EV_CHARGER ], inverter_group_info = components_by_type [ ComponentCategory . INVERTER ], ) self . _add_formula ( METRIC_CLIENT_LOAD , client_load_formula ) grid_load_formula = self . _create_grid_load_formula ( meter_group_info = components_by_type [ ComponentCategory . METER ], ev_charger_group_info = components_by_type [ ComponentCategory . EV_CHARGER ], inverter_group_info = components_by_type [ ComponentCategory . INVERTER ], ) self . _add_formula ( METRIC_GRID_LOAD , grid_load_formula ) pv_prod_formula = self . _create_pv_prod_formula ( meter_group_info = components_by_type [ ComponentCategory . METER ] ) self . _add_formula ( METRIC_PV_PROD , pv_prod_formula ) ev_active_power_consumption_formula = ( self . _create_ev_active_power_consumption_formula ( ev_charger_ids = components_by_type [ ComponentCategory . EV_CHARGER ] . ids ) ) self . _add_formula ( METRIC_EV_CHARGERS_CONSUMPTION , ev_active_power_consumption_formula ) active_power_formula = self . _create_active_power_formula ( inverter_ids = components_by_type [ ComponentCategory . INVERTER ] . ids ) self . _add_formula ( METRIC_BATTERIES_ACTIVE_POWER , active_power_formula ) batteries_active_power_bounds_formula = ( self . _create_batteries_active_power_bounds_formula ( battery_ids = self . filter_selected_batteries ( battery_ids = components_by_type [ ComponentCategory . BATTERY ] . ids , formula_name = METRIC_BATTERIES_ACTIVE_POWER_BOUNDS , ), battery_inverter_mappings = self . battery_inverter_mappings , ) ) self . _add_formula ( METRIC_BATTERIES_ACTIVE_POWER_BOUNDS , batteries_active_power_bounds_formula ) total_energy_formula = self . _create_total_energy_formula ( battery_ids = self . filter_selected_batteries ( battery_ids = components_by_type [ ComponentCategory . BATTERY ] . ids , formula_name = METRIC_BATTERIES_REMAINING_ENERGY , ), ) self . _add_formula ( METRIC_BATTERIES_REMAINING_ENERGY , total_energy_formula ) batteries_capacity_formula = self . _create_batteries_capacity_formula ( battery_ids = self . filter_selected_batteries ( battery_ids = components_by_type [ ComponentCategory . BATTERY ] . ids , formula_name = METRIC_BATTERIES_CAPACITY , ), ) self . _add_formula ( METRIC_BATTERIES_CAPACITY , batteries_capacity_formula )","title":"set_microgrid_formulas()"},{"location":"reference/frequenz/sdk/data_ingestion/formula_calculator/#frequenz.sdk.data_ingestion.formula_calculator.FormulaCalculator.update_symbol_values","text":"Update all the symbol values with latest streamed component data. In order to have the formulas computed, the user has to provide symbol mappings, which map symbols to attributes from protobuf messages. When a single component sends data, the values of the corresponding symbols will be updated, e.g. when an inverter with id=8 sends the following data: { 'active_power': 255.0, 'active_power_lower_bound': -999.0, 'active_power_upper_bound': 1000.0, 'id': 8, 'timestamp': datetime.datetime(2022, 9, 1, 16, 36, 42, 575424, tzinfo= ) } values of the declared symbols related to that component id will be updated as follows: TimeSeriesEntry( 'inverter_8_active_power', datetime.datetime(2022, 9, 1, 16, 36, 42, 575424, tzinfo= ), 255.0 ) TimeSeriesEntry( 'inverter_8_active_power_lower_bound', datetime.datetime(2022, 9, 1, 16, 36, 42, 575424, tzinfo= ), -999.0 ) TimeSeriesEntry( 'inverter_8_active_power_upper_bound', datetime.datetime(2022, 9, 1, 16, 36, 42, 575424, tzinfo= ), 1000.0 ) If a symbol for a given component hasn't been declared, its value will not be updated, even if that component sends some data. PARAMETER DESCRIPTION component_data latest streamed component data from a single device TYPE: Dict [ str , Any ] RETURNS DESCRIPTION Set [ str ] The set of updated symbols. Source code in frequenz/sdk/data_ingestion/formula_calculator.py 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 def update_symbol_values ( self , component_data : Dict [ str , Any ]) -> Set [ str ]: \"\"\"Update all the symbol values with latest streamed component data. In order to have the formulas computed, the user has to provide symbol mappings, which map symbols to attributes from protobuf messages. When a single component sends data, the values of the corresponding symbols will be updated, e.g. when an inverter with id=8 sends the following data: { 'active_power': 255.0, 'active_power_lower_bound': -999.0, 'active_power_upper_bound': 1000.0, 'id': 8, 'timestamp': datetime.datetime(2022, 9, 1, 16, 36, 42, 575424, tzinfo=<UTC>) } values of the declared symbols related to that component id will be updated as follows: TimeSeriesEntry( 'inverter_8_active_power', datetime.datetime(2022, 9, 1, 16, 36, 42, 575424, tzinfo=<UTC>), 255.0 ) TimeSeriesEntry( 'inverter_8_active_power_lower_bound', datetime.datetime(2022, 9, 1, 16, 36, 42, 575424, tzinfo=<UTC>), -999.0 ) TimeSeriesEntry( 'inverter_8_active_power_upper_bound', datetime.datetime(2022, 9, 1, 16, 36, 42, 575424, tzinfo=<UTC>), 1000.0 ) If a symbol for a given component hasn't been declared, its value will not be updated, even if that component sends some data. Args: component_data: latest streamed component data from a single device Returns: The set of updated symbols. \"\"\" updated_symbol_mappings = [ symbol_mapping for symbol_mapping in self . symbol_mappings . values () if symbol_mapping . component_id == component_data [ \"id\" ] ] for symbol_mapping in updated_symbol_mappings : self . symbol_values . update ( key = symbol_mapping . symbol , entry = TimeSeriesEntry ( timestamp = component_data [ \"timestamp\" ], value = component_data [ symbol_mapping . field . value ], ), ) return set ( symbol_mapping . symbol for symbol_mapping in updated_symbol_mappings )","title":"update_symbol_values()"},{"location":"reference/frequenz/sdk/data_ingestion/formula_calculator/#frequenz.sdk.data_ingestion.formula_calculator-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/data_ingestion/gen_component_receivers/","text":"frequenz.sdk.data_ingestion.gen_component_receivers \u00a4 Functions for generating DataColletor with necessary fields from ComponentInfo. Classes \u00a4 Functions \u00a4 frequenz . sdk . data_ingestion . gen_component_receivers . gen_component_receivers ( component_infos , microgrid_client ) async \u00a4 Generate receivers for all components grouped by component category. Group all components provided in component_infos by ComponentCategory and create a receiver for each group to collect data from the components belonging to that group. PARAMETER DESCRIPTION component_infos list of ComponentInfo for all the components from which to collect data from TYPE: List [ ComponentInfo ] microgrid_client microgrid client TYPE: client . MicrogridApiClient RETURNS DESCRIPTION Dict [ ComponentCategory , Receiver [ Dict [ str , Any ]]] Receiver of the data per each component category. RAISES DESCRIPTION ValueError if any of the receivers receives a metric from an unsupported type of component. Source code in frequenz/sdk/data_ingestion/gen_component_receivers.py 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 async def gen_component_receivers ( component_infos : List [ ComponentInfo ], microgrid_client : client . MicrogridApiClient , ) -> Dict [ ComponentCategory , Receiver [ Dict [ str , Any ]]]: \"\"\"Generate receivers for all components grouped by component category. Group all components provided in `component_infos` by `ComponentCategory` and create a receiver for each group to collect data from the components belonging to that group. Args: component_infos: list of ComponentInfo for all the components from which to collect data from microgrid_client: microgrid client Returns: Receiver of the data per each component category. Raises: ValueError: if any of the receivers receives a metric from an unsupported type of component. \"\"\" grouped_component_infos : Dict [ ComponentCategory , List [ ComponentInfo ]] = {} for component_info in component_infos : if component_info . category not in grouped_component_infos : grouped_component_infos [ component_info . category ] = [] grouped_component_infos [ component_info . category ] . append ( component_info ) recv_components : Dict [ ComponentCategory , Receiver [ Dict [ str , Any ]]] = {} for component_category , infos in grouped_component_infos . items (): receivers = [] for component_info in infos : component_id = component_info . component_id if component_category == ComponentCategory . BATTERY : receiver = await _create_battery_receiver ( component_id , microgrid_client ) elif component_category == ComponentCategory . INVERTER : receiver = await _create_inverter_receiver ( component_id , microgrid_client ) elif component_category == ComponentCategory . EV_CHARGER : receiver = await _create_ev_charger_receiver ( component_id , microgrid_client ) elif component_category in { ComponentCategory . METER , ComponentCategory . CHP , ComponentCategory . PV_ARRAY , }: receiver = await _create_meter_receiver ( component_id , microgrid_client ) else : raise ValueError ( f \"Unsupported type: { component_category } \" ) receivers . append ( receiver ) recv_components [ component_category ] = Merge ( * receivers ) return recv_components frequenz . sdk . data_ingestion . gen_component_receivers . transform_battery_data ( data ) \u00a4 Transform component reading from a Battery into a dict. PARAMETER DESCRIPTION data reading from Battery component TYPE: BatteryData RETURNS DESCRIPTION Dict [ str , Any ] Metrics collected from a Battery. Source code in frequenz/sdk/data_ingestion/gen_component_receivers.py 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 def transform_battery_data ( data : BatteryData , ) -> Dict [ str , Any ]: \"\"\"Transform component reading from a Battery into a dict. Args: data: reading from Battery component Returns: Metrics collected from a Battery. \"\"\" result : Dict [ str , Any ] = {} result [ METRIC_COMPONENT_ID ] = data . component_id result [ METRIC_TIMESTAMP ] = data . timestamp result [ METRIC_SOC ] = data . soc result [ METRIC_CAPACITY ] = data . capacity result [ METRIC_POWER_UPPER_BOUND ] = data . power_upper_bound result [ METRIC_POWER_LOWER_BOUND ] = data . power_lower_bound return result frequenz . sdk . data_ingestion . gen_component_receivers . transform_ev_charger_data ( data ) \u00a4 Transform component reading from an EV Charger into a dict. PARAMETER DESCRIPTION data data from EV Charger component TYPE: EVChargerData RETURNS DESCRIPTION Dict [ str , Any ] Metrics collected from an EV Charger. Source code in frequenz/sdk/data_ingestion/gen_component_receivers.py 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def transform_ev_charger_data ( data : EVChargerData , ) -> Dict [ str , Any ]: \"\"\"Transform component reading from an EV Charger into a dict. Args: data: data from EV Charger component Returns: Metrics collected from an EV Charger. \"\"\" result : Dict [ str , Any ] = {} result [ METRIC_COMPONENT_ID ] = data . component_id result [ METRIC_TIMESTAMP ] = data . timestamp result [ METRIC_EV_ACTIVE_POWER ] = data . active_power return result frequenz . sdk . data_ingestion . gen_component_receivers . transform_inverter_data ( data ) \u00a4 Transform component reading from an Inverter into a dict. PARAMETER DESCRIPTION data reading from Inverter component TYPE: InverterData RETURNS DESCRIPTION Dict [ str , Any ] Metrics collected from an Inverter. Source code in frequenz/sdk/data_ingestion/gen_component_receivers.py 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 def transform_inverter_data ( data : InverterData , ) -> Dict [ str , Any ]: \"\"\"Transform component reading from an Inverter into a dict. Args: data: reading from Inverter component Returns: Metrics collected from an Inverter. \"\"\" result : Dict [ str , Any ] = {} result [ METRIC_COMPONENT_ID ] = data . component_id result [ METRIC_TIMESTAMP ] = data . timestamp result [ METRIC_ACTIVE_POWER_UPPER_BOUND ] = data . active_power_upper_bound result [ METRIC_ACTIVE_POWER_LOWER_BOUND ] = data . active_power_lower_bound # Active Power shouldn't be a single value, but bounds instead # Bounds(data.active_power_lower_bound, data.active_power_upper_bound) result [ METRIC_ACTIVE_POWER ] = data . active_power return result frequenz . sdk . data_ingestion . gen_component_receivers . transform_meter_data ( data ) \u00a4 Transform component reading from a Meter into a dict. PARAMETER DESCRIPTION data reading from Meter component TYPE: MeterData RETURNS DESCRIPTION Dict [ str , Any ] Metrics collected from a Meter. Source code in frequenz/sdk/data_ingestion/gen_component_receivers.py 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 def transform_meter_data ( data : MeterData , ) -> Dict [ str , Any ]: \"\"\"Transform component reading from a Meter into a dict. Args: data: reading from Meter component Returns: Metrics collected from a Meter. \"\"\" result : Dict [ str , Any ] = {} result [ METRIC_COMPONENT_ID ] = data . component_id result [ METRIC_TIMESTAMP ] = data . timestamp result [ METRIC_ACTIVE_POWER ] = data . active_power return result","title":"gen_component_receivers"},{"location":"reference/frequenz/sdk/data_ingestion/gen_component_receivers/#frequenz.sdk.data_ingestion.gen_component_receivers","text":"Functions for generating DataColletor with necessary fields from ComponentInfo.","title":"gen_component_receivers"},{"location":"reference/frequenz/sdk/data_ingestion/gen_component_receivers/#frequenz.sdk.data_ingestion.gen_component_receivers-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/data_ingestion/gen_component_receivers/#frequenz.sdk.data_ingestion.gen_component_receivers-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/data_ingestion/gen_component_receivers/#frequenz.sdk.data_ingestion.gen_component_receivers.gen_component_receivers","text":"Generate receivers for all components grouped by component category. Group all components provided in component_infos by ComponentCategory and create a receiver for each group to collect data from the components belonging to that group. PARAMETER DESCRIPTION component_infos list of ComponentInfo for all the components from which to collect data from TYPE: List [ ComponentInfo ] microgrid_client microgrid client TYPE: client . MicrogridApiClient RETURNS DESCRIPTION Dict [ ComponentCategory , Receiver [ Dict [ str , Any ]]] Receiver of the data per each component category. RAISES DESCRIPTION ValueError if any of the receivers receives a metric from an unsupported type of component. Source code in frequenz/sdk/data_ingestion/gen_component_receivers.py 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 async def gen_component_receivers ( component_infos : List [ ComponentInfo ], microgrid_client : client . MicrogridApiClient , ) -> Dict [ ComponentCategory , Receiver [ Dict [ str , Any ]]]: \"\"\"Generate receivers for all components grouped by component category. Group all components provided in `component_infos` by `ComponentCategory` and create a receiver for each group to collect data from the components belonging to that group. Args: component_infos: list of ComponentInfo for all the components from which to collect data from microgrid_client: microgrid client Returns: Receiver of the data per each component category. Raises: ValueError: if any of the receivers receives a metric from an unsupported type of component. \"\"\" grouped_component_infos : Dict [ ComponentCategory , List [ ComponentInfo ]] = {} for component_info in component_infos : if component_info . category not in grouped_component_infos : grouped_component_infos [ component_info . category ] = [] grouped_component_infos [ component_info . category ] . append ( component_info ) recv_components : Dict [ ComponentCategory , Receiver [ Dict [ str , Any ]]] = {} for component_category , infos in grouped_component_infos . items (): receivers = [] for component_info in infos : component_id = component_info . component_id if component_category == ComponentCategory . BATTERY : receiver = await _create_battery_receiver ( component_id , microgrid_client ) elif component_category == ComponentCategory . INVERTER : receiver = await _create_inverter_receiver ( component_id , microgrid_client ) elif component_category == ComponentCategory . EV_CHARGER : receiver = await _create_ev_charger_receiver ( component_id , microgrid_client ) elif component_category in { ComponentCategory . METER , ComponentCategory . CHP , ComponentCategory . PV_ARRAY , }: receiver = await _create_meter_receiver ( component_id , microgrid_client ) else : raise ValueError ( f \"Unsupported type: { component_category } \" ) receivers . append ( receiver ) recv_components [ component_category ] = Merge ( * receivers ) return recv_components","title":"gen_component_receivers()"},{"location":"reference/frequenz/sdk/data_ingestion/gen_component_receivers/#frequenz.sdk.data_ingestion.gen_component_receivers.transform_battery_data","text":"Transform component reading from a Battery into a dict. PARAMETER DESCRIPTION data reading from Battery component TYPE: BatteryData RETURNS DESCRIPTION Dict [ str , Any ] Metrics collected from a Battery. Source code in frequenz/sdk/data_ingestion/gen_component_receivers.py 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 def transform_battery_data ( data : BatteryData , ) -> Dict [ str , Any ]: \"\"\"Transform component reading from a Battery into a dict. Args: data: reading from Battery component Returns: Metrics collected from a Battery. \"\"\" result : Dict [ str , Any ] = {} result [ METRIC_COMPONENT_ID ] = data . component_id result [ METRIC_TIMESTAMP ] = data . timestamp result [ METRIC_SOC ] = data . soc result [ METRIC_CAPACITY ] = data . capacity result [ METRIC_POWER_UPPER_BOUND ] = data . power_upper_bound result [ METRIC_POWER_LOWER_BOUND ] = data . power_lower_bound return result","title":"transform_battery_data()"},{"location":"reference/frequenz/sdk/data_ingestion/gen_component_receivers/#frequenz.sdk.data_ingestion.gen_component_receivers.transform_ev_charger_data","text":"Transform component reading from an EV Charger into a dict. PARAMETER DESCRIPTION data data from EV Charger component TYPE: EVChargerData RETURNS DESCRIPTION Dict [ str , Any ] Metrics collected from an EV Charger. Source code in frequenz/sdk/data_ingestion/gen_component_receivers.py 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def transform_ev_charger_data ( data : EVChargerData , ) -> Dict [ str , Any ]: \"\"\"Transform component reading from an EV Charger into a dict. Args: data: data from EV Charger component Returns: Metrics collected from an EV Charger. \"\"\" result : Dict [ str , Any ] = {} result [ METRIC_COMPONENT_ID ] = data . component_id result [ METRIC_TIMESTAMP ] = data . timestamp result [ METRIC_EV_ACTIVE_POWER ] = data . active_power return result","title":"transform_ev_charger_data()"},{"location":"reference/frequenz/sdk/data_ingestion/gen_component_receivers/#frequenz.sdk.data_ingestion.gen_component_receivers.transform_inverter_data","text":"Transform component reading from an Inverter into a dict. PARAMETER DESCRIPTION data reading from Inverter component TYPE: InverterData RETURNS DESCRIPTION Dict [ str , Any ] Metrics collected from an Inverter. Source code in frequenz/sdk/data_ingestion/gen_component_receivers.py 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 def transform_inverter_data ( data : InverterData , ) -> Dict [ str , Any ]: \"\"\"Transform component reading from an Inverter into a dict. Args: data: reading from Inverter component Returns: Metrics collected from an Inverter. \"\"\" result : Dict [ str , Any ] = {} result [ METRIC_COMPONENT_ID ] = data . component_id result [ METRIC_TIMESTAMP ] = data . timestamp result [ METRIC_ACTIVE_POWER_UPPER_BOUND ] = data . active_power_upper_bound result [ METRIC_ACTIVE_POWER_LOWER_BOUND ] = data . active_power_lower_bound # Active Power shouldn't be a single value, but bounds instead # Bounds(data.active_power_lower_bound, data.active_power_upper_bound) result [ METRIC_ACTIVE_POWER ] = data . active_power return result","title":"transform_inverter_data()"},{"location":"reference/frequenz/sdk/data_ingestion/gen_component_receivers/#frequenz.sdk.data_ingestion.gen_component_receivers.transform_meter_data","text":"Transform component reading from a Meter into a dict. PARAMETER DESCRIPTION data reading from Meter component TYPE: MeterData RETURNS DESCRIPTION Dict [ str , Any ] Metrics collected from a Meter. Source code in frequenz/sdk/data_ingestion/gen_component_receivers.py 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 def transform_meter_data ( data : MeterData , ) -> Dict [ str , Any ]: \"\"\"Transform component reading from a Meter into a dict. Args: data: reading from Meter component Returns: Metrics collected from a Meter. \"\"\" result : Dict [ str , Any ] = {} result [ METRIC_COMPONENT_ID ] = data . component_id result [ METRIC_TIMESTAMP ] = data . timestamp result [ METRIC_ACTIVE_POWER ] = data . active_power return result","title":"transform_meter_data()"},{"location":"reference/frequenz/sdk/data_ingestion/load_historic_data/","text":"frequenz.sdk.data_ingestion.load_historic_data \u00a4 LoadHistoricData is a tool for loading historic parquet files. This object can be called from within other IOperation s or outside of the pipeline. Please be aware that the loading of parquet files is not asynchronous, running this will block other IOperation tasks unless done in a different thread. Classes \u00a4 frequenz.sdk.data_ingestion.load_historic_data.ComponentInfo dataclass \u00a4 Object containing component information. Source code in frequenz/sdk/data_ingestion/load_historic_data.py 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 @dataclass class ComponentInfo : \"\"\"Object containing component information.\"\"\" # component id component_id : int # category of component; \"Meter\"/\"Inverter\"/\"Battery\" category : str # type of meter; \"pv\"/\"market\"/\"grid\"/None (when component_category != \"Meter\") meter_type : Optional [ str ] = None def __post_init__ ( self ) -> None : \"\"\"Validate fields once an object has been created. Raises: ValueError: on validation failure. \"\"\" if ( self . category in [ \"Meter\" , \"Battery\" , \"Inverter\" , ] ) is False : raise ValueError ( \"category must be one of following: `Meter`, `Battery` or `Inverter`\" ) if self . category == \"Meter\" : if ( self . meter_type in [ \"pv\" , \"market\" , \"grid\" , ] ) is False : raise ValueError ( \"meter type must be one of following: `pv`, `market`, `grid`\" ) Functions \u00a4 __post_init__ () \u00a4 Validate fields once an object has been created. RAISES DESCRIPTION ValueError on validation failure. Source code in frequenz/sdk/data_ingestion/load_historic_data.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 def __post_init__ ( self ) -> None : \"\"\"Validate fields once an object has been created. Raises: ValueError: on validation failure. \"\"\" if ( self . category in [ \"Meter\" , \"Battery\" , \"Inverter\" , ] ) is False : raise ValueError ( \"category must be one of following: `Meter`, `Battery` or `Inverter`\" ) if self . category == \"Meter\" : if ( self . meter_type in [ \"pv\" , \"market\" , \"grid\" , ] ) is False : raise ValueError ( \"meter type must be one of following: `pv`, `market`, `grid`\" ) frequenz.sdk.data_ingestion.load_historic_data.FeatureGenerator dataclass \u00a4 Object containing the info for generating features from historic data. Source code in frequenz/sdk/data_ingestion/load_historic_data.py 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 @dataclass class FeatureGenerator : \"\"\"Object containing the info for generating features from historic data.\"\"\" # columns to read for generating features, can be single column or multiple # columns (e.g. if user wants to generate a feature by adding two columns # together) a key within a column could also be specified, e.g. soc.now read_cols : List [ str ] # user-defined functions to apply to columns (wrapped through pandas .apply() # function) for generating features # when set to None, there should be only one column specified in read_cols # it will be returned as it is apply_func : Optional [ Callable [[ pd . DataFrame ], pd . DataFrame ]] = None # column name for the generated feature in the return dataframe # when set to None, there should be only one column specified in read_cols # it will be set to be the same as the existing column / column.key name feature : Optional [ str ] = None def __post_init__ ( self ) -> None : \"\"\"Validate fields once an object has been created. Raises: ValueError: on validation failure. \"\"\" if self . apply_func is None : if len ( self . read_cols ) != 1 : raise ValueError ( \"length of read_cols must be 1 when apply_func is None\" ) if self . feature is None : if len ( self . read_cols ) != 1 : raise ValueError ( \"length of read_cols must be 1 when feature is None\" ) self . feature = self . read_cols [ 0 ] Functions \u00a4 __post_init__ () \u00a4 Validate fields once an object has been created. RAISES DESCRIPTION ValueError on validation failure. Source code in frequenz/sdk/data_ingestion/load_historic_data.py 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 def __post_init__ ( self ) -> None : \"\"\"Validate fields once an object has been created. Raises: ValueError: on validation failure. \"\"\" if self . apply_func is None : if len ( self . read_cols ) != 1 : raise ValueError ( \"length of read_cols must be 1 when apply_func is None\" ) if self . feature is None : if len ( self . read_cols ) != 1 : raise ValueError ( \"length of read_cols must be 1 when feature is None\" ) self . feature = self . read_cols [ 0 ] frequenz.sdk.data_ingestion.load_historic_data.LoadHistoricData \u00a4 Load historical data from parquet files. Can be used from within IOperation s or separately. Not asynchronous, so will block other IOperation s and actors, unless run in a separate thread. Source code in frequenz/sdk/data_ingestion/load_historic_data.py 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 class LoadHistoricData : \"\"\"Load historical data from parquet files. Can be used from within `IOperation`s or separately. Not asynchronous, so will block other `IOperation`s and actors, unless run in a separate thread. \"\"\" def __init__ ( self , microgrid_id : int , ignore_faulty_files : bool = True , ) -> None : \"\"\"Create a `LoadHistoricalData` instance. Args: microgrid_id: mid of site ignore_faulty_files: mode for handling faulty files when True: individual faulty file will be ignored. The reader will print out an error message but continue to read other files within the specified time range. when False: once the reader encounters a faulty file, the whole reader will be stopped and an error will be raised. \"\"\" self . histdata_dir = os . path . join ( HISTDATA_DIR , \"messstellen_id=\" + str ( microgrid_id ) ) self . file_time_format = FILE_TIMEFORMAT self . file_time_prefix = FILE_TIMEPREFIX self . file_time_suffix = FILE_TIMESUFFIX + str ( microgrid_id ) + \".parquet\" self . ignore_faulty_files = ignore_faulty_files def get_file_timestamps ( self , filenames : List [ str ]) -> pd . Series : \"\"\"Get the timestamps for a list of historic parquet data files. Args: filenames: list of historic parquet data files Returns: Timestamps of each of the files. \"\"\" timestamps = pd . to_datetime ( [ file . split ( self . file_time_suffix )[ 0 ] . split ( self . file_time_prefix )[ - 1 ] for file in filenames ], format = self . file_time_format , ) . tz_localize ( timezone . utc ) return timestamps def gen_datafile_list ( self , data_dir : str , dates : pd . DatetimeIndex , start_time : datetime , end_time : datetime , ) -> List [ str ]: \"\"\"Generate the list of historic parquet files to read. Args: data_dir: directory of all the historic data of the particular component dates: the dates over which histori data should be read start_time: will read from this timestamp onwards end_time: will read up to this timestamp Returns: The list of files that will be read within the specified timerange. \"\"\" data : List [ str ] = [] date_dirs = gen_date_dirs ( data_dir , dates ) for date , date_dir in zip ( dates , date_dirs ): date_files = sorted ( glob . glob ( os . path . join ( date_dir , \"*.parquet\" , ) ) ) if ( date == dates [ 0 ]) | ( date == dates [ - 1 ]): timestamps = self . get_file_timestamps ( date_files ) date_files = [ date_files [ i ] for i in range ( len ( date_files )) if (( timestamps [ i ] >= start_time ) & ( timestamps [ i ] <= end_time )) ] data = data + date_files return data def load_parquet_file ( self , file : str , read_cols : List [ str ]) -> pd . DataFrame : \"\"\"Load one parquet file. Args: file: path of the file to read read_cols: list of columns to read Returns: Return dataframe of the read file with the specified columns Raises: RuntimeError: if file is not found or cannot be read \"\"\" try : data = pq . ParquetDataset ( file ) . read ( columns = read_cols ) df_read = data . to_pandas () except Exception as exception : # pylint: disable=broad-except logger . exception ( \"failed loading data from file: %s , due to: %s \" , file , exception ) df_read = pd . DataFrame () if self . ignore_faulty_files is False : raise RuntimeError from exception return df_read def load_parquet_files ( self , files : List [ str ], read_cols : List [ str ], resampling_str : str = \"1S\" ) -> List [ pd . DataFrame ]: \"\"\"Load multiple parquet files. Args: files: list of paths of the files to read read_cols: list of columns to read resampling_str: rule to use for resampling. Returns: List of return dataframes per file. \"\"\" df_list : List [ pd . DataFrame ] = [] for file in tqdm ( files ): df_read = self . load_parquet_file ( file , read_cols ) if len ( df_read ) > 0 : df_list . append ( df_read . set_index ( \"ts\" ) . resample ( resampling_str ) . first () . ffill () . reset_index () ) return df_list def read ( self , load_hd_settings : LoadHistoricDataSettings , start_time : datetime , end_time : datetime , ) -> pd . DataFrame : \"\"\"Read historical data. Args: load_hd_settings: instruction on which historic data to read. start_time: will read from this timestamp onwards. end_time: will read up to this timestamp. Returns: Dataframe containing historical data with column `timestamp` specifying the timestamp and the features generated with names `FeatureGenerator.feature` in feature_generators. \"\"\" data_dir = os . path . join ( self . histdata_dir , \"category=\" + load_hd_settings . component_info . category , \"component_id=\" + str ( load_hd_settings . component_info . component_id ), ) if start_time . tzinfo is None : start_time = start_time . replace ( tzinfo = timezone . utc ) if end_time . tzinfo is None : end_time = end_time . replace ( tzinfo = timezone . utc ) logger . info ( \"reading historic data from component id= %s within the time interval: %s to %s \" , load_hd_settings . component_info . component_id , start_time , end_time , ) dates = pd . date_range ( start_time . date (), end_time . date ()) data_files = self . gen_datafile_list ( data_dir , dates , start_time , end_time ) read_cols = list ( set ( itertools . chain ( * [ feature_generator . read_cols for feature_generator in load_hd_settings . feature_generators ] ) ) ) read_cols = list ( set ([ \"ts\" ] + read_cols )) df_list = self . load_parquet_files ( data_files , read_cols , resampling_str = str ( load_hd_settings . data_sampling_rate ) + \"S\" , ) if len ( df_list ) == 0 : return pd . DataFrame () df0 = crop_df_list_by_time ( df_list , start_time , end_time ) df_features = gen_features ( df0 , load_hd_settings . feature_generators ) . rename ( columns = { \"ts\" : \"timestamp\" } ) return df_features Functions \u00a4 __init__ ( microgrid_id , ignore_faulty_files = True ) \u00a4 Create a LoadHistoricalData instance. PARAMETER DESCRIPTION microgrid_id mid of site TYPE: int ignore_faulty_files mode for handling faulty files when True: individual faulty file will be ignored. The reader will print out an error message but continue to read other files within the specified time range. when False: once the reader encounters a faulty file, the whole reader will be stopped and an error will be raised. TYPE: bool DEFAULT: True Source code in frequenz/sdk/data_ingestion/load_historic_data.py 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 def __init__ ( self , microgrid_id : int , ignore_faulty_files : bool = True , ) -> None : \"\"\"Create a `LoadHistoricalData` instance. Args: microgrid_id: mid of site ignore_faulty_files: mode for handling faulty files when True: individual faulty file will be ignored. The reader will print out an error message but continue to read other files within the specified time range. when False: once the reader encounters a faulty file, the whole reader will be stopped and an error will be raised. \"\"\" self . histdata_dir = os . path . join ( HISTDATA_DIR , \"messstellen_id=\" + str ( microgrid_id ) ) self . file_time_format = FILE_TIMEFORMAT self . file_time_prefix = FILE_TIMEPREFIX self . file_time_suffix = FILE_TIMESUFFIX + str ( microgrid_id ) + \".parquet\" self . ignore_faulty_files = ignore_faulty_files gen_datafile_list ( data_dir , dates , start_time , end_time ) \u00a4 Generate the list of historic parquet files to read. PARAMETER DESCRIPTION data_dir directory of all the historic data of the particular component TYPE: str dates the dates over which histori data should be read TYPE: pd . DatetimeIndex start_time will read from this timestamp onwards TYPE: datetime end_time will read up to this timestamp TYPE: datetime RETURNS DESCRIPTION List [ str ] The list of files that will be read within the specified timerange. Source code in frequenz/sdk/data_ingestion/load_historic_data.py 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 def gen_datafile_list ( self , data_dir : str , dates : pd . DatetimeIndex , start_time : datetime , end_time : datetime , ) -> List [ str ]: \"\"\"Generate the list of historic parquet files to read. Args: data_dir: directory of all the historic data of the particular component dates: the dates over which histori data should be read start_time: will read from this timestamp onwards end_time: will read up to this timestamp Returns: The list of files that will be read within the specified timerange. \"\"\" data : List [ str ] = [] date_dirs = gen_date_dirs ( data_dir , dates ) for date , date_dir in zip ( dates , date_dirs ): date_files = sorted ( glob . glob ( os . path . join ( date_dir , \"*.parquet\" , ) ) ) if ( date == dates [ 0 ]) | ( date == dates [ - 1 ]): timestamps = self . get_file_timestamps ( date_files ) date_files = [ date_files [ i ] for i in range ( len ( date_files )) if (( timestamps [ i ] >= start_time ) & ( timestamps [ i ] <= end_time )) ] data = data + date_files return data get_file_timestamps ( filenames ) \u00a4 Get the timestamps for a list of historic parquet data files. PARAMETER DESCRIPTION filenames list of historic parquet data files TYPE: List [ str ] RETURNS DESCRIPTION pd . Series Timestamps of each of the files. Source code in frequenz/sdk/data_ingestion/load_historic_data.py 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 def get_file_timestamps ( self , filenames : List [ str ]) -> pd . Series : \"\"\"Get the timestamps for a list of historic parquet data files. Args: filenames: list of historic parquet data files Returns: Timestamps of each of the files. \"\"\" timestamps = pd . to_datetime ( [ file . split ( self . file_time_suffix )[ 0 ] . split ( self . file_time_prefix )[ - 1 ] for file in filenames ], format = self . file_time_format , ) . tz_localize ( timezone . utc ) return timestamps load_parquet_file ( file , read_cols ) \u00a4 Load one parquet file. PARAMETER DESCRIPTION file path of the file to read TYPE: str read_cols list of columns to read TYPE: List [ str ] RETURNS DESCRIPTION pd . DataFrame Return dataframe of the read file with the specified columns RAISES DESCRIPTION RuntimeError if file is not found or cannot be read Source code in frequenz/sdk/data_ingestion/load_historic_data.py 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 def load_parquet_file ( self , file : str , read_cols : List [ str ]) -> pd . DataFrame : \"\"\"Load one parquet file. Args: file: path of the file to read read_cols: list of columns to read Returns: Return dataframe of the read file with the specified columns Raises: RuntimeError: if file is not found or cannot be read \"\"\" try : data = pq . ParquetDataset ( file ) . read ( columns = read_cols ) df_read = data . to_pandas () except Exception as exception : # pylint: disable=broad-except logger . exception ( \"failed loading data from file: %s , due to: %s \" , file , exception ) df_read = pd . DataFrame () if self . ignore_faulty_files is False : raise RuntimeError from exception return df_read load_parquet_files ( files , read_cols , resampling_str = '1S' ) \u00a4 Load multiple parquet files. PARAMETER DESCRIPTION files list of paths of the files to read TYPE: List [ str ] read_cols list of columns to read TYPE: List [ str ] resampling_str rule to use for resampling. TYPE: str DEFAULT: '1S' RETURNS DESCRIPTION List [ pd . DataFrame ] List of return dataframes per file. Source code in frequenz/sdk/data_ingestion/load_historic_data.py 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 def load_parquet_files ( self , files : List [ str ], read_cols : List [ str ], resampling_str : str = \"1S\" ) -> List [ pd . DataFrame ]: \"\"\"Load multiple parquet files. Args: files: list of paths of the files to read read_cols: list of columns to read resampling_str: rule to use for resampling. Returns: List of return dataframes per file. \"\"\" df_list : List [ pd . DataFrame ] = [] for file in tqdm ( files ): df_read = self . load_parquet_file ( file , read_cols ) if len ( df_read ) > 0 : df_list . append ( df_read . set_index ( \"ts\" ) . resample ( resampling_str ) . first () . ffill () . reset_index () ) return df_list read ( load_hd_settings , start_time , end_time ) \u00a4 Read historical data. PARAMETER DESCRIPTION load_hd_settings instruction on which historic data to read. TYPE: LoadHistoricDataSettings start_time will read from this timestamp onwards. TYPE: datetime end_time will read up to this timestamp. TYPE: datetime RETURNS DESCRIPTION pd . DataFrame Dataframe containing historical data with column timestamp specifying the timestamp and the features generated with names FeatureGenerator.feature in feature_generators. Source code in frequenz/sdk/data_ingestion/load_historic_data.py 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 def read ( self , load_hd_settings : LoadHistoricDataSettings , start_time : datetime , end_time : datetime , ) -> pd . DataFrame : \"\"\"Read historical data. Args: load_hd_settings: instruction on which historic data to read. start_time: will read from this timestamp onwards. end_time: will read up to this timestamp. Returns: Dataframe containing historical data with column `timestamp` specifying the timestamp and the features generated with names `FeatureGenerator.feature` in feature_generators. \"\"\" data_dir = os . path . join ( self . histdata_dir , \"category=\" + load_hd_settings . component_info . category , \"component_id=\" + str ( load_hd_settings . component_info . component_id ), ) if start_time . tzinfo is None : start_time = start_time . replace ( tzinfo = timezone . utc ) if end_time . tzinfo is None : end_time = end_time . replace ( tzinfo = timezone . utc ) logger . info ( \"reading historic data from component id= %s within the time interval: %s to %s \" , load_hd_settings . component_info . component_id , start_time , end_time , ) dates = pd . date_range ( start_time . date (), end_time . date ()) data_files = self . gen_datafile_list ( data_dir , dates , start_time , end_time ) read_cols = list ( set ( itertools . chain ( * [ feature_generator . read_cols for feature_generator in load_hd_settings . feature_generators ] ) ) ) read_cols = list ( set ([ \"ts\" ] + read_cols )) df_list = self . load_parquet_files ( data_files , read_cols , resampling_str = str ( load_hd_settings . data_sampling_rate ) + \"S\" , ) if len ( df_list ) == 0 : return pd . DataFrame () df0 = crop_df_list_by_time ( df_list , start_time , end_time ) df_features = gen_features ( df0 , load_hd_settings . feature_generators ) . rename ( columns = { \"ts\" : \"timestamp\" } ) return df_features frequenz.sdk.data_ingestion.load_historic_data.LoadHistoricDataSettings dataclass \u00a4 Object containing instruction on which historic data to read. Source code in frequenz/sdk/data_ingestion/load_historic_data.py 114 115 116 117 118 119 120 121 122 123 @dataclass class LoadHistoricDataSettings : \"\"\"Object containing instruction on which historic data to read.\"\"\" # specify which component to read component_info : ComponentInfo # specify the list of features to generate feature_generators : List [ FeatureGenerator ] # rate at which data should be sampled in seconds data_sampling_rate : float Functions \u00a4 frequenz . sdk . data_ingestion . load_historic_data . crop_df_list_by_time ( df_list , start_time , end_time ) \u00a4 Concat and crop read data by the specified start and end time. Cropping is implemented in case the specified start and end times lie within individual data files PARAMETER DESCRIPTION df_list list of read dataframes per file TYPE: List [ pd . DataFrame ] start_time will read from this timestamp onwards TYPE: datetime end_time will read up to this timestamp TYPE: datetime RETURNS DESCRIPTION pd . DataFrame All dataframes in the list combined to one and cropped to fit within the specified start and end times. Source code in frequenz/sdk/data_ingestion/load_historic_data.py 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 def crop_df_list_by_time ( df_list : List [ pd . DataFrame ], start_time : datetime , end_time : datetime , ) -> pd . DataFrame : \"\"\"Concat and crop read data by the specified start and end time. Cropping is implemented in case the specified start and end times lie within individual data files Args: df_list: list of read dataframes per file start_time: will read from this timestamp onwards end_time: will read up to this timestamp Returns: All dataframes in the list combined to one and cropped to fit within the specified start and end times. \"\"\" df0 = pd . concat ( df_list ) . reset_index ( drop = True ) df0 [ \"ts\" ] = pd . to_datetime ( df0 [ \"ts\" ]) . tz_localize ( timezone . utc ) df0 = df0 . loc [(( df0 [ \"ts\" ] >= start_time ) & ( df0 [ \"ts\" ] <= end_time ))] . reset_index ( drop = True ) return df0 frequenz . sdk . data_ingestion . load_historic_data . gen_date_dirs ( data_dir , dates ) \u00a4 Generate the historical data directory paths for the given dates. PARAMETER DESCRIPTION data_dir directory of all the historic data of the particular component TYPE: str dates the dates over which historic data should be read TYPE: pd . DatetimeIndex RETURNS DESCRIPTION List [ str ] A list of directories of the specified dates. Source code in frequenz/sdk/data_ingestion/load_historic_data.py 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 def gen_date_dirs ( data_dir : str , dates : pd . DatetimeIndex ) -> List [ str ]: \"\"\"Generate the historical data directory paths for the given dates. Args: data_dir: directory of all the historic data of the particular component dates: the dates over which historic data should be read Returns: A list of directories of the specified dates. \"\"\" date_dirs = [ os . path . join ( data_dir , \"year=\" + str ( date . year ), \"month=\" + ( \"0\" + str ( date . month ))[ - 2 :], \"day=\" + ( \"0\" + str ( date . day ))[ - 2 :], ) for date in dates ] return date_dirs frequenz . sdk . data_ingestion . load_historic_data . gen_features ( df_read , feature_generators ) \u00a4 Generate the specified features. This is done by applying the input feature_generator.apply_func on feature_generator.read_cols PARAMETER DESCRIPTION df_read read historical data containing all the read_cols specified in its original form TYPE: pd . DataFrame feature_generators list of FeatureGenerator objects specifying the features to generate TYPE: List [ FeatureGenerator ] RETURNS DESCRIPTION pd . DataFrame A dataframe containing the generated features. Source code in frequenz/sdk/data_ingestion/load_historic_data.py 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 def gen_features ( df_read : pd . DataFrame , feature_generators : List [ FeatureGenerator ] ) -> pd . DataFrame : \"\"\"Generate the specified features. This is done by applying the input feature_generator.apply_func on feature_generator.read_cols Args: df_read: read historical data containing all the read_cols specified in its original form feature_generators: list of FeatureGenerator objects specifying the features to generate Returns: A dataframe containing the generated features. \"\"\" features : List [ Any ] = [] for feature_generator in feature_generators : if feature_generator . apply_func is None : df_read [ feature_generator . feature ] = df_read [ feature_generator . read_cols [ 0 ]] elif len ( feature_generator . read_cols ) > 1 : df_read [ feature_generator . feature ] = df_read [ feature_generator . read_cols ] . apply ( feature_generator . apply_func , axis = 1 ) else : df_read [ feature_generator . feature ] = df_read [ feature_generator . read_cols [ 0 ] ] . apply ( feature_generator . apply_func ) features . append ( feature_generator . feature ) features = list ( set ([ \"ts\" ] + features )) return df_read [ features ]","title":"load_historic_data"},{"location":"reference/frequenz/sdk/data_ingestion/load_historic_data/#frequenz.sdk.data_ingestion.load_historic_data","text":"LoadHistoricData is a tool for loading historic parquet files. This object can be called from within other IOperation s or outside of the pipeline. Please be aware that the loading of parquet files is not asynchronous, running this will block other IOperation tasks unless done in a different thread.","title":"load_historic_data"},{"location":"reference/frequenz/sdk/data_ingestion/load_historic_data/#frequenz.sdk.data_ingestion.load_historic_data-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/data_ingestion/load_historic_data/#frequenz.sdk.data_ingestion.load_historic_data.ComponentInfo","text":"Object containing component information. Source code in frequenz/sdk/data_ingestion/load_historic_data.py 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 @dataclass class ComponentInfo : \"\"\"Object containing component information.\"\"\" # component id component_id : int # category of component; \"Meter\"/\"Inverter\"/\"Battery\" category : str # type of meter; \"pv\"/\"market\"/\"grid\"/None (when component_category != \"Meter\") meter_type : Optional [ str ] = None def __post_init__ ( self ) -> None : \"\"\"Validate fields once an object has been created. Raises: ValueError: on validation failure. \"\"\" if ( self . category in [ \"Meter\" , \"Battery\" , \"Inverter\" , ] ) is False : raise ValueError ( \"category must be one of following: `Meter`, `Battery` or `Inverter`\" ) if self . category == \"Meter\" : if ( self . meter_type in [ \"pv\" , \"market\" , \"grid\" , ] ) is False : raise ValueError ( \"meter type must be one of following: `pv`, `market`, `grid`\" )","title":"ComponentInfo"},{"location":"reference/frequenz/sdk/data_ingestion/load_historic_data/#frequenz.sdk.data_ingestion.load_historic_data.ComponentInfo-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/data_ingestion/load_historic_data/#frequenz.sdk.data_ingestion.load_historic_data.ComponentInfo.__post_init__","text":"Validate fields once an object has been created. RAISES DESCRIPTION ValueError on validation failure. Source code in frequenz/sdk/data_ingestion/load_historic_data.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 def __post_init__ ( self ) -> None : \"\"\"Validate fields once an object has been created. Raises: ValueError: on validation failure. \"\"\" if ( self . category in [ \"Meter\" , \"Battery\" , \"Inverter\" , ] ) is False : raise ValueError ( \"category must be one of following: `Meter`, `Battery` or `Inverter`\" ) if self . category == \"Meter\" : if ( self . meter_type in [ \"pv\" , \"market\" , \"grid\" , ] ) is False : raise ValueError ( \"meter type must be one of following: `pv`, `market`, `grid`\" )","title":"__post_init__()"},{"location":"reference/frequenz/sdk/data_ingestion/load_historic_data/#frequenz.sdk.data_ingestion.load_historic_data.FeatureGenerator","text":"Object containing the info for generating features from historic data. Source code in frequenz/sdk/data_ingestion/load_historic_data.py 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 @dataclass class FeatureGenerator : \"\"\"Object containing the info for generating features from historic data.\"\"\" # columns to read for generating features, can be single column or multiple # columns (e.g. if user wants to generate a feature by adding two columns # together) a key within a column could also be specified, e.g. soc.now read_cols : List [ str ] # user-defined functions to apply to columns (wrapped through pandas .apply() # function) for generating features # when set to None, there should be only one column specified in read_cols # it will be returned as it is apply_func : Optional [ Callable [[ pd . DataFrame ], pd . DataFrame ]] = None # column name for the generated feature in the return dataframe # when set to None, there should be only one column specified in read_cols # it will be set to be the same as the existing column / column.key name feature : Optional [ str ] = None def __post_init__ ( self ) -> None : \"\"\"Validate fields once an object has been created. Raises: ValueError: on validation failure. \"\"\" if self . apply_func is None : if len ( self . read_cols ) != 1 : raise ValueError ( \"length of read_cols must be 1 when apply_func is None\" ) if self . feature is None : if len ( self . read_cols ) != 1 : raise ValueError ( \"length of read_cols must be 1 when feature is None\" ) self . feature = self . read_cols [ 0 ]","title":"FeatureGenerator"},{"location":"reference/frequenz/sdk/data_ingestion/load_historic_data/#frequenz.sdk.data_ingestion.load_historic_data.FeatureGenerator-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/data_ingestion/load_historic_data/#frequenz.sdk.data_ingestion.load_historic_data.FeatureGenerator.__post_init__","text":"Validate fields once an object has been created. RAISES DESCRIPTION ValueError on validation failure. Source code in frequenz/sdk/data_ingestion/load_historic_data.py 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 def __post_init__ ( self ) -> None : \"\"\"Validate fields once an object has been created. Raises: ValueError: on validation failure. \"\"\" if self . apply_func is None : if len ( self . read_cols ) != 1 : raise ValueError ( \"length of read_cols must be 1 when apply_func is None\" ) if self . feature is None : if len ( self . read_cols ) != 1 : raise ValueError ( \"length of read_cols must be 1 when feature is None\" ) self . feature = self . read_cols [ 0 ]","title":"__post_init__()"},{"location":"reference/frequenz/sdk/data_ingestion/load_historic_data/#frequenz.sdk.data_ingestion.load_historic_data.LoadHistoricData","text":"Load historical data from parquet files. Can be used from within IOperation s or separately. Not asynchronous, so will block other IOperation s and actors, unless run in a separate thread. Source code in frequenz/sdk/data_ingestion/load_historic_data.py 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 class LoadHistoricData : \"\"\"Load historical data from parquet files. Can be used from within `IOperation`s or separately. Not asynchronous, so will block other `IOperation`s and actors, unless run in a separate thread. \"\"\" def __init__ ( self , microgrid_id : int , ignore_faulty_files : bool = True , ) -> None : \"\"\"Create a `LoadHistoricalData` instance. Args: microgrid_id: mid of site ignore_faulty_files: mode for handling faulty files when True: individual faulty file will be ignored. The reader will print out an error message but continue to read other files within the specified time range. when False: once the reader encounters a faulty file, the whole reader will be stopped and an error will be raised. \"\"\" self . histdata_dir = os . path . join ( HISTDATA_DIR , \"messstellen_id=\" + str ( microgrid_id ) ) self . file_time_format = FILE_TIMEFORMAT self . file_time_prefix = FILE_TIMEPREFIX self . file_time_suffix = FILE_TIMESUFFIX + str ( microgrid_id ) + \".parquet\" self . ignore_faulty_files = ignore_faulty_files def get_file_timestamps ( self , filenames : List [ str ]) -> pd . Series : \"\"\"Get the timestamps for a list of historic parquet data files. Args: filenames: list of historic parquet data files Returns: Timestamps of each of the files. \"\"\" timestamps = pd . to_datetime ( [ file . split ( self . file_time_suffix )[ 0 ] . split ( self . file_time_prefix )[ - 1 ] for file in filenames ], format = self . file_time_format , ) . tz_localize ( timezone . utc ) return timestamps def gen_datafile_list ( self , data_dir : str , dates : pd . DatetimeIndex , start_time : datetime , end_time : datetime , ) -> List [ str ]: \"\"\"Generate the list of historic parquet files to read. Args: data_dir: directory of all the historic data of the particular component dates: the dates over which histori data should be read start_time: will read from this timestamp onwards end_time: will read up to this timestamp Returns: The list of files that will be read within the specified timerange. \"\"\" data : List [ str ] = [] date_dirs = gen_date_dirs ( data_dir , dates ) for date , date_dir in zip ( dates , date_dirs ): date_files = sorted ( glob . glob ( os . path . join ( date_dir , \"*.parquet\" , ) ) ) if ( date == dates [ 0 ]) | ( date == dates [ - 1 ]): timestamps = self . get_file_timestamps ( date_files ) date_files = [ date_files [ i ] for i in range ( len ( date_files )) if (( timestamps [ i ] >= start_time ) & ( timestamps [ i ] <= end_time )) ] data = data + date_files return data def load_parquet_file ( self , file : str , read_cols : List [ str ]) -> pd . DataFrame : \"\"\"Load one parquet file. Args: file: path of the file to read read_cols: list of columns to read Returns: Return dataframe of the read file with the specified columns Raises: RuntimeError: if file is not found or cannot be read \"\"\" try : data = pq . ParquetDataset ( file ) . read ( columns = read_cols ) df_read = data . to_pandas () except Exception as exception : # pylint: disable=broad-except logger . exception ( \"failed loading data from file: %s , due to: %s \" , file , exception ) df_read = pd . DataFrame () if self . ignore_faulty_files is False : raise RuntimeError from exception return df_read def load_parquet_files ( self , files : List [ str ], read_cols : List [ str ], resampling_str : str = \"1S\" ) -> List [ pd . DataFrame ]: \"\"\"Load multiple parquet files. Args: files: list of paths of the files to read read_cols: list of columns to read resampling_str: rule to use for resampling. Returns: List of return dataframes per file. \"\"\" df_list : List [ pd . DataFrame ] = [] for file in tqdm ( files ): df_read = self . load_parquet_file ( file , read_cols ) if len ( df_read ) > 0 : df_list . append ( df_read . set_index ( \"ts\" ) . resample ( resampling_str ) . first () . ffill () . reset_index () ) return df_list def read ( self , load_hd_settings : LoadHistoricDataSettings , start_time : datetime , end_time : datetime , ) -> pd . DataFrame : \"\"\"Read historical data. Args: load_hd_settings: instruction on which historic data to read. start_time: will read from this timestamp onwards. end_time: will read up to this timestamp. Returns: Dataframe containing historical data with column `timestamp` specifying the timestamp and the features generated with names `FeatureGenerator.feature` in feature_generators. \"\"\" data_dir = os . path . join ( self . histdata_dir , \"category=\" + load_hd_settings . component_info . category , \"component_id=\" + str ( load_hd_settings . component_info . component_id ), ) if start_time . tzinfo is None : start_time = start_time . replace ( tzinfo = timezone . utc ) if end_time . tzinfo is None : end_time = end_time . replace ( tzinfo = timezone . utc ) logger . info ( \"reading historic data from component id= %s within the time interval: %s to %s \" , load_hd_settings . component_info . component_id , start_time , end_time , ) dates = pd . date_range ( start_time . date (), end_time . date ()) data_files = self . gen_datafile_list ( data_dir , dates , start_time , end_time ) read_cols = list ( set ( itertools . chain ( * [ feature_generator . read_cols for feature_generator in load_hd_settings . feature_generators ] ) ) ) read_cols = list ( set ([ \"ts\" ] + read_cols )) df_list = self . load_parquet_files ( data_files , read_cols , resampling_str = str ( load_hd_settings . data_sampling_rate ) + \"S\" , ) if len ( df_list ) == 0 : return pd . DataFrame () df0 = crop_df_list_by_time ( df_list , start_time , end_time ) df_features = gen_features ( df0 , load_hd_settings . feature_generators ) . rename ( columns = { \"ts\" : \"timestamp\" } ) return df_features","title":"LoadHistoricData"},{"location":"reference/frequenz/sdk/data_ingestion/load_historic_data/#frequenz.sdk.data_ingestion.load_historic_data.LoadHistoricData-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/data_ingestion/load_historic_data/#frequenz.sdk.data_ingestion.load_historic_data.LoadHistoricData.__init__","text":"Create a LoadHistoricalData instance. PARAMETER DESCRIPTION microgrid_id mid of site TYPE: int ignore_faulty_files mode for handling faulty files when True: individual faulty file will be ignored. The reader will print out an error message but continue to read other files within the specified time range. when False: once the reader encounters a faulty file, the whole reader will be stopped and an error will be raised. TYPE: bool DEFAULT: True Source code in frequenz/sdk/data_ingestion/load_historic_data.py 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 def __init__ ( self , microgrid_id : int , ignore_faulty_files : bool = True , ) -> None : \"\"\"Create a `LoadHistoricalData` instance. Args: microgrid_id: mid of site ignore_faulty_files: mode for handling faulty files when True: individual faulty file will be ignored. The reader will print out an error message but continue to read other files within the specified time range. when False: once the reader encounters a faulty file, the whole reader will be stopped and an error will be raised. \"\"\" self . histdata_dir = os . path . join ( HISTDATA_DIR , \"messstellen_id=\" + str ( microgrid_id ) ) self . file_time_format = FILE_TIMEFORMAT self . file_time_prefix = FILE_TIMEPREFIX self . file_time_suffix = FILE_TIMESUFFIX + str ( microgrid_id ) + \".parquet\" self . ignore_faulty_files = ignore_faulty_files","title":"__init__()"},{"location":"reference/frequenz/sdk/data_ingestion/load_historic_data/#frequenz.sdk.data_ingestion.load_historic_data.LoadHistoricData.gen_datafile_list","text":"Generate the list of historic parquet files to read. PARAMETER DESCRIPTION data_dir directory of all the historic data of the particular component TYPE: str dates the dates over which histori data should be read TYPE: pd . DatetimeIndex start_time will read from this timestamp onwards TYPE: datetime end_time will read up to this timestamp TYPE: datetime RETURNS DESCRIPTION List [ str ] The list of files that will be read within the specified timerange. Source code in frequenz/sdk/data_ingestion/load_historic_data.py 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 def gen_datafile_list ( self , data_dir : str , dates : pd . DatetimeIndex , start_time : datetime , end_time : datetime , ) -> List [ str ]: \"\"\"Generate the list of historic parquet files to read. Args: data_dir: directory of all the historic data of the particular component dates: the dates over which histori data should be read start_time: will read from this timestamp onwards end_time: will read up to this timestamp Returns: The list of files that will be read within the specified timerange. \"\"\" data : List [ str ] = [] date_dirs = gen_date_dirs ( data_dir , dates ) for date , date_dir in zip ( dates , date_dirs ): date_files = sorted ( glob . glob ( os . path . join ( date_dir , \"*.parquet\" , ) ) ) if ( date == dates [ 0 ]) | ( date == dates [ - 1 ]): timestamps = self . get_file_timestamps ( date_files ) date_files = [ date_files [ i ] for i in range ( len ( date_files )) if (( timestamps [ i ] >= start_time ) & ( timestamps [ i ] <= end_time )) ] data = data + date_files return data","title":"gen_datafile_list()"},{"location":"reference/frequenz/sdk/data_ingestion/load_historic_data/#frequenz.sdk.data_ingestion.load_historic_data.LoadHistoricData.get_file_timestamps","text":"Get the timestamps for a list of historic parquet data files. PARAMETER DESCRIPTION filenames list of historic parquet data files TYPE: List [ str ] RETURNS DESCRIPTION pd . Series Timestamps of each of the files. Source code in frequenz/sdk/data_ingestion/load_historic_data.py 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 def get_file_timestamps ( self , filenames : List [ str ]) -> pd . Series : \"\"\"Get the timestamps for a list of historic parquet data files. Args: filenames: list of historic parquet data files Returns: Timestamps of each of the files. \"\"\" timestamps = pd . to_datetime ( [ file . split ( self . file_time_suffix )[ 0 ] . split ( self . file_time_prefix )[ - 1 ] for file in filenames ], format = self . file_time_format , ) . tz_localize ( timezone . utc ) return timestamps","title":"get_file_timestamps()"},{"location":"reference/frequenz/sdk/data_ingestion/load_historic_data/#frequenz.sdk.data_ingestion.load_historic_data.LoadHistoricData.load_parquet_file","text":"Load one parquet file. PARAMETER DESCRIPTION file path of the file to read TYPE: str read_cols list of columns to read TYPE: List [ str ] RETURNS DESCRIPTION pd . DataFrame Return dataframe of the read file with the specified columns RAISES DESCRIPTION RuntimeError if file is not found or cannot be read Source code in frequenz/sdk/data_ingestion/load_historic_data.py 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 def load_parquet_file ( self , file : str , read_cols : List [ str ]) -> pd . DataFrame : \"\"\"Load one parquet file. Args: file: path of the file to read read_cols: list of columns to read Returns: Return dataframe of the read file with the specified columns Raises: RuntimeError: if file is not found or cannot be read \"\"\" try : data = pq . ParquetDataset ( file ) . read ( columns = read_cols ) df_read = data . to_pandas () except Exception as exception : # pylint: disable=broad-except logger . exception ( \"failed loading data from file: %s , due to: %s \" , file , exception ) df_read = pd . DataFrame () if self . ignore_faulty_files is False : raise RuntimeError from exception return df_read","title":"load_parquet_file()"},{"location":"reference/frequenz/sdk/data_ingestion/load_historic_data/#frequenz.sdk.data_ingestion.load_historic_data.LoadHistoricData.load_parquet_files","text":"Load multiple parquet files. PARAMETER DESCRIPTION files list of paths of the files to read TYPE: List [ str ] read_cols list of columns to read TYPE: List [ str ] resampling_str rule to use for resampling. TYPE: str DEFAULT: '1S' RETURNS DESCRIPTION List [ pd . DataFrame ] List of return dataframes per file. Source code in frequenz/sdk/data_ingestion/load_historic_data.py 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 def load_parquet_files ( self , files : List [ str ], read_cols : List [ str ], resampling_str : str = \"1S\" ) -> List [ pd . DataFrame ]: \"\"\"Load multiple parquet files. Args: files: list of paths of the files to read read_cols: list of columns to read resampling_str: rule to use for resampling. Returns: List of return dataframes per file. \"\"\" df_list : List [ pd . DataFrame ] = [] for file in tqdm ( files ): df_read = self . load_parquet_file ( file , read_cols ) if len ( df_read ) > 0 : df_list . append ( df_read . set_index ( \"ts\" ) . resample ( resampling_str ) . first () . ffill () . reset_index () ) return df_list","title":"load_parquet_files()"},{"location":"reference/frequenz/sdk/data_ingestion/load_historic_data/#frequenz.sdk.data_ingestion.load_historic_data.LoadHistoricData.read","text":"Read historical data. PARAMETER DESCRIPTION load_hd_settings instruction on which historic data to read. TYPE: LoadHistoricDataSettings start_time will read from this timestamp onwards. TYPE: datetime end_time will read up to this timestamp. TYPE: datetime RETURNS DESCRIPTION pd . DataFrame Dataframe containing historical data with column timestamp specifying the timestamp and the features generated with names FeatureGenerator.feature in feature_generators. Source code in frequenz/sdk/data_ingestion/load_historic_data.py 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 def read ( self , load_hd_settings : LoadHistoricDataSettings , start_time : datetime , end_time : datetime , ) -> pd . DataFrame : \"\"\"Read historical data. Args: load_hd_settings: instruction on which historic data to read. start_time: will read from this timestamp onwards. end_time: will read up to this timestamp. Returns: Dataframe containing historical data with column `timestamp` specifying the timestamp and the features generated with names `FeatureGenerator.feature` in feature_generators. \"\"\" data_dir = os . path . join ( self . histdata_dir , \"category=\" + load_hd_settings . component_info . category , \"component_id=\" + str ( load_hd_settings . component_info . component_id ), ) if start_time . tzinfo is None : start_time = start_time . replace ( tzinfo = timezone . utc ) if end_time . tzinfo is None : end_time = end_time . replace ( tzinfo = timezone . utc ) logger . info ( \"reading historic data from component id= %s within the time interval: %s to %s \" , load_hd_settings . component_info . component_id , start_time , end_time , ) dates = pd . date_range ( start_time . date (), end_time . date ()) data_files = self . gen_datafile_list ( data_dir , dates , start_time , end_time ) read_cols = list ( set ( itertools . chain ( * [ feature_generator . read_cols for feature_generator in load_hd_settings . feature_generators ] ) ) ) read_cols = list ( set ([ \"ts\" ] + read_cols )) df_list = self . load_parquet_files ( data_files , read_cols , resampling_str = str ( load_hd_settings . data_sampling_rate ) + \"S\" , ) if len ( df_list ) == 0 : return pd . DataFrame () df0 = crop_df_list_by_time ( df_list , start_time , end_time ) df_features = gen_features ( df0 , load_hd_settings . feature_generators ) . rename ( columns = { \"ts\" : \"timestamp\" } ) return df_features","title":"read()"},{"location":"reference/frequenz/sdk/data_ingestion/load_historic_data/#frequenz.sdk.data_ingestion.load_historic_data.LoadHistoricDataSettings","text":"Object containing instruction on which historic data to read. Source code in frequenz/sdk/data_ingestion/load_historic_data.py 114 115 116 117 118 119 120 121 122 123 @dataclass class LoadHistoricDataSettings : \"\"\"Object containing instruction on which historic data to read.\"\"\" # specify which component to read component_info : ComponentInfo # specify the list of features to generate feature_generators : List [ FeatureGenerator ] # rate at which data should be sampled in seconds data_sampling_rate : float","title":"LoadHistoricDataSettings"},{"location":"reference/frequenz/sdk/data_ingestion/load_historic_data/#frequenz.sdk.data_ingestion.load_historic_data-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/data_ingestion/load_historic_data/#frequenz.sdk.data_ingestion.load_historic_data.crop_df_list_by_time","text":"Concat and crop read data by the specified start and end time. Cropping is implemented in case the specified start and end times lie within individual data files PARAMETER DESCRIPTION df_list list of read dataframes per file TYPE: List [ pd . DataFrame ] start_time will read from this timestamp onwards TYPE: datetime end_time will read up to this timestamp TYPE: datetime RETURNS DESCRIPTION pd . DataFrame All dataframes in the list combined to one and cropped to fit within the specified start and end times. Source code in frequenz/sdk/data_ingestion/load_historic_data.py 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 def crop_df_list_by_time ( df_list : List [ pd . DataFrame ], start_time : datetime , end_time : datetime , ) -> pd . DataFrame : \"\"\"Concat and crop read data by the specified start and end time. Cropping is implemented in case the specified start and end times lie within individual data files Args: df_list: list of read dataframes per file start_time: will read from this timestamp onwards end_time: will read up to this timestamp Returns: All dataframes in the list combined to one and cropped to fit within the specified start and end times. \"\"\" df0 = pd . concat ( df_list ) . reset_index ( drop = True ) df0 [ \"ts\" ] = pd . to_datetime ( df0 [ \"ts\" ]) . tz_localize ( timezone . utc ) df0 = df0 . loc [(( df0 [ \"ts\" ] >= start_time ) & ( df0 [ \"ts\" ] <= end_time ))] . reset_index ( drop = True ) return df0","title":"crop_df_list_by_time()"},{"location":"reference/frequenz/sdk/data_ingestion/load_historic_data/#frequenz.sdk.data_ingestion.load_historic_data.gen_date_dirs","text":"Generate the historical data directory paths for the given dates. PARAMETER DESCRIPTION data_dir directory of all the historic data of the particular component TYPE: str dates the dates over which historic data should be read TYPE: pd . DatetimeIndex RETURNS DESCRIPTION List [ str ] A list of directories of the specified dates. Source code in frequenz/sdk/data_ingestion/load_historic_data.py 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 def gen_date_dirs ( data_dir : str , dates : pd . DatetimeIndex ) -> List [ str ]: \"\"\"Generate the historical data directory paths for the given dates. Args: data_dir: directory of all the historic data of the particular component dates: the dates over which historic data should be read Returns: A list of directories of the specified dates. \"\"\" date_dirs = [ os . path . join ( data_dir , \"year=\" + str ( date . year ), \"month=\" + ( \"0\" + str ( date . month ))[ - 2 :], \"day=\" + ( \"0\" + str ( date . day ))[ - 2 :], ) for date in dates ] return date_dirs","title":"gen_date_dirs()"},{"location":"reference/frequenz/sdk/data_ingestion/load_historic_data/#frequenz.sdk.data_ingestion.load_historic_data.gen_features","text":"Generate the specified features. This is done by applying the input feature_generator.apply_func on feature_generator.read_cols PARAMETER DESCRIPTION df_read read historical data containing all the read_cols specified in its original form TYPE: pd . DataFrame feature_generators list of FeatureGenerator objects specifying the features to generate TYPE: List [ FeatureGenerator ] RETURNS DESCRIPTION pd . DataFrame A dataframe containing the generated features. Source code in frequenz/sdk/data_ingestion/load_historic_data.py 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 def gen_features ( df_read : pd . DataFrame , feature_generators : List [ FeatureGenerator ] ) -> pd . DataFrame : \"\"\"Generate the specified features. This is done by applying the input feature_generator.apply_func on feature_generator.read_cols Args: df_read: read historical data containing all the read_cols specified in its original form feature_generators: list of FeatureGenerator objects specifying the features to generate Returns: A dataframe containing the generated features. \"\"\" features : List [ Any ] = [] for feature_generator in feature_generators : if feature_generator . apply_func is None : df_read [ feature_generator . feature ] = df_read [ feature_generator . read_cols [ 0 ]] elif len ( feature_generator . read_cols ) > 1 : df_read [ feature_generator . feature ] = df_read [ feature_generator . read_cols ] . apply ( feature_generator . apply_func , axis = 1 ) else : df_read [ feature_generator . feature ] = df_read [ feature_generator . read_cols [ 0 ] ] . apply ( feature_generator . apply_func ) features . append ( feature_generator . feature ) features = list ( set ([ \"ts\" ] + features )) return df_read [ features ]","title":"gen_features()"},{"location":"reference/frequenz/sdk/data_ingestion/microgrid_data/","text":"frequenz.sdk.data_ingestion.microgrid_data \u00a4 Actor for combining stream data from different components using TimeSeriesFormula. Including default standard formulas for client load, grid load, total pv production, ev charging rate, battery SoC, active power, max consume and supply rate. Classes \u00a4 frequenz.sdk.data_ingestion.microgrid_data.MicrogridData \u00a4 Actor for receiving component data, calculating formulas and sending results. Source code in frequenz/sdk/data_ingestion/microgrid_data.py 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 @actor class MicrogridData : # pylint: disable=too-many-instance-attributes \"\"\"Actor for receiving component data, calculating formulas and sending results.\"\"\" # current number of arguments already minimum for purpose of MicrogridData # (client, component graph, output channels, additional formula and symbols) def __init__ ( # pylint: disable=too-many-arguments self , microgrid_client : MicrogridApiClient , component_graph : ComponentGraph , outputs : Dict [ str , Sender [ TimeSeriesEntry [ Any ]]], formula_calculator : FormulaCalculator , config_update_receiver : Optional [ Receiver [ Config ]] = None , wait_for_data_sec : float = 2 , formula_update_interval_sec : float = 0.5 , ) -> None : \"\"\"Initialise MicrogridData actor. Args: microgrid_client: microgrid client component_graph: component graph of microgrid outputs: senders for output to channel formula_calculator: an instance of FormulaCalculator responsible for managing symbols and evaluating formulas config_update_receiver: receiver for receiving config file updates wait_for_data_sec: how long actor should wait before processing first request. It is a time needed to collect first components data. formula_update_interval_sec: how frequently send formula results. With this frequency all results from formulas will be send. Raises: ValueError: if a sender corresponding to any of the microgrid_formulas is not provided \"\"\" component_infos , battery_inverter_mappings = infer_microgrid_config ( component_graph ) self . component_graph = component_graph self . component_infos = component_infos self . battery_inverter_mappings = battery_inverter_mappings self . microgrid_client = microgrid_client self . _outputs = outputs # Fallback to an empty receiver so that `Select` doesn't raise `KeyError`s if config_update_receiver is not None : self . _config_update_receiver = config_update_receiver else : self . _config_update_receiver = Broadcast [ Config ]( \"microgrid_data_config_update_channel\" ) . new_receiver () self . _formula_update_interval_sec : float = formula_update_interval_sec self . _wait_for_data_sec = wait_for_data_sec self . formula_calculator = formula_calculator self . microgrid_formula_overrides : Dict [ str , Set [ int ]] = {} for output_channel_name in outputs . keys (): if output_channel_name not in self . formula_calculator . microgrid_formulas : raise ValueError ( f \"No formula defined for output channel { output_channel_name } .\" ) async def resend_formulas ( self ) -> None : \"\"\"Send formulas results with some period.\"\"\" # Sleep first to collect initial data from all component await asyncio . sleep ( self . _wait_for_data_sec ) tasks : List [ asyncio . Task [ bool ]] = [] while True : start_time = datetime . now ( timezone . utc ) # For every formula that was updated at least once, send that formula. for name , formula_result in self . formula_calculator . results . items (): if name not in self . _outputs : # If formula was computed but there is not output channel in # MicrogridData then it is bug in MicrogridData. logger . error ( \"MicrogridData: No channel for formula %s .\" , name , ) else : task = asyncio . create_task ( self . _outputs [ name ] . send ( formula_result )) tasks . append ( task ) await asyncio . gather ( * tasks , return_exceptions = True ) diff : float = ( datetime . now ( timezone . utc ) - start_time ) . total_seconds () if diff >= self . _formula_update_interval_sec : logger . error ( \"Sending results of formulas took too long: %f , \" \"expected sending interval: %f \" , diff , self . _formula_update_interval_sec , ) else : await asyncio . sleep ( self . _formula_update_interval_sec - diff ) def parse_formula_overrides ( self , config : Config ) -> Dict [ str , Set [ int ]]: \"\"\"Parse formula overrides from the config file. The following format of the config file is expected: ... formula_grid_load = \"[1,3,4]\" formula_batteries_remaining_power = \"[75,123,1]\" ... \"formula_\" is a configurable prefix defined in `CONFIG_FILE_FORMULA_PREFIX`. Args: config: contents of the recently updated config file. Returns: mapping of formula names to list of battery ids to be taken into account when evaluating the formula Raises: ValueError: if value provided refers to a formula that wasn't defined in formula calculator AttributeError: if value provided for a formula name doesn't have `split` method TypeError: if battery ids to be taken into account for a formula are not integers \"\"\" formula_overrides : Dict [ str , Set [ int ]] = {} try : formula_config = config . get_dict ( CONFIG_FILE_FORMULA_PREFIX , expected_values_type = Set [ int ] ) except ValueError as err : logger . error ( \"Formula overrides (config variables starting with %s \" \" are expected to be str -> Set[int] mappings: %s \" , CONFIG_FILE_FORMULA_PREFIX , err , ) raise for formula_name , battery_ids in formula_config . items (): if formula_name not in self . formula_calculator . microgrid_formulas : logger . error ( \"Formula %s cannot be updated, because it does not exist.\" , formula_name , ) continue formula_overrides [ formula_name ] = battery_ids return formula_overrides # pylint: disable=unused-argument async def _reinitialize ( self , config : Config , resend_formulas_task : asyncio . Task [ None ] ) -> None : \"\"\"Reinitialize MicrogridData with updated config. To be implemented once the config file scheme for updating formulas is known. This function will: - reinitialize formula calculator based on the new config - change and apply settings like `formula_update_interval_sec` or `wait_for_data_sec` Args: config: contents of the recently updated config file. resend_formulas_task: task for sending formula results Raises: Exception: when an error occurred either while parsing the new config or when creating a new instance of FormulaCalculator \"\"\" try : new_overrides = self . parse_formula_overrides ( config ) except Exception as err : # pylint: disable=broad-except # This is an error, because it shouldn't happen, but in general we don't need # to log a stack trace too because it should be just bad user input logger . error ( \"An error occurred while applying the new configuration: %s \" , err ) raise try : new_formula_calculator = FormulaCalculator ( self . component_graph , battery_ids_overrides = new_overrides , ) except Exception : # pylint: disable=broad-except # If this fails, there is a bug for sure, so we print the stack track. logger . exception ( \"An error occurred while creating the new formula calculator\" ) raise resend_formulas_task . cancel () self . microgrid_formula_overrides = new_overrides self . formula_calculator = new_formula_calculator async def run ( self ) -> None : \"\"\"Run the actor.\"\"\" while True : receivers = await gen_component_receivers ( self . component_infos , self . microgrid_client ) # Create a task that will periodically send formula results. resend_formulas_task = asyncio . create_task ( self . resend_formulas ()) select = Select ( component_data_receiver = Merge ( * receivers . values ()), config_update_receiver = self . _config_update_receiver , ) while await select . ready (): if msg := select . component_data_receiver : # Update symbols and recalculate formulas. updated_symbols = self . formula_calculator . update_symbol_values ( msg . inner ) self . formula_calculator . compute ( updated_symbols , only_formula_names = set ( self . _outputs . keys ()) ) elif msg := select . config_update_receiver : try : await self . _reinitialize ( msg . inner , resend_formulas_task ) except Exception as err : # pylint: disable=broad-except logger . error ( \"Reinitialization failed, because an error occurred \" \"while applying the new configuration: %s \" , err , ) else : # Break from the inner loop to regenerate component receivers break Functions \u00a4 __init__ ( microgrid_client , component_graph , outputs , formula_calculator , config_update_receiver = None , wait_for_data_sec = 2 , formula_update_interval_sec = 0.5 ) \u00a4 Initialise MicrogridData actor. PARAMETER DESCRIPTION microgrid_client microgrid client TYPE: MicrogridApiClient component_graph component graph of microgrid TYPE: ComponentGraph outputs senders for output to channel TYPE: Dict [ str , Sender [ TimeSeriesEntry [ Any ]]] formula_calculator an instance of FormulaCalculator responsible for managing symbols and evaluating formulas TYPE: FormulaCalculator config_update_receiver receiver for receiving config file updates TYPE: Optional [ Receiver [ Config ]] DEFAULT: None wait_for_data_sec how long actor should wait before processing first request. It is a time needed to collect first components data. TYPE: float DEFAULT: 2 formula_update_interval_sec how frequently send formula results. With this frequency all results from formulas will be send. TYPE: float DEFAULT: 0.5 RAISES DESCRIPTION ValueError if a sender corresponding to any of the microgrid_formulas is not provided Source code in frequenz/sdk/data_ingestion/microgrid_data.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 def __init__ ( # pylint: disable=too-many-arguments self , microgrid_client : MicrogridApiClient , component_graph : ComponentGraph , outputs : Dict [ str , Sender [ TimeSeriesEntry [ Any ]]], formula_calculator : FormulaCalculator , config_update_receiver : Optional [ Receiver [ Config ]] = None , wait_for_data_sec : float = 2 , formula_update_interval_sec : float = 0.5 , ) -> None : \"\"\"Initialise MicrogridData actor. Args: microgrid_client: microgrid client component_graph: component graph of microgrid outputs: senders for output to channel formula_calculator: an instance of FormulaCalculator responsible for managing symbols and evaluating formulas config_update_receiver: receiver for receiving config file updates wait_for_data_sec: how long actor should wait before processing first request. It is a time needed to collect first components data. formula_update_interval_sec: how frequently send formula results. With this frequency all results from formulas will be send. Raises: ValueError: if a sender corresponding to any of the microgrid_formulas is not provided \"\"\" component_infos , battery_inverter_mappings = infer_microgrid_config ( component_graph ) self . component_graph = component_graph self . component_infos = component_infos self . battery_inverter_mappings = battery_inverter_mappings self . microgrid_client = microgrid_client self . _outputs = outputs # Fallback to an empty receiver so that `Select` doesn't raise `KeyError`s if config_update_receiver is not None : self . _config_update_receiver = config_update_receiver else : self . _config_update_receiver = Broadcast [ Config ]( \"microgrid_data_config_update_channel\" ) . new_receiver () self . _formula_update_interval_sec : float = formula_update_interval_sec self . _wait_for_data_sec = wait_for_data_sec self . formula_calculator = formula_calculator self . microgrid_formula_overrides : Dict [ str , Set [ int ]] = {} for output_channel_name in outputs . keys (): if output_channel_name not in self . formula_calculator . microgrid_formulas : raise ValueError ( f \"No formula defined for output channel { output_channel_name } .\" ) parse_formula_overrides ( config ) \u00a4 Parse formula overrides from the config file. The following format of the config file is expected: ... formula_grid_load = \"[1,3,4]\" formula_batteries_remaining_power = \"[75,123,1]\" ... \"formula_\" is a configurable prefix defined in CONFIG_FILE_FORMULA_PREFIX . PARAMETER DESCRIPTION config contents of the recently updated config file. TYPE: Config RETURNS DESCRIPTION Dict [ str , Set [ int ]] mapping of formula names to list of battery ids to be taken into account when evaluating the formula RAISES DESCRIPTION ValueError if value provided refers to a formula that wasn't defined in formula calculator AttributeError if value provided for a formula name doesn't have split method TypeError if battery ids to be taken into account for a formula are not integers Source code in frequenz/sdk/data_ingestion/microgrid_data.py 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 def parse_formula_overrides ( self , config : Config ) -> Dict [ str , Set [ int ]]: \"\"\"Parse formula overrides from the config file. The following format of the config file is expected: ... formula_grid_load = \"[1,3,4]\" formula_batteries_remaining_power = \"[75,123,1]\" ... \"formula_\" is a configurable prefix defined in `CONFIG_FILE_FORMULA_PREFIX`. Args: config: contents of the recently updated config file. Returns: mapping of formula names to list of battery ids to be taken into account when evaluating the formula Raises: ValueError: if value provided refers to a formula that wasn't defined in formula calculator AttributeError: if value provided for a formula name doesn't have `split` method TypeError: if battery ids to be taken into account for a formula are not integers \"\"\" formula_overrides : Dict [ str , Set [ int ]] = {} try : formula_config = config . get_dict ( CONFIG_FILE_FORMULA_PREFIX , expected_values_type = Set [ int ] ) except ValueError as err : logger . error ( \"Formula overrides (config variables starting with %s \" \" are expected to be str -> Set[int] mappings: %s \" , CONFIG_FILE_FORMULA_PREFIX , err , ) raise for formula_name , battery_ids in formula_config . items (): if formula_name not in self . formula_calculator . microgrid_formulas : logger . error ( \"Formula %s cannot be updated, because it does not exist.\" , formula_name , ) continue formula_overrides [ formula_name ] = battery_ids return formula_overrides resend_formulas () async \u00a4 Send formulas results with some period. Source code in frequenz/sdk/data_ingestion/microgrid_data.py 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 async def resend_formulas ( self ) -> None : \"\"\"Send formulas results with some period.\"\"\" # Sleep first to collect initial data from all component await asyncio . sleep ( self . _wait_for_data_sec ) tasks : List [ asyncio . Task [ bool ]] = [] while True : start_time = datetime . now ( timezone . utc ) # For every formula that was updated at least once, send that formula. for name , formula_result in self . formula_calculator . results . items (): if name not in self . _outputs : # If formula was computed but there is not output channel in # MicrogridData then it is bug in MicrogridData. logger . error ( \"MicrogridData: No channel for formula %s .\" , name , ) else : task = asyncio . create_task ( self . _outputs [ name ] . send ( formula_result )) tasks . append ( task ) await asyncio . gather ( * tasks , return_exceptions = True ) diff : float = ( datetime . now ( timezone . utc ) - start_time ) . total_seconds () if diff >= self . _formula_update_interval_sec : logger . error ( \"Sending results of formulas took too long: %f , \" \"expected sending interval: %f \" , diff , self . _formula_update_interval_sec , ) else : await asyncio . sleep ( self . _formula_update_interval_sec - diff ) run () async \u00a4 Run the actor. Source code in frequenz/sdk/data_ingestion/microgrid_data.py 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 async def run ( self ) -> None : \"\"\"Run the actor.\"\"\" while True : receivers = await gen_component_receivers ( self . component_infos , self . microgrid_client ) # Create a task that will periodically send formula results. resend_formulas_task = asyncio . create_task ( self . resend_formulas ()) select = Select ( component_data_receiver = Merge ( * receivers . values ()), config_update_receiver = self . _config_update_receiver , ) while await select . ready (): if msg := select . component_data_receiver : # Update symbols and recalculate formulas. updated_symbols = self . formula_calculator . update_symbol_values ( msg . inner ) self . formula_calculator . compute ( updated_symbols , only_formula_names = set ( self . _outputs . keys ()) ) elif msg := select . config_update_receiver : try : await self . _reinitialize ( msg . inner , resend_formulas_task ) except Exception as err : # pylint: disable=broad-except logger . error ( \"Reinitialization failed, because an error occurred \" \"while applying the new configuration: %s \" , err , ) else : # Break from the inner loop to regenerate component receivers break Functions \u00a4","title":"microgrid_data"},{"location":"reference/frequenz/sdk/data_ingestion/microgrid_data/#frequenz.sdk.data_ingestion.microgrid_data","text":"Actor for combining stream data from different components using TimeSeriesFormula. Including default standard formulas for client load, grid load, total pv production, ev charging rate, battery SoC, active power, max consume and supply rate.","title":"microgrid_data"},{"location":"reference/frequenz/sdk/data_ingestion/microgrid_data/#frequenz.sdk.data_ingestion.microgrid_data-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/data_ingestion/microgrid_data/#frequenz.sdk.data_ingestion.microgrid_data.MicrogridData","text":"Actor for receiving component data, calculating formulas and sending results. Source code in frequenz/sdk/data_ingestion/microgrid_data.py 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 @actor class MicrogridData : # pylint: disable=too-many-instance-attributes \"\"\"Actor for receiving component data, calculating formulas and sending results.\"\"\" # current number of arguments already minimum for purpose of MicrogridData # (client, component graph, output channels, additional formula and symbols) def __init__ ( # pylint: disable=too-many-arguments self , microgrid_client : MicrogridApiClient , component_graph : ComponentGraph , outputs : Dict [ str , Sender [ TimeSeriesEntry [ Any ]]], formula_calculator : FormulaCalculator , config_update_receiver : Optional [ Receiver [ Config ]] = None , wait_for_data_sec : float = 2 , formula_update_interval_sec : float = 0.5 , ) -> None : \"\"\"Initialise MicrogridData actor. Args: microgrid_client: microgrid client component_graph: component graph of microgrid outputs: senders for output to channel formula_calculator: an instance of FormulaCalculator responsible for managing symbols and evaluating formulas config_update_receiver: receiver for receiving config file updates wait_for_data_sec: how long actor should wait before processing first request. It is a time needed to collect first components data. formula_update_interval_sec: how frequently send formula results. With this frequency all results from formulas will be send. Raises: ValueError: if a sender corresponding to any of the microgrid_formulas is not provided \"\"\" component_infos , battery_inverter_mappings = infer_microgrid_config ( component_graph ) self . component_graph = component_graph self . component_infos = component_infos self . battery_inverter_mappings = battery_inverter_mappings self . microgrid_client = microgrid_client self . _outputs = outputs # Fallback to an empty receiver so that `Select` doesn't raise `KeyError`s if config_update_receiver is not None : self . _config_update_receiver = config_update_receiver else : self . _config_update_receiver = Broadcast [ Config ]( \"microgrid_data_config_update_channel\" ) . new_receiver () self . _formula_update_interval_sec : float = formula_update_interval_sec self . _wait_for_data_sec = wait_for_data_sec self . formula_calculator = formula_calculator self . microgrid_formula_overrides : Dict [ str , Set [ int ]] = {} for output_channel_name in outputs . keys (): if output_channel_name not in self . formula_calculator . microgrid_formulas : raise ValueError ( f \"No formula defined for output channel { output_channel_name } .\" ) async def resend_formulas ( self ) -> None : \"\"\"Send formulas results with some period.\"\"\" # Sleep first to collect initial data from all component await asyncio . sleep ( self . _wait_for_data_sec ) tasks : List [ asyncio . Task [ bool ]] = [] while True : start_time = datetime . now ( timezone . utc ) # For every formula that was updated at least once, send that formula. for name , formula_result in self . formula_calculator . results . items (): if name not in self . _outputs : # If formula was computed but there is not output channel in # MicrogridData then it is bug in MicrogridData. logger . error ( \"MicrogridData: No channel for formula %s .\" , name , ) else : task = asyncio . create_task ( self . _outputs [ name ] . send ( formula_result )) tasks . append ( task ) await asyncio . gather ( * tasks , return_exceptions = True ) diff : float = ( datetime . now ( timezone . utc ) - start_time ) . total_seconds () if diff >= self . _formula_update_interval_sec : logger . error ( \"Sending results of formulas took too long: %f , \" \"expected sending interval: %f \" , diff , self . _formula_update_interval_sec , ) else : await asyncio . sleep ( self . _formula_update_interval_sec - diff ) def parse_formula_overrides ( self , config : Config ) -> Dict [ str , Set [ int ]]: \"\"\"Parse formula overrides from the config file. The following format of the config file is expected: ... formula_grid_load = \"[1,3,4]\" formula_batteries_remaining_power = \"[75,123,1]\" ... \"formula_\" is a configurable prefix defined in `CONFIG_FILE_FORMULA_PREFIX`. Args: config: contents of the recently updated config file. Returns: mapping of formula names to list of battery ids to be taken into account when evaluating the formula Raises: ValueError: if value provided refers to a formula that wasn't defined in formula calculator AttributeError: if value provided for a formula name doesn't have `split` method TypeError: if battery ids to be taken into account for a formula are not integers \"\"\" formula_overrides : Dict [ str , Set [ int ]] = {} try : formula_config = config . get_dict ( CONFIG_FILE_FORMULA_PREFIX , expected_values_type = Set [ int ] ) except ValueError as err : logger . error ( \"Formula overrides (config variables starting with %s \" \" are expected to be str -> Set[int] mappings: %s \" , CONFIG_FILE_FORMULA_PREFIX , err , ) raise for formula_name , battery_ids in formula_config . items (): if formula_name not in self . formula_calculator . microgrid_formulas : logger . error ( \"Formula %s cannot be updated, because it does not exist.\" , formula_name , ) continue formula_overrides [ formula_name ] = battery_ids return formula_overrides # pylint: disable=unused-argument async def _reinitialize ( self , config : Config , resend_formulas_task : asyncio . Task [ None ] ) -> None : \"\"\"Reinitialize MicrogridData with updated config. To be implemented once the config file scheme for updating formulas is known. This function will: - reinitialize formula calculator based on the new config - change and apply settings like `formula_update_interval_sec` or `wait_for_data_sec` Args: config: contents of the recently updated config file. resend_formulas_task: task for sending formula results Raises: Exception: when an error occurred either while parsing the new config or when creating a new instance of FormulaCalculator \"\"\" try : new_overrides = self . parse_formula_overrides ( config ) except Exception as err : # pylint: disable=broad-except # This is an error, because it shouldn't happen, but in general we don't need # to log a stack trace too because it should be just bad user input logger . error ( \"An error occurred while applying the new configuration: %s \" , err ) raise try : new_formula_calculator = FormulaCalculator ( self . component_graph , battery_ids_overrides = new_overrides , ) except Exception : # pylint: disable=broad-except # If this fails, there is a bug for sure, so we print the stack track. logger . exception ( \"An error occurred while creating the new formula calculator\" ) raise resend_formulas_task . cancel () self . microgrid_formula_overrides = new_overrides self . formula_calculator = new_formula_calculator async def run ( self ) -> None : \"\"\"Run the actor.\"\"\" while True : receivers = await gen_component_receivers ( self . component_infos , self . microgrid_client ) # Create a task that will periodically send formula results. resend_formulas_task = asyncio . create_task ( self . resend_formulas ()) select = Select ( component_data_receiver = Merge ( * receivers . values ()), config_update_receiver = self . _config_update_receiver , ) while await select . ready (): if msg := select . component_data_receiver : # Update symbols and recalculate formulas. updated_symbols = self . formula_calculator . update_symbol_values ( msg . inner ) self . formula_calculator . compute ( updated_symbols , only_formula_names = set ( self . _outputs . keys ()) ) elif msg := select . config_update_receiver : try : await self . _reinitialize ( msg . inner , resend_formulas_task ) except Exception as err : # pylint: disable=broad-except logger . error ( \"Reinitialization failed, because an error occurred \" \"while applying the new configuration: %s \" , err , ) else : # Break from the inner loop to regenerate component receivers break","title":"MicrogridData"},{"location":"reference/frequenz/sdk/data_ingestion/microgrid_data/#frequenz.sdk.data_ingestion.microgrid_data.MicrogridData-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/data_ingestion/microgrid_data/#frequenz.sdk.data_ingestion.microgrid_data.MicrogridData.__init__","text":"Initialise MicrogridData actor. PARAMETER DESCRIPTION microgrid_client microgrid client TYPE: MicrogridApiClient component_graph component graph of microgrid TYPE: ComponentGraph outputs senders for output to channel TYPE: Dict [ str , Sender [ TimeSeriesEntry [ Any ]]] formula_calculator an instance of FormulaCalculator responsible for managing symbols and evaluating formulas TYPE: FormulaCalculator config_update_receiver receiver for receiving config file updates TYPE: Optional [ Receiver [ Config ]] DEFAULT: None wait_for_data_sec how long actor should wait before processing first request. It is a time needed to collect first components data. TYPE: float DEFAULT: 2 formula_update_interval_sec how frequently send formula results. With this frequency all results from formulas will be send. TYPE: float DEFAULT: 0.5 RAISES DESCRIPTION ValueError if a sender corresponding to any of the microgrid_formulas is not provided Source code in frequenz/sdk/data_ingestion/microgrid_data.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 def __init__ ( # pylint: disable=too-many-arguments self , microgrid_client : MicrogridApiClient , component_graph : ComponentGraph , outputs : Dict [ str , Sender [ TimeSeriesEntry [ Any ]]], formula_calculator : FormulaCalculator , config_update_receiver : Optional [ Receiver [ Config ]] = None , wait_for_data_sec : float = 2 , formula_update_interval_sec : float = 0.5 , ) -> None : \"\"\"Initialise MicrogridData actor. Args: microgrid_client: microgrid client component_graph: component graph of microgrid outputs: senders for output to channel formula_calculator: an instance of FormulaCalculator responsible for managing symbols and evaluating formulas config_update_receiver: receiver for receiving config file updates wait_for_data_sec: how long actor should wait before processing first request. It is a time needed to collect first components data. formula_update_interval_sec: how frequently send formula results. With this frequency all results from formulas will be send. Raises: ValueError: if a sender corresponding to any of the microgrid_formulas is not provided \"\"\" component_infos , battery_inverter_mappings = infer_microgrid_config ( component_graph ) self . component_graph = component_graph self . component_infos = component_infos self . battery_inverter_mappings = battery_inverter_mappings self . microgrid_client = microgrid_client self . _outputs = outputs # Fallback to an empty receiver so that `Select` doesn't raise `KeyError`s if config_update_receiver is not None : self . _config_update_receiver = config_update_receiver else : self . _config_update_receiver = Broadcast [ Config ]( \"microgrid_data_config_update_channel\" ) . new_receiver () self . _formula_update_interval_sec : float = formula_update_interval_sec self . _wait_for_data_sec = wait_for_data_sec self . formula_calculator = formula_calculator self . microgrid_formula_overrides : Dict [ str , Set [ int ]] = {} for output_channel_name in outputs . keys (): if output_channel_name not in self . formula_calculator . microgrid_formulas : raise ValueError ( f \"No formula defined for output channel { output_channel_name } .\" )","title":"__init__()"},{"location":"reference/frequenz/sdk/data_ingestion/microgrid_data/#frequenz.sdk.data_ingestion.microgrid_data.MicrogridData.parse_formula_overrides","text":"Parse formula overrides from the config file. The following format of the config file is expected: ... formula_grid_load = \"[1,3,4]\" formula_batteries_remaining_power = \"[75,123,1]\" ... \"formula_\" is a configurable prefix defined in CONFIG_FILE_FORMULA_PREFIX . PARAMETER DESCRIPTION config contents of the recently updated config file. TYPE: Config RETURNS DESCRIPTION Dict [ str , Set [ int ]] mapping of formula names to list of battery ids to be taken into account when evaluating the formula RAISES DESCRIPTION ValueError if value provided refers to a formula that wasn't defined in formula calculator AttributeError if value provided for a formula name doesn't have split method TypeError if battery ids to be taken into account for a formula are not integers Source code in frequenz/sdk/data_ingestion/microgrid_data.py 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 def parse_formula_overrides ( self , config : Config ) -> Dict [ str , Set [ int ]]: \"\"\"Parse formula overrides from the config file. The following format of the config file is expected: ... formula_grid_load = \"[1,3,4]\" formula_batteries_remaining_power = \"[75,123,1]\" ... \"formula_\" is a configurable prefix defined in `CONFIG_FILE_FORMULA_PREFIX`. Args: config: contents of the recently updated config file. Returns: mapping of formula names to list of battery ids to be taken into account when evaluating the formula Raises: ValueError: if value provided refers to a formula that wasn't defined in formula calculator AttributeError: if value provided for a formula name doesn't have `split` method TypeError: if battery ids to be taken into account for a formula are not integers \"\"\" formula_overrides : Dict [ str , Set [ int ]] = {} try : formula_config = config . get_dict ( CONFIG_FILE_FORMULA_PREFIX , expected_values_type = Set [ int ] ) except ValueError as err : logger . error ( \"Formula overrides (config variables starting with %s \" \" are expected to be str -> Set[int] mappings: %s \" , CONFIG_FILE_FORMULA_PREFIX , err , ) raise for formula_name , battery_ids in formula_config . items (): if formula_name not in self . formula_calculator . microgrid_formulas : logger . error ( \"Formula %s cannot be updated, because it does not exist.\" , formula_name , ) continue formula_overrides [ formula_name ] = battery_ids return formula_overrides","title":"parse_formula_overrides()"},{"location":"reference/frequenz/sdk/data_ingestion/microgrid_data/#frequenz.sdk.data_ingestion.microgrid_data.MicrogridData.resend_formulas","text":"Send formulas results with some period. Source code in frequenz/sdk/data_ingestion/microgrid_data.py 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 async def resend_formulas ( self ) -> None : \"\"\"Send formulas results with some period.\"\"\" # Sleep first to collect initial data from all component await asyncio . sleep ( self . _wait_for_data_sec ) tasks : List [ asyncio . Task [ bool ]] = [] while True : start_time = datetime . now ( timezone . utc ) # For every formula that was updated at least once, send that formula. for name , formula_result in self . formula_calculator . results . items (): if name not in self . _outputs : # If formula was computed but there is not output channel in # MicrogridData then it is bug in MicrogridData. logger . error ( \"MicrogridData: No channel for formula %s .\" , name , ) else : task = asyncio . create_task ( self . _outputs [ name ] . send ( formula_result )) tasks . append ( task ) await asyncio . gather ( * tasks , return_exceptions = True ) diff : float = ( datetime . now ( timezone . utc ) - start_time ) . total_seconds () if diff >= self . _formula_update_interval_sec : logger . error ( \"Sending results of formulas took too long: %f , \" \"expected sending interval: %f \" , diff , self . _formula_update_interval_sec , ) else : await asyncio . sleep ( self . _formula_update_interval_sec - diff )","title":"resend_formulas()"},{"location":"reference/frequenz/sdk/data_ingestion/microgrid_data/#frequenz.sdk.data_ingestion.microgrid_data.MicrogridData.run","text":"Run the actor. Source code in frequenz/sdk/data_ingestion/microgrid_data.py 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 async def run ( self ) -> None : \"\"\"Run the actor.\"\"\" while True : receivers = await gen_component_receivers ( self . component_infos , self . microgrid_client ) # Create a task that will periodically send formula results. resend_formulas_task = asyncio . create_task ( self . resend_formulas ()) select = Select ( component_data_receiver = Merge ( * receivers . values ()), config_update_receiver = self . _config_update_receiver , ) while await select . ready (): if msg := select . component_data_receiver : # Update symbols and recalculate formulas. updated_symbols = self . formula_calculator . update_symbol_values ( msg . inner ) self . formula_calculator . compute ( updated_symbols , only_formula_names = set ( self . _outputs . keys ()) ) elif msg := select . config_update_receiver : try : await self . _reinitialize ( msg . inner , resend_formulas_task ) except Exception as err : # pylint: disable=broad-except logger . error ( \"Reinitialization failed, because an error occurred \" \"while applying the new configuration: %s \" , err , ) else : # Break from the inner loop to regenerate component receivers break","title":"run()"},{"location":"reference/frequenz/sdk/data_ingestion/microgrid_data/#frequenz.sdk.data_ingestion.microgrid_data-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/microgrid/","text":"frequenz.sdk.microgrid \u00a4 Microgrid monitoring and control system. This package provides a complete suite of data structures and functionality for monitoring and adjusting the state of a microgrid. Classes \u00a4 frequenz.sdk.microgrid.BatteryData dataclass \u00a4 Bases: ComponentData A wrapper class for holding battery data. ATTRIBUTE DESCRIPTION soc battery's overall SoC in percent (%). TYPE: float soc_lower_bound the SoC below which discharge commands will be blocked by the system, in percent (%). TYPE: float soc_upper_bound the SoC above which charge commands will be blocked by the system, in percent (%). TYPE: float capacity the capacity of the battery in Wh (Watt-hour) TYPE: float power_lower_bound the maximum discharge power, in Watts, represented in the passive sign convention. This will be a negative number, or zero if no discharging is possible. TYPE: float power_upper_bound the maximum charge power, in Watts, represented in the passive sign convention. This will be a positive number, or zero if no charging is possible. TYPE: float Source code in frequenz/sdk/microgrid/component_data.py 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 @dataclass ( frozen = True ) class BatteryData ( ComponentData ): \"\"\"A wrapper class for holding battery data. Attributes: soc: battery's overall SoC in percent (%). soc_lower_bound: the SoC below which discharge commands will be blocked by the system, in percent (%). soc_upper_bound: the SoC above which charge commands will be blocked by the system, in percent (%). capacity: the capacity of the battery in Wh (Watt-hour) power_lower_bound: the maximum discharge power, in Watts, represented in the passive sign convention. This will be a negative number, or zero if no discharging is possible. power_upper_bound: the maximum charge power, in Watts, represented in the passive sign convention. This will be a positive number, or zero if no charging is possible. \"\"\" soc : float soc_lower_bound : float soc_upper_bound : float capacity : float power_lower_bound : float power_upper_bound : float @classmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> BatteryData : \"\"\"Create BatteryData from a protobuf message. Args: raw: raw component data as decoded from the wire. Returns: Instance of BatteryData created from the protobuf message. \"\"\" battery_data = cls ( component_id = raw . id , timestamp = raw . ts . ToDatetime ( tzinfo = pytz . UTC ), soc = raw . battery . data . soc . avg , soc_lower_bound = raw . battery . data . soc . system_bounds . lower , soc_upper_bound = raw . battery . data . soc . system_bounds . upper , capacity = raw . battery . properties . capacity , power_lower_bound = raw . battery . data . dc . power . system_bounds . lower , power_upper_bound = raw . battery . data . dc . power . system_bounds . upper , ) battery_data . _set_raw ( raw = raw ) return battery_data Functions \u00a4 from_proto ( raw ) classmethod \u00a4 Create BatteryData from a protobuf message. PARAMETER DESCRIPTION raw raw component data as decoded from the wire. TYPE: microgrid_pb . ComponentData RETURNS DESCRIPTION BatteryData Instance of BatteryData created from the protobuf message. Source code in frequenz/sdk/microgrid/component_data.py 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 @classmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> BatteryData : \"\"\"Create BatteryData from a protobuf message. Args: raw: raw component data as decoded from the wire. Returns: Instance of BatteryData created from the protobuf message. \"\"\" battery_data = cls ( component_id = raw . id , timestamp = raw . ts . ToDatetime ( tzinfo = pytz . UTC ), soc = raw . battery . data . soc . avg , soc_lower_bound = raw . battery . data . soc . system_bounds . lower , soc_upper_bound = raw . battery . data . soc . system_bounds . upper , capacity = raw . battery . properties . capacity , power_lower_bound = raw . battery . data . dc . power . system_bounds . lower , power_upper_bound = raw . battery . data . dc . power . system_bounds . upper , ) battery_data . _set_raw ( raw = raw ) return battery_data frequenz.sdk.microgrid.Component dataclass \u00a4 Metadata for a single microgrid component. Source code in frequenz/sdk/microgrid/component.py 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 @dataclass ( frozen = True ) class Component : \"\"\"Metadata for a single microgrid component.\"\"\" component_id : int category : ComponentCategory def is_valid ( self ) -> bool : \"\"\"Check if this instance contains valid data. Returns: `True` if `id > 0` and `type` is a valid `ComponentCategory`, or if `id == 0` and `type` is `GRID`, `False` otherwise \"\"\" return ( self . component_id > 0 and any ( t == self . category for t in ComponentCategory ) ) or ( self . component_id == 0 and self . category == ComponentCategory . GRID ) Functions \u00a4 is_valid () \u00a4 Check if this instance contains valid data. RETURNS DESCRIPTION bool True if id > 0 and type is a valid ComponentCategory , or if id == 0 and type is GRID , False otherwise Source code in frequenz/sdk/microgrid/component.py 66 67 68 69 70 71 72 73 74 75 def is_valid ( self ) -> bool : \"\"\"Check if this instance contains valid data. Returns: `True` if `id > 0` and `type` is a valid `ComponentCategory`, or if `id == 0` and `type` is `GRID`, `False` otherwise \"\"\" return ( self . component_id > 0 and any ( t == self . category for t in ComponentCategory ) ) or ( self . component_id == 0 and self . category == ComponentCategory . GRID ) frequenz.sdk.microgrid.ComponentCategory \u00a4 Bases: Enum Possible types of microgrid component. Source code in frequenz/sdk/microgrid/component.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 class ComponentCategory ( Enum ): \"\"\"Possible types of microgrid component.\"\"\" NONE = microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_UNSPECIFIED GRID = microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_GRID JUNCTION = microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_JUNCTION METER = microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_METER INVERTER = microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_INVERTER BATTERY = microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_BATTERY EV_CHARGER = microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_EV_CHARGER LOAD = microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_LOAD # types not yet supported by the API but which can be inferred # from available graph info PV_ARRAY = 1000001 CHP = 1000002 # combined heat and power plant frequenz.sdk.microgrid.ComponentGraph \u00a4 Bases: ABC Interface for component graph implementations. Source code in frequenz/sdk/microgrid/graph.py 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 class ComponentGraph ( ABC ): \"\"\"Interface for component graph implementations.\"\"\" @abstractmethod def components ( self , component_id : Optional [ Set [ int ]] = None , component_category : Optional [ Set [ ComponentCategory ]] = None , ) -> Set [ Component ]: \"\"\"Fetch the components of the microgrid. Args: component_id: filter out any components not matching one of the provided IDs component_category: filter out any components not matching one of the provided types Returns: Set of the components currently connected to the microgrid, filtered by the provided `component_id` and `component_category` values. \"\"\" @abstractmethod def connections ( self , start : Optional [ Set [ int ]] = None , end : Optional [ Set [ int ]] = None , ) -> Set [ Connection ]: \"\"\"Fetch the connections between microgrid components. Args: start: filter out any connections whose `start` does not match one of these component IDs end: filter out any connections whose `end` does not match one of these component IDs Returns: Set of the connections between components in the microgrid, filtered by the provided `start`/`end` choices. \"\"\" @abstractmethod def predecessors ( self , component_id : int ) -> Set [ Component ]: \"\"\"Fetch the graph predecessors of the specified component. Args: component_id: numerical ID of the component whose predecessors should be fetched Returns: Set of IDs of the components that are predecessors of `component_id`, i.e. for which there is a connection from each of these components to `component_id`. Raises: KeyError: if the specified `component_id` is not in the graph \"\"\" @abstractmethod def successors ( self , component_id : int ) -> Set [ Component ]: \"\"\"Fetch the graph successors of the specified component. Args: component_id: numerical ID of the component whose successors should be fetched Returns: Set of IDs of the components that are successors of `component_id`, i.e. for which there is a connection from `component_id` to each of these components. Raises: KeyError: if the specified `component_id` is not in the graph \"\"\" Functions \u00a4 components ( component_id = None , component_category = None ) abstractmethod \u00a4 Fetch the components of the microgrid. PARAMETER DESCRIPTION component_id filter out any components not matching one of the provided IDs TYPE: Optional [ Set [ int ]] DEFAULT: None component_category filter out any components not matching one of the provided types TYPE: Optional [ Set [ ComponentCategory ]] DEFAULT: None RETURNS DESCRIPTION Set [ Component ] Set of the components currently connected to the microgrid, filtered by the provided component_id and component_category values. Source code in frequenz/sdk/microgrid/graph.py 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 @abstractmethod def components ( self , component_id : Optional [ Set [ int ]] = None , component_category : Optional [ Set [ ComponentCategory ]] = None , ) -> Set [ Component ]: \"\"\"Fetch the components of the microgrid. Args: component_id: filter out any components not matching one of the provided IDs component_category: filter out any components not matching one of the provided types Returns: Set of the components currently connected to the microgrid, filtered by the provided `component_id` and `component_category` values. \"\"\" connections ( start = None , end = None ) abstractmethod \u00a4 Fetch the connections between microgrid components. PARAMETER DESCRIPTION start filter out any connections whose start does not match one of these component IDs TYPE: Optional [ Set [ int ]] DEFAULT: None end filter out any connections whose end does not match one of these component IDs TYPE: Optional [ Set [ int ]] DEFAULT: None RETURNS DESCRIPTION Set [ Connection ] Set of the connections between components in the microgrid, filtered by the provided start / end choices. Source code in frequenz/sdk/microgrid/graph.py 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 @abstractmethod def connections ( self , start : Optional [ Set [ int ]] = None , end : Optional [ Set [ int ]] = None , ) -> Set [ Connection ]: \"\"\"Fetch the connections between microgrid components. Args: start: filter out any connections whose `start` does not match one of these component IDs end: filter out any connections whose `end` does not match one of these component IDs Returns: Set of the connections between components in the microgrid, filtered by the provided `start`/`end` choices. \"\"\" predecessors ( component_id ) abstractmethod \u00a4 Fetch the graph predecessors of the specified component. PARAMETER DESCRIPTION component_id numerical ID of the component whose predecessors should be fetched TYPE: int RETURNS DESCRIPTION Set [ Component ] Set of IDs of the components that are predecessors of component_id , i.e. for which there is a connection from each of these components to component_id . RAISES DESCRIPTION KeyError if the specified component_id is not in the graph Source code in frequenz/sdk/microgrid/graph.py 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 @abstractmethod def predecessors ( self , component_id : int ) -> Set [ Component ]: \"\"\"Fetch the graph predecessors of the specified component. Args: component_id: numerical ID of the component whose predecessors should be fetched Returns: Set of IDs of the components that are predecessors of `component_id`, i.e. for which there is a connection from each of these components to `component_id`. Raises: KeyError: if the specified `component_id` is not in the graph \"\"\" successors ( component_id ) abstractmethod \u00a4 Fetch the graph successors of the specified component. PARAMETER DESCRIPTION component_id numerical ID of the component whose successors should be fetched TYPE: int RETURNS DESCRIPTION Set [ Component ] Set of IDs of the components that are successors of component_id , i.e. for which there is a connection from component_id to each of these components. RAISES DESCRIPTION KeyError if the specified component_id is not in the graph Source code in frequenz/sdk/microgrid/graph.py 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 @abstractmethod def successors ( self , component_id : int ) -> Set [ Component ]: \"\"\"Fetch the graph successors of the specified component. Args: component_id: numerical ID of the component whose successors should be fetched Returns: Set of IDs of the components that are successors of `component_id`, i.e. for which there is a connection from `component_id` to each of these components. Raises: KeyError: if the specified `component_id` is not in the graph \"\"\" frequenz.sdk.microgrid.Connection \u00a4 Bases: NamedTuple Metadata for a connection between microgrid components. Source code in frequenz/sdk/microgrid/connection.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 class Connection ( NamedTuple ): \"\"\"Metadata for a connection between microgrid components.\"\"\" start : int end : int def is_valid ( self ) -> bool : \"\"\"Check if this instance contains valid data. Returns: `True` if `start >= 0`, `end > 0`, and `start != end`, `False` otherwise. \"\"\" return self . start >= 0 and self . end > 0 and self . start != self . end Functions \u00a4 is_valid () \u00a4 Check if this instance contains valid data. RETURNS DESCRIPTION bool True if start >= 0 , end > 0 , and start != end , False otherwise. Source code in frequenz/sdk/microgrid/connection.py 15 16 17 18 19 20 21 22 def is_valid ( self ) -> bool : \"\"\"Check if this instance contains valid data. Returns: `True` if `start >= 0`, `end > 0`, and `start != end`, `False` otherwise. \"\"\" return self . start >= 0 and self . end > 0 and self . start != self . end frequenz.sdk.microgrid.EVChargerData dataclass \u00a4 Bases: ComponentData A wrapper class for holding ev_charger data. ATTRIBUTE DESCRIPTION active_power_consumption the 3-phase active power, in Watts, represented in the passive sign convention. +ve current means consumption, away from the grid. -ve current means supply into the grid. current_per_phase AC current in Amperes (A) for phase/line 1,2 and 3 respectively. +ve current means consumption, away from the grid. -ve current means supply into the grid. TYPE: Tuple [ float , float , float ] voltage_per_phase the AC voltage in Volts (V) between the line and the neutral wire for phase/line 1,2 and 3 respectively. TYPE: Tuple [ float , float , float ] cable_state the state of the ev charger's cable TYPE: EVChargerCableState Source code in frequenz/sdk/microgrid/component_data.py 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 @dataclass ( frozen = True ) class EVChargerData ( ComponentData ): \"\"\"A wrapper class for holding ev_charger data. Attributes: active_power_consumption: the 3-phase active power, in Watts, represented in the passive sign convention. +ve current means consumption, away from the grid. -ve current means supply into the grid. current_per_phase: AC current in Amperes (A) for phase/line 1,2 and 3 respectively. +ve current means consumption, away from the grid. -ve current means supply into the grid. voltage_per_phase: the AC voltage in Volts (V) between the line and the neutral wire for phase/line 1,2 and 3 respectively. cable_state: the state of the ev charger's cable \"\"\" active_power : float current_per_phase : Tuple [ float , float , float ] voltage_per_phase : Tuple [ float , float , float ] cable_state : EVChargerCableState @classmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> EVChargerData : \"\"\"Create EVChargerData from a protobuf message. Args: raw: raw component data as decoded from the wire. Returns: Instance of EVChargerData created from the protobuf message. \"\"\" ev_charger_data = cls ( component_id = raw . id , timestamp = raw . ts . ToDatetime ( tzinfo = pytz . UTC ), active_power = raw . ev_charger . data . ac . power_active . value , current_per_phase = ( raw . ev_charger . data . ac . phase_1 . current . value , raw . ev_charger . data . ac . phase_2 . current . value , raw . ev_charger . data . ac . phase_3 . current . value , ), voltage_per_phase = ( raw . ev_charger . data . ac . phase_1 . voltage . value , raw . ev_charger . data . ac . phase_2 . voltage . value , raw . ev_charger . data . ac . phase_3 . voltage . value , ), cable_state = EVChargerCableState . from_pb ( raw . ev_charger . state . cable_state ), ) ev_charger_data . _set_raw ( raw = raw ) return ev_charger_data Functions \u00a4 from_proto ( raw ) classmethod \u00a4 Create EVChargerData from a protobuf message. PARAMETER DESCRIPTION raw raw component data as decoded from the wire. TYPE: microgrid_pb . ComponentData RETURNS DESCRIPTION EVChargerData Instance of EVChargerData created from the protobuf message. Source code in frequenz/sdk/microgrid/component_data.py 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 @classmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> EVChargerData : \"\"\"Create EVChargerData from a protobuf message. Args: raw: raw component data as decoded from the wire. Returns: Instance of EVChargerData created from the protobuf message. \"\"\" ev_charger_data = cls ( component_id = raw . id , timestamp = raw . ts . ToDatetime ( tzinfo = pytz . UTC ), active_power = raw . ev_charger . data . ac . power_active . value , current_per_phase = ( raw . ev_charger . data . ac . phase_1 . current . value , raw . ev_charger . data . ac . phase_2 . current . value , raw . ev_charger . data . ac . phase_3 . current . value , ), voltage_per_phase = ( raw . ev_charger . data . ac . phase_1 . voltage . value , raw . ev_charger . data . ac . phase_2 . voltage . value , raw . ev_charger . data . ac . phase_3 . voltage . value , ), cable_state = EVChargerCableState . from_pb ( raw . ev_charger . state . cable_state ), ) ev_charger_data . _set_raw ( raw = raw ) return ev_charger_data frequenz.sdk.microgrid.InverterData dataclass \u00a4 Bases: ComponentData A wrapper class for holding inverter data. ATTRIBUTE DESCRIPTION active_power the 3-phase active power, in Watts, represented in the passive sign convention. +ve current means consumption, away from the grid. -ve current means supply into the grid. TYPE: float active_power_lower_bound the maximum discharge power, in Watts, represented in the passive sign convention. This will be a negative number, or zero if no discharging is possible. TYPE: float active_power_upper_bound the maximum charge power, in Watts, represented in the passive sign convention. This will be a positive number, or zero if no charging is possible. TYPE: float Source code in frequenz/sdk/microgrid/component_data.py 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 @dataclass ( frozen = True ) class InverterData ( ComponentData ): \"\"\"A wrapper class for holding inverter data. Attributes: active_power: the 3-phase active power, in Watts, represented in the passive sign convention. +ve current means consumption, away from the grid. -ve current means supply into the grid. active_power_lower_bound: the maximum discharge power, in Watts, represented in the passive sign convention. This will be a negative number, or zero if no discharging is possible. active_power_upper_bound: the maximum charge power, in Watts, represented in the passive sign convention. This will be a positive number, or zero if no charging is possible. \"\"\" active_power : float active_power_lower_bound : float active_power_upper_bound : float @classmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> InverterData : \"\"\"Create InverterData from a protobuf message. Args: raw: raw component data as decoded from the wire. Returns: Instance of InverterData created from the protobuf message. \"\"\" inverter_data = cls ( component_id = raw . id , timestamp = raw . ts . ToDatetime ( tzinfo = pytz . UTC ), active_power = raw . inverter . data . ac . power_active . value , active_power_lower_bound = raw . inverter . data . ac . power_active . system_bounds . lower , active_power_upper_bound = raw . inverter . data . ac . power_active . system_bounds . upper , ) inverter_data . _set_raw ( raw = raw ) return inverter_data Functions \u00a4 from_proto ( raw ) classmethod \u00a4 Create InverterData from a protobuf message. PARAMETER DESCRIPTION raw raw component data as decoded from the wire. TYPE: microgrid_pb . ComponentData RETURNS DESCRIPTION InverterData Instance of InverterData created from the protobuf message. Source code in frequenz/sdk/microgrid/component_data.py 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 @classmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> InverterData : \"\"\"Create InverterData from a protobuf message. Args: raw: raw component data as decoded from the wire. Returns: Instance of InverterData created from the protobuf message. \"\"\" inverter_data = cls ( component_id = raw . id , timestamp = raw . ts . ToDatetime ( tzinfo = pytz . UTC ), active_power = raw . inverter . data . ac . power_active . value , active_power_lower_bound = raw . inverter . data . ac . power_active . system_bounds . lower , active_power_upper_bound = raw . inverter . data . ac . power_active . system_bounds . upper , ) inverter_data . _set_raw ( raw = raw ) return inverter_data frequenz.sdk.microgrid.MeterData dataclass \u00a4 Bases: ComponentData A wrapper class for holding meter data. ATTRIBUTE DESCRIPTION active_power the 3-phase active power, in Watts, represented in the passive sign convention. +ve current means consumption, away from the grid. -ve current means supply into the grid. TYPE: float current_per_phase AC current in Amperes (A) for phase/line 1,2 and 3 respectively. +ve current means consumption, away from the grid. -ve current means supply into the grid. TYPE: Tuple [ float , float , float ] voltage_per_phase the AC voltage in Volts (V) between the line and the neutral wire for phase/line 1,2 and 3 respectively. TYPE: Tuple [ float , float , float ] Source code in frequenz/sdk/microgrid/component_data.py 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 @dataclass ( frozen = True ) class MeterData ( ComponentData ): \"\"\"A wrapper class for holding meter data. Attributes: active_power: the 3-phase active power, in Watts, represented in the passive sign convention. +ve current means consumption, away from the grid. -ve current means supply into the grid. current_per_phase: AC current in Amperes (A) for phase/line 1,2 and 3 respectively. +ve current means consumption, away from the grid. -ve current means supply into the grid. voltage_per_phase: the AC voltage in Volts (V) between the line and the neutral wire for phase/line 1,2 and 3 respectively. \"\"\" active_power : float current_per_phase : Tuple [ float , float , float ] voltage_per_phase : Tuple [ float , float , float ] @classmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> MeterData : \"\"\"Create MeterData from a protobuf message. Args: raw: raw component data as decoded from the wire. Returns: Instance of MeterData created from the protobuf message. \"\"\" meter_data = cls ( component_id = raw . id , timestamp = raw . ts . ToDatetime ( tzinfo = pytz . UTC ), active_power = raw . meter . data . ac . power_active . value , current_per_phase = ( raw . meter . data . ac . phase_1 . current . value , raw . meter . data . ac . phase_2 . current . value , raw . meter . data . ac . phase_3 . current . value , ), voltage_per_phase = ( raw . meter . data . ac . phase_1 . voltage . value , raw . meter . data . ac . phase_2 . voltage . value , raw . meter . data . ac . phase_3 . voltage . value , ), ) meter_data . _set_raw ( raw = raw ) return meter_data Functions \u00a4 from_proto ( raw ) classmethod \u00a4 Create MeterData from a protobuf message. PARAMETER DESCRIPTION raw raw component data as decoded from the wire. TYPE: microgrid_pb . ComponentData RETURNS DESCRIPTION MeterData Instance of MeterData created from the protobuf message. Source code in frequenz/sdk/microgrid/component_data.py 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 @classmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> MeterData : \"\"\"Create MeterData from a protobuf message. Args: raw: raw component data as decoded from the wire. Returns: Instance of MeterData created from the protobuf message. \"\"\" meter_data = cls ( component_id = raw . id , timestamp = raw . ts . ToDatetime ( tzinfo = pytz . UTC ), active_power = raw . meter . data . ac . power_active . value , current_per_phase = ( raw . meter . data . ac . phase_1 . current . value , raw . meter . data . ac . phase_2 . current . value , raw . meter . data . ac . phase_3 . current . value , ), voltage_per_phase = ( raw . meter . data . ac . phase_1 . voltage . value , raw . meter . data . ac . phase_2 . voltage . value , raw . meter . data . ac . phase_3 . voltage . value , ), ) meter_data . _set_raw ( raw = raw ) return meter_data frequenz.sdk.microgrid.MicrogridApi \u00a4 Bases: ABC Creates and stores core features. Source code in frequenz/sdk/microgrid/microgrid_api.py 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 class MicrogridApi ( ABC ): \"\"\"Creates and stores core features.\"\"\" def __init__ ( self , host : str , port : int ) -> None : \"\"\"Create object instance. Args: host: server host port: server port \"\"\" super () . __init__ () self . _host : str = host self . _port : int = port @property def host ( self ) -> str : \"\"\"Get host of the currently connected server. Returns: host \"\"\" return self . _host @property def port ( self ) -> int : \"\"\"Get port of the currently connected server. Returns: port \"\"\" return self . _port @property @abstractmethod def microgrid_api_client ( self ) -> MicrogridApiClient : \"\"\"Get MicrogridApiClient. Returns: api client \"\"\" @property @abstractmethod def component_graph ( self ) -> ComponentGraph : \"\"\"Get component graph. Returns: component graph \"\"\" async def _update_api ( self , host : str , port : int ) -> None : self . _host = host self . _port = port @abstractmethod async def _initialize ( self ) -> None : \"\"\"Initialize the object. This function should be called only once.\"\"\" Functions \u00a4 __init__ ( host , port ) \u00a4 Create object instance. PARAMETER DESCRIPTION host server host TYPE: str port server port TYPE: int Source code in frequenz/sdk/microgrid/microgrid_api.py 22 23 24 25 26 27 28 29 30 31 def __init__ ( self , host : str , port : int ) -> None : \"\"\"Create object instance. Args: host: server host port: server port \"\"\" super () . __init__ () self . _host : str = host self . _port : int = port component_graph () property abstractmethod \u00a4 Get component graph. RETURNS DESCRIPTION ComponentGraph component graph Source code in frequenz/sdk/microgrid/microgrid_api.py 60 61 62 63 64 65 66 67 @property @abstractmethod def component_graph ( self ) -> ComponentGraph : \"\"\"Get component graph. Returns: component graph \"\"\" host () property \u00a4 Get host of the currently connected server. RETURNS DESCRIPTION str host Source code in frequenz/sdk/microgrid/microgrid_api.py 33 34 35 36 37 38 39 40 @property def host ( self ) -> str : \"\"\"Get host of the currently connected server. Returns: host \"\"\" return self . _host microgrid_api_client () property abstractmethod \u00a4 Get MicrogridApiClient. RETURNS DESCRIPTION MicrogridApiClient api client Source code in frequenz/sdk/microgrid/microgrid_api.py 51 52 53 54 55 56 57 58 @property @abstractmethod def microgrid_api_client ( self ) -> MicrogridApiClient : \"\"\"Get MicrogridApiClient. Returns: api client \"\"\" port () property \u00a4 Get port of the currently connected server. RETURNS DESCRIPTION int port Source code in frequenz/sdk/microgrid/microgrid_api.py 42 43 44 45 46 47 48 49 @property def port ( self ) -> int : \"\"\"Get port of the currently connected server. Returns: port \"\"\" return self . _port frequenz.sdk.microgrid.MicrogridApiClient \u00a4 Bases: ABC Base interface for microgrid API clients to implement. Source code in frequenz/sdk/microgrid/client.py 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 class MicrogridApiClient ( ABC ): \"\"\"Base interface for microgrid API clients to implement.\"\"\" @abstractmethod async def components ( self ) -> Iterable [ Component ]: \"\"\"Fetch all the components present in the microgrid. Returns: Iterator whose elements are all the components in the microgrid. \"\"\" @abstractmethod async def connections ( self , starts : Optional [ Set [ int ]] = None , ends : Optional [ Set [ int ]] = None , ) -> Iterable [ Connection ]: \"\"\"Fetch the connections between components in the microgrid. Args: starts: if set and non-empty, only include connections whose start value matches one of the provided component IDs ends: if set and non-empty, only include connections whose end value matches one of the provided component IDs Returns: Microgrid connections matching the provided start and end filters. \"\"\" @abstractmethod async def meter_data ( self , component_id : int , ) -> Receiver [ MeterData ]: \"\"\"Return a channel receiver that provides a `MeterData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Args: component_id: id of the meter to get data for. Returns: A channel receiver that provides realtime meter data. \"\"\" @abstractmethod async def battery_data ( self , component_id : int , ) -> Receiver [ BatteryData ]: \"\"\"Return a channel receiver that provides a `BatteryData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Args: component_id: id of the battery to get data for. Returns: A channel receiver that provides realtime battery data. \"\"\" @abstractmethod async def inverter_data ( self , component_id : int , ) -> Receiver [ InverterData ]: \"\"\"Return a channel receiver that provides an `InverterData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Args: component_id: id of the inverter to get data for. Returns: A channel receiver that provides realtime inverter data. \"\"\" @abstractmethod async def ev_charger_data ( self , component_id : int , ) -> Receiver [ EVChargerData ]: \"\"\"Return a channel receiver that provides an `EvChargeData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Args: component_id: id of the ev charger to get data for. Returns: A channel receiver that provides realtime ev charger data. \"\"\" @abstractmethod async def set_power ( self , component_id : int , power_w : int ) -> Empty : \"\"\"Send request to the Microgrid to set power for component. If power > 0, then component will be charged with this power. If power < 0, then component will be discharged with this power. If power == 0, then stop charging or discharging component. Args: component_id: id of the component to set power. power_w: power to set for the component. Returns: Empty response. \"\"\" @abstractmethod async def set_bounds ( self , component_id : int , lower : float , upper : float ) -> None : \"\"\"Send `SetBoundsParam`s received from a channel to nitrogen. Args: component_id: ID of the component to set bounds for. lower: Lower bound to be set for the component. upper: Upper bound to be set for the component. \"\"\" Functions \u00a4 battery_data ( component_id ) async abstractmethod \u00a4 Return a channel receiver that provides a BatteryData stream. If only the latest value is required, the Receiver returned by this method can be converted into a Peekable with the into_peekable method on the Receiver. PARAMETER DESCRIPTION component_id id of the battery to get data for. TYPE: int RETURNS DESCRIPTION Receiver [ BatteryData ] A channel receiver that provides realtime battery data. Source code in frequenz/sdk/microgrid/client.py 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 @abstractmethod async def battery_data ( self , component_id : int , ) -> Receiver [ BatteryData ]: \"\"\"Return a channel receiver that provides a `BatteryData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Args: component_id: id of the battery to get data for. Returns: A channel receiver that provides realtime battery data. \"\"\" components () async abstractmethod \u00a4 Fetch all the components present in the microgrid. RETURNS DESCRIPTION Iterable [ Component ] Iterator whose elements are all the components in the microgrid. Source code in frequenz/sdk/microgrid/client.py 43 44 45 46 47 48 49 @abstractmethod async def components ( self ) -> Iterable [ Component ]: \"\"\"Fetch all the components present in the microgrid. Returns: Iterator whose elements are all the components in the microgrid. \"\"\" connections ( starts = None , ends = None ) async abstractmethod \u00a4 Fetch the connections between components in the microgrid. PARAMETER DESCRIPTION starts if set and non-empty, only include connections whose start value matches one of the provided component IDs TYPE: Optional [ Set [ int ]] DEFAULT: None ends if set and non-empty, only include connections whose end value matches one of the provided component IDs TYPE: Optional [ Set [ int ]] DEFAULT: None RETURNS DESCRIPTION Iterable [ Connection ] Microgrid connections matching the provided start and end filters. Source code in frequenz/sdk/microgrid/client.py 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 @abstractmethod async def connections ( self , starts : Optional [ Set [ int ]] = None , ends : Optional [ Set [ int ]] = None , ) -> Iterable [ Connection ]: \"\"\"Fetch the connections between components in the microgrid. Args: starts: if set and non-empty, only include connections whose start value matches one of the provided component IDs ends: if set and non-empty, only include connections whose end value matches one of the provided component IDs Returns: Microgrid connections matching the provided start and end filters. \"\"\" ev_charger_data ( component_id ) async abstractmethod \u00a4 Return a channel receiver that provides an EvChargeData stream. If only the latest value is required, the Receiver returned by this method can be converted into a Peekable with the into_peekable method on the Receiver. PARAMETER DESCRIPTION component_id id of the ev charger to get data for. TYPE: int RETURNS DESCRIPTION Receiver [ EVChargerData ] A channel receiver that provides realtime ev charger data. Source code in frequenz/sdk/microgrid/client.py 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 @abstractmethod async def ev_charger_data ( self , component_id : int , ) -> Receiver [ EVChargerData ]: \"\"\"Return a channel receiver that provides an `EvChargeData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Args: component_id: id of the ev charger to get data for. Returns: A channel receiver that provides realtime ev charger data. \"\"\" inverter_data ( component_id ) async abstractmethod \u00a4 Return a channel receiver that provides an InverterData stream. If only the latest value is required, the Receiver returned by this method can be converted into a Peekable with the into_peekable method on the Receiver. PARAMETER DESCRIPTION component_id id of the inverter to get data for. TYPE: int RETURNS DESCRIPTION Receiver [ InverterData ] A channel receiver that provides realtime inverter data. Source code in frequenz/sdk/microgrid/client.py 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 @abstractmethod async def inverter_data ( self , component_id : int , ) -> Receiver [ InverterData ]: \"\"\"Return a channel receiver that provides an `InverterData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Args: component_id: id of the inverter to get data for. Returns: A channel receiver that provides realtime inverter data. \"\"\" meter_data ( component_id ) async abstractmethod \u00a4 Return a channel receiver that provides a MeterData stream. If only the latest value is required, the Receiver returned by this method can be converted into a Peekable with the into_peekable method on the Receiver. PARAMETER DESCRIPTION component_id id of the meter to get data for. TYPE: int RETURNS DESCRIPTION Receiver [ MeterData ] A channel receiver that provides realtime meter data. Source code in frequenz/sdk/microgrid/client.py 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 @abstractmethod async def meter_data ( self , component_id : int , ) -> Receiver [ MeterData ]: \"\"\"Return a channel receiver that provides a `MeterData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Args: component_id: id of the meter to get data for. Returns: A channel receiver that provides realtime meter data. \"\"\" set_bounds ( component_id , lower , upper ) async abstractmethod \u00a4 Send SetBoundsParam s received from a channel to nitrogen. PARAMETER DESCRIPTION component_id ID of the component to set bounds for. TYPE: int lower Lower bound to be set for the component. TYPE: float upper Upper bound to be set for the component. TYPE: float Source code in frequenz/sdk/microgrid/client.py 158 159 160 161 162 163 164 165 166 @abstractmethod async def set_bounds ( self , component_id : int , lower : float , upper : float ) -> None : \"\"\"Send `SetBoundsParam`s received from a channel to nitrogen. Args: component_id: ID of the component to set bounds for. lower: Lower bound to be set for the component. upper: Upper bound to be set for the component. \"\"\" set_power ( component_id , power_w ) async abstractmethod \u00a4 Send request to the Microgrid to set power for component. If power > 0, then component will be charged with this power. If power < 0, then component will be discharged with this power. If power == 0, then stop charging or discharging component. PARAMETER DESCRIPTION component_id id of the component to set power. TYPE: int power_w power to set for the component. TYPE: int RETURNS DESCRIPTION Empty Empty response. Source code in frequenz/sdk/microgrid/client.py 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 @abstractmethod async def set_power ( self , component_id : int , power_w : int ) -> Empty : \"\"\"Send request to the Microgrid to set power for component. If power > 0, then component will be charged with this power. If power < 0, then component will be discharged with this power. If power == 0, then stop charging or discharging component. Args: component_id: id of the component to set power. power_w: power to set for the component. Returns: Empty response. \"\"\"","title":"microgrid"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid","text":"Microgrid monitoring and control system. This package provides a complete suite of data structures and functionality for monitoring and adjusting the state of a microgrid.","title":"microgrid"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid.BatteryData","text":"Bases: ComponentData A wrapper class for holding battery data. ATTRIBUTE DESCRIPTION soc battery's overall SoC in percent (%). TYPE: float soc_lower_bound the SoC below which discharge commands will be blocked by the system, in percent (%). TYPE: float soc_upper_bound the SoC above which charge commands will be blocked by the system, in percent (%). TYPE: float capacity the capacity of the battery in Wh (Watt-hour) TYPE: float power_lower_bound the maximum discharge power, in Watts, represented in the passive sign convention. This will be a negative number, or zero if no discharging is possible. TYPE: float power_upper_bound the maximum charge power, in Watts, represented in the passive sign convention. This will be a positive number, or zero if no charging is possible. TYPE: float Source code in frequenz/sdk/microgrid/component_data.py 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 @dataclass ( frozen = True ) class BatteryData ( ComponentData ): \"\"\"A wrapper class for holding battery data. Attributes: soc: battery's overall SoC in percent (%). soc_lower_bound: the SoC below which discharge commands will be blocked by the system, in percent (%). soc_upper_bound: the SoC above which charge commands will be blocked by the system, in percent (%). capacity: the capacity of the battery in Wh (Watt-hour) power_lower_bound: the maximum discharge power, in Watts, represented in the passive sign convention. This will be a negative number, or zero if no discharging is possible. power_upper_bound: the maximum charge power, in Watts, represented in the passive sign convention. This will be a positive number, or zero if no charging is possible. \"\"\" soc : float soc_lower_bound : float soc_upper_bound : float capacity : float power_lower_bound : float power_upper_bound : float @classmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> BatteryData : \"\"\"Create BatteryData from a protobuf message. Args: raw: raw component data as decoded from the wire. Returns: Instance of BatteryData created from the protobuf message. \"\"\" battery_data = cls ( component_id = raw . id , timestamp = raw . ts . ToDatetime ( tzinfo = pytz . UTC ), soc = raw . battery . data . soc . avg , soc_lower_bound = raw . battery . data . soc . system_bounds . lower , soc_upper_bound = raw . battery . data . soc . system_bounds . upper , capacity = raw . battery . properties . capacity , power_lower_bound = raw . battery . data . dc . power . system_bounds . lower , power_upper_bound = raw . battery . data . dc . power . system_bounds . upper , ) battery_data . _set_raw ( raw = raw ) return battery_data","title":"BatteryData"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid.BatteryData-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid.component_data.BatteryData.from_proto","text":"Create BatteryData from a protobuf message. PARAMETER DESCRIPTION raw raw component data as decoded from the wire. TYPE: microgrid_pb . ComponentData RETURNS DESCRIPTION BatteryData Instance of BatteryData created from the protobuf message. Source code in frequenz/sdk/microgrid/component_data.py 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 @classmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> BatteryData : \"\"\"Create BatteryData from a protobuf message. Args: raw: raw component data as decoded from the wire. Returns: Instance of BatteryData created from the protobuf message. \"\"\" battery_data = cls ( component_id = raw . id , timestamp = raw . ts . ToDatetime ( tzinfo = pytz . UTC ), soc = raw . battery . data . soc . avg , soc_lower_bound = raw . battery . data . soc . system_bounds . lower , soc_upper_bound = raw . battery . data . soc . system_bounds . upper , capacity = raw . battery . properties . capacity , power_lower_bound = raw . battery . data . dc . power . system_bounds . lower , power_upper_bound = raw . battery . data . dc . power . system_bounds . upper , ) battery_data . _set_raw ( raw = raw ) return battery_data","title":"from_proto()"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid.Component","text":"Metadata for a single microgrid component. Source code in frequenz/sdk/microgrid/component.py 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 @dataclass ( frozen = True ) class Component : \"\"\"Metadata for a single microgrid component.\"\"\" component_id : int category : ComponentCategory def is_valid ( self ) -> bool : \"\"\"Check if this instance contains valid data. Returns: `True` if `id > 0` and `type` is a valid `ComponentCategory`, or if `id == 0` and `type` is `GRID`, `False` otherwise \"\"\" return ( self . component_id > 0 and any ( t == self . category for t in ComponentCategory ) ) or ( self . component_id == 0 and self . category == ComponentCategory . GRID )","title":"Component"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid.Component-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid.component.Component.is_valid","text":"Check if this instance contains valid data. RETURNS DESCRIPTION bool True if id > 0 and type is a valid ComponentCategory , or if id == 0 and type is GRID , False otherwise Source code in frequenz/sdk/microgrid/component.py 66 67 68 69 70 71 72 73 74 75 def is_valid ( self ) -> bool : \"\"\"Check if this instance contains valid data. Returns: `True` if `id > 0` and `type` is a valid `ComponentCategory`, or if `id == 0` and `type` is `GRID`, `False` otherwise \"\"\" return ( self . component_id > 0 and any ( t == self . category for t in ComponentCategory ) ) or ( self . component_id == 0 and self . category == ComponentCategory . GRID )","title":"is_valid()"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid.ComponentCategory","text":"Bases: Enum Possible types of microgrid component. Source code in frequenz/sdk/microgrid/component.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 class ComponentCategory ( Enum ): \"\"\"Possible types of microgrid component.\"\"\" NONE = microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_UNSPECIFIED GRID = microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_GRID JUNCTION = microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_JUNCTION METER = microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_METER INVERTER = microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_INVERTER BATTERY = microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_BATTERY EV_CHARGER = microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_EV_CHARGER LOAD = microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_LOAD # types not yet supported by the API but which can be inferred # from available graph info PV_ARRAY = 1000001 CHP = 1000002 # combined heat and power plant","title":"ComponentCategory"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid.ComponentGraph","text":"Bases: ABC Interface for component graph implementations. Source code in frequenz/sdk/microgrid/graph.py 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 class ComponentGraph ( ABC ): \"\"\"Interface for component graph implementations.\"\"\" @abstractmethod def components ( self , component_id : Optional [ Set [ int ]] = None , component_category : Optional [ Set [ ComponentCategory ]] = None , ) -> Set [ Component ]: \"\"\"Fetch the components of the microgrid. Args: component_id: filter out any components not matching one of the provided IDs component_category: filter out any components not matching one of the provided types Returns: Set of the components currently connected to the microgrid, filtered by the provided `component_id` and `component_category` values. \"\"\" @abstractmethod def connections ( self , start : Optional [ Set [ int ]] = None , end : Optional [ Set [ int ]] = None , ) -> Set [ Connection ]: \"\"\"Fetch the connections between microgrid components. Args: start: filter out any connections whose `start` does not match one of these component IDs end: filter out any connections whose `end` does not match one of these component IDs Returns: Set of the connections between components in the microgrid, filtered by the provided `start`/`end` choices. \"\"\" @abstractmethod def predecessors ( self , component_id : int ) -> Set [ Component ]: \"\"\"Fetch the graph predecessors of the specified component. Args: component_id: numerical ID of the component whose predecessors should be fetched Returns: Set of IDs of the components that are predecessors of `component_id`, i.e. for which there is a connection from each of these components to `component_id`. Raises: KeyError: if the specified `component_id` is not in the graph \"\"\" @abstractmethod def successors ( self , component_id : int ) -> Set [ Component ]: \"\"\"Fetch the graph successors of the specified component. Args: component_id: numerical ID of the component whose successors should be fetched Returns: Set of IDs of the components that are successors of `component_id`, i.e. for which there is a connection from `component_id` to each of these components. Raises: KeyError: if the specified `component_id` is not in the graph \"\"\"","title":"ComponentGraph"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid.ComponentGraph-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid.graph.ComponentGraph.components","text":"Fetch the components of the microgrid. PARAMETER DESCRIPTION component_id filter out any components not matching one of the provided IDs TYPE: Optional [ Set [ int ]] DEFAULT: None component_category filter out any components not matching one of the provided types TYPE: Optional [ Set [ ComponentCategory ]] DEFAULT: None RETURNS DESCRIPTION Set [ Component ] Set of the components currently connected to the microgrid, filtered by the provided component_id and component_category values. Source code in frequenz/sdk/microgrid/graph.py 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 @abstractmethod def components ( self , component_id : Optional [ Set [ int ]] = None , component_category : Optional [ Set [ ComponentCategory ]] = None , ) -> Set [ Component ]: \"\"\"Fetch the components of the microgrid. Args: component_id: filter out any components not matching one of the provided IDs component_category: filter out any components not matching one of the provided types Returns: Set of the components currently connected to the microgrid, filtered by the provided `component_id` and `component_category` values. \"\"\"","title":"components()"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid.graph.ComponentGraph.connections","text":"Fetch the connections between microgrid components. PARAMETER DESCRIPTION start filter out any connections whose start does not match one of these component IDs TYPE: Optional [ Set [ int ]] DEFAULT: None end filter out any connections whose end does not match one of these component IDs TYPE: Optional [ Set [ int ]] DEFAULT: None RETURNS DESCRIPTION Set [ Connection ] Set of the connections between components in the microgrid, filtered by the provided start / end choices. Source code in frequenz/sdk/microgrid/graph.py 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 @abstractmethod def connections ( self , start : Optional [ Set [ int ]] = None , end : Optional [ Set [ int ]] = None , ) -> Set [ Connection ]: \"\"\"Fetch the connections between microgrid components. Args: start: filter out any connections whose `start` does not match one of these component IDs end: filter out any connections whose `end` does not match one of these component IDs Returns: Set of the connections between components in the microgrid, filtered by the provided `start`/`end` choices. \"\"\"","title":"connections()"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid.graph.ComponentGraph.predecessors","text":"Fetch the graph predecessors of the specified component. PARAMETER DESCRIPTION component_id numerical ID of the component whose predecessors should be fetched TYPE: int RETURNS DESCRIPTION Set [ Component ] Set of IDs of the components that are predecessors of component_id , i.e. for which there is a connection from each of these components to component_id . RAISES DESCRIPTION KeyError if the specified component_id is not in the graph Source code in frequenz/sdk/microgrid/graph.py 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 @abstractmethod def predecessors ( self , component_id : int ) -> Set [ Component ]: \"\"\"Fetch the graph predecessors of the specified component. Args: component_id: numerical ID of the component whose predecessors should be fetched Returns: Set of IDs of the components that are predecessors of `component_id`, i.e. for which there is a connection from each of these components to `component_id`. Raises: KeyError: if the specified `component_id` is not in the graph \"\"\"","title":"predecessors()"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid.graph.ComponentGraph.successors","text":"Fetch the graph successors of the specified component. PARAMETER DESCRIPTION component_id numerical ID of the component whose successors should be fetched TYPE: int RETURNS DESCRIPTION Set [ Component ] Set of IDs of the components that are successors of component_id , i.e. for which there is a connection from component_id to each of these components. RAISES DESCRIPTION KeyError if the specified component_id is not in the graph Source code in frequenz/sdk/microgrid/graph.py 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 @abstractmethod def successors ( self , component_id : int ) -> Set [ Component ]: \"\"\"Fetch the graph successors of the specified component. Args: component_id: numerical ID of the component whose successors should be fetched Returns: Set of IDs of the components that are successors of `component_id`, i.e. for which there is a connection from `component_id` to each of these components. Raises: KeyError: if the specified `component_id` is not in the graph \"\"\"","title":"successors()"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid.Connection","text":"Bases: NamedTuple Metadata for a connection between microgrid components. Source code in frequenz/sdk/microgrid/connection.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 class Connection ( NamedTuple ): \"\"\"Metadata for a connection between microgrid components.\"\"\" start : int end : int def is_valid ( self ) -> bool : \"\"\"Check if this instance contains valid data. Returns: `True` if `start >= 0`, `end > 0`, and `start != end`, `False` otherwise. \"\"\" return self . start >= 0 and self . end > 0 and self . start != self . end","title":"Connection"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid.Connection-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid.connection.Connection.is_valid","text":"Check if this instance contains valid data. RETURNS DESCRIPTION bool True if start >= 0 , end > 0 , and start != end , False otherwise. Source code in frequenz/sdk/microgrid/connection.py 15 16 17 18 19 20 21 22 def is_valid ( self ) -> bool : \"\"\"Check if this instance contains valid data. Returns: `True` if `start >= 0`, `end > 0`, and `start != end`, `False` otherwise. \"\"\" return self . start >= 0 and self . end > 0 and self . start != self . end","title":"is_valid()"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid.EVChargerData","text":"Bases: ComponentData A wrapper class for holding ev_charger data. ATTRIBUTE DESCRIPTION active_power_consumption the 3-phase active power, in Watts, represented in the passive sign convention. +ve current means consumption, away from the grid. -ve current means supply into the grid. current_per_phase AC current in Amperes (A) for phase/line 1,2 and 3 respectively. +ve current means consumption, away from the grid. -ve current means supply into the grid. TYPE: Tuple [ float , float , float ] voltage_per_phase the AC voltage in Volts (V) between the line and the neutral wire for phase/line 1,2 and 3 respectively. TYPE: Tuple [ float , float , float ] cable_state the state of the ev charger's cable TYPE: EVChargerCableState Source code in frequenz/sdk/microgrid/component_data.py 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 @dataclass ( frozen = True ) class EVChargerData ( ComponentData ): \"\"\"A wrapper class for holding ev_charger data. Attributes: active_power_consumption: the 3-phase active power, in Watts, represented in the passive sign convention. +ve current means consumption, away from the grid. -ve current means supply into the grid. current_per_phase: AC current in Amperes (A) for phase/line 1,2 and 3 respectively. +ve current means consumption, away from the grid. -ve current means supply into the grid. voltage_per_phase: the AC voltage in Volts (V) between the line and the neutral wire for phase/line 1,2 and 3 respectively. cable_state: the state of the ev charger's cable \"\"\" active_power : float current_per_phase : Tuple [ float , float , float ] voltage_per_phase : Tuple [ float , float , float ] cable_state : EVChargerCableState @classmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> EVChargerData : \"\"\"Create EVChargerData from a protobuf message. Args: raw: raw component data as decoded from the wire. Returns: Instance of EVChargerData created from the protobuf message. \"\"\" ev_charger_data = cls ( component_id = raw . id , timestamp = raw . ts . ToDatetime ( tzinfo = pytz . UTC ), active_power = raw . ev_charger . data . ac . power_active . value , current_per_phase = ( raw . ev_charger . data . ac . phase_1 . current . value , raw . ev_charger . data . ac . phase_2 . current . value , raw . ev_charger . data . ac . phase_3 . current . value , ), voltage_per_phase = ( raw . ev_charger . data . ac . phase_1 . voltage . value , raw . ev_charger . data . ac . phase_2 . voltage . value , raw . ev_charger . data . ac . phase_3 . voltage . value , ), cable_state = EVChargerCableState . from_pb ( raw . ev_charger . state . cable_state ), ) ev_charger_data . _set_raw ( raw = raw ) return ev_charger_data","title":"EVChargerData"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid.EVChargerData-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid.component_data.EVChargerData.from_proto","text":"Create EVChargerData from a protobuf message. PARAMETER DESCRIPTION raw raw component data as decoded from the wire. TYPE: microgrid_pb . ComponentData RETURNS DESCRIPTION EVChargerData Instance of EVChargerData created from the protobuf message. Source code in frequenz/sdk/microgrid/component_data.py 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 @classmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> EVChargerData : \"\"\"Create EVChargerData from a protobuf message. Args: raw: raw component data as decoded from the wire. Returns: Instance of EVChargerData created from the protobuf message. \"\"\" ev_charger_data = cls ( component_id = raw . id , timestamp = raw . ts . ToDatetime ( tzinfo = pytz . UTC ), active_power = raw . ev_charger . data . ac . power_active . value , current_per_phase = ( raw . ev_charger . data . ac . phase_1 . current . value , raw . ev_charger . data . ac . phase_2 . current . value , raw . ev_charger . data . ac . phase_3 . current . value , ), voltage_per_phase = ( raw . ev_charger . data . ac . phase_1 . voltage . value , raw . ev_charger . data . ac . phase_2 . voltage . value , raw . ev_charger . data . ac . phase_3 . voltage . value , ), cable_state = EVChargerCableState . from_pb ( raw . ev_charger . state . cable_state ), ) ev_charger_data . _set_raw ( raw = raw ) return ev_charger_data","title":"from_proto()"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid.InverterData","text":"Bases: ComponentData A wrapper class for holding inverter data. ATTRIBUTE DESCRIPTION active_power the 3-phase active power, in Watts, represented in the passive sign convention. +ve current means consumption, away from the grid. -ve current means supply into the grid. TYPE: float active_power_lower_bound the maximum discharge power, in Watts, represented in the passive sign convention. This will be a negative number, or zero if no discharging is possible. TYPE: float active_power_upper_bound the maximum charge power, in Watts, represented in the passive sign convention. This will be a positive number, or zero if no charging is possible. TYPE: float Source code in frequenz/sdk/microgrid/component_data.py 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 @dataclass ( frozen = True ) class InverterData ( ComponentData ): \"\"\"A wrapper class for holding inverter data. Attributes: active_power: the 3-phase active power, in Watts, represented in the passive sign convention. +ve current means consumption, away from the grid. -ve current means supply into the grid. active_power_lower_bound: the maximum discharge power, in Watts, represented in the passive sign convention. This will be a negative number, or zero if no discharging is possible. active_power_upper_bound: the maximum charge power, in Watts, represented in the passive sign convention. This will be a positive number, or zero if no charging is possible. \"\"\" active_power : float active_power_lower_bound : float active_power_upper_bound : float @classmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> InverterData : \"\"\"Create InverterData from a protobuf message. Args: raw: raw component data as decoded from the wire. Returns: Instance of InverterData created from the protobuf message. \"\"\" inverter_data = cls ( component_id = raw . id , timestamp = raw . ts . ToDatetime ( tzinfo = pytz . UTC ), active_power = raw . inverter . data . ac . power_active . value , active_power_lower_bound = raw . inverter . data . ac . power_active . system_bounds . lower , active_power_upper_bound = raw . inverter . data . ac . power_active . system_bounds . upper , ) inverter_data . _set_raw ( raw = raw ) return inverter_data","title":"InverterData"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid.InverterData-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid.component_data.InverterData.from_proto","text":"Create InverterData from a protobuf message. PARAMETER DESCRIPTION raw raw component data as decoded from the wire. TYPE: microgrid_pb . ComponentData RETURNS DESCRIPTION InverterData Instance of InverterData created from the protobuf message. Source code in frequenz/sdk/microgrid/component_data.py 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 @classmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> InverterData : \"\"\"Create InverterData from a protobuf message. Args: raw: raw component data as decoded from the wire. Returns: Instance of InverterData created from the protobuf message. \"\"\" inverter_data = cls ( component_id = raw . id , timestamp = raw . ts . ToDatetime ( tzinfo = pytz . UTC ), active_power = raw . inverter . data . ac . power_active . value , active_power_lower_bound = raw . inverter . data . ac . power_active . system_bounds . lower , active_power_upper_bound = raw . inverter . data . ac . power_active . system_bounds . upper , ) inverter_data . _set_raw ( raw = raw ) return inverter_data","title":"from_proto()"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid.MeterData","text":"Bases: ComponentData A wrapper class for holding meter data. ATTRIBUTE DESCRIPTION active_power the 3-phase active power, in Watts, represented in the passive sign convention. +ve current means consumption, away from the grid. -ve current means supply into the grid. TYPE: float current_per_phase AC current in Amperes (A) for phase/line 1,2 and 3 respectively. +ve current means consumption, away from the grid. -ve current means supply into the grid. TYPE: Tuple [ float , float , float ] voltage_per_phase the AC voltage in Volts (V) between the line and the neutral wire for phase/line 1,2 and 3 respectively. TYPE: Tuple [ float , float , float ] Source code in frequenz/sdk/microgrid/component_data.py 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 @dataclass ( frozen = True ) class MeterData ( ComponentData ): \"\"\"A wrapper class for holding meter data. Attributes: active_power: the 3-phase active power, in Watts, represented in the passive sign convention. +ve current means consumption, away from the grid. -ve current means supply into the grid. current_per_phase: AC current in Amperes (A) for phase/line 1,2 and 3 respectively. +ve current means consumption, away from the grid. -ve current means supply into the grid. voltage_per_phase: the AC voltage in Volts (V) between the line and the neutral wire for phase/line 1,2 and 3 respectively. \"\"\" active_power : float current_per_phase : Tuple [ float , float , float ] voltage_per_phase : Tuple [ float , float , float ] @classmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> MeterData : \"\"\"Create MeterData from a protobuf message. Args: raw: raw component data as decoded from the wire. Returns: Instance of MeterData created from the protobuf message. \"\"\" meter_data = cls ( component_id = raw . id , timestamp = raw . ts . ToDatetime ( tzinfo = pytz . UTC ), active_power = raw . meter . data . ac . power_active . value , current_per_phase = ( raw . meter . data . ac . phase_1 . current . value , raw . meter . data . ac . phase_2 . current . value , raw . meter . data . ac . phase_3 . current . value , ), voltage_per_phase = ( raw . meter . data . ac . phase_1 . voltage . value , raw . meter . data . ac . phase_2 . voltage . value , raw . meter . data . ac . phase_3 . voltage . value , ), ) meter_data . _set_raw ( raw = raw ) return meter_data","title":"MeterData"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid.MeterData-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid.component_data.MeterData.from_proto","text":"Create MeterData from a protobuf message. PARAMETER DESCRIPTION raw raw component data as decoded from the wire. TYPE: microgrid_pb . ComponentData RETURNS DESCRIPTION MeterData Instance of MeterData created from the protobuf message. Source code in frequenz/sdk/microgrid/component_data.py 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 @classmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> MeterData : \"\"\"Create MeterData from a protobuf message. Args: raw: raw component data as decoded from the wire. Returns: Instance of MeterData created from the protobuf message. \"\"\" meter_data = cls ( component_id = raw . id , timestamp = raw . ts . ToDatetime ( tzinfo = pytz . UTC ), active_power = raw . meter . data . ac . power_active . value , current_per_phase = ( raw . meter . data . ac . phase_1 . current . value , raw . meter . data . ac . phase_2 . current . value , raw . meter . data . ac . phase_3 . current . value , ), voltage_per_phase = ( raw . meter . data . ac . phase_1 . voltage . value , raw . meter . data . ac . phase_2 . voltage . value , raw . meter . data . ac . phase_3 . voltage . value , ), ) meter_data . _set_raw ( raw = raw ) return meter_data","title":"from_proto()"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid.MicrogridApi","text":"Bases: ABC Creates and stores core features. Source code in frequenz/sdk/microgrid/microgrid_api.py 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 class MicrogridApi ( ABC ): \"\"\"Creates and stores core features.\"\"\" def __init__ ( self , host : str , port : int ) -> None : \"\"\"Create object instance. Args: host: server host port: server port \"\"\" super () . __init__ () self . _host : str = host self . _port : int = port @property def host ( self ) -> str : \"\"\"Get host of the currently connected server. Returns: host \"\"\" return self . _host @property def port ( self ) -> int : \"\"\"Get port of the currently connected server. Returns: port \"\"\" return self . _port @property @abstractmethod def microgrid_api_client ( self ) -> MicrogridApiClient : \"\"\"Get MicrogridApiClient. Returns: api client \"\"\" @property @abstractmethod def component_graph ( self ) -> ComponentGraph : \"\"\"Get component graph. Returns: component graph \"\"\" async def _update_api ( self , host : str , port : int ) -> None : self . _host = host self . _port = port @abstractmethod async def _initialize ( self ) -> None : \"\"\"Initialize the object. This function should be called only once.\"\"\"","title":"MicrogridApi"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid.MicrogridApi-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid.microgrid_api.MicrogridApi.__init__","text":"Create object instance. PARAMETER DESCRIPTION host server host TYPE: str port server port TYPE: int Source code in frequenz/sdk/microgrid/microgrid_api.py 22 23 24 25 26 27 28 29 30 31 def __init__ ( self , host : str , port : int ) -> None : \"\"\"Create object instance. Args: host: server host port: server port \"\"\" super () . __init__ () self . _host : str = host self . _port : int = port","title":"__init__()"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid.microgrid_api.MicrogridApi.component_graph","text":"Get component graph. RETURNS DESCRIPTION ComponentGraph component graph Source code in frequenz/sdk/microgrid/microgrid_api.py 60 61 62 63 64 65 66 67 @property @abstractmethod def component_graph ( self ) -> ComponentGraph : \"\"\"Get component graph. Returns: component graph \"\"\"","title":"component_graph()"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid.microgrid_api.MicrogridApi.host","text":"Get host of the currently connected server. RETURNS DESCRIPTION str host Source code in frequenz/sdk/microgrid/microgrid_api.py 33 34 35 36 37 38 39 40 @property def host ( self ) -> str : \"\"\"Get host of the currently connected server. Returns: host \"\"\" return self . _host","title":"host()"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid.microgrid_api.MicrogridApi.microgrid_api_client","text":"Get MicrogridApiClient. RETURNS DESCRIPTION MicrogridApiClient api client Source code in frequenz/sdk/microgrid/microgrid_api.py 51 52 53 54 55 56 57 58 @property @abstractmethod def microgrid_api_client ( self ) -> MicrogridApiClient : \"\"\"Get MicrogridApiClient. Returns: api client \"\"\"","title":"microgrid_api_client()"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid.microgrid_api.MicrogridApi.port","text":"Get port of the currently connected server. RETURNS DESCRIPTION int port Source code in frequenz/sdk/microgrid/microgrid_api.py 42 43 44 45 46 47 48 49 @property def port ( self ) -> int : \"\"\"Get port of the currently connected server. Returns: port \"\"\" return self . _port","title":"port()"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid.MicrogridApiClient","text":"Bases: ABC Base interface for microgrid API clients to implement. Source code in frequenz/sdk/microgrid/client.py 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 class MicrogridApiClient ( ABC ): \"\"\"Base interface for microgrid API clients to implement.\"\"\" @abstractmethod async def components ( self ) -> Iterable [ Component ]: \"\"\"Fetch all the components present in the microgrid. Returns: Iterator whose elements are all the components in the microgrid. \"\"\" @abstractmethod async def connections ( self , starts : Optional [ Set [ int ]] = None , ends : Optional [ Set [ int ]] = None , ) -> Iterable [ Connection ]: \"\"\"Fetch the connections between components in the microgrid. Args: starts: if set and non-empty, only include connections whose start value matches one of the provided component IDs ends: if set and non-empty, only include connections whose end value matches one of the provided component IDs Returns: Microgrid connections matching the provided start and end filters. \"\"\" @abstractmethod async def meter_data ( self , component_id : int , ) -> Receiver [ MeterData ]: \"\"\"Return a channel receiver that provides a `MeterData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Args: component_id: id of the meter to get data for. Returns: A channel receiver that provides realtime meter data. \"\"\" @abstractmethod async def battery_data ( self , component_id : int , ) -> Receiver [ BatteryData ]: \"\"\"Return a channel receiver that provides a `BatteryData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Args: component_id: id of the battery to get data for. Returns: A channel receiver that provides realtime battery data. \"\"\" @abstractmethod async def inverter_data ( self , component_id : int , ) -> Receiver [ InverterData ]: \"\"\"Return a channel receiver that provides an `InverterData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Args: component_id: id of the inverter to get data for. Returns: A channel receiver that provides realtime inverter data. \"\"\" @abstractmethod async def ev_charger_data ( self , component_id : int , ) -> Receiver [ EVChargerData ]: \"\"\"Return a channel receiver that provides an `EvChargeData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Args: component_id: id of the ev charger to get data for. Returns: A channel receiver that provides realtime ev charger data. \"\"\" @abstractmethod async def set_power ( self , component_id : int , power_w : int ) -> Empty : \"\"\"Send request to the Microgrid to set power for component. If power > 0, then component will be charged with this power. If power < 0, then component will be discharged with this power. If power == 0, then stop charging or discharging component. Args: component_id: id of the component to set power. power_w: power to set for the component. Returns: Empty response. \"\"\" @abstractmethod async def set_bounds ( self , component_id : int , lower : float , upper : float ) -> None : \"\"\"Send `SetBoundsParam`s received from a channel to nitrogen. Args: component_id: ID of the component to set bounds for. lower: Lower bound to be set for the component. upper: Upper bound to be set for the component. \"\"\"","title":"MicrogridApiClient"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid.MicrogridApiClient-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid.client.MicrogridApiClient.battery_data","text":"Return a channel receiver that provides a BatteryData stream. If only the latest value is required, the Receiver returned by this method can be converted into a Peekable with the into_peekable method on the Receiver. PARAMETER DESCRIPTION component_id id of the battery to get data for. TYPE: int RETURNS DESCRIPTION Receiver [ BatteryData ] A channel receiver that provides realtime battery data. Source code in frequenz/sdk/microgrid/client.py 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 @abstractmethod async def battery_data ( self , component_id : int , ) -> Receiver [ BatteryData ]: \"\"\"Return a channel receiver that provides a `BatteryData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Args: component_id: id of the battery to get data for. Returns: A channel receiver that provides realtime battery data. \"\"\"","title":"battery_data()"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid.client.MicrogridApiClient.components","text":"Fetch all the components present in the microgrid. RETURNS DESCRIPTION Iterable [ Component ] Iterator whose elements are all the components in the microgrid. Source code in frequenz/sdk/microgrid/client.py 43 44 45 46 47 48 49 @abstractmethod async def components ( self ) -> Iterable [ Component ]: \"\"\"Fetch all the components present in the microgrid. Returns: Iterator whose elements are all the components in the microgrid. \"\"\"","title":"components()"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid.client.MicrogridApiClient.connections","text":"Fetch the connections between components in the microgrid. PARAMETER DESCRIPTION starts if set and non-empty, only include connections whose start value matches one of the provided component IDs TYPE: Optional [ Set [ int ]] DEFAULT: None ends if set and non-empty, only include connections whose end value matches one of the provided component IDs TYPE: Optional [ Set [ int ]] DEFAULT: None RETURNS DESCRIPTION Iterable [ Connection ] Microgrid connections matching the provided start and end filters. Source code in frequenz/sdk/microgrid/client.py 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 @abstractmethod async def connections ( self , starts : Optional [ Set [ int ]] = None , ends : Optional [ Set [ int ]] = None , ) -> Iterable [ Connection ]: \"\"\"Fetch the connections between components in the microgrid. Args: starts: if set and non-empty, only include connections whose start value matches one of the provided component IDs ends: if set and non-empty, only include connections whose end value matches one of the provided component IDs Returns: Microgrid connections matching the provided start and end filters. \"\"\"","title":"connections()"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid.client.MicrogridApiClient.ev_charger_data","text":"Return a channel receiver that provides an EvChargeData stream. If only the latest value is required, the Receiver returned by this method can be converted into a Peekable with the into_peekable method on the Receiver. PARAMETER DESCRIPTION component_id id of the ev charger to get data for. TYPE: int RETURNS DESCRIPTION Receiver [ EVChargerData ] A channel receiver that provides realtime ev charger data. Source code in frequenz/sdk/microgrid/client.py 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 @abstractmethod async def ev_charger_data ( self , component_id : int , ) -> Receiver [ EVChargerData ]: \"\"\"Return a channel receiver that provides an `EvChargeData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Args: component_id: id of the ev charger to get data for. Returns: A channel receiver that provides realtime ev charger data. \"\"\"","title":"ev_charger_data()"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid.client.MicrogridApiClient.inverter_data","text":"Return a channel receiver that provides an InverterData stream. If only the latest value is required, the Receiver returned by this method can be converted into a Peekable with the into_peekable method on the Receiver. PARAMETER DESCRIPTION component_id id of the inverter to get data for. TYPE: int RETURNS DESCRIPTION Receiver [ InverterData ] A channel receiver that provides realtime inverter data. Source code in frequenz/sdk/microgrid/client.py 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 @abstractmethod async def inverter_data ( self , component_id : int , ) -> Receiver [ InverterData ]: \"\"\"Return a channel receiver that provides an `InverterData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Args: component_id: id of the inverter to get data for. Returns: A channel receiver that provides realtime inverter data. \"\"\"","title":"inverter_data()"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid.client.MicrogridApiClient.meter_data","text":"Return a channel receiver that provides a MeterData stream. If only the latest value is required, the Receiver returned by this method can be converted into a Peekable with the into_peekable method on the Receiver. PARAMETER DESCRIPTION component_id id of the meter to get data for. TYPE: int RETURNS DESCRIPTION Receiver [ MeterData ] A channel receiver that provides realtime meter data. Source code in frequenz/sdk/microgrid/client.py 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 @abstractmethod async def meter_data ( self , component_id : int , ) -> Receiver [ MeterData ]: \"\"\"Return a channel receiver that provides a `MeterData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Args: component_id: id of the meter to get data for. Returns: A channel receiver that provides realtime meter data. \"\"\"","title":"meter_data()"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid.client.MicrogridApiClient.set_bounds","text":"Send SetBoundsParam s received from a channel to nitrogen. PARAMETER DESCRIPTION component_id ID of the component to set bounds for. TYPE: int lower Lower bound to be set for the component. TYPE: float upper Upper bound to be set for the component. TYPE: float Source code in frequenz/sdk/microgrid/client.py 158 159 160 161 162 163 164 165 166 @abstractmethod async def set_bounds ( self , component_id : int , lower : float , upper : float ) -> None : \"\"\"Send `SetBoundsParam`s received from a channel to nitrogen. Args: component_id: ID of the component to set bounds for. lower: Lower bound to be set for the component. upper: Upper bound to be set for the component. \"\"\"","title":"set_bounds()"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid.client.MicrogridApiClient.set_power","text":"Send request to the Microgrid to set power for component. If power > 0, then component will be charged with this power. If power < 0, then component will be discharged with this power. If power == 0, then stop charging or discharging component. PARAMETER DESCRIPTION component_id id of the component to set power. TYPE: int power_w power to set for the component. TYPE: int RETURNS DESCRIPTION Empty Empty response. Source code in frequenz/sdk/microgrid/client.py 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 @abstractmethod async def set_power ( self , component_id : int , power_w : int ) -> Empty : \"\"\"Send request to the Microgrid to set power for component. If power > 0, then component will be charged with this power. If power < 0, then component will be discharged with this power. If power == 0, then stop charging or discharging component. Args: component_id: id of the component to set power. power_w: power to set for the component. Returns: Empty response. \"\"\"","title":"set_power()"},{"location":"reference/frequenz/sdk/microgrid/client/","text":"frequenz.sdk.microgrid.client \u00a4 Client for requests to the Microgrid API. Classes \u00a4 frequenz.sdk.microgrid.client.MicrogridApiClient \u00a4 Bases: ABC Base interface for microgrid API clients to implement. Source code in frequenz/sdk/microgrid/client.py 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 class MicrogridApiClient ( ABC ): \"\"\"Base interface for microgrid API clients to implement.\"\"\" @abstractmethod async def components ( self ) -> Iterable [ Component ]: \"\"\"Fetch all the components present in the microgrid. Returns: Iterator whose elements are all the components in the microgrid. \"\"\" @abstractmethod async def connections ( self , starts : Optional [ Set [ int ]] = None , ends : Optional [ Set [ int ]] = None , ) -> Iterable [ Connection ]: \"\"\"Fetch the connections between components in the microgrid. Args: starts: if set and non-empty, only include connections whose start value matches one of the provided component IDs ends: if set and non-empty, only include connections whose end value matches one of the provided component IDs Returns: Microgrid connections matching the provided start and end filters. \"\"\" @abstractmethod async def meter_data ( self , component_id : int , ) -> Receiver [ MeterData ]: \"\"\"Return a channel receiver that provides a `MeterData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Args: component_id: id of the meter to get data for. Returns: A channel receiver that provides realtime meter data. \"\"\" @abstractmethod async def battery_data ( self , component_id : int , ) -> Receiver [ BatteryData ]: \"\"\"Return a channel receiver that provides a `BatteryData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Args: component_id: id of the battery to get data for. Returns: A channel receiver that provides realtime battery data. \"\"\" @abstractmethod async def inverter_data ( self , component_id : int , ) -> Receiver [ InverterData ]: \"\"\"Return a channel receiver that provides an `InverterData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Args: component_id: id of the inverter to get data for. Returns: A channel receiver that provides realtime inverter data. \"\"\" @abstractmethod async def ev_charger_data ( self , component_id : int , ) -> Receiver [ EVChargerData ]: \"\"\"Return a channel receiver that provides an `EvChargeData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Args: component_id: id of the ev charger to get data for. Returns: A channel receiver that provides realtime ev charger data. \"\"\" @abstractmethod async def set_power ( self , component_id : int , power_w : int ) -> Empty : \"\"\"Send request to the Microgrid to set power for component. If power > 0, then component will be charged with this power. If power < 0, then component will be discharged with this power. If power == 0, then stop charging or discharging component. Args: component_id: id of the component to set power. power_w: power to set for the component. Returns: Empty response. \"\"\" @abstractmethod async def set_bounds ( self , component_id : int , lower : float , upper : float ) -> None : \"\"\"Send `SetBoundsParam`s received from a channel to nitrogen. Args: component_id: ID of the component to set bounds for. lower: Lower bound to be set for the component. upper: Upper bound to be set for the component. \"\"\" Functions \u00a4 battery_data ( component_id ) async abstractmethod \u00a4 Return a channel receiver that provides a BatteryData stream. If only the latest value is required, the Receiver returned by this method can be converted into a Peekable with the into_peekable method on the Receiver. PARAMETER DESCRIPTION component_id id of the battery to get data for. TYPE: int RETURNS DESCRIPTION Receiver [ BatteryData ] A channel receiver that provides realtime battery data. Source code in frequenz/sdk/microgrid/client.py 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 @abstractmethod async def battery_data ( self , component_id : int , ) -> Receiver [ BatteryData ]: \"\"\"Return a channel receiver that provides a `BatteryData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Args: component_id: id of the battery to get data for. Returns: A channel receiver that provides realtime battery data. \"\"\" components () async abstractmethod \u00a4 Fetch all the components present in the microgrid. RETURNS DESCRIPTION Iterable [ Component ] Iterator whose elements are all the components in the microgrid. Source code in frequenz/sdk/microgrid/client.py 43 44 45 46 47 48 49 @abstractmethod async def components ( self ) -> Iterable [ Component ]: \"\"\"Fetch all the components present in the microgrid. Returns: Iterator whose elements are all the components in the microgrid. \"\"\" connections ( starts = None , ends = None ) async abstractmethod \u00a4 Fetch the connections between components in the microgrid. PARAMETER DESCRIPTION starts if set and non-empty, only include connections whose start value matches one of the provided component IDs TYPE: Optional [ Set [ int ]] DEFAULT: None ends if set and non-empty, only include connections whose end value matches one of the provided component IDs TYPE: Optional [ Set [ int ]] DEFAULT: None RETURNS DESCRIPTION Iterable [ Connection ] Microgrid connections matching the provided start and end filters. Source code in frequenz/sdk/microgrid/client.py 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 @abstractmethod async def connections ( self , starts : Optional [ Set [ int ]] = None , ends : Optional [ Set [ int ]] = None , ) -> Iterable [ Connection ]: \"\"\"Fetch the connections between components in the microgrid. Args: starts: if set and non-empty, only include connections whose start value matches one of the provided component IDs ends: if set and non-empty, only include connections whose end value matches one of the provided component IDs Returns: Microgrid connections matching the provided start and end filters. \"\"\" ev_charger_data ( component_id ) async abstractmethod \u00a4 Return a channel receiver that provides an EvChargeData stream. If only the latest value is required, the Receiver returned by this method can be converted into a Peekable with the into_peekable method on the Receiver. PARAMETER DESCRIPTION component_id id of the ev charger to get data for. TYPE: int RETURNS DESCRIPTION Receiver [ EVChargerData ] A channel receiver that provides realtime ev charger data. Source code in frequenz/sdk/microgrid/client.py 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 @abstractmethod async def ev_charger_data ( self , component_id : int , ) -> Receiver [ EVChargerData ]: \"\"\"Return a channel receiver that provides an `EvChargeData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Args: component_id: id of the ev charger to get data for. Returns: A channel receiver that provides realtime ev charger data. \"\"\" inverter_data ( component_id ) async abstractmethod \u00a4 Return a channel receiver that provides an InverterData stream. If only the latest value is required, the Receiver returned by this method can be converted into a Peekable with the into_peekable method on the Receiver. PARAMETER DESCRIPTION component_id id of the inverter to get data for. TYPE: int RETURNS DESCRIPTION Receiver [ InverterData ] A channel receiver that provides realtime inverter data. Source code in frequenz/sdk/microgrid/client.py 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 @abstractmethod async def inverter_data ( self , component_id : int , ) -> Receiver [ InverterData ]: \"\"\"Return a channel receiver that provides an `InverterData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Args: component_id: id of the inverter to get data for. Returns: A channel receiver that provides realtime inverter data. \"\"\" meter_data ( component_id ) async abstractmethod \u00a4 Return a channel receiver that provides a MeterData stream. If only the latest value is required, the Receiver returned by this method can be converted into a Peekable with the into_peekable method on the Receiver. PARAMETER DESCRIPTION component_id id of the meter to get data for. TYPE: int RETURNS DESCRIPTION Receiver [ MeterData ] A channel receiver that provides realtime meter data. Source code in frequenz/sdk/microgrid/client.py 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 @abstractmethod async def meter_data ( self , component_id : int , ) -> Receiver [ MeterData ]: \"\"\"Return a channel receiver that provides a `MeterData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Args: component_id: id of the meter to get data for. Returns: A channel receiver that provides realtime meter data. \"\"\" set_bounds ( component_id , lower , upper ) async abstractmethod \u00a4 Send SetBoundsParam s received from a channel to nitrogen. PARAMETER DESCRIPTION component_id ID of the component to set bounds for. TYPE: int lower Lower bound to be set for the component. TYPE: float upper Upper bound to be set for the component. TYPE: float Source code in frequenz/sdk/microgrid/client.py 158 159 160 161 162 163 164 165 166 @abstractmethod async def set_bounds ( self , component_id : int , lower : float , upper : float ) -> None : \"\"\"Send `SetBoundsParam`s received from a channel to nitrogen. Args: component_id: ID of the component to set bounds for. lower: Lower bound to be set for the component. upper: Upper bound to be set for the component. \"\"\" set_power ( component_id , power_w ) async abstractmethod \u00a4 Send request to the Microgrid to set power for component. If power > 0, then component will be charged with this power. If power < 0, then component will be discharged with this power. If power == 0, then stop charging or discharging component. PARAMETER DESCRIPTION component_id id of the component to set power. TYPE: int power_w power to set for the component. TYPE: int RETURNS DESCRIPTION Empty Empty response. Source code in frequenz/sdk/microgrid/client.py 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 @abstractmethod async def set_power ( self , component_id : int , power_w : int ) -> Empty : \"\"\"Send request to the Microgrid to set power for component. If power > 0, then component will be charged with this power. If power < 0, then component will be discharged with this power. If power == 0, then stop charging or discharging component. Args: component_id: id of the component to set power. power_w: power to set for the component. Returns: Empty response. \"\"\" frequenz.sdk.microgrid.client.MicrogridGrpcClient \u00a4 Bases: MicrogridApiClient Microgrid API client implementation using gRPC as the underlying protocol. Source code in frequenz/sdk/microgrid/client.py 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 class MicrogridGrpcClient ( MicrogridApiClient ): \"\"\"Microgrid API client implementation using gRPC as the underlying protocol.\"\"\" def __init__ ( self , grpc_channel : grpc . aio . Channel , target : str , retry_spec : RetryStrategy = LinearBackoff (), ) -> None : \"\"\"Initialize the class instance. Args: grpc_channel: asyncio-supporting gRPC channel target: server (host:port) to be used for asyncio-supporting gRPC channel that the client should use to contact the API retry_spec: Specs on how to retry if the connection to a streaming method gets lost. \"\"\" self . target = target self . api = MicrogridStub ( grpc_channel ) self . _component_streams : Dict [ int , Broadcast [ Any ]] = {} self . _retry_spec = retry_spec async def components ( self ) -> Iterable [ Component ]: \"\"\"Fetch all the components present in the microgrid. Returns: Iterator whose elements are all the components in the microgrid. Raises: AioRpcError: if connection to Microgrid API cannot be established or when the api call exceeded timeout \"\"\" try : component_list = await self . api . ListComponents ( microgrid_pb . ComponentFilter (), timeout = DEFAULT_GRPC_CALL_TIMEOUT , ) except grpc . aio . AioRpcError as err : msg = f \"Failed to list components. Microgrid API: { self . target } . Err: { err . details () } \" raise grpc . aio . AioRpcError ( code = err . code (), initial_metadata = err . initial_metadata (), trailing_metadata = err . trailing_metadata (), details = msg , debug_error_string = err . debug_error_string (), ) components_only = filter ( lambda c : c . category not in ( microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_SENSOR , microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_LOAD , ), component_list . components , ) result : Iterable [ Component ] = map ( lambda c : Component ( c . id , _component_category_from_protobuf ( c . category )), components_only , ) return result async def connections ( self , starts : Optional [ Set [ int ]] = None , ends : Optional [ Set [ int ]] = None , ) -> Iterable [ Connection ]: \"\"\"Fetch the connections between components in the microgrid. Args: starts: if set and non-empty, only include connections whose start value matches one of the provided component IDs ends: if set and non-empty, only include connections whose end value matches one of the provided component IDs Returns: Microgrid connections matching the provided start and end filters. Raises: AioRpcError: if connection to Microgrid API cannot be established or when the api call exceeded timeout \"\"\" connection_filter = microgrid_pb . ConnectionFilter ( starts = starts , ends = ends ) try : valid_components , all_connections = await asyncio . gather ( self . components (), self . api . ListConnections ( connection_filter , timeout = DEFAULT_GRPC_CALL_TIMEOUT ), ) except grpc . aio . AioRpcError as err : msg = f \"Failed to list connections. Microgrid API: { self . target } . Err: { err . details () } \" raise grpc . aio . AioRpcError ( code = err . code (), initial_metadata = err . initial_metadata (), trailing_metadata = err . trailing_metadata (), details = msg , debug_error_string = err . debug_error_string (), ) # Filter out the components filtered in `components` method. # id=0 is an exception indicating grid component. valid_ids = { c . component_id for c in valid_components } valid_ids . add ( 0 ) connections = filter ( lambda c : ( c . start in valid_ids and c . end in valid_ids ), all_connections . connections , ) result : Iterable [ Connection ] = map ( lambda c : Connection ( c . start , c . end ), connections ) return result async def _component_data_task ( self , component_id : int , transform : Callable [[ microgrid_pb . ComponentData ], _GenericComponentData ], sender : Sender [ _GenericComponentData ], ) -> None : \"\"\"Read data from the microgrid API and send to a channel. Args: component_id: id of the component to get data for. transform: A method for transforming raw component data into the desired output type. sender: A channel sender, to send the component data to. Raises: AioRpcError: if connection to Microgrid API cannot be established \"\"\" retry_spec : RetryStrategy = self . _retry_spec . copy () while True : logger . debug ( \"Making call to `GetComponentData`, for component_id= %d \" , component_id ) try : call = self . api . GetComponentData ( microgrid_pb . ComponentIdParam ( id = component_id ), ) async for msg in call : await sender . send ( transform ( msg )) except grpc . aio . AioRpcError as err : api_details = f \"Microgrid API: { self . target } .\" logger . exception ( \"`GetComponentData`, for component_id= %d : exception: %s api: %s \" , component_id , err , api_details , ) if interval := retry_spec . next_interval (): logger . warning ( \"`GetComponentData`, for component_id= %d : connection ended, \" \"retrying %s in %0.3f seconds.\" , component_id , retry_spec . get_progress (), interval , ) await asyncio . sleep ( interval ) # type: ignore else : logger . warning ( \"`GetComponentData`, for component_id= %d : connection ended, \" \"retry limit exceeded %s .\" , component_id , retry_spec . get_progress (), ) break def _get_component_data_channel ( self , component_id : int , transform : Callable [[ microgrid_pb . ComponentData ], _GenericComponentData ], ) -> Broadcast [ _GenericComponentData ]: \"\"\"Return the broadcast channel for a given component_id. If a broadcast channel for the given component_id doesn't exist, create a new channel and a task for reading data from the microgrid api and sending them to the channel. Args: component_id: id of the component to get data for. transform: A method for transforming raw component data into the desired output type. Returns: The channel for the given component_id. \"\"\" if component_id in self . _component_streams : return self . _component_streams [ component_id ] task_name = f \"raw-component-data- { component_id } \" chan = Broadcast [ _GenericComponentData ]( task_name ) self . _component_streams [ component_id ] = chan asyncio . create_task ( self . _component_data_task ( component_id , transform , chan . new_sender (), ), name = task_name , ) return chan async def _expect_category ( self , component_id : int , expected_category : ComponentCategory , ) -> None : \"\"\"Check if the given component_id is of the expected type. Raises: ValueError: if the given id is unknown or has a different type. Args: component_id: Component id to check. expected_category: Component category that the given id is expected to have. \"\"\" try : comp = next ( comp for comp in await self . components () if comp . component_id == component_id ) except StopIteration as exc : raise ValueError ( f \"Unable to find component with id { component_id } \" ) from exc if comp . category != expected_category : raise ValueError ( f \"Component id { component_id } is a { comp . category } \" f \", not a { expected_category } .\" ) async def meter_data ( self , component_id : int , ) -> Receiver [ MeterData ]: \"\"\"Return a channel receiver that provides a `MeterData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Raises: ValueError: if the given id is unknown or has a different type. Args: component_id: id of the meter to get data for. Returns: A channel receiver that provides realtime meter data. \"\"\" await self . _expect_category ( component_id , ComponentCategory . METER , ) return self . _get_component_data_channel ( component_id , MeterData . from_proto , ) . new_receiver () async def battery_data ( self , component_id : int , ) -> Receiver [ BatteryData ]: \"\"\"Return a channel receiver that provides a `BatteryData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Raises: ValueError: if the given id is unknown or has a different type. Args: component_id: id of the battery to get data for. Returns: A channel receiver that provides realtime battery data. \"\"\" await self . _expect_category ( component_id , ComponentCategory . BATTERY , ) return self . _get_component_data_channel ( component_id , BatteryData . from_proto , ) . new_receiver () async def inverter_data ( self , component_id : int , ) -> Receiver [ InverterData ]: \"\"\"Return a channel receiver that provides an `InverterData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Raises: ValueError: if the given id is unknown or has a different type. Args: component_id: id of the inverter to get data for. Returns: A channel receiver that provides realtime inverter data. \"\"\" await self . _expect_category ( component_id , ComponentCategory . INVERTER , ) return self . _get_component_data_channel ( component_id , InverterData . from_proto , ) . new_receiver () async def ev_charger_data ( self , component_id : int , ) -> Receiver [ EVChargerData ]: \"\"\"Return a channel receiver that provides an `EvChargeData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Raises: ValueError: if the given id is unknown or has a different type. Args: component_id: id of the ev charger to get data for. Returns: A channel receiver that provides realtime ev charger data. \"\"\" await self . _expect_category ( component_id , ComponentCategory . EV_CHARGER , ) return self . _get_component_data_channel ( component_id , EVChargerData . from_proto , ) . new_receiver () async def set_power ( self , component_id : int , power_w : int ) -> Empty : \"\"\"Send request to the Microgrid to set power for component. If power > 0, then component will be charged with this power. If power < 0, then component will be discharged with this power. If power == 0, then stop charging or discharging component. Args: component_id: id of the component to set power. power_w: power to set for the component. Returns: Empty response. Raises: AioRpcError: if connection to Microgrid API cannot be established or when the api call exceeded timeout \"\"\" try : if power_w >= 0 : result : Empty = await self . api . Charge ( microgrid_pb . PowerLevelParam ( component_id = component_id , power_w = power_w ), timeout = DEFAULT_GRPC_CALL_TIMEOUT , ) else : power_w *= - 1 result = await self . api . Discharge ( microgrid_pb . PowerLevelParam ( component_id = component_id , power_w = power_w ), timeout = DEFAULT_GRPC_CALL_TIMEOUT , ) except grpc . aio . AioRpcError as err : msg = f \"Failed to set power. Microgrid API: { self . target } . Err: { err . details () } \" raise grpc . aio . AioRpcError ( code = err . code (), initial_metadata = err . initial_metadata (), trailing_metadata = err . trailing_metadata (), details = msg , debug_error_string = err . debug_error_string (), ) return result async def set_bounds ( self , component_id : int , lower : float , upper : float , ) -> None : \"\"\"Send `SetBoundsParam`s received from a channel to nitrogen. Args: component_id: ID of the component to set bounds for. lower: Lower bound to be set for the component. upper: Upper bound to be set for the component. Raises: ValueError: when upper bound is less than 0, or when lower bound is greater than 0. grpc.aio.AioRpcError: if connection to Microgrid API cannot be established or when the api call exceeded timeout \"\"\" api_details = f \"Microgrid API: { self . target } .\" if upper < 0 : raise ValueError ( f \"Upper bound { upper } must be greater than or equal to 0.\" ) if lower > 0 : raise ValueError ( f \"Lower bound { upper } must be less than or equal to 0.\" ) set_bounds_call = self . api . SetBounds ( timeout = DEFAULT_GRPC_CALL_TIMEOUT ) try : await set_bounds_call . write ( microgrid_pb . SetBoundsParam ( component_id = component_id , # pylint: disable=no-member,line-too-long target_metric = microgrid_pb . SetBoundsParam . TargetMetric . TARGET_METRIC_POWER_ACTIVE , bounds = common_pb . Bounds ( lower = lower , upper = upper ), ), ) except grpc . aio . AioRpcError as err : logger . error ( \"set_bounds write failed: %s , for message: %s , api: %s . Err: %s \" , err , next , api_details , err . details (), ) raise Functions \u00a4 __init__ ( grpc_channel , target , retry_spec = LinearBackoff ()) \u00a4 Initialize the class instance. PARAMETER DESCRIPTION grpc_channel asyncio-supporting gRPC channel TYPE: grpc . aio . Channel target server (host:port) to be used for asyncio-supporting gRPC channel that the client should use to contact the API TYPE: str retry_spec Specs on how to retry if the connection to a streaming method gets lost. TYPE: RetryStrategy DEFAULT: LinearBackoff() Source code in frequenz/sdk/microgrid/client.py 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 def __init__ ( self , grpc_channel : grpc . aio . Channel , target : str , retry_spec : RetryStrategy = LinearBackoff (), ) -> None : \"\"\"Initialize the class instance. Args: grpc_channel: asyncio-supporting gRPC channel target: server (host:port) to be used for asyncio-supporting gRPC channel that the client should use to contact the API retry_spec: Specs on how to retry if the connection to a streaming method gets lost. \"\"\" self . target = target self . api = MicrogridStub ( grpc_channel ) self . _component_streams : Dict [ int , Broadcast [ Any ]] = {} self . _retry_spec = retry_spec battery_data ( component_id ) async \u00a4 Return a channel receiver that provides a BatteryData stream. If only the latest value is required, the Receiver returned by this method can be converted into a Peekable with the into_peekable method on the Receiver. RAISES DESCRIPTION ValueError if the given id is unknown or has a different type. PARAMETER DESCRIPTION component_id id of the battery to get data for. TYPE: int RETURNS DESCRIPTION Receiver [ BatteryData ] A channel receiver that provides realtime battery data. Source code in frequenz/sdk/microgrid/client.py 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 async def battery_data ( self , component_id : int , ) -> Receiver [ BatteryData ]: \"\"\"Return a channel receiver that provides a `BatteryData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Raises: ValueError: if the given id is unknown or has a different type. Args: component_id: id of the battery to get data for. Returns: A channel receiver that provides realtime battery data. \"\"\" await self . _expect_category ( component_id , ComponentCategory . BATTERY , ) return self . _get_component_data_channel ( component_id , BatteryData . from_proto , ) . new_receiver () components () async \u00a4 Fetch all the components present in the microgrid. RETURNS DESCRIPTION Iterable [ Component ] Iterator whose elements are all the components in the microgrid. RAISES DESCRIPTION AioRpcError if connection to Microgrid API cannot be established or when the api call exceeded timeout Source code in frequenz/sdk/microgrid/client.py 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 async def components ( self ) -> Iterable [ Component ]: \"\"\"Fetch all the components present in the microgrid. Returns: Iterator whose elements are all the components in the microgrid. Raises: AioRpcError: if connection to Microgrid API cannot be established or when the api call exceeded timeout \"\"\" try : component_list = await self . api . ListComponents ( microgrid_pb . ComponentFilter (), timeout = DEFAULT_GRPC_CALL_TIMEOUT , ) except grpc . aio . AioRpcError as err : msg = f \"Failed to list components. Microgrid API: { self . target } . Err: { err . details () } \" raise grpc . aio . AioRpcError ( code = err . code (), initial_metadata = err . initial_metadata (), trailing_metadata = err . trailing_metadata (), details = msg , debug_error_string = err . debug_error_string (), ) components_only = filter ( lambda c : c . category not in ( microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_SENSOR , microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_LOAD , ), component_list . components , ) result : Iterable [ Component ] = map ( lambda c : Component ( c . id , _component_category_from_protobuf ( c . category )), components_only , ) return result connections ( starts = None , ends = None ) async \u00a4 Fetch the connections between components in the microgrid. PARAMETER DESCRIPTION starts if set and non-empty, only include connections whose start value matches one of the provided component IDs TYPE: Optional [ Set [ int ]] DEFAULT: None ends if set and non-empty, only include connections whose end value matches one of the provided component IDs TYPE: Optional [ Set [ int ]] DEFAULT: None RETURNS DESCRIPTION Iterable [ Connection ] Microgrid connections matching the provided start and end filters. RAISES DESCRIPTION AioRpcError if connection to Microgrid API cannot be established or when the api call exceeded timeout Source code in frequenz/sdk/microgrid/client.py 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 async def connections ( self , starts : Optional [ Set [ int ]] = None , ends : Optional [ Set [ int ]] = None , ) -> Iterable [ Connection ]: \"\"\"Fetch the connections between components in the microgrid. Args: starts: if set and non-empty, only include connections whose start value matches one of the provided component IDs ends: if set and non-empty, only include connections whose end value matches one of the provided component IDs Returns: Microgrid connections matching the provided start and end filters. Raises: AioRpcError: if connection to Microgrid API cannot be established or when the api call exceeded timeout \"\"\" connection_filter = microgrid_pb . ConnectionFilter ( starts = starts , ends = ends ) try : valid_components , all_connections = await asyncio . gather ( self . components (), self . api . ListConnections ( connection_filter , timeout = DEFAULT_GRPC_CALL_TIMEOUT ), ) except grpc . aio . AioRpcError as err : msg = f \"Failed to list connections. Microgrid API: { self . target } . Err: { err . details () } \" raise grpc . aio . AioRpcError ( code = err . code (), initial_metadata = err . initial_metadata (), trailing_metadata = err . trailing_metadata (), details = msg , debug_error_string = err . debug_error_string (), ) # Filter out the components filtered in `components` method. # id=0 is an exception indicating grid component. valid_ids = { c . component_id for c in valid_components } valid_ids . add ( 0 ) connections = filter ( lambda c : ( c . start in valid_ids and c . end in valid_ids ), all_connections . connections , ) result : Iterable [ Connection ] = map ( lambda c : Connection ( c . start , c . end ), connections ) return result ev_charger_data ( component_id ) async \u00a4 Return a channel receiver that provides an EvChargeData stream. If only the latest value is required, the Receiver returned by this method can be converted into a Peekable with the into_peekable method on the Receiver. RAISES DESCRIPTION ValueError if the given id is unknown or has a different type. PARAMETER DESCRIPTION component_id id of the ev charger to get data for. TYPE: int RETURNS DESCRIPTION Receiver [ EVChargerData ] A channel receiver that provides realtime ev charger data. Source code in frequenz/sdk/microgrid/client.py 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 async def ev_charger_data ( self , component_id : int , ) -> Receiver [ EVChargerData ]: \"\"\"Return a channel receiver that provides an `EvChargeData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Raises: ValueError: if the given id is unknown or has a different type. Args: component_id: id of the ev charger to get data for. Returns: A channel receiver that provides realtime ev charger data. \"\"\" await self . _expect_category ( component_id , ComponentCategory . EV_CHARGER , ) return self . _get_component_data_channel ( component_id , EVChargerData . from_proto , ) . new_receiver () inverter_data ( component_id ) async \u00a4 Return a channel receiver that provides an InverterData stream. If only the latest value is required, the Receiver returned by this method can be converted into a Peekable with the into_peekable method on the Receiver. RAISES DESCRIPTION ValueError if the given id is unknown or has a different type. PARAMETER DESCRIPTION component_id id of the inverter to get data for. TYPE: int RETURNS DESCRIPTION Receiver [ InverterData ] A channel receiver that provides realtime inverter data. Source code in frequenz/sdk/microgrid/client.py 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 async def inverter_data ( self , component_id : int , ) -> Receiver [ InverterData ]: \"\"\"Return a channel receiver that provides an `InverterData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Raises: ValueError: if the given id is unknown or has a different type. Args: component_id: id of the inverter to get data for. Returns: A channel receiver that provides realtime inverter data. \"\"\" await self . _expect_category ( component_id , ComponentCategory . INVERTER , ) return self . _get_component_data_channel ( component_id , InverterData . from_proto , ) . new_receiver () meter_data ( component_id ) async \u00a4 Return a channel receiver that provides a MeterData stream. If only the latest value is required, the Receiver returned by this method can be converted into a Peekable with the into_peekable method on the Receiver. RAISES DESCRIPTION ValueError if the given id is unknown or has a different type. PARAMETER DESCRIPTION component_id id of the meter to get data for. TYPE: int RETURNS DESCRIPTION Receiver [ MeterData ] A channel receiver that provides realtime meter data. Source code in frequenz/sdk/microgrid/client.py 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 async def meter_data ( self , component_id : int , ) -> Receiver [ MeterData ]: \"\"\"Return a channel receiver that provides a `MeterData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Raises: ValueError: if the given id is unknown or has a different type. Args: component_id: id of the meter to get data for. Returns: A channel receiver that provides realtime meter data. \"\"\" await self . _expect_category ( component_id , ComponentCategory . METER , ) return self . _get_component_data_channel ( component_id , MeterData . from_proto , ) . new_receiver () set_bounds ( component_id , lower , upper ) async \u00a4 Send SetBoundsParam s received from a channel to nitrogen. PARAMETER DESCRIPTION component_id ID of the component to set bounds for. TYPE: int lower Lower bound to be set for the component. TYPE: float upper Upper bound to be set for the component. TYPE: float RAISES DESCRIPTION ValueError when upper bound is less than 0, or when lower bound is greater than 0. grpc . aio . AioRpcError if connection to Microgrid API cannot be established or when the api call exceeded timeout Source code in frequenz/sdk/microgrid/client.py 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 async def set_bounds ( self , component_id : int , lower : float , upper : float , ) -> None : \"\"\"Send `SetBoundsParam`s received from a channel to nitrogen. Args: component_id: ID of the component to set bounds for. lower: Lower bound to be set for the component. upper: Upper bound to be set for the component. Raises: ValueError: when upper bound is less than 0, or when lower bound is greater than 0. grpc.aio.AioRpcError: if connection to Microgrid API cannot be established or when the api call exceeded timeout \"\"\" api_details = f \"Microgrid API: { self . target } .\" if upper < 0 : raise ValueError ( f \"Upper bound { upper } must be greater than or equal to 0.\" ) if lower > 0 : raise ValueError ( f \"Lower bound { upper } must be less than or equal to 0.\" ) set_bounds_call = self . api . SetBounds ( timeout = DEFAULT_GRPC_CALL_TIMEOUT ) try : await set_bounds_call . write ( microgrid_pb . SetBoundsParam ( component_id = component_id , # pylint: disable=no-member,line-too-long target_metric = microgrid_pb . SetBoundsParam . TargetMetric . TARGET_METRIC_POWER_ACTIVE , bounds = common_pb . Bounds ( lower = lower , upper = upper ), ), ) except grpc . aio . AioRpcError as err : logger . error ( \"set_bounds write failed: %s , for message: %s , api: %s . Err: %s \" , err , next , api_details , err . details (), ) raise set_power ( component_id , power_w ) async \u00a4 Send request to the Microgrid to set power for component. If power > 0, then component will be charged with this power. If power < 0, then component will be discharged with this power. If power == 0, then stop charging or discharging component. PARAMETER DESCRIPTION component_id id of the component to set power. TYPE: int power_w power to set for the component. TYPE: int RETURNS DESCRIPTION Empty Empty response. RAISES DESCRIPTION AioRpcError if connection to Microgrid API cannot be established or when the api call exceeded timeout Source code in frequenz/sdk/microgrid/client.py 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 async def set_power ( self , component_id : int , power_w : int ) -> Empty : \"\"\"Send request to the Microgrid to set power for component. If power > 0, then component will be charged with this power. If power < 0, then component will be discharged with this power. If power == 0, then stop charging or discharging component. Args: component_id: id of the component to set power. power_w: power to set for the component. Returns: Empty response. Raises: AioRpcError: if connection to Microgrid API cannot be established or when the api call exceeded timeout \"\"\" try : if power_w >= 0 : result : Empty = await self . api . Charge ( microgrid_pb . PowerLevelParam ( component_id = component_id , power_w = power_w ), timeout = DEFAULT_GRPC_CALL_TIMEOUT , ) else : power_w *= - 1 result = await self . api . Discharge ( microgrid_pb . PowerLevelParam ( component_id = component_id , power_w = power_w ), timeout = DEFAULT_GRPC_CALL_TIMEOUT , ) except grpc . aio . AioRpcError as err : msg = f \"Failed to set power. Microgrid API: { self . target } . Err: { err . details () } \" raise grpc . aio . AioRpcError ( code = err . code (), initial_metadata = err . initial_metadata (), trailing_metadata = err . trailing_metadata (), details = msg , debug_error_string = err . debug_error_string (), ) return result","title":"client"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client","text":"Client for requests to the Microgrid API.","title":"client"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client.MicrogridApiClient","text":"Bases: ABC Base interface for microgrid API clients to implement. Source code in frequenz/sdk/microgrid/client.py 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 class MicrogridApiClient ( ABC ): \"\"\"Base interface for microgrid API clients to implement.\"\"\" @abstractmethod async def components ( self ) -> Iterable [ Component ]: \"\"\"Fetch all the components present in the microgrid. Returns: Iterator whose elements are all the components in the microgrid. \"\"\" @abstractmethod async def connections ( self , starts : Optional [ Set [ int ]] = None , ends : Optional [ Set [ int ]] = None , ) -> Iterable [ Connection ]: \"\"\"Fetch the connections between components in the microgrid. Args: starts: if set and non-empty, only include connections whose start value matches one of the provided component IDs ends: if set and non-empty, only include connections whose end value matches one of the provided component IDs Returns: Microgrid connections matching the provided start and end filters. \"\"\" @abstractmethod async def meter_data ( self , component_id : int , ) -> Receiver [ MeterData ]: \"\"\"Return a channel receiver that provides a `MeterData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Args: component_id: id of the meter to get data for. Returns: A channel receiver that provides realtime meter data. \"\"\" @abstractmethod async def battery_data ( self , component_id : int , ) -> Receiver [ BatteryData ]: \"\"\"Return a channel receiver that provides a `BatteryData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Args: component_id: id of the battery to get data for. Returns: A channel receiver that provides realtime battery data. \"\"\" @abstractmethod async def inverter_data ( self , component_id : int , ) -> Receiver [ InverterData ]: \"\"\"Return a channel receiver that provides an `InverterData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Args: component_id: id of the inverter to get data for. Returns: A channel receiver that provides realtime inverter data. \"\"\" @abstractmethod async def ev_charger_data ( self , component_id : int , ) -> Receiver [ EVChargerData ]: \"\"\"Return a channel receiver that provides an `EvChargeData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Args: component_id: id of the ev charger to get data for. Returns: A channel receiver that provides realtime ev charger data. \"\"\" @abstractmethod async def set_power ( self , component_id : int , power_w : int ) -> Empty : \"\"\"Send request to the Microgrid to set power for component. If power > 0, then component will be charged with this power. If power < 0, then component will be discharged with this power. If power == 0, then stop charging or discharging component. Args: component_id: id of the component to set power. power_w: power to set for the component. Returns: Empty response. \"\"\" @abstractmethod async def set_bounds ( self , component_id : int , lower : float , upper : float ) -> None : \"\"\"Send `SetBoundsParam`s received from a channel to nitrogen. Args: component_id: ID of the component to set bounds for. lower: Lower bound to be set for the component. upper: Upper bound to be set for the component. \"\"\"","title":"MicrogridApiClient"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client.MicrogridApiClient-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client.MicrogridApiClient.battery_data","text":"Return a channel receiver that provides a BatteryData stream. If only the latest value is required, the Receiver returned by this method can be converted into a Peekable with the into_peekable method on the Receiver. PARAMETER DESCRIPTION component_id id of the battery to get data for. TYPE: int RETURNS DESCRIPTION Receiver [ BatteryData ] A channel receiver that provides realtime battery data. Source code in frequenz/sdk/microgrid/client.py 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 @abstractmethod async def battery_data ( self , component_id : int , ) -> Receiver [ BatteryData ]: \"\"\"Return a channel receiver that provides a `BatteryData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Args: component_id: id of the battery to get data for. Returns: A channel receiver that provides realtime battery data. \"\"\"","title":"battery_data()"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client.MicrogridApiClient.components","text":"Fetch all the components present in the microgrid. RETURNS DESCRIPTION Iterable [ Component ] Iterator whose elements are all the components in the microgrid. Source code in frequenz/sdk/microgrid/client.py 43 44 45 46 47 48 49 @abstractmethod async def components ( self ) -> Iterable [ Component ]: \"\"\"Fetch all the components present in the microgrid. Returns: Iterator whose elements are all the components in the microgrid. \"\"\"","title":"components()"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client.MicrogridApiClient.connections","text":"Fetch the connections between components in the microgrid. PARAMETER DESCRIPTION starts if set and non-empty, only include connections whose start value matches one of the provided component IDs TYPE: Optional [ Set [ int ]] DEFAULT: None ends if set and non-empty, only include connections whose end value matches one of the provided component IDs TYPE: Optional [ Set [ int ]] DEFAULT: None RETURNS DESCRIPTION Iterable [ Connection ] Microgrid connections matching the provided start and end filters. Source code in frequenz/sdk/microgrid/client.py 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 @abstractmethod async def connections ( self , starts : Optional [ Set [ int ]] = None , ends : Optional [ Set [ int ]] = None , ) -> Iterable [ Connection ]: \"\"\"Fetch the connections between components in the microgrid. Args: starts: if set and non-empty, only include connections whose start value matches one of the provided component IDs ends: if set and non-empty, only include connections whose end value matches one of the provided component IDs Returns: Microgrid connections matching the provided start and end filters. \"\"\"","title":"connections()"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client.MicrogridApiClient.ev_charger_data","text":"Return a channel receiver that provides an EvChargeData stream. If only the latest value is required, the Receiver returned by this method can be converted into a Peekable with the into_peekable method on the Receiver. PARAMETER DESCRIPTION component_id id of the ev charger to get data for. TYPE: int RETURNS DESCRIPTION Receiver [ EVChargerData ] A channel receiver that provides realtime ev charger data. Source code in frequenz/sdk/microgrid/client.py 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 @abstractmethod async def ev_charger_data ( self , component_id : int , ) -> Receiver [ EVChargerData ]: \"\"\"Return a channel receiver that provides an `EvChargeData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Args: component_id: id of the ev charger to get data for. Returns: A channel receiver that provides realtime ev charger data. \"\"\"","title":"ev_charger_data()"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client.MicrogridApiClient.inverter_data","text":"Return a channel receiver that provides an InverterData stream. If only the latest value is required, the Receiver returned by this method can be converted into a Peekable with the into_peekable method on the Receiver. PARAMETER DESCRIPTION component_id id of the inverter to get data for. TYPE: int RETURNS DESCRIPTION Receiver [ InverterData ] A channel receiver that provides realtime inverter data. Source code in frequenz/sdk/microgrid/client.py 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 @abstractmethod async def inverter_data ( self , component_id : int , ) -> Receiver [ InverterData ]: \"\"\"Return a channel receiver that provides an `InverterData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Args: component_id: id of the inverter to get data for. Returns: A channel receiver that provides realtime inverter data. \"\"\"","title":"inverter_data()"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client.MicrogridApiClient.meter_data","text":"Return a channel receiver that provides a MeterData stream. If only the latest value is required, the Receiver returned by this method can be converted into a Peekable with the into_peekable method on the Receiver. PARAMETER DESCRIPTION component_id id of the meter to get data for. TYPE: int RETURNS DESCRIPTION Receiver [ MeterData ] A channel receiver that provides realtime meter data. Source code in frequenz/sdk/microgrid/client.py 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 @abstractmethod async def meter_data ( self , component_id : int , ) -> Receiver [ MeterData ]: \"\"\"Return a channel receiver that provides a `MeterData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Args: component_id: id of the meter to get data for. Returns: A channel receiver that provides realtime meter data. \"\"\"","title":"meter_data()"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client.MicrogridApiClient.set_bounds","text":"Send SetBoundsParam s received from a channel to nitrogen. PARAMETER DESCRIPTION component_id ID of the component to set bounds for. TYPE: int lower Lower bound to be set for the component. TYPE: float upper Upper bound to be set for the component. TYPE: float Source code in frequenz/sdk/microgrid/client.py 158 159 160 161 162 163 164 165 166 @abstractmethod async def set_bounds ( self , component_id : int , lower : float , upper : float ) -> None : \"\"\"Send `SetBoundsParam`s received from a channel to nitrogen. Args: component_id: ID of the component to set bounds for. lower: Lower bound to be set for the component. upper: Upper bound to be set for the component. \"\"\"","title":"set_bounds()"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client.MicrogridApiClient.set_power","text":"Send request to the Microgrid to set power for component. If power > 0, then component will be charged with this power. If power < 0, then component will be discharged with this power. If power == 0, then stop charging or discharging component. PARAMETER DESCRIPTION component_id id of the component to set power. TYPE: int power_w power to set for the component. TYPE: int RETURNS DESCRIPTION Empty Empty response. Source code in frequenz/sdk/microgrid/client.py 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 @abstractmethod async def set_power ( self , component_id : int , power_w : int ) -> Empty : \"\"\"Send request to the Microgrid to set power for component. If power > 0, then component will be charged with this power. If power < 0, then component will be discharged with this power. If power == 0, then stop charging or discharging component. Args: component_id: id of the component to set power. power_w: power to set for the component. Returns: Empty response. \"\"\"","title":"set_power()"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client.MicrogridGrpcClient","text":"Bases: MicrogridApiClient Microgrid API client implementation using gRPC as the underlying protocol. Source code in frequenz/sdk/microgrid/client.py 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 class MicrogridGrpcClient ( MicrogridApiClient ): \"\"\"Microgrid API client implementation using gRPC as the underlying protocol.\"\"\" def __init__ ( self , grpc_channel : grpc . aio . Channel , target : str , retry_spec : RetryStrategy = LinearBackoff (), ) -> None : \"\"\"Initialize the class instance. Args: grpc_channel: asyncio-supporting gRPC channel target: server (host:port) to be used for asyncio-supporting gRPC channel that the client should use to contact the API retry_spec: Specs on how to retry if the connection to a streaming method gets lost. \"\"\" self . target = target self . api = MicrogridStub ( grpc_channel ) self . _component_streams : Dict [ int , Broadcast [ Any ]] = {} self . _retry_spec = retry_spec async def components ( self ) -> Iterable [ Component ]: \"\"\"Fetch all the components present in the microgrid. Returns: Iterator whose elements are all the components in the microgrid. Raises: AioRpcError: if connection to Microgrid API cannot be established or when the api call exceeded timeout \"\"\" try : component_list = await self . api . ListComponents ( microgrid_pb . ComponentFilter (), timeout = DEFAULT_GRPC_CALL_TIMEOUT , ) except grpc . aio . AioRpcError as err : msg = f \"Failed to list components. Microgrid API: { self . target } . Err: { err . details () } \" raise grpc . aio . AioRpcError ( code = err . code (), initial_metadata = err . initial_metadata (), trailing_metadata = err . trailing_metadata (), details = msg , debug_error_string = err . debug_error_string (), ) components_only = filter ( lambda c : c . category not in ( microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_SENSOR , microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_LOAD , ), component_list . components , ) result : Iterable [ Component ] = map ( lambda c : Component ( c . id , _component_category_from_protobuf ( c . category )), components_only , ) return result async def connections ( self , starts : Optional [ Set [ int ]] = None , ends : Optional [ Set [ int ]] = None , ) -> Iterable [ Connection ]: \"\"\"Fetch the connections between components in the microgrid. Args: starts: if set and non-empty, only include connections whose start value matches one of the provided component IDs ends: if set and non-empty, only include connections whose end value matches one of the provided component IDs Returns: Microgrid connections matching the provided start and end filters. Raises: AioRpcError: if connection to Microgrid API cannot be established or when the api call exceeded timeout \"\"\" connection_filter = microgrid_pb . ConnectionFilter ( starts = starts , ends = ends ) try : valid_components , all_connections = await asyncio . gather ( self . components (), self . api . ListConnections ( connection_filter , timeout = DEFAULT_GRPC_CALL_TIMEOUT ), ) except grpc . aio . AioRpcError as err : msg = f \"Failed to list connections. Microgrid API: { self . target } . Err: { err . details () } \" raise grpc . aio . AioRpcError ( code = err . code (), initial_metadata = err . initial_metadata (), trailing_metadata = err . trailing_metadata (), details = msg , debug_error_string = err . debug_error_string (), ) # Filter out the components filtered in `components` method. # id=0 is an exception indicating grid component. valid_ids = { c . component_id for c in valid_components } valid_ids . add ( 0 ) connections = filter ( lambda c : ( c . start in valid_ids and c . end in valid_ids ), all_connections . connections , ) result : Iterable [ Connection ] = map ( lambda c : Connection ( c . start , c . end ), connections ) return result async def _component_data_task ( self , component_id : int , transform : Callable [[ microgrid_pb . ComponentData ], _GenericComponentData ], sender : Sender [ _GenericComponentData ], ) -> None : \"\"\"Read data from the microgrid API and send to a channel. Args: component_id: id of the component to get data for. transform: A method for transforming raw component data into the desired output type. sender: A channel sender, to send the component data to. Raises: AioRpcError: if connection to Microgrid API cannot be established \"\"\" retry_spec : RetryStrategy = self . _retry_spec . copy () while True : logger . debug ( \"Making call to `GetComponentData`, for component_id= %d \" , component_id ) try : call = self . api . GetComponentData ( microgrid_pb . ComponentIdParam ( id = component_id ), ) async for msg in call : await sender . send ( transform ( msg )) except grpc . aio . AioRpcError as err : api_details = f \"Microgrid API: { self . target } .\" logger . exception ( \"`GetComponentData`, for component_id= %d : exception: %s api: %s \" , component_id , err , api_details , ) if interval := retry_spec . next_interval (): logger . warning ( \"`GetComponentData`, for component_id= %d : connection ended, \" \"retrying %s in %0.3f seconds.\" , component_id , retry_spec . get_progress (), interval , ) await asyncio . sleep ( interval ) # type: ignore else : logger . warning ( \"`GetComponentData`, for component_id= %d : connection ended, \" \"retry limit exceeded %s .\" , component_id , retry_spec . get_progress (), ) break def _get_component_data_channel ( self , component_id : int , transform : Callable [[ microgrid_pb . ComponentData ], _GenericComponentData ], ) -> Broadcast [ _GenericComponentData ]: \"\"\"Return the broadcast channel for a given component_id. If a broadcast channel for the given component_id doesn't exist, create a new channel and a task for reading data from the microgrid api and sending them to the channel. Args: component_id: id of the component to get data for. transform: A method for transforming raw component data into the desired output type. Returns: The channel for the given component_id. \"\"\" if component_id in self . _component_streams : return self . _component_streams [ component_id ] task_name = f \"raw-component-data- { component_id } \" chan = Broadcast [ _GenericComponentData ]( task_name ) self . _component_streams [ component_id ] = chan asyncio . create_task ( self . _component_data_task ( component_id , transform , chan . new_sender (), ), name = task_name , ) return chan async def _expect_category ( self , component_id : int , expected_category : ComponentCategory , ) -> None : \"\"\"Check if the given component_id is of the expected type. Raises: ValueError: if the given id is unknown or has a different type. Args: component_id: Component id to check. expected_category: Component category that the given id is expected to have. \"\"\" try : comp = next ( comp for comp in await self . components () if comp . component_id == component_id ) except StopIteration as exc : raise ValueError ( f \"Unable to find component with id { component_id } \" ) from exc if comp . category != expected_category : raise ValueError ( f \"Component id { component_id } is a { comp . category } \" f \", not a { expected_category } .\" ) async def meter_data ( self , component_id : int , ) -> Receiver [ MeterData ]: \"\"\"Return a channel receiver that provides a `MeterData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Raises: ValueError: if the given id is unknown or has a different type. Args: component_id: id of the meter to get data for. Returns: A channel receiver that provides realtime meter data. \"\"\" await self . _expect_category ( component_id , ComponentCategory . METER , ) return self . _get_component_data_channel ( component_id , MeterData . from_proto , ) . new_receiver () async def battery_data ( self , component_id : int , ) -> Receiver [ BatteryData ]: \"\"\"Return a channel receiver that provides a `BatteryData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Raises: ValueError: if the given id is unknown or has a different type. Args: component_id: id of the battery to get data for. Returns: A channel receiver that provides realtime battery data. \"\"\" await self . _expect_category ( component_id , ComponentCategory . BATTERY , ) return self . _get_component_data_channel ( component_id , BatteryData . from_proto , ) . new_receiver () async def inverter_data ( self , component_id : int , ) -> Receiver [ InverterData ]: \"\"\"Return a channel receiver that provides an `InverterData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Raises: ValueError: if the given id is unknown or has a different type. Args: component_id: id of the inverter to get data for. Returns: A channel receiver that provides realtime inverter data. \"\"\" await self . _expect_category ( component_id , ComponentCategory . INVERTER , ) return self . _get_component_data_channel ( component_id , InverterData . from_proto , ) . new_receiver () async def ev_charger_data ( self , component_id : int , ) -> Receiver [ EVChargerData ]: \"\"\"Return a channel receiver that provides an `EvChargeData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Raises: ValueError: if the given id is unknown or has a different type. Args: component_id: id of the ev charger to get data for. Returns: A channel receiver that provides realtime ev charger data. \"\"\" await self . _expect_category ( component_id , ComponentCategory . EV_CHARGER , ) return self . _get_component_data_channel ( component_id , EVChargerData . from_proto , ) . new_receiver () async def set_power ( self , component_id : int , power_w : int ) -> Empty : \"\"\"Send request to the Microgrid to set power for component. If power > 0, then component will be charged with this power. If power < 0, then component will be discharged with this power. If power == 0, then stop charging or discharging component. Args: component_id: id of the component to set power. power_w: power to set for the component. Returns: Empty response. Raises: AioRpcError: if connection to Microgrid API cannot be established or when the api call exceeded timeout \"\"\" try : if power_w >= 0 : result : Empty = await self . api . Charge ( microgrid_pb . PowerLevelParam ( component_id = component_id , power_w = power_w ), timeout = DEFAULT_GRPC_CALL_TIMEOUT , ) else : power_w *= - 1 result = await self . api . Discharge ( microgrid_pb . PowerLevelParam ( component_id = component_id , power_w = power_w ), timeout = DEFAULT_GRPC_CALL_TIMEOUT , ) except grpc . aio . AioRpcError as err : msg = f \"Failed to set power. Microgrid API: { self . target } . Err: { err . details () } \" raise grpc . aio . AioRpcError ( code = err . code (), initial_metadata = err . initial_metadata (), trailing_metadata = err . trailing_metadata (), details = msg , debug_error_string = err . debug_error_string (), ) return result async def set_bounds ( self , component_id : int , lower : float , upper : float , ) -> None : \"\"\"Send `SetBoundsParam`s received from a channel to nitrogen. Args: component_id: ID of the component to set bounds for. lower: Lower bound to be set for the component. upper: Upper bound to be set for the component. Raises: ValueError: when upper bound is less than 0, or when lower bound is greater than 0. grpc.aio.AioRpcError: if connection to Microgrid API cannot be established or when the api call exceeded timeout \"\"\" api_details = f \"Microgrid API: { self . target } .\" if upper < 0 : raise ValueError ( f \"Upper bound { upper } must be greater than or equal to 0.\" ) if lower > 0 : raise ValueError ( f \"Lower bound { upper } must be less than or equal to 0.\" ) set_bounds_call = self . api . SetBounds ( timeout = DEFAULT_GRPC_CALL_TIMEOUT ) try : await set_bounds_call . write ( microgrid_pb . SetBoundsParam ( component_id = component_id , # pylint: disable=no-member,line-too-long target_metric = microgrid_pb . SetBoundsParam . TargetMetric . TARGET_METRIC_POWER_ACTIVE , bounds = common_pb . Bounds ( lower = lower , upper = upper ), ), ) except grpc . aio . AioRpcError as err : logger . error ( \"set_bounds write failed: %s , for message: %s , api: %s . Err: %s \" , err , next , api_details , err . details (), ) raise","title":"MicrogridGrpcClient"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client.MicrogridGrpcClient-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client.MicrogridGrpcClient.__init__","text":"Initialize the class instance. PARAMETER DESCRIPTION grpc_channel asyncio-supporting gRPC channel TYPE: grpc . aio . Channel target server (host:port) to be used for asyncio-supporting gRPC channel that the client should use to contact the API TYPE: str retry_spec Specs on how to retry if the connection to a streaming method gets lost. TYPE: RetryStrategy DEFAULT: LinearBackoff() Source code in frequenz/sdk/microgrid/client.py 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 def __init__ ( self , grpc_channel : grpc . aio . Channel , target : str , retry_spec : RetryStrategy = LinearBackoff (), ) -> None : \"\"\"Initialize the class instance. Args: grpc_channel: asyncio-supporting gRPC channel target: server (host:port) to be used for asyncio-supporting gRPC channel that the client should use to contact the API retry_spec: Specs on how to retry if the connection to a streaming method gets lost. \"\"\" self . target = target self . api = MicrogridStub ( grpc_channel ) self . _component_streams : Dict [ int , Broadcast [ Any ]] = {} self . _retry_spec = retry_spec","title":"__init__()"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client.MicrogridGrpcClient.battery_data","text":"Return a channel receiver that provides a BatteryData stream. If only the latest value is required, the Receiver returned by this method can be converted into a Peekable with the into_peekable method on the Receiver. RAISES DESCRIPTION ValueError if the given id is unknown or has a different type. PARAMETER DESCRIPTION component_id id of the battery to get data for. TYPE: int RETURNS DESCRIPTION Receiver [ BatteryData ] A channel receiver that provides realtime battery data. Source code in frequenz/sdk/microgrid/client.py 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 async def battery_data ( self , component_id : int , ) -> Receiver [ BatteryData ]: \"\"\"Return a channel receiver that provides a `BatteryData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Raises: ValueError: if the given id is unknown or has a different type. Args: component_id: id of the battery to get data for. Returns: A channel receiver that provides realtime battery data. \"\"\" await self . _expect_category ( component_id , ComponentCategory . BATTERY , ) return self . _get_component_data_channel ( component_id , BatteryData . from_proto , ) . new_receiver ()","title":"battery_data()"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client.MicrogridGrpcClient.components","text":"Fetch all the components present in the microgrid. RETURNS DESCRIPTION Iterable [ Component ] Iterator whose elements are all the components in the microgrid. RAISES DESCRIPTION AioRpcError if connection to Microgrid API cannot be established or when the api call exceeded timeout Source code in frequenz/sdk/microgrid/client.py 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 async def components ( self ) -> Iterable [ Component ]: \"\"\"Fetch all the components present in the microgrid. Returns: Iterator whose elements are all the components in the microgrid. Raises: AioRpcError: if connection to Microgrid API cannot be established or when the api call exceeded timeout \"\"\" try : component_list = await self . api . ListComponents ( microgrid_pb . ComponentFilter (), timeout = DEFAULT_GRPC_CALL_TIMEOUT , ) except grpc . aio . AioRpcError as err : msg = f \"Failed to list components. Microgrid API: { self . target } . Err: { err . details () } \" raise grpc . aio . AioRpcError ( code = err . code (), initial_metadata = err . initial_metadata (), trailing_metadata = err . trailing_metadata (), details = msg , debug_error_string = err . debug_error_string (), ) components_only = filter ( lambda c : c . category not in ( microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_SENSOR , microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_LOAD , ), component_list . components , ) result : Iterable [ Component ] = map ( lambda c : Component ( c . id , _component_category_from_protobuf ( c . category )), components_only , ) return result","title":"components()"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client.MicrogridGrpcClient.connections","text":"Fetch the connections between components in the microgrid. PARAMETER DESCRIPTION starts if set and non-empty, only include connections whose start value matches one of the provided component IDs TYPE: Optional [ Set [ int ]] DEFAULT: None ends if set and non-empty, only include connections whose end value matches one of the provided component IDs TYPE: Optional [ Set [ int ]] DEFAULT: None RETURNS DESCRIPTION Iterable [ Connection ] Microgrid connections matching the provided start and end filters. RAISES DESCRIPTION AioRpcError if connection to Microgrid API cannot be established or when the api call exceeded timeout Source code in frequenz/sdk/microgrid/client.py 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 async def connections ( self , starts : Optional [ Set [ int ]] = None , ends : Optional [ Set [ int ]] = None , ) -> Iterable [ Connection ]: \"\"\"Fetch the connections between components in the microgrid. Args: starts: if set and non-empty, only include connections whose start value matches one of the provided component IDs ends: if set and non-empty, only include connections whose end value matches one of the provided component IDs Returns: Microgrid connections matching the provided start and end filters. Raises: AioRpcError: if connection to Microgrid API cannot be established or when the api call exceeded timeout \"\"\" connection_filter = microgrid_pb . ConnectionFilter ( starts = starts , ends = ends ) try : valid_components , all_connections = await asyncio . gather ( self . components (), self . api . ListConnections ( connection_filter , timeout = DEFAULT_GRPC_CALL_TIMEOUT ), ) except grpc . aio . AioRpcError as err : msg = f \"Failed to list connections. Microgrid API: { self . target } . Err: { err . details () } \" raise grpc . aio . AioRpcError ( code = err . code (), initial_metadata = err . initial_metadata (), trailing_metadata = err . trailing_metadata (), details = msg , debug_error_string = err . debug_error_string (), ) # Filter out the components filtered in `components` method. # id=0 is an exception indicating grid component. valid_ids = { c . component_id for c in valid_components } valid_ids . add ( 0 ) connections = filter ( lambda c : ( c . start in valid_ids and c . end in valid_ids ), all_connections . connections , ) result : Iterable [ Connection ] = map ( lambda c : Connection ( c . start , c . end ), connections ) return result","title":"connections()"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client.MicrogridGrpcClient.ev_charger_data","text":"Return a channel receiver that provides an EvChargeData stream. If only the latest value is required, the Receiver returned by this method can be converted into a Peekable with the into_peekable method on the Receiver. RAISES DESCRIPTION ValueError if the given id is unknown or has a different type. PARAMETER DESCRIPTION component_id id of the ev charger to get data for. TYPE: int RETURNS DESCRIPTION Receiver [ EVChargerData ] A channel receiver that provides realtime ev charger data. Source code in frequenz/sdk/microgrid/client.py 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 async def ev_charger_data ( self , component_id : int , ) -> Receiver [ EVChargerData ]: \"\"\"Return a channel receiver that provides an `EvChargeData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Raises: ValueError: if the given id is unknown or has a different type. Args: component_id: id of the ev charger to get data for. Returns: A channel receiver that provides realtime ev charger data. \"\"\" await self . _expect_category ( component_id , ComponentCategory . EV_CHARGER , ) return self . _get_component_data_channel ( component_id , EVChargerData . from_proto , ) . new_receiver ()","title":"ev_charger_data()"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client.MicrogridGrpcClient.inverter_data","text":"Return a channel receiver that provides an InverterData stream. If only the latest value is required, the Receiver returned by this method can be converted into a Peekable with the into_peekable method on the Receiver. RAISES DESCRIPTION ValueError if the given id is unknown or has a different type. PARAMETER DESCRIPTION component_id id of the inverter to get data for. TYPE: int RETURNS DESCRIPTION Receiver [ InverterData ] A channel receiver that provides realtime inverter data. Source code in frequenz/sdk/microgrid/client.py 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 async def inverter_data ( self , component_id : int , ) -> Receiver [ InverterData ]: \"\"\"Return a channel receiver that provides an `InverterData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Raises: ValueError: if the given id is unknown or has a different type. Args: component_id: id of the inverter to get data for. Returns: A channel receiver that provides realtime inverter data. \"\"\" await self . _expect_category ( component_id , ComponentCategory . INVERTER , ) return self . _get_component_data_channel ( component_id , InverterData . from_proto , ) . new_receiver ()","title":"inverter_data()"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client.MicrogridGrpcClient.meter_data","text":"Return a channel receiver that provides a MeterData stream. If only the latest value is required, the Receiver returned by this method can be converted into a Peekable with the into_peekable method on the Receiver. RAISES DESCRIPTION ValueError if the given id is unknown or has a different type. PARAMETER DESCRIPTION component_id id of the meter to get data for. TYPE: int RETURNS DESCRIPTION Receiver [ MeterData ] A channel receiver that provides realtime meter data. Source code in frequenz/sdk/microgrid/client.py 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 async def meter_data ( self , component_id : int , ) -> Receiver [ MeterData ]: \"\"\"Return a channel receiver that provides a `MeterData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Raises: ValueError: if the given id is unknown or has a different type. Args: component_id: id of the meter to get data for. Returns: A channel receiver that provides realtime meter data. \"\"\" await self . _expect_category ( component_id , ComponentCategory . METER , ) return self . _get_component_data_channel ( component_id , MeterData . from_proto , ) . new_receiver ()","title":"meter_data()"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client.MicrogridGrpcClient.set_bounds","text":"Send SetBoundsParam s received from a channel to nitrogen. PARAMETER DESCRIPTION component_id ID of the component to set bounds for. TYPE: int lower Lower bound to be set for the component. TYPE: float upper Upper bound to be set for the component. TYPE: float RAISES DESCRIPTION ValueError when upper bound is less than 0, or when lower bound is greater than 0. grpc . aio . AioRpcError if connection to Microgrid API cannot be established or when the api call exceeded timeout Source code in frequenz/sdk/microgrid/client.py 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 async def set_bounds ( self , component_id : int , lower : float , upper : float , ) -> None : \"\"\"Send `SetBoundsParam`s received from a channel to nitrogen. Args: component_id: ID of the component to set bounds for. lower: Lower bound to be set for the component. upper: Upper bound to be set for the component. Raises: ValueError: when upper bound is less than 0, or when lower bound is greater than 0. grpc.aio.AioRpcError: if connection to Microgrid API cannot be established or when the api call exceeded timeout \"\"\" api_details = f \"Microgrid API: { self . target } .\" if upper < 0 : raise ValueError ( f \"Upper bound { upper } must be greater than or equal to 0.\" ) if lower > 0 : raise ValueError ( f \"Lower bound { upper } must be less than or equal to 0.\" ) set_bounds_call = self . api . SetBounds ( timeout = DEFAULT_GRPC_CALL_TIMEOUT ) try : await set_bounds_call . write ( microgrid_pb . SetBoundsParam ( component_id = component_id , # pylint: disable=no-member,line-too-long target_metric = microgrid_pb . SetBoundsParam . TargetMetric . TARGET_METRIC_POWER_ACTIVE , bounds = common_pb . Bounds ( lower = lower , upper = upper ), ), ) except grpc . aio . AioRpcError as err : logger . error ( \"set_bounds write failed: %s , for message: %s , api: %s . Err: %s \" , err , next , api_details , err . details (), ) raise","title":"set_bounds()"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client.MicrogridGrpcClient.set_power","text":"Send request to the Microgrid to set power for component. If power > 0, then component will be charged with this power. If power < 0, then component will be discharged with this power. If power == 0, then stop charging or discharging component. PARAMETER DESCRIPTION component_id id of the component to set power. TYPE: int power_w power to set for the component. TYPE: int RETURNS DESCRIPTION Empty Empty response. RAISES DESCRIPTION AioRpcError if connection to Microgrid API cannot be established or when the api call exceeded timeout Source code in frequenz/sdk/microgrid/client.py 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 async def set_power ( self , component_id : int , power_w : int ) -> Empty : \"\"\"Send request to the Microgrid to set power for component. If power > 0, then component will be charged with this power. If power < 0, then component will be discharged with this power. If power == 0, then stop charging or discharging component. Args: component_id: id of the component to set power. power_w: power to set for the component. Returns: Empty response. Raises: AioRpcError: if connection to Microgrid API cannot be established or when the api call exceeded timeout \"\"\" try : if power_w >= 0 : result : Empty = await self . api . Charge ( microgrid_pb . PowerLevelParam ( component_id = component_id , power_w = power_w ), timeout = DEFAULT_GRPC_CALL_TIMEOUT , ) else : power_w *= - 1 result = await self . api . Discharge ( microgrid_pb . PowerLevelParam ( component_id = component_id , power_w = power_w ), timeout = DEFAULT_GRPC_CALL_TIMEOUT , ) except grpc . aio . AioRpcError as err : msg = f \"Failed to set power. Microgrid API: { self . target } . Err: { err . details () } \" raise grpc . aio . AioRpcError ( code = err . code (), initial_metadata = err . initial_metadata (), trailing_metadata = err . trailing_metadata (), details = msg , debug_error_string = err . debug_error_string (), ) return result","title":"set_power()"},{"location":"reference/frequenz/sdk/microgrid/component/","text":"frequenz.sdk.microgrid.component \u00a4 Defines the components that can be used in a microgrid. Classes \u00a4 frequenz.sdk.microgrid.component.Component dataclass \u00a4 Metadata for a single microgrid component. Source code in frequenz/sdk/microgrid/component.py 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 @dataclass ( frozen = True ) class Component : \"\"\"Metadata for a single microgrid component.\"\"\" component_id : int category : ComponentCategory def is_valid ( self ) -> bool : \"\"\"Check if this instance contains valid data. Returns: `True` if `id > 0` and `type` is a valid `ComponentCategory`, or if `id == 0` and `type` is `GRID`, `False` otherwise \"\"\" return ( self . component_id > 0 and any ( t == self . category for t in ComponentCategory ) ) or ( self . component_id == 0 and self . category == ComponentCategory . GRID ) Functions \u00a4 is_valid () \u00a4 Check if this instance contains valid data. RETURNS DESCRIPTION bool True if id > 0 and type is a valid ComponentCategory , or if id == 0 and type is GRID , False otherwise Source code in frequenz/sdk/microgrid/component.py 66 67 68 69 70 71 72 73 74 75 def is_valid ( self ) -> bool : \"\"\"Check if this instance contains valid data. Returns: `True` if `id > 0` and `type` is a valid `ComponentCategory`, or if `id == 0` and `type` is `GRID`, `False` otherwise \"\"\" return ( self . component_id > 0 and any ( t == self . category for t in ComponentCategory ) ) or ( self . component_id == 0 and self . category == ComponentCategory . GRID ) frequenz.sdk.microgrid.component.ComponentCategory \u00a4 Bases: Enum Possible types of microgrid component. Source code in frequenz/sdk/microgrid/component.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 class ComponentCategory ( Enum ): \"\"\"Possible types of microgrid component.\"\"\" NONE = microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_UNSPECIFIED GRID = microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_GRID JUNCTION = microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_JUNCTION METER = microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_METER INVERTER = microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_INVERTER BATTERY = microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_BATTERY EV_CHARGER = microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_EV_CHARGER LOAD = microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_LOAD # types not yet supported by the API but which can be inferred # from available graph info PV_ARRAY = 1000001 CHP = 1000002 # combined heat and power plant","title":"component"},{"location":"reference/frequenz/sdk/microgrid/component/#frequenz.sdk.microgrid.component","text":"Defines the components that can be used in a microgrid.","title":"component"},{"location":"reference/frequenz/sdk/microgrid/component/#frequenz.sdk.microgrid.component-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/microgrid/component/#frequenz.sdk.microgrid.component.Component","text":"Metadata for a single microgrid component. Source code in frequenz/sdk/microgrid/component.py 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 @dataclass ( frozen = True ) class Component : \"\"\"Metadata for a single microgrid component.\"\"\" component_id : int category : ComponentCategory def is_valid ( self ) -> bool : \"\"\"Check if this instance contains valid data. Returns: `True` if `id > 0` and `type` is a valid `ComponentCategory`, or if `id == 0` and `type` is `GRID`, `False` otherwise \"\"\" return ( self . component_id > 0 and any ( t == self . category for t in ComponentCategory ) ) or ( self . component_id == 0 and self . category == ComponentCategory . GRID )","title":"Component"},{"location":"reference/frequenz/sdk/microgrid/component/#frequenz.sdk.microgrid.component.Component-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/microgrid/component/#frequenz.sdk.microgrid.component.Component.is_valid","text":"Check if this instance contains valid data. RETURNS DESCRIPTION bool True if id > 0 and type is a valid ComponentCategory , or if id == 0 and type is GRID , False otherwise Source code in frequenz/sdk/microgrid/component.py 66 67 68 69 70 71 72 73 74 75 def is_valid ( self ) -> bool : \"\"\"Check if this instance contains valid data. Returns: `True` if `id > 0` and `type` is a valid `ComponentCategory`, or if `id == 0` and `type` is `GRID`, `False` otherwise \"\"\" return ( self . component_id > 0 and any ( t == self . category for t in ComponentCategory ) ) or ( self . component_id == 0 and self . category == ComponentCategory . GRID )","title":"is_valid()"},{"location":"reference/frequenz/sdk/microgrid/component/#frequenz.sdk.microgrid.component.ComponentCategory","text":"Bases: Enum Possible types of microgrid component. Source code in frequenz/sdk/microgrid/component.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 class ComponentCategory ( Enum ): \"\"\"Possible types of microgrid component.\"\"\" NONE = microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_UNSPECIFIED GRID = microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_GRID JUNCTION = microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_JUNCTION METER = microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_METER INVERTER = microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_INVERTER BATTERY = microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_BATTERY EV_CHARGER = microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_EV_CHARGER LOAD = microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_LOAD # types not yet supported by the API but which can be inferred # from available graph info PV_ARRAY = 1000001 CHP = 1000002 # combined heat and power plant","title":"ComponentCategory"},{"location":"reference/frequenz/sdk/microgrid/component_data/","text":"frequenz.sdk.microgrid.component_data \u00a4 Component data types for data coming from a microgrid. Classes \u00a4 frequenz.sdk.microgrid.component_data.BatteryData dataclass \u00a4 Bases: ComponentData A wrapper class for holding battery data. ATTRIBUTE DESCRIPTION soc battery's overall SoC in percent (%). TYPE: float soc_lower_bound the SoC below which discharge commands will be blocked by the system, in percent (%). TYPE: float soc_upper_bound the SoC above which charge commands will be blocked by the system, in percent (%). TYPE: float capacity the capacity of the battery in Wh (Watt-hour) TYPE: float power_lower_bound the maximum discharge power, in Watts, represented in the passive sign convention. This will be a negative number, or zero if no discharging is possible. TYPE: float power_upper_bound the maximum charge power, in Watts, represented in the passive sign convention. This will be a positive number, or zero if no charging is possible. TYPE: float Source code in frequenz/sdk/microgrid/component_data.py 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 @dataclass ( frozen = True ) class BatteryData ( ComponentData ): \"\"\"A wrapper class for holding battery data. Attributes: soc: battery's overall SoC in percent (%). soc_lower_bound: the SoC below which discharge commands will be blocked by the system, in percent (%). soc_upper_bound: the SoC above which charge commands will be blocked by the system, in percent (%). capacity: the capacity of the battery in Wh (Watt-hour) power_lower_bound: the maximum discharge power, in Watts, represented in the passive sign convention. This will be a negative number, or zero if no discharging is possible. power_upper_bound: the maximum charge power, in Watts, represented in the passive sign convention. This will be a positive number, or zero if no charging is possible. \"\"\" soc : float soc_lower_bound : float soc_upper_bound : float capacity : float power_lower_bound : float power_upper_bound : float @classmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> BatteryData : \"\"\"Create BatteryData from a protobuf message. Args: raw: raw component data as decoded from the wire. Returns: Instance of BatteryData created from the protobuf message. \"\"\" battery_data = cls ( component_id = raw . id , timestamp = raw . ts . ToDatetime ( tzinfo = pytz . UTC ), soc = raw . battery . data . soc . avg , soc_lower_bound = raw . battery . data . soc . system_bounds . lower , soc_upper_bound = raw . battery . data . soc . system_bounds . upper , capacity = raw . battery . properties . capacity , power_lower_bound = raw . battery . data . dc . power . system_bounds . lower , power_upper_bound = raw . battery . data . dc . power . system_bounds . upper , ) battery_data . _set_raw ( raw = raw ) return battery_data Functions \u00a4 from_proto ( raw ) classmethod \u00a4 Create BatteryData from a protobuf message. PARAMETER DESCRIPTION raw raw component data as decoded from the wire. TYPE: microgrid_pb . ComponentData RETURNS DESCRIPTION BatteryData Instance of BatteryData created from the protobuf message. Source code in frequenz/sdk/microgrid/component_data.py 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 @classmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> BatteryData : \"\"\"Create BatteryData from a protobuf message. Args: raw: raw component data as decoded from the wire. Returns: Instance of BatteryData created from the protobuf message. \"\"\" battery_data = cls ( component_id = raw . id , timestamp = raw . ts . ToDatetime ( tzinfo = pytz . UTC ), soc = raw . battery . data . soc . avg , soc_lower_bound = raw . battery . data . soc . system_bounds . lower , soc_upper_bound = raw . battery . data . soc . system_bounds . upper , capacity = raw . battery . properties . capacity , power_lower_bound = raw . battery . data . dc . power . system_bounds . lower , power_upper_bound = raw . battery . data . dc . power . system_bounds . upper , ) battery_data . _set_raw ( raw = raw ) return battery_data frequenz.sdk.microgrid.component_data.ComponentData dataclass \u00a4 Bases: ABC A private base class for strongly typed component data classes. ATTRIBUTE DESCRIPTION component_id the ID identifying this component in the microgrid TYPE: int timestamp the timestamp of when the data was measured. TYPE: datetime raw raw component data as decoded from the wire TYPE: Optional [ microgrid_pb . ComponentData ] Source code in frequenz/sdk/microgrid/component_data.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 @dataclass ( frozen = True ) class ComponentData ( ABC ): \"\"\"A private base class for strongly typed component data classes. Attributes: component_id: the ID identifying this component in the microgrid timestamp: the timestamp of when the data was measured. raw: raw component data as decoded from the wire \"\"\" component_id : int timestamp : datetime # The `raw` attribute is excluded from the constructor as it can only be provided # when instantiating `ComponentData` using the `from_proto` method, which reads # data from a protobuf message. The whole protobuf message is stored as the `raw` # attribute. When `ComponentData` is not instantiated from a protobuf message, # i.e. using the constructor, `raw` will be set to `None`. raw : Optional [ microgrid_pb . ComponentData ] = field ( default = None , init = False ) def _set_raw ( self , raw : microgrid_pb . ComponentData ) -> None : \"\"\"Store raw protobuf message. It is preferred to keep the dataclasses immutable (frozen) and make the `raw` attribute read-only, which is why the approach of writing to `__dict__` was used, instead of mutating the `self.raw = raw` attribute directly. Args: raw: raw component data as decoded from the wire. \"\"\" self . __dict__ [ \"raw\" ] = raw @classmethod @abstractmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> ComponentData : \"\"\"Create ComponentData from a protobuf message. Args: raw: raw component data as decoded from the wire. \"\"\" Functions \u00a4 from_proto ( raw ) classmethod abstractmethod \u00a4 Create ComponentData from a protobuf message. PARAMETER DESCRIPTION raw raw component data as decoded from the wire. TYPE: microgrid_pb . ComponentData Source code in frequenz/sdk/microgrid/component_data.py 49 50 51 52 53 54 55 56 @classmethod @abstractmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> ComponentData : \"\"\"Create ComponentData from a protobuf message. Args: raw: raw component data as decoded from the wire. \"\"\" frequenz.sdk.microgrid.component_data.EVChargerData dataclass \u00a4 Bases: ComponentData A wrapper class for holding ev_charger data. ATTRIBUTE DESCRIPTION active_power_consumption the 3-phase active power, in Watts, represented in the passive sign convention. +ve current means consumption, away from the grid. -ve current means supply into the grid. current_per_phase AC current in Amperes (A) for phase/line 1,2 and 3 respectively. +ve current means consumption, away from the grid. -ve current means supply into the grid. TYPE: Tuple [ float , float , float ] voltage_per_phase the AC voltage in Volts (V) between the line and the neutral wire for phase/line 1,2 and 3 respectively. TYPE: Tuple [ float , float , float ] cable_state the state of the ev charger's cable TYPE: EVChargerCableState Source code in frequenz/sdk/microgrid/component_data.py 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 @dataclass ( frozen = True ) class EVChargerData ( ComponentData ): \"\"\"A wrapper class for holding ev_charger data. Attributes: active_power_consumption: the 3-phase active power, in Watts, represented in the passive sign convention. +ve current means consumption, away from the grid. -ve current means supply into the grid. current_per_phase: AC current in Amperes (A) for phase/line 1,2 and 3 respectively. +ve current means consumption, away from the grid. -ve current means supply into the grid. voltage_per_phase: the AC voltage in Volts (V) between the line and the neutral wire for phase/line 1,2 and 3 respectively. cable_state: the state of the ev charger's cable \"\"\" active_power : float current_per_phase : Tuple [ float , float , float ] voltage_per_phase : Tuple [ float , float , float ] cable_state : EVChargerCableState @classmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> EVChargerData : \"\"\"Create EVChargerData from a protobuf message. Args: raw: raw component data as decoded from the wire. Returns: Instance of EVChargerData created from the protobuf message. \"\"\" ev_charger_data = cls ( component_id = raw . id , timestamp = raw . ts . ToDatetime ( tzinfo = pytz . UTC ), active_power = raw . ev_charger . data . ac . power_active . value , current_per_phase = ( raw . ev_charger . data . ac . phase_1 . current . value , raw . ev_charger . data . ac . phase_2 . current . value , raw . ev_charger . data . ac . phase_3 . current . value , ), voltage_per_phase = ( raw . ev_charger . data . ac . phase_1 . voltage . value , raw . ev_charger . data . ac . phase_2 . voltage . value , raw . ev_charger . data . ac . phase_3 . voltage . value , ), cable_state = EVChargerCableState . from_pb ( raw . ev_charger . state . cable_state ), ) ev_charger_data . _set_raw ( raw = raw ) return ev_charger_data Functions \u00a4 from_proto ( raw ) classmethod \u00a4 Create EVChargerData from a protobuf message. PARAMETER DESCRIPTION raw raw component data as decoded from the wire. TYPE: microgrid_pb . ComponentData RETURNS DESCRIPTION EVChargerData Instance of EVChargerData created from the protobuf message. Source code in frequenz/sdk/microgrid/component_data.py 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 @classmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> EVChargerData : \"\"\"Create EVChargerData from a protobuf message. Args: raw: raw component data as decoded from the wire. Returns: Instance of EVChargerData created from the protobuf message. \"\"\" ev_charger_data = cls ( component_id = raw . id , timestamp = raw . ts . ToDatetime ( tzinfo = pytz . UTC ), active_power = raw . ev_charger . data . ac . power_active . value , current_per_phase = ( raw . ev_charger . data . ac . phase_1 . current . value , raw . ev_charger . data . ac . phase_2 . current . value , raw . ev_charger . data . ac . phase_3 . current . value , ), voltage_per_phase = ( raw . ev_charger . data . ac . phase_1 . voltage . value , raw . ev_charger . data . ac . phase_2 . voltage . value , raw . ev_charger . data . ac . phase_3 . voltage . value , ), cable_state = EVChargerCableState . from_pb ( raw . ev_charger . state . cable_state ), ) ev_charger_data . _set_raw ( raw = raw ) return ev_charger_data frequenz.sdk.microgrid.component_data.InverterData dataclass \u00a4 Bases: ComponentData A wrapper class for holding inverter data. ATTRIBUTE DESCRIPTION active_power the 3-phase active power, in Watts, represented in the passive sign convention. +ve current means consumption, away from the grid. -ve current means supply into the grid. TYPE: float active_power_lower_bound the maximum discharge power, in Watts, represented in the passive sign convention. This will be a negative number, or zero if no discharging is possible. TYPE: float active_power_upper_bound the maximum charge power, in Watts, represented in the passive sign convention. This will be a positive number, or zero if no charging is possible. TYPE: float Source code in frequenz/sdk/microgrid/component_data.py 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 @dataclass ( frozen = True ) class InverterData ( ComponentData ): \"\"\"A wrapper class for holding inverter data. Attributes: active_power: the 3-phase active power, in Watts, represented in the passive sign convention. +ve current means consumption, away from the grid. -ve current means supply into the grid. active_power_lower_bound: the maximum discharge power, in Watts, represented in the passive sign convention. This will be a negative number, or zero if no discharging is possible. active_power_upper_bound: the maximum charge power, in Watts, represented in the passive sign convention. This will be a positive number, or zero if no charging is possible. \"\"\" active_power : float active_power_lower_bound : float active_power_upper_bound : float @classmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> InverterData : \"\"\"Create InverterData from a protobuf message. Args: raw: raw component data as decoded from the wire. Returns: Instance of InverterData created from the protobuf message. \"\"\" inverter_data = cls ( component_id = raw . id , timestamp = raw . ts . ToDatetime ( tzinfo = pytz . UTC ), active_power = raw . inverter . data . ac . power_active . value , active_power_lower_bound = raw . inverter . data . ac . power_active . system_bounds . lower , active_power_upper_bound = raw . inverter . data . ac . power_active . system_bounds . upper , ) inverter_data . _set_raw ( raw = raw ) return inverter_data Functions \u00a4 from_proto ( raw ) classmethod \u00a4 Create InverterData from a protobuf message. PARAMETER DESCRIPTION raw raw component data as decoded from the wire. TYPE: microgrid_pb . ComponentData RETURNS DESCRIPTION InverterData Instance of InverterData created from the protobuf message. Source code in frequenz/sdk/microgrid/component_data.py 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 @classmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> InverterData : \"\"\"Create InverterData from a protobuf message. Args: raw: raw component data as decoded from the wire. Returns: Instance of InverterData created from the protobuf message. \"\"\" inverter_data = cls ( component_id = raw . id , timestamp = raw . ts . ToDatetime ( tzinfo = pytz . UTC ), active_power = raw . inverter . data . ac . power_active . value , active_power_lower_bound = raw . inverter . data . ac . power_active . system_bounds . lower , active_power_upper_bound = raw . inverter . data . ac . power_active . system_bounds . upper , ) inverter_data . _set_raw ( raw = raw ) return inverter_data frequenz.sdk.microgrid.component_data.MeterData dataclass \u00a4 Bases: ComponentData A wrapper class for holding meter data. ATTRIBUTE DESCRIPTION active_power the 3-phase active power, in Watts, represented in the passive sign convention. +ve current means consumption, away from the grid. -ve current means supply into the grid. TYPE: float current_per_phase AC current in Amperes (A) for phase/line 1,2 and 3 respectively. +ve current means consumption, away from the grid. -ve current means supply into the grid. TYPE: Tuple [ float , float , float ] voltage_per_phase the AC voltage in Volts (V) between the line and the neutral wire for phase/line 1,2 and 3 respectively. TYPE: Tuple [ float , float , float ] Source code in frequenz/sdk/microgrid/component_data.py 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 @dataclass ( frozen = True ) class MeterData ( ComponentData ): \"\"\"A wrapper class for holding meter data. Attributes: active_power: the 3-phase active power, in Watts, represented in the passive sign convention. +ve current means consumption, away from the grid. -ve current means supply into the grid. current_per_phase: AC current in Amperes (A) for phase/line 1,2 and 3 respectively. +ve current means consumption, away from the grid. -ve current means supply into the grid. voltage_per_phase: the AC voltage in Volts (V) between the line and the neutral wire for phase/line 1,2 and 3 respectively. \"\"\" active_power : float current_per_phase : Tuple [ float , float , float ] voltage_per_phase : Tuple [ float , float , float ] @classmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> MeterData : \"\"\"Create MeterData from a protobuf message. Args: raw: raw component data as decoded from the wire. Returns: Instance of MeterData created from the protobuf message. \"\"\" meter_data = cls ( component_id = raw . id , timestamp = raw . ts . ToDatetime ( tzinfo = pytz . UTC ), active_power = raw . meter . data . ac . power_active . value , current_per_phase = ( raw . meter . data . ac . phase_1 . current . value , raw . meter . data . ac . phase_2 . current . value , raw . meter . data . ac . phase_3 . current . value , ), voltage_per_phase = ( raw . meter . data . ac . phase_1 . voltage . value , raw . meter . data . ac . phase_2 . voltage . value , raw . meter . data . ac . phase_3 . voltage . value , ), ) meter_data . _set_raw ( raw = raw ) return meter_data Functions \u00a4 from_proto ( raw ) classmethod \u00a4 Create MeterData from a protobuf message. PARAMETER DESCRIPTION raw raw component data as decoded from the wire. TYPE: microgrid_pb . ComponentData RETURNS DESCRIPTION MeterData Instance of MeterData created from the protobuf message. Source code in frequenz/sdk/microgrid/component_data.py 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 @classmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> MeterData : \"\"\"Create MeterData from a protobuf message. Args: raw: raw component data as decoded from the wire. Returns: Instance of MeterData created from the protobuf message. \"\"\" meter_data = cls ( component_id = raw . id , timestamp = raw . ts . ToDatetime ( tzinfo = pytz . UTC ), active_power = raw . meter . data . ac . power_active . value , current_per_phase = ( raw . meter . data . ac . phase_1 . current . value , raw . meter . data . ac . phase_2 . current . value , raw . meter . data . ac . phase_3 . current . value , ), voltage_per_phase = ( raw . meter . data . ac . phase_1 . voltage . value , raw . meter . data . ac . phase_2 . voltage . value , raw . meter . data . ac . phase_3 . voltage . value , ), ) meter_data . _set_raw ( raw = raw ) return meter_data","title":"component_data"},{"location":"reference/frequenz/sdk/microgrid/component_data/#frequenz.sdk.microgrid.component_data","text":"Component data types for data coming from a microgrid.","title":"component_data"},{"location":"reference/frequenz/sdk/microgrid/component_data/#frequenz.sdk.microgrid.component_data-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/microgrid/component_data/#frequenz.sdk.microgrid.component_data.BatteryData","text":"Bases: ComponentData A wrapper class for holding battery data. ATTRIBUTE DESCRIPTION soc battery's overall SoC in percent (%). TYPE: float soc_lower_bound the SoC below which discharge commands will be blocked by the system, in percent (%). TYPE: float soc_upper_bound the SoC above which charge commands will be blocked by the system, in percent (%). TYPE: float capacity the capacity of the battery in Wh (Watt-hour) TYPE: float power_lower_bound the maximum discharge power, in Watts, represented in the passive sign convention. This will be a negative number, or zero if no discharging is possible. TYPE: float power_upper_bound the maximum charge power, in Watts, represented in the passive sign convention. This will be a positive number, or zero if no charging is possible. TYPE: float Source code in frequenz/sdk/microgrid/component_data.py 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 @dataclass ( frozen = True ) class BatteryData ( ComponentData ): \"\"\"A wrapper class for holding battery data. Attributes: soc: battery's overall SoC in percent (%). soc_lower_bound: the SoC below which discharge commands will be blocked by the system, in percent (%). soc_upper_bound: the SoC above which charge commands will be blocked by the system, in percent (%). capacity: the capacity of the battery in Wh (Watt-hour) power_lower_bound: the maximum discharge power, in Watts, represented in the passive sign convention. This will be a negative number, or zero if no discharging is possible. power_upper_bound: the maximum charge power, in Watts, represented in the passive sign convention. This will be a positive number, or zero if no charging is possible. \"\"\" soc : float soc_lower_bound : float soc_upper_bound : float capacity : float power_lower_bound : float power_upper_bound : float @classmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> BatteryData : \"\"\"Create BatteryData from a protobuf message. Args: raw: raw component data as decoded from the wire. Returns: Instance of BatteryData created from the protobuf message. \"\"\" battery_data = cls ( component_id = raw . id , timestamp = raw . ts . ToDatetime ( tzinfo = pytz . UTC ), soc = raw . battery . data . soc . avg , soc_lower_bound = raw . battery . data . soc . system_bounds . lower , soc_upper_bound = raw . battery . data . soc . system_bounds . upper , capacity = raw . battery . properties . capacity , power_lower_bound = raw . battery . data . dc . power . system_bounds . lower , power_upper_bound = raw . battery . data . dc . power . system_bounds . upper , ) battery_data . _set_raw ( raw = raw ) return battery_data","title":"BatteryData"},{"location":"reference/frequenz/sdk/microgrid/component_data/#frequenz.sdk.microgrid.component_data.BatteryData-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/microgrid/component_data/#frequenz.sdk.microgrid.component_data.BatteryData.from_proto","text":"Create BatteryData from a protobuf message. PARAMETER DESCRIPTION raw raw component data as decoded from the wire. TYPE: microgrid_pb . ComponentData RETURNS DESCRIPTION BatteryData Instance of BatteryData created from the protobuf message. Source code in frequenz/sdk/microgrid/component_data.py 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 @classmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> BatteryData : \"\"\"Create BatteryData from a protobuf message. Args: raw: raw component data as decoded from the wire. Returns: Instance of BatteryData created from the protobuf message. \"\"\" battery_data = cls ( component_id = raw . id , timestamp = raw . ts . ToDatetime ( tzinfo = pytz . UTC ), soc = raw . battery . data . soc . avg , soc_lower_bound = raw . battery . data . soc . system_bounds . lower , soc_upper_bound = raw . battery . data . soc . system_bounds . upper , capacity = raw . battery . properties . capacity , power_lower_bound = raw . battery . data . dc . power . system_bounds . lower , power_upper_bound = raw . battery . data . dc . power . system_bounds . upper , ) battery_data . _set_raw ( raw = raw ) return battery_data","title":"from_proto()"},{"location":"reference/frequenz/sdk/microgrid/component_data/#frequenz.sdk.microgrid.component_data.ComponentData","text":"Bases: ABC A private base class for strongly typed component data classes. ATTRIBUTE DESCRIPTION component_id the ID identifying this component in the microgrid TYPE: int timestamp the timestamp of when the data was measured. TYPE: datetime raw raw component data as decoded from the wire TYPE: Optional [ microgrid_pb . ComponentData ] Source code in frequenz/sdk/microgrid/component_data.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 @dataclass ( frozen = True ) class ComponentData ( ABC ): \"\"\"A private base class for strongly typed component data classes. Attributes: component_id: the ID identifying this component in the microgrid timestamp: the timestamp of when the data was measured. raw: raw component data as decoded from the wire \"\"\" component_id : int timestamp : datetime # The `raw` attribute is excluded from the constructor as it can only be provided # when instantiating `ComponentData` using the `from_proto` method, which reads # data from a protobuf message. The whole protobuf message is stored as the `raw` # attribute. When `ComponentData` is not instantiated from a protobuf message, # i.e. using the constructor, `raw` will be set to `None`. raw : Optional [ microgrid_pb . ComponentData ] = field ( default = None , init = False ) def _set_raw ( self , raw : microgrid_pb . ComponentData ) -> None : \"\"\"Store raw protobuf message. It is preferred to keep the dataclasses immutable (frozen) and make the `raw` attribute read-only, which is why the approach of writing to `__dict__` was used, instead of mutating the `self.raw = raw` attribute directly. Args: raw: raw component data as decoded from the wire. \"\"\" self . __dict__ [ \"raw\" ] = raw @classmethod @abstractmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> ComponentData : \"\"\"Create ComponentData from a protobuf message. Args: raw: raw component data as decoded from the wire. \"\"\"","title":"ComponentData"},{"location":"reference/frequenz/sdk/microgrid/component_data/#frequenz.sdk.microgrid.component_data.ComponentData-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/microgrid/component_data/#frequenz.sdk.microgrid.component_data.ComponentData.from_proto","text":"Create ComponentData from a protobuf message. PARAMETER DESCRIPTION raw raw component data as decoded from the wire. TYPE: microgrid_pb . ComponentData Source code in frequenz/sdk/microgrid/component_data.py 49 50 51 52 53 54 55 56 @classmethod @abstractmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> ComponentData : \"\"\"Create ComponentData from a protobuf message. Args: raw: raw component data as decoded from the wire. \"\"\"","title":"from_proto()"},{"location":"reference/frequenz/sdk/microgrid/component_data/#frequenz.sdk.microgrid.component_data.EVChargerData","text":"Bases: ComponentData A wrapper class for holding ev_charger data. ATTRIBUTE DESCRIPTION active_power_consumption the 3-phase active power, in Watts, represented in the passive sign convention. +ve current means consumption, away from the grid. -ve current means supply into the grid. current_per_phase AC current in Amperes (A) for phase/line 1,2 and 3 respectively. +ve current means consumption, away from the grid. -ve current means supply into the grid. TYPE: Tuple [ float , float , float ] voltage_per_phase the AC voltage in Volts (V) between the line and the neutral wire for phase/line 1,2 and 3 respectively. TYPE: Tuple [ float , float , float ] cable_state the state of the ev charger's cable TYPE: EVChargerCableState Source code in frequenz/sdk/microgrid/component_data.py 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 @dataclass ( frozen = True ) class EVChargerData ( ComponentData ): \"\"\"A wrapper class for holding ev_charger data. Attributes: active_power_consumption: the 3-phase active power, in Watts, represented in the passive sign convention. +ve current means consumption, away from the grid. -ve current means supply into the grid. current_per_phase: AC current in Amperes (A) for phase/line 1,2 and 3 respectively. +ve current means consumption, away from the grid. -ve current means supply into the grid. voltage_per_phase: the AC voltage in Volts (V) between the line and the neutral wire for phase/line 1,2 and 3 respectively. cable_state: the state of the ev charger's cable \"\"\" active_power : float current_per_phase : Tuple [ float , float , float ] voltage_per_phase : Tuple [ float , float , float ] cable_state : EVChargerCableState @classmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> EVChargerData : \"\"\"Create EVChargerData from a protobuf message. Args: raw: raw component data as decoded from the wire. Returns: Instance of EVChargerData created from the protobuf message. \"\"\" ev_charger_data = cls ( component_id = raw . id , timestamp = raw . ts . ToDatetime ( tzinfo = pytz . UTC ), active_power = raw . ev_charger . data . ac . power_active . value , current_per_phase = ( raw . ev_charger . data . ac . phase_1 . current . value , raw . ev_charger . data . ac . phase_2 . current . value , raw . ev_charger . data . ac . phase_3 . current . value , ), voltage_per_phase = ( raw . ev_charger . data . ac . phase_1 . voltage . value , raw . ev_charger . data . ac . phase_2 . voltage . value , raw . ev_charger . data . ac . phase_3 . voltage . value , ), cable_state = EVChargerCableState . from_pb ( raw . ev_charger . state . cable_state ), ) ev_charger_data . _set_raw ( raw = raw ) return ev_charger_data","title":"EVChargerData"},{"location":"reference/frequenz/sdk/microgrid/component_data/#frequenz.sdk.microgrid.component_data.EVChargerData-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/microgrid/component_data/#frequenz.sdk.microgrid.component_data.EVChargerData.from_proto","text":"Create EVChargerData from a protobuf message. PARAMETER DESCRIPTION raw raw component data as decoded from the wire. TYPE: microgrid_pb . ComponentData RETURNS DESCRIPTION EVChargerData Instance of EVChargerData created from the protobuf message. Source code in frequenz/sdk/microgrid/component_data.py 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 @classmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> EVChargerData : \"\"\"Create EVChargerData from a protobuf message. Args: raw: raw component data as decoded from the wire. Returns: Instance of EVChargerData created from the protobuf message. \"\"\" ev_charger_data = cls ( component_id = raw . id , timestamp = raw . ts . ToDatetime ( tzinfo = pytz . UTC ), active_power = raw . ev_charger . data . ac . power_active . value , current_per_phase = ( raw . ev_charger . data . ac . phase_1 . current . value , raw . ev_charger . data . ac . phase_2 . current . value , raw . ev_charger . data . ac . phase_3 . current . value , ), voltage_per_phase = ( raw . ev_charger . data . ac . phase_1 . voltage . value , raw . ev_charger . data . ac . phase_2 . voltage . value , raw . ev_charger . data . ac . phase_3 . voltage . value , ), cable_state = EVChargerCableState . from_pb ( raw . ev_charger . state . cable_state ), ) ev_charger_data . _set_raw ( raw = raw ) return ev_charger_data","title":"from_proto()"},{"location":"reference/frequenz/sdk/microgrid/component_data/#frequenz.sdk.microgrid.component_data.InverterData","text":"Bases: ComponentData A wrapper class for holding inverter data. ATTRIBUTE DESCRIPTION active_power the 3-phase active power, in Watts, represented in the passive sign convention. +ve current means consumption, away from the grid. -ve current means supply into the grid. TYPE: float active_power_lower_bound the maximum discharge power, in Watts, represented in the passive sign convention. This will be a negative number, or zero if no discharging is possible. TYPE: float active_power_upper_bound the maximum charge power, in Watts, represented in the passive sign convention. This will be a positive number, or zero if no charging is possible. TYPE: float Source code in frequenz/sdk/microgrid/component_data.py 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 @dataclass ( frozen = True ) class InverterData ( ComponentData ): \"\"\"A wrapper class for holding inverter data. Attributes: active_power: the 3-phase active power, in Watts, represented in the passive sign convention. +ve current means consumption, away from the grid. -ve current means supply into the grid. active_power_lower_bound: the maximum discharge power, in Watts, represented in the passive sign convention. This will be a negative number, or zero if no discharging is possible. active_power_upper_bound: the maximum charge power, in Watts, represented in the passive sign convention. This will be a positive number, or zero if no charging is possible. \"\"\" active_power : float active_power_lower_bound : float active_power_upper_bound : float @classmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> InverterData : \"\"\"Create InverterData from a protobuf message. Args: raw: raw component data as decoded from the wire. Returns: Instance of InverterData created from the protobuf message. \"\"\" inverter_data = cls ( component_id = raw . id , timestamp = raw . ts . ToDatetime ( tzinfo = pytz . UTC ), active_power = raw . inverter . data . ac . power_active . value , active_power_lower_bound = raw . inverter . data . ac . power_active . system_bounds . lower , active_power_upper_bound = raw . inverter . data . ac . power_active . system_bounds . upper , ) inverter_data . _set_raw ( raw = raw ) return inverter_data","title":"InverterData"},{"location":"reference/frequenz/sdk/microgrid/component_data/#frequenz.sdk.microgrid.component_data.InverterData-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/microgrid/component_data/#frequenz.sdk.microgrid.component_data.InverterData.from_proto","text":"Create InverterData from a protobuf message. PARAMETER DESCRIPTION raw raw component data as decoded from the wire. TYPE: microgrid_pb . ComponentData RETURNS DESCRIPTION InverterData Instance of InverterData created from the protobuf message. Source code in frequenz/sdk/microgrid/component_data.py 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 @classmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> InverterData : \"\"\"Create InverterData from a protobuf message. Args: raw: raw component data as decoded from the wire. Returns: Instance of InverterData created from the protobuf message. \"\"\" inverter_data = cls ( component_id = raw . id , timestamp = raw . ts . ToDatetime ( tzinfo = pytz . UTC ), active_power = raw . inverter . data . ac . power_active . value , active_power_lower_bound = raw . inverter . data . ac . power_active . system_bounds . lower , active_power_upper_bound = raw . inverter . data . ac . power_active . system_bounds . upper , ) inverter_data . _set_raw ( raw = raw ) return inverter_data","title":"from_proto()"},{"location":"reference/frequenz/sdk/microgrid/component_data/#frequenz.sdk.microgrid.component_data.MeterData","text":"Bases: ComponentData A wrapper class for holding meter data. ATTRIBUTE DESCRIPTION active_power the 3-phase active power, in Watts, represented in the passive sign convention. +ve current means consumption, away from the grid. -ve current means supply into the grid. TYPE: float current_per_phase AC current in Amperes (A) for phase/line 1,2 and 3 respectively. +ve current means consumption, away from the grid. -ve current means supply into the grid. TYPE: Tuple [ float , float , float ] voltage_per_phase the AC voltage in Volts (V) between the line and the neutral wire for phase/line 1,2 and 3 respectively. TYPE: Tuple [ float , float , float ] Source code in frequenz/sdk/microgrid/component_data.py 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 @dataclass ( frozen = True ) class MeterData ( ComponentData ): \"\"\"A wrapper class for holding meter data. Attributes: active_power: the 3-phase active power, in Watts, represented in the passive sign convention. +ve current means consumption, away from the grid. -ve current means supply into the grid. current_per_phase: AC current in Amperes (A) for phase/line 1,2 and 3 respectively. +ve current means consumption, away from the grid. -ve current means supply into the grid. voltage_per_phase: the AC voltage in Volts (V) between the line and the neutral wire for phase/line 1,2 and 3 respectively. \"\"\" active_power : float current_per_phase : Tuple [ float , float , float ] voltage_per_phase : Tuple [ float , float , float ] @classmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> MeterData : \"\"\"Create MeterData from a protobuf message. Args: raw: raw component data as decoded from the wire. Returns: Instance of MeterData created from the protobuf message. \"\"\" meter_data = cls ( component_id = raw . id , timestamp = raw . ts . ToDatetime ( tzinfo = pytz . UTC ), active_power = raw . meter . data . ac . power_active . value , current_per_phase = ( raw . meter . data . ac . phase_1 . current . value , raw . meter . data . ac . phase_2 . current . value , raw . meter . data . ac . phase_3 . current . value , ), voltage_per_phase = ( raw . meter . data . ac . phase_1 . voltage . value , raw . meter . data . ac . phase_2 . voltage . value , raw . meter . data . ac . phase_3 . voltage . value , ), ) meter_data . _set_raw ( raw = raw ) return meter_data","title":"MeterData"},{"location":"reference/frequenz/sdk/microgrid/component_data/#frequenz.sdk.microgrid.component_data.MeterData-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/microgrid/component_data/#frequenz.sdk.microgrid.component_data.MeterData.from_proto","text":"Create MeterData from a protobuf message. PARAMETER DESCRIPTION raw raw component data as decoded from the wire. TYPE: microgrid_pb . ComponentData RETURNS DESCRIPTION MeterData Instance of MeterData created from the protobuf message. Source code in frequenz/sdk/microgrid/component_data.py 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 @classmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> MeterData : \"\"\"Create MeterData from a protobuf message. Args: raw: raw component data as decoded from the wire. Returns: Instance of MeterData created from the protobuf message. \"\"\" meter_data = cls ( component_id = raw . id , timestamp = raw . ts . ToDatetime ( tzinfo = pytz . UTC ), active_power = raw . meter . data . ac . power_active . value , current_per_phase = ( raw . meter . data . ac . phase_1 . current . value , raw . meter . data . ac . phase_2 . current . value , raw . meter . data . ac . phase_3 . current . value , ), voltage_per_phase = ( raw . meter . data . ac . phase_1 . voltage . value , raw . meter . data . ac . phase_2 . voltage . value , raw . meter . data . ac . phase_3 . voltage . value , ), ) meter_data . _set_raw ( raw = raw ) return meter_data","title":"from_proto()"},{"location":"reference/frequenz/sdk/microgrid/component_states/","text":"frequenz.sdk.microgrid.component_states \u00a4 Defines states of components that can be used in a microgrid. Classes \u00a4 frequenz.sdk.microgrid.component_states.EVChargerCableState \u00a4 Bases: Enum Cable states of an EV Charger. Source code in frequenz/sdk/microgrid/component_states.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 class EVChargerCableState ( Enum ): \"\"\"Cable states of an EV Charger.\"\"\" UNSPECIFIED = ev_charger_pb . CableState . CABLE_STATE_UNSPECIFIED UNPLUGGED = ev_charger_pb . CableState . CABLE_STATE_UNPLUGGED CHARGING_STATION_PLUGGED = ( ev_charger_pb . CableState . CABLE_STATE_CHARGING_STATION_PLUGGED ) CHARGING_STATION_LOCKED = ( ev_charger_pb . CableState . CABLE_STATE_CHARGING_STATION_LOCKED ) EV_PLUGGED = ev_charger_pb . CableState . CABLE_STATE_EV_PLUGGED EV_LOCKED = ev_charger_pb . CableState . CABLE_STATE_EV_LOCKED @classmethod def from_pb ( cls , evc_state : ev_charger_pb . CableState . ValueType ) -> EVChargerCableState : \"\"\"Convert a protobuf CableState value to EVChargerCableState enum. Args: evc_state: protobuf cable state to convert. Returns: Enum value corresponding to the protobuf message. \"\"\" if not any ( t . value == evc_state for t in EVChargerCableState ): return cls . UNSPECIFIED return EVChargerCableState ( evc_state ) Functions \u00a4 from_pb ( evc_state ) classmethod \u00a4 Convert a protobuf CableState value to EVChargerCableState enum. PARAMETER DESCRIPTION evc_state protobuf cable state to convert. TYPE: ev_charger_pb . CableState . ValueType RETURNS DESCRIPTION EVChargerCableState Enum value corresponding to the protobuf message. Source code in frequenz/sdk/microgrid/component_states.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 @classmethod def from_pb ( cls , evc_state : ev_charger_pb . CableState . ValueType ) -> EVChargerCableState : \"\"\"Convert a protobuf CableState value to EVChargerCableState enum. Args: evc_state: protobuf cable state to convert. Returns: Enum value corresponding to the protobuf message. \"\"\" if not any ( t . value == evc_state for t in EVChargerCableState ): return cls . UNSPECIFIED return EVChargerCableState ( evc_state )","title":"component_states"},{"location":"reference/frequenz/sdk/microgrid/component_states/#frequenz.sdk.microgrid.component_states","text":"Defines states of components that can be used in a microgrid.","title":"component_states"},{"location":"reference/frequenz/sdk/microgrid/component_states/#frequenz.sdk.microgrid.component_states-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/microgrid/component_states/#frequenz.sdk.microgrid.component_states.EVChargerCableState","text":"Bases: Enum Cable states of an EV Charger. Source code in frequenz/sdk/microgrid/component_states.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 class EVChargerCableState ( Enum ): \"\"\"Cable states of an EV Charger.\"\"\" UNSPECIFIED = ev_charger_pb . CableState . CABLE_STATE_UNSPECIFIED UNPLUGGED = ev_charger_pb . CableState . CABLE_STATE_UNPLUGGED CHARGING_STATION_PLUGGED = ( ev_charger_pb . CableState . CABLE_STATE_CHARGING_STATION_PLUGGED ) CHARGING_STATION_LOCKED = ( ev_charger_pb . CableState . CABLE_STATE_CHARGING_STATION_LOCKED ) EV_PLUGGED = ev_charger_pb . CableState . CABLE_STATE_EV_PLUGGED EV_LOCKED = ev_charger_pb . CableState . CABLE_STATE_EV_LOCKED @classmethod def from_pb ( cls , evc_state : ev_charger_pb . CableState . ValueType ) -> EVChargerCableState : \"\"\"Convert a protobuf CableState value to EVChargerCableState enum. Args: evc_state: protobuf cable state to convert. Returns: Enum value corresponding to the protobuf message. \"\"\" if not any ( t . value == evc_state for t in EVChargerCableState ): return cls . UNSPECIFIED return EVChargerCableState ( evc_state )","title":"EVChargerCableState"},{"location":"reference/frequenz/sdk/microgrid/component_states/#frequenz.sdk.microgrid.component_states.EVChargerCableState-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/microgrid/component_states/#frequenz.sdk.microgrid.component_states.EVChargerCableState.from_pb","text":"Convert a protobuf CableState value to EVChargerCableState enum. PARAMETER DESCRIPTION evc_state protobuf cable state to convert. TYPE: ev_charger_pb . CableState . ValueType RETURNS DESCRIPTION EVChargerCableState Enum value corresponding to the protobuf message. Source code in frequenz/sdk/microgrid/component_states.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 @classmethod def from_pb ( cls , evc_state : ev_charger_pb . CableState . ValueType ) -> EVChargerCableState : \"\"\"Convert a protobuf CableState value to EVChargerCableState enum. Args: evc_state: protobuf cable state to convert. Returns: Enum value corresponding to the protobuf message. \"\"\" if not any ( t . value == evc_state for t in EVChargerCableState ): return cls . UNSPECIFIED return EVChargerCableState ( evc_state )","title":"from_pb()"},{"location":"reference/frequenz/sdk/microgrid/connection/","text":"frequenz.sdk.microgrid.connection \u00a4 Defines the connections between microgrid components. Classes \u00a4 frequenz.sdk.microgrid.connection.Connection \u00a4 Bases: NamedTuple Metadata for a connection between microgrid components. Source code in frequenz/sdk/microgrid/connection.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 class Connection ( NamedTuple ): \"\"\"Metadata for a connection between microgrid components.\"\"\" start : int end : int def is_valid ( self ) -> bool : \"\"\"Check if this instance contains valid data. Returns: `True` if `start >= 0`, `end > 0`, and `start != end`, `False` otherwise. \"\"\" return self . start >= 0 and self . end > 0 and self . start != self . end Functions \u00a4 is_valid () \u00a4 Check if this instance contains valid data. RETURNS DESCRIPTION bool True if start >= 0 , end > 0 , and start != end , False otherwise. Source code in frequenz/sdk/microgrid/connection.py 15 16 17 18 19 20 21 22 def is_valid ( self ) -> bool : \"\"\"Check if this instance contains valid data. Returns: `True` if `start >= 0`, `end > 0`, and `start != end`, `False` otherwise. \"\"\" return self . start >= 0 and self . end > 0 and self . start != self . end","title":"connection"},{"location":"reference/frequenz/sdk/microgrid/connection/#frequenz.sdk.microgrid.connection","text":"Defines the connections between microgrid components.","title":"connection"},{"location":"reference/frequenz/sdk/microgrid/connection/#frequenz.sdk.microgrid.connection-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/microgrid/connection/#frequenz.sdk.microgrid.connection.Connection","text":"Bases: NamedTuple Metadata for a connection between microgrid components. Source code in frequenz/sdk/microgrid/connection.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 class Connection ( NamedTuple ): \"\"\"Metadata for a connection between microgrid components.\"\"\" start : int end : int def is_valid ( self ) -> bool : \"\"\"Check if this instance contains valid data. Returns: `True` if `start >= 0`, `end > 0`, and `start != end`, `False` otherwise. \"\"\" return self . start >= 0 and self . end > 0 and self . start != self . end","title":"Connection"},{"location":"reference/frequenz/sdk/microgrid/connection/#frequenz.sdk.microgrid.connection.Connection-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/microgrid/connection/#frequenz.sdk.microgrid.connection.Connection.is_valid","text":"Check if this instance contains valid data. RETURNS DESCRIPTION bool True if start >= 0 , end > 0 , and start != end , False otherwise. Source code in frequenz/sdk/microgrid/connection.py 15 16 17 18 19 20 21 22 def is_valid ( self ) -> bool : \"\"\"Check if this instance contains valid data. Returns: `True` if `start >= 0`, `end > 0`, and `start != end`, `False` otherwise. \"\"\" return self . start >= 0 and self . end > 0 and self . start != self . end","title":"is_valid()"},{"location":"reference/frequenz/sdk/microgrid/graph/","text":"frequenz.sdk.microgrid.graph \u00a4 Defines a graph representation of how microgrid components are connected. The component graph is an approximate representation of the microgrid circuit, abstracted to a level appropriate for higher-level monitoring and control. Examples of use-cases would be using the graph structure to infer which component measurements need to be combined to obtain grid power or onsite load identifying which inverter(s) need to be engaged to (dis)charge a particular battery understanding which power flows in the microgrid are derived from green and grey sources It deliberately does not include all pieces of hardware placed in the microgrid, instead limiting itself to just those that are needed to monitor and control the flow of power. Classes \u00a4 frequenz.sdk.microgrid.graph.ComponentGraph \u00a4 Bases: ABC Interface for component graph implementations. Source code in frequenz/sdk/microgrid/graph.py 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 class ComponentGraph ( ABC ): \"\"\"Interface for component graph implementations.\"\"\" @abstractmethod def components ( self , component_id : Optional [ Set [ int ]] = None , component_category : Optional [ Set [ ComponentCategory ]] = None , ) -> Set [ Component ]: \"\"\"Fetch the components of the microgrid. Args: component_id: filter out any components not matching one of the provided IDs component_category: filter out any components not matching one of the provided types Returns: Set of the components currently connected to the microgrid, filtered by the provided `component_id` and `component_category` values. \"\"\" @abstractmethod def connections ( self , start : Optional [ Set [ int ]] = None , end : Optional [ Set [ int ]] = None , ) -> Set [ Connection ]: \"\"\"Fetch the connections between microgrid components. Args: start: filter out any connections whose `start` does not match one of these component IDs end: filter out any connections whose `end` does not match one of these component IDs Returns: Set of the connections between components in the microgrid, filtered by the provided `start`/`end` choices. \"\"\" @abstractmethod def predecessors ( self , component_id : int ) -> Set [ Component ]: \"\"\"Fetch the graph predecessors of the specified component. Args: component_id: numerical ID of the component whose predecessors should be fetched Returns: Set of IDs of the components that are predecessors of `component_id`, i.e. for which there is a connection from each of these components to `component_id`. Raises: KeyError: if the specified `component_id` is not in the graph \"\"\" @abstractmethod def successors ( self , component_id : int ) -> Set [ Component ]: \"\"\"Fetch the graph successors of the specified component. Args: component_id: numerical ID of the component whose successors should be fetched Returns: Set of IDs of the components that are successors of `component_id`, i.e. for which there is a connection from `component_id` to each of these components. Raises: KeyError: if the specified `component_id` is not in the graph \"\"\" Functions \u00a4 components ( component_id = None , component_category = None ) abstractmethod \u00a4 Fetch the components of the microgrid. PARAMETER DESCRIPTION component_id filter out any components not matching one of the provided IDs TYPE: Optional [ Set [ int ]] DEFAULT: None component_category filter out any components not matching one of the provided types TYPE: Optional [ Set [ ComponentCategory ]] DEFAULT: None RETURNS DESCRIPTION Set [ Component ] Set of the components currently connected to the microgrid, filtered by the provided component_id and component_category values. Source code in frequenz/sdk/microgrid/graph.py 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 @abstractmethod def components ( self , component_id : Optional [ Set [ int ]] = None , component_category : Optional [ Set [ ComponentCategory ]] = None , ) -> Set [ Component ]: \"\"\"Fetch the components of the microgrid. Args: component_id: filter out any components not matching one of the provided IDs component_category: filter out any components not matching one of the provided types Returns: Set of the components currently connected to the microgrid, filtered by the provided `component_id` and `component_category` values. \"\"\" connections ( start = None , end = None ) abstractmethod \u00a4 Fetch the connections between microgrid components. PARAMETER DESCRIPTION start filter out any connections whose start does not match one of these component IDs TYPE: Optional [ Set [ int ]] DEFAULT: None end filter out any connections whose end does not match one of these component IDs TYPE: Optional [ Set [ int ]] DEFAULT: None RETURNS DESCRIPTION Set [ Connection ] Set of the connections between components in the microgrid, filtered by the provided start / end choices. Source code in frequenz/sdk/microgrid/graph.py 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 @abstractmethod def connections ( self , start : Optional [ Set [ int ]] = None , end : Optional [ Set [ int ]] = None , ) -> Set [ Connection ]: \"\"\"Fetch the connections between microgrid components. Args: start: filter out any connections whose `start` does not match one of these component IDs end: filter out any connections whose `end` does not match one of these component IDs Returns: Set of the connections between components in the microgrid, filtered by the provided `start`/`end` choices. \"\"\" predecessors ( component_id ) abstractmethod \u00a4 Fetch the graph predecessors of the specified component. PARAMETER DESCRIPTION component_id numerical ID of the component whose predecessors should be fetched TYPE: int RETURNS DESCRIPTION Set [ Component ] Set of IDs of the components that are predecessors of component_id , i.e. for which there is a connection from each of these components to component_id . RAISES DESCRIPTION KeyError if the specified component_id is not in the graph Source code in frequenz/sdk/microgrid/graph.py 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 @abstractmethod def predecessors ( self , component_id : int ) -> Set [ Component ]: \"\"\"Fetch the graph predecessors of the specified component. Args: component_id: numerical ID of the component whose predecessors should be fetched Returns: Set of IDs of the components that are predecessors of `component_id`, i.e. for which there is a connection from each of these components to `component_id`. Raises: KeyError: if the specified `component_id` is not in the graph \"\"\" successors ( component_id ) abstractmethod \u00a4 Fetch the graph successors of the specified component. PARAMETER DESCRIPTION component_id numerical ID of the component whose successors should be fetched TYPE: int RETURNS DESCRIPTION Set [ Component ] Set of IDs of the components that are successors of component_id , i.e. for which there is a connection from component_id to each of these components. RAISES DESCRIPTION KeyError if the specified component_id is not in the graph Source code in frequenz/sdk/microgrid/graph.py 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 @abstractmethod def successors ( self , component_id : int ) -> Set [ Component ]: \"\"\"Fetch the graph successors of the specified component. Args: component_id: numerical ID of the component whose successors should be fetched Returns: Set of IDs of the components that are successors of `component_id`, i.e. for which there is a connection from `component_id` to each of these components. Raises: KeyError: if the specified `component_id` is not in the graph \"\"\" frequenz.sdk.microgrid.graph.InvalidGraphError \u00a4 Bases: Exception Exception type that will be thrown if graph data is not valid. Source code in frequenz/sdk/microgrid/graph.py 39 40 class InvalidGraphError ( Exception ): \"\"\"Exception type that will be thrown if graph data is not valid.\"\"\"","title":"graph"},{"location":"reference/frequenz/sdk/microgrid/graph/#frequenz.sdk.microgrid.graph","text":"Defines a graph representation of how microgrid components are connected. The component graph is an approximate representation of the microgrid circuit, abstracted to a level appropriate for higher-level monitoring and control. Examples of use-cases would be using the graph structure to infer which component measurements need to be combined to obtain grid power or onsite load identifying which inverter(s) need to be engaged to (dis)charge a particular battery understanding which power flows in the microgrid are derived from green and grey sources It deliberately does not include all pieces of hardware placed in the microgrid, instead limiting itself to just those that are needed to monitor and control the flow of power.","title":"graph"},{"location":"reference/frequenz/sdk/microgrid/graph/#frequenz.sdk.microgrid.graph-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/microgrid/graph/#frequenz.sdk.microgrid.graph.ComponentGraph","text":"Bases: ABC Interface for component graph implementations. Source code in frequenz/sdk/microgrid/graph.py 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 class ComponentGraph ( ABC ): \"\"\"Interface for component graph implementations.\"\"\" @abstractmethod def components ( self , component_id : Optional [ Set [ int ]] = None , component_category : Optional [ Set [ ComponentCategory ]] = None , ) -> Set [ Component ]: \"\"\"Fetch the components of the microgrid. Args: component_id: filter out any components not matching one of the provided IDs component_category: filter out any components not matching one of the provided types Returns: Set of the components currently connected to the microgrid, filtered by the provided `component_id` and `component_category` values. \"\"\" @abstractmethod def connections ( self , start : Optional [ Set [ int ]] = None , end : Optional [ Set [ int ]] = None , ) -> Set [ Connection ]: \"\"\"Fetch the connections between microgrid components. Args: start: filter out any connections whose `start` does not match one of these component IDs end: filter out any connections whose `end` does not match one of these component IDs Returns: Set of the connections between components in the microgrid, filtered by the provided `start`/`end` choices. \"\"\" @abstractmethod def predecessors ( self , component_id : int ) -> Set [ Component ]: \"\"\"Fetch the graph predecessors of the specified component. Args: component_id: numerical ID of the component whose predecessors should be fetched Returns: Set of IDs of the components that are predecessors of `component_id`, i.e. for which there is a connection from each of these components to `component_id`. Raises: KeyError: if the specified `component_id` is not in the graph \"\"\" @abstractmethod def successors ( self , component_id : int ) -> Set [ Component ]: \"\"\"Fetch the graph successors of the specified component. Args: component_id: numerical ID of the component whose successors should be fetched Returns: Set of IDs of the components that are successors of `component_id`, i.e. for which there is a connection from `component_id` to each of these components. Raises: KeyError: if the specified `component_id` is not in the graph \"\"\"","title":"ComponentGraph"},{"location":"reference/frequenz/sdk/microgrid/graph/#frequenz.sdk.microgrid.graph.ComponentGraph-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/microgrid/graph/#frequenz.sdk.microgrid.graph.ComponentGraph.components","text":"Fetch the components of the microgrid. PARAMETER DESCRIPTION component_id filter out any components not matching one of the provided IDs TYPE: Optional [ Set [ int ]] DEFAULT: None component_category filter out any components not matching one of the provided types TYPE: Optional [ Set [ ComponentCategory ]] DEFAULT: None RETURNS DESCRIPTION Set [ Component ] Set of the components currently connected to the microgrid, filtered by the provided component_id and component_category values. Source code in frequenz/sdk/microgrid/graph.py 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 @abstractmethod def components ( self , component_id : Optional [ Set [ int ]] = None , component_category : Optional [ Set [ ComponentCategory ]] = None , ) -> Set [ Component ]: \"\"\"Fetch the components of the microgrid. Args: component_id: filter out any components not matching one of the provided IDs component_category: filter out any components not matching one of the provided types Returns: Set of the components currently connected to the microgrid, filtered by the provided `component_id` and `component_category` values. \"\"\"","title":"components()"},{"location":"reference/frequenz/sdk/microgrid/graph/#frequenz.sdk.microgrid.graph.ComponentGraph.connections","text":"Fetch the connections between microgrid components. PARAMETER DESCRIPTION start filter out any connections whose start does not match one of these component IDs TYPE: Optional [ Set [ int ]] DEFAULT: None end filter out any connections whose end does not match one of these component IDs TYPE: Optional [ Set [ int ]] DEFAULT: None RETURNS DESCRIPTION Set [ Connection ] Set of the connections between components in the microgrid, filtered by the provided start / end choices. Source code in frequenz/sdk/microgrid/graph.py 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 @abstractmethod def connections ( self , start : Optional [ Set [ int ]] = None , end : Optional [ Set [ int ]] = None , ) -> Set [ Connection ]: \"\"\"Fetch the connections between microgrid components. Args: start: filter out any connections whose `start` does not match one of these component IDs end: filter out any connections whose `end` does not match one of these component IDs Returns: Set of the connections between components in the microgrid, filtered by the provided `start`/`end` choices. \"\"\"","title":"connections()"},{"location":"reference/frequenz/sdk/microgrid/graph/#frequenz.sdk.microgrid.graph.ComponentGraph.predecessors","text":"Fetch the graph predecessors of the specified component. PARAMETER DESCRIPTION component_id numerical ID of the component whose predecessors should be fetched TYPE: int RETURNS DESCRIPTION Set [ Component ] Set of IDs of the components that are predecessors of component_id , i.e. for which there is a connection from each of these components to component_id . RAISES DESCRIPTION KeyError if the specified component_id is not in the graph Source code in frequenz/sdk/microgrid/graph.py 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 @abstractmethod def predecessors ( self , component_id : int ) -> Set [ Component ]: \"\"\"Fetch the graph predecessors of the specified component. Args: component_id: numerical ID of the component whose predecessors should be fetched Returns: Set of IDs of the components that are predecessors of `component_id`, i.e. for which there is a connection from each of these components to `component_id`. Raises: KeyError: if the specified `component_id` is not in the graph \"\"\"","title":"predecessors()"},{"location":"reference/frequenz/sdk/microgrid/graph/#frequenz.sdk.microgrid.graph.ComponentGraph.successors","text":"Fetch the graph successors of the specified component. PARAMETER DESCRIPTION component_id numerical ID of the component whose successors should be fetched TYPE: int RETURNS DESCRIPTION Set [ Component ] Set of IDs of the components that are successors of component_id , i.e. for which there is a connection from component_id to each of these components. RAISES DESCRIPTION KeyError if the specified component_id is not in the graph Source code in frequenz/sdk/microgrid/graph.py 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 @abstractmethod def successors ( self , component_id : int ) -> Set [ Component ]: \"\"\"Fetch the graph successors of the specified component. Args: component_id: numerical ID of the component whose successors should be fetched Returns: Set of IDs of the components that are successors of `component_id`, i.e. for which there is a connection from `component_id` to each of these components. Raises: KeyError: if the specified `component_id` is not in the graph \"\"\"","title":"successors()"},{"location":"reference/frequenz/sdk/microgrid/graph/#frequenz.sdk.microgrid.graph.InvalidGraphError","text":"Bases: Exception Exception type that will be thrown if graph data is not valid. Source code in frequenz/sdk/microgrid/graph.py 39 40 class InvalidGraphError ( Exception ): \"\"\"Exception type that will be thrown if graph data is not valid.\"\"\"","title":"InvalidGraphError"},{"location":"reference/frequenz/sdk/microgrid/microgrid_api/","text":"frequenz.sdk.microgrid.microgrid_api \u00a4 Microgrid Api Wrapper. Classes \u00a4 frequenz.sdk.microgrid.microgrid_api.MicrogridApi \u00a4 Bases: ABC Creates and stores core features. Source code in frequenz/sdk/microgrid/microgrid_api.py 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 class MicrogridApi ( ABC ): \"\"\"Creates and stores core features.\"\"\" def __init__ ( self , host : str , port : int ) -> None : \"\"\"Create object instance. Args: host: server host port: server port \"\"\" super () . __init__ () self . _host : str = host self . _port : int = port @property def host ( self ) -> str : \"\"\"Get host of the currently connected server. Returns: host \"\"\" return self . _host @property def port ( self ) -> int : \"\"\"Get port of the currently connected server. Returns: port \"\"\" return self . _port @property @abstractmethod def microgrid_api_client ( self ) -> MicrogridApiClient : \"\"\"Get MicrogridApiClient. Returns: api client \"\"\" @property @abstractmethod def component_graph ( self ) -> ComponentGraph : \"\"\"Get component graph. Returns: component graph \"\"\" async def _update_api ( self , host : str , port : int ) -> None : self . _host = host self . _port = port @abstractmethod async def _initialize ( self ) -> None : \"\"\"Initialize the object. This function should be called only once.\"\"\" Functions \u00a4 __init__ ( host , port ) \u00a4 Create object instance. PARAMETER DESCRIPTION host server host TYPE: str port server port TYPE: int Source code in frequenz/sdk/microgrid/microgrid_api.py 22 23 24 25 26 27 28 29 30 31 def __init__ ( self , host : str , port : int ) -> None : \"\"\"Create object instance. Args: host: server host port: server port \"\"\" super () . __init__ () self . _host : str = host self . _port : int = port component_graph () property abstractmethod \u00a4 Get component graph. RETURNS DESCRIPTION ComponentGraph component graph Source code in frequenz/sdk/microgrid/microgrid_api.py 60 61 62 63 64 65 66 67 @property @abstractmethod def component_graph ( self ) -> ComponentGraph : \"\"\"Get component graph. Returns: component graph \"\"\" host () property \u00a4 Get host of the currently connected server. RETURNS DESCRIPTION str host Source code in frequenz/sdk/microgrid/microgrid_api.py 33 34 35 36 37 38 39 40 @property def host ( self ) -> str : \"\"\"Get host of the currently connected server. Returns: host \"\"\" return self . _host microgrid_api_client () property abstractmethod \u00a4 Get MicrogridApiClient. RETURNS DESCRIPTION MicrogridApiClient api client Source code in frequenz/sdk/microgrid/microgrid_api.py 51 52 53 54 55 56 57 58 @property @abstractmethod def microgrid_api_client ( self ) -> MicrogridApiClient : \"\"\"Get MicrogridApiClient. Returns: api client \"\"\" port () property \u00a4 Get port of the currently connected server. RETURNS DESCRIPTION int port Source code in frequenz/sdk/microgrid/microgrid_api.py 42 43 44 45 46 47 48 49 @property def port ( self ) -> int : \"\"\"Get port of the currently connected server. Returns: port \"\"\" return self . _port Functions \u00a4 frequenz . sdk . microgrid . microgrid_api . get () \u00a4 Get the MicrogridApi instance created by initialize(). This function should be only called after initialize(). RAISES DESCRIPTION RuntimeError Raised when: * If initialize() method was not called before this call. * If initialize() methods was called but was not awaited and instance was not created yet. RETURNS DESCRIPTION MicrogridApi MicrogridApi instance. Source code in frequenz/sdk/microgrid/microgrid_api.py 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 def get () -> MicrogridApi : \"\"\"Get the MicrogridApi instance created by initialize(). This function should be only called after initialize(). Raises: RuntimeError: Raised when: * If `initialize()` method was not called before this call. * If `initialize()` methods was called but was not awaited and instance was not created yet. Returns: MicrogridApi instance. \"\"\" if _MICROGRID_API is None : raise RuntimeError ( \"MicrogridApi is not initialized (or the initialization didn't \" \"finished yet). Call and/or await for initialize() to finish.\" ) return _MICROGRID_API frequenz . sdk . microgrid . microgrid_api . initialize ( host , port ) async \u00a4 Initialize the MicrogridApi. This function should be called only once. PARAMETER DESCRIPTION host Microgrid host TYPE: str port Microgrid port TYPE: int RAISES DESCRIPTION AssertionError If method was called more then once. Source code in frequenz/sdk/microgrid/microgrid_api.py 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 async def initialize ( host : str , port : int ) -> None : \"\"\"Initialize the MicrogridApi. This function should be called only once. Args: host: Microgrid host port: Microgrid port Raises: AssertionError: If method was called more then once. \"\"\" # From Doc: pylint just try to discourage this usage. # That doesn't mean you cannot use it. global _MICROGRID_API # pylint: disable=global-statement if _MICROGRID_API is not None : raise AssertionError ( \"MicrogridApi was already initialized.\" ) microgrid_api = _MicrogridApiInsecure ( host , port ) await microgrid_api . _initialize () # pylint: disable=protected-access # Check again that _MICROGRID_API is None in case somebody had the great idea of # calling initialize() twice and in parallel. if _MICROGRID_API is not None : raise AssertionError ( \"MicrogridApi was already initialized.\" ) _MICROGRID_API = microgrid_api","title":"microgrid_api"},{"location":"reference/frequenz/sdk/microgrid/microgrid_api/#frequenz.sdk.microgrid.microgrid_api","text":"Microgrid Api Wrapper.","title":"microgrid_api"},{"location":"reference/frequenz/sdk/microgrid/microgrid_api/#frequenz.sdk.microgrid.microgrid_api-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/microgrid/microgrid_api/#frequenz.sdk.microgrid.microgrid_api.MicrogridApi","text":"Bases: ABC Creates and stores core features. Source code in frequenz/sdk/microgrid/microgrid_api.py 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 class MicrogridApi ( ABC ): \"\"\"Creates and stores core features.\"\"\" def __init__ ( self , host : str , port : int ) -> None : \"\"\"Create object instance. Args: host: server host port: server port \"\"\" super () . __init__ () self . _host : str = host self . _port : int = port @property def host ( self ) -> str : \"\"\"Get host of the currently connected server. Returns: host \"\"\" return self . _host @property def port ( self ) -> int : \"\"\"Get port of the currently connected server. Returns: port \"\"\" return self . _port @property @abstractmethod def microgrid_api_client ( self ) -> MicrogridApiClient : \"\"\"Get MicrogridApiClient. Returns: api client \"\"\" @property @abstractmethod def component_graph ( self ) -> ComponentGraph : \"\"\"Get component graph. Returns: component graph \"\"\" async def _update_api ( self , host : str , port : int ) -> None : self . _host = host self . _port = port @abstractmethod async def _initialize ( self ) -> None : \"\"\"Initialize the object. This function should be called only once.\"\"\"","title":"MicrogridApi"},{"location":"reference/frequenz/sdk/microgrid/microgrid_api/#frequenz.sdk.microgrid.microgrid_api.MicrogridApi-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/microgrid/microgrid_api/#frequenz.sdk.microgrid.microgrid_api.MicrogridApi.__init__","text":"Create object instance. PARAMETER DESCRIPTION host server host TYPE: str port server port TYPE: int Source code in frequenz/sdk/microgrid/microgrid_api.py 22 23 24 25 26 27 28 29 30 31 def __init__ ( self , host : str , port : int ) -> None : \"\"\"Create object instance. Args: host: server host port: server port \"\"\" super () . __init__ () self . _host : str = host self . _port : int = port","title":"__init__()"},{"location":"reference/frequenz/sdk/microgrid/microgrid_api/#frequenz.sdk.microgrid.microgrid_api.MicrogridApi.component_graph","text":"Get component graph. RETURNS DESCRIPTION ComponentGraph component graph Source code in frequenz/sdk/microgrid/microgrid_api.py 60 61 62 63 64 65 66 67 @property @abstractmethod def component_graph ( self ) -> ComponentGraph : \"\"\"Get component graph. Returns: component graph \"\"\"","title":"component_graph()"},{"location":"reference/frequenz/sdk/microgrid/microgrid_api/#frequenz.sdk.microgrid.microgrid_api.MicrogridApi.host","text":"Get host of the currently connected server. RETURNS DESCRIPTION str host Source code in frequenz/sdk/microgrid/microgrid_api.py 33 34 35 36 37 38 39 40 @property def host ( self ) -> str : \"\"\"Get host of the currently connected server. Returns: host \"\"\" return self . _host","title":"host()"},{"location":"reference/frequenz/sdk/microgrid/microgrid_api/#frequenz.sdk.microgrid.microgrid_api.MicrogridApi.microgrid_api_client","text":"Get MicrogridApiClient. RETURNS DESCRIPTION MicrogridApiClient api client Source code in frequenz/sdk/microgrid/microgrid_api.py 51 52 53 54 55 56 57 58 @property @abstractmethod def microgrid_api_client ( self ) -> MicrogridApiClient : \"\"\"Get MicrogridApiClient. Returns: api client \"\"\"","title":"microgrid_api_client()"},{"location":"reference/frequenz/sdk/microgrid/microgrid_api/#frequenz.sdk.microgrid.microgrid_api.MicrogridApi.port","text":"Get port of the currently connected server. RETURNS DESCRIPTION int port Source code in frequenz/sdk/microgrid/microgrid_api.py 42 43 44 45 46 47 48 49 @property def port ( self ) -> int : \"\"\"Get port of the currently connected server. Returns: port \"\"\" return self . _port","title":"port()"},{"location":"reference/frequenz/sdk/microgrid/microgrid_api/#frequenz.sdk.microgrid.microgrid_api-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/microgrid/microgrid_api/#frequenz.sdk.microgrid.microgrid_api.get","text":"Get the MicrogridApi instance created by initialize(). This function should be only called after initialize(). RAISES DESCRIPTION RuntimeError Raised when: * If initialize() method was not called before this call. * If initialize() methods was called but was not awaited and instance was not created yet. RETURNS DESCRIPTION MicrogridApi MicrogridApi instance. Source code in frequenz/sdk/microgrid/microgrid_api.py 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 def get () -> MicrogridApi : \"\"\"Get the MicrogridApi instance created by initialize(). This function should be only called after initialize(). Raises: RuntimeError: Raised when: * If `initialize()` method was not called before this call. * If `initialize()` methods was called but was not awaited and instance was not created yet. Returns: MicrogridApi instance. \"\"\" if _MICROGRID_API is None : raise RuntimeError ( \"MicrogridApi is not initialized (or the initialization didn't \" \"finished yet). Call and/or await for initialize() to finish.\" ) return _MICROGRID_API","title":"get()"},{"location":"reference/frequenz/sdk/microgrid/microgrid_api/#frequenz.sdk.microgrid.microgrid_api.initialize","text":"Initialize the MicrogridApi. This function should be called only once. PARAMETER DESCRIPTION host Microgrid host TYPE: str port Microgrid port TYPE: int RAISES DESCRIPTION AssertionError If method was called more then once. Source code in frequenz/sdk/microgrid/microgrid_api.py 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 async def initialize ( host : str , port : int ) -> None : \"\"\"Initialize the MicrogridApi. This function should be called only once. Args: host: Microgrid host port: Microgrid port Raises: AssertionError: If method was called more then once. \"\"\" # From Doc: pylint just try to discourage this usage. # That doesn't mean you cannot use it. global _MICROGRID_API # pylint: disable=global-statement if _MICROGRID_API is not None : raise AssertionError ( \"MicrogridApi was already initialized.\" ) microgrid_api = _MicrogridApiInsecure ( host , port ) await microgrid_api . _initialize () # pylint: disable=protected-access # Check again that _MICROGRID_API is None in case somebody had the great idea of # calling initialize() twice and in parallel. if _MICROGRID_API is not None : raise AssertionError ( \"MicrogridApi was already initialized.\" ) _MICROGRID_API = microgrid_api","title":"initialize()"},{"location":"reference/frequenz/sdk/microgrid/retry/","text":"frequenz.sdk.microgrid.retry \u00a4 Implementations for retry strategies. Classes \u00a4 frequenz.sdk.microgrid.retry.ExponentialBackoff \u00a4 Bases: RetryStrategy Provides methods for calculating the exponential interval between retries. Source code in frequenz/sdk/microgrid/retry.py 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 class ExponentialBackoff ( RetryStrategy ): \"\"\"Provides methods for calculating the exponential interval between retries.\"\"\" DEFAULT_INTERVAL = DEFAULT_RETRY_INTERVAL DEFAULT_MAX_INTERVAL = 60.0 DEFAULT_MULTIPLIER = 2.0 # pylint: disable=too-many-arguments def __init__ ( self , initial_interval : float = DEFAULT_INTERVAL , max_interval : float = DEFAULT_MAX_INTERVAL , multiplier : float = DEFAULT_MULTIPLIER , jitter : float = DEFAULT_RETRY_JITTER , limit : Optional [ int ] = None , ) -> None : \"\"\"Create a `ExponentialBackoff` instance. Args: initial_interval: time to wait for before the first retry, in seconds. max_interval: maximum interval, in seconds. multiplier: exponential increment for interval. jitter: a jitter to add to the retry interval. limit: max number of retries before giving up. `None` means no limit, and `0` means no retry. \"\"\" self . _initial = initial_interval self . _max = max_interval self . _multiplier = multiplier self . _jitter = jitter self . _limit = limit self . _count = 0 def next_interval ( self ) -> Optional [ float ]: \"\"\"Return the time to wait before the next retry. Returns `None` if the retry limit has been reached, and no more retries are possible. Returns: Time until next retry when below retry limit, and None otherwise. \"\"\" if self . _limit is not None and self . _count >= self . _limit : return None self . _count += 1 exp_backoff_interval = self . _initial * self . _multiplier ** ( self . _count - 1 ) return min ( exp_backoff_interval + random . uniform ( 0.0 , self . _jitter ), self . _max ) Functions \u00a4 __init__ ( initial_interval = DEFAULT_INTERVAL , max_interval = DEFAULT_MAX_INTERVAL , multiplier = DEFAULT_MULTIPLIER , jitter = DEFAULT_RETRY_JITTER , limit = None ) \u00a4 Create a ExponentialBackoff instance. PARAMETER DESCRIPTION initial_interval time to wait for before the first retry, in seconds. TYPE: float DEFAULT: DEFAULT_INTERVAL max_interval maximum interval, in seconds. TYPE: float DEFAULT: DEFAULT_MAX_INTERVAL multiplier exponential increment for interval. TYPE: float DEFAULT: DEFAULT_MULTIPLIER jitter a jitter to add to the retry interval. TYPE: float DEFAULT: DEFAULT_RETRY_JITTER limit max number of retries before giving up. None means no limit, and 0 means no retry. TYPE: Optional [ int ] DEFAULT: None Source code in frequenz/sdk/microgrid/retry.py 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 def __init__ ( self , initial_interval : float = DEFAULT_INTERVAL , max_interval : float = DEFAULT_MAX_INTERVAL , multiplier : float = DEFAULT_MULTIPLIER , jitter : float = DEFAULT_RETRY_JITTER , limit : Optional [ int ] = None , ) -> None : \"\"\"Create a `ExponentialBackoff` instance. Args: initial_interval: time to wait for before the first retry, in seconds. max_interval: maximum interval, in seconds. multiplier: exponential increment for interval. jitter: a jitter to add to the retry interval. limit: max number of retries before giving up. `None` means no limit, and `0` means no retry. \"\"\" self . _initial = initial_interval self . _max = max_interval self . _multiplier = multiplier self . _jitter = jitter self . _limit = limit self . _count = 0 next_interval () \u00a4 Return the time to wait before the next retry. Returns None if the retry limit has been reached, and no more retries are possible. RETURNS DESCRIPTION Optional [ float ] Time until next retry when below retry limit, and None otherwise. Source code in frequenz/sdk/microgrid/retry.py 148 149 150 151 152 153 154 155 156 157 158 159 160 161 def next_interval ( self ) -> Optional [ float ]: \"\"\"Return the time to wait before the next retry. Returns `None` if the retry limit has been reached, and no more retries are possible. Returns: Time until next retry when below retry limit, and None otherwise. \"\"\" if self . _limit is not None and self . _count >= self . _limit : return None self . _count += 1 exp_backoff_interval = self . _initial * self . _multiplier ** ( self . _count - 1 ) return min ( exp_backoff_interval + random . uniform ( 0.0 , self . _jitter ), self . _max ) frequenz.sdk.microgrid.retry.LinearBackoff \u00a4 Bases: RetryStrategy Provides methods for calculating the interval between retries. Source code in frequenz/sdk/microgrid/retry.py 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 class LinearBackoff ( RetryStrategy ): \"\"\"Provides methods for calculating the interval between retries.\"\"\" def __init__ ( self , interval : float = DEFAULT_RETRY_INTERVAL , jitter : float = DEFAULT_RETRY_JITTER , limit : Optional [ int ] = None , ) -> None : \"\"\"Create a `LinearBackoff` instance. Args: interval: time to wait for before the next retry, in seconds. jitter: a jitter to add to the retry interval. limit: max number of retries before giving up. `None` means no limit, and `0` means no retry. \"\"\" self . _interval = interval self . _jitter = jitter self . _limit = limit self . _count = 0 def next_interval ( self ) -> Optional [ float ]: \"\"\"Return the time to wait before the next retry. Returns `None` if the retry limit has been reached, and no more retries are possible. Returns: Time until next retry when below retry limit, and None otherwise. \"\"\" if self . _limit is not None and self . _count >= self . _limit : return None self . _count += 1 return self . _interval + random . uniform ( 0.0 , self . _jitter ) Functions \u00a4 __init__ ( interval = DEFAULT_RETRY_INTERVAL , jitter = DEFAULT_RETRY_JITTER , limit = None ) \u00a4 Create a LinearBackoff instance. PARAMETER DESCRIPTION interval time to wait for before the next retry, in seconds. TYPE: float DEFAULT: DEFAULT_RETRY_INTERVAL jitter a jitter to add to the retry interval. TYPE: float DEFAULT: DEFAULT_RETRY_JITTER limit max number of retries before giving up. None means no limit, and 0 means no retry. TYPE: Optional [ int ] DEFAULT: None Source code in frequenz/sdk/microgrid/retry.py 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 def __init__ ( self , interval : float = DEFAULT_RETRY_INTERVAL , jitter : float = DEFAULT_RETRY_JITTER , limit : Optional [ int ] = None , ) -> None : \"\"\"Create a `LinearBackoff` instance. Args: interval: time to wait for before the next retry, in seconds. jitter: a jitter to add to the retry interval. limit: max number of retries before giving up. `None` means no limit, and `0` means no retry. \"\"\" self . _interval = interval self . _jitter = jitter self . _limit = limit self . _count = 0 next_interval () \u00a4 Return the time to wait before the next retry. Returns None if the retry limit has been reached, and no more retries are possible. RETURNS DESCRIPTION Optional [ float ] Time until next retry when below retry limit, and None otherwise. Source code in frequenz/sdk/microgrid/retry.py 98 99 100 101 102 103 104 105 106 107 108 109 110 def next_interval ( self ) -> Optional [ float ]: \"\"\"Return the time to wait before the next retry. Returns `None` if the retry limit has been reached, and no more retries are possible. Returns: Time until next retry when below retry limit, and None otherwise. \"\"\" if self . _limit is not None and self . _count >= self . _limit : return None self . _count += 1 return self . _interval + random . uniform ( 0.0 , self . _jitter ) frequenz.sdk.microgrid.retry.RetryStrategy \u00a4 Bases: ABC Interface for implementing retry strategies. Source code in frequenz/sdk/microgrid/retry.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 class RetryStrategy ( ABC ): \"\"\"Interface for implementing retry strategies.\"\"\" _limit : Optional [ int ] _count : int @abstractmethod def next_interval ( self ) -> Optional [ float ]: \"\"\"Return the time to wait before the next retry. Returns `None` if the retry limit has been reached, and no more retries are possible. Returns: Time until next retry when below retry limit, and None otherwise. \"\"\" def get_progress ( self ) -> str : \"\"\"Return a string denoting the retry progress. Returns: String denoting retry progress in the form \"(count/limit)\" \"\"\" if self . _limit is None : return f \"( { self . _count } /\u221e)\" return f \"( { self . _count } / { self . _limit } )\" def reset ( self ) -> None : \"\"\"Reset the retry counter. To be called as soon as a connection is successful. \"\"\" self . _count = 0 def copy ( self ) -> RetryStrategy : \"\"\"Create a new instance of `self`. Returns: A deepcopy of `self`. \"\"\" ret = deepcopy ( self ) ret . reset () return ret def __iter__ ( self ) -> Iterator [ float ]: \"\"\"Return an iterator over the retry intervals. Yields: Next retry interval in seconds. \"\"\" while True : interval = self . next_interval () if interval is None : break yield interval Functions \u00a4 __iter__ () \u00a4 Return an iterator over the retry intervals. YIELDS DESCRIPTION Iterator [ float ] Next retry interval in seconds. Source code in frequenz/sdk/microgrid/retry.py 62 63 64 65 66 67 68 69 70 71 72 def __iter__ ( self ) -> Iterator [ float ]: \"\"\"Return an iterator over the retry intervals. Yields: Next retry interval in seconds. \"\"\" while True : interval = self . next_interval () if interval is None : break yield interval copy () \u00a4 Create a new instance of self . RETURNS DESCRIPTION RetryStrategy A deepcopy of self . Source code in frequenz/sdk/microgrid/retry.py 52 53 54 55 56 57 58 59 60 def copy ( self ) -> RetryStrategy : \"\"\"Create a new instance of `self`. Returns: A deepcopy of `self`. \"\"\" ret = deepcopy ( self ) ret . reset () return ret get_progress () \u00a4 Return a string denoting the retry progress. RETURNS DESCRIPTION str String denoting retry progress in the form \"(count/limit)\" Source code in frequenz/sdk/microgrid/retry.py 34 35 36 37 38 39 40 41 42 43 def get_progress ( self ) -> str : \"\"\"Return a string denoting the retry progress. Returns: String denoting retry progress in the form \"(count/limit)\" \"\"\" if self . _limit is None : return f \"( { self . _count } /\u221e)\" return f \"( { self . _count } / { self . _limit } )\" next_interval () abstractmethod \u00a4 Return the time to wait before the next retry. Returns None if the retry limit has been reached, and no more retries are possible. RETURNS DESCRIPTION Optional [ float ] Time until next retry when below retry limit, and None otherwise. Source code in frequenz/sdk/microgrid/retry.py 23 24 25 26 27 28 29 30 31 32 @abstractmethod def next_interval ( self ) -> Optional [ float ]: \"\"\"Return the time to wait before the next retry. Returns `None` if the retry limit has been reached, and no more retries are possible. Returns: Time until next retry when below retry limit, and None otherwise. \"\"\" reset () \u00a4 Reset the retry counter. To be called as soon as a connection is successful. Source code in frequenz/sdk/microgrid/retry.py 45 46 47 48 49 50 def reset ( self ) -> None : \"\"\"Reset the retry counter. To be called as soon as a connection is successful. \"\"\" self . _count = 0","title":"retry"},{"location":"reference/frequenz/sdk/microgrid/retry/#frequenz.sdk.microgrid.retry","text":"Implementations for retry strategies.","title":"retry"},{"location":"reference/frequenz/sdk/microgrid/retry/#frequenz.sdk.microgrid.retry-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/microgrid/retry/#frequenz.sdk.microgrid.retry.ExponentialBackoff","text":"Bases: RetryStrategy Provides methods for calculating the exponential interval between retries. Source code in frequenz/sdk/microgrid/retry.py 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 class ExponentialBackoff ( RetryStrategy ): \"\"\"Provides methods for calculating the exponential interval between retries.\"\"\" DEFAULT_INTERVAL = DEFAULT_RETRY_INTERVAL DEFAULT_MAX_INTERVAL = 60.0 DEFAULT_MULTIPLIER = 2.0 # pylint: disable=too-many-arguments def __init__ ( self , initial_interval : float = DEFAULT_INTERVAL , max_interval : float = DEFAULT_MAX_INTERVAL , multiplier : float = DEFAULT_MULTIPLIER , jitter : float = DEFAULT_RETRY_JITTER , limit : Optional [ int ] = None , ) -> None : \"\"\"Create a `ExponentialBackoff` instance. Args: initial_interval: time to wait for before the first retry, in seconds. max_interval: maximum interval, in seconds. multiplier: exponential increment for interval. jitter: a jitter to add to the retry interval. limit: max number of retries before giving up. `None` means no limit, and `0` means no retry. \"\"\" self . _initial = initial_interval self . _max = max_interval self . _multiplier = multiplier self . _jitter = jitter self . _limit = limit self . _count = 0 def next_interval ( self ) -> Optional [ float ]: \"\"\"Return the time to wait before the next retry. Returns `None` if the retry limit has been reached, and no more retries are possible. Returns: Time until next retry when below retry limit, and None otherwise. \"\"\" if self . _limit is not None and self . _count >= self . _limit : return None self . _count += 1 exp_backoff_interval = self . _initial * self . _multiplier ** ( self . _count - 1 ) return min ( exp_backoff_interval + random . uniform ( 0.0 , self . _jitter ), self . _max )","title":"ExponentialBackoff"},{"location":"reference/frequenz/sdk/microgrid/retry/#frequenz.sdk.microgrid.retry.ExponentialBackoff-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/microgrid/retry/#frequenz.sdk.microgrid.retry.ExponentialBackoff.__init__","text":"Create a ExponentialBackoff instance. PARAMETER DESCRIPTION initial_interval time to wait for before the first retry, in seconds. TYPE: float DEFAULT: DEFAULT_INTERVAL max_interval maximum interval, in seconds. TYPE: float DEFAULT: DEFAULT_MAX_INTERVAL multiplier exponential increment for interval. TYPE: float DEFAULT: DEFAULT_MULTIPLIER jitter a jitter to add to the retry interval. TYPE: float DEFAULT: DEFAULT_RETRY_JITTER limit max number of retries before giving up. None means no limit, and 0 means no retry. TYPE: Optional [ int ] DEFAULT: None Source code in frequenz/sdk/microgrid/retry.py 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 def __init__ ( self , initial_interval : float = DEFAULT_INTERVAL , max_interval : float = DEFAULT_MAX_INTERVAL , multiplier : float = DEFAULT_MULTIPLIER , jitter : float = DEFAULT_RETRY_JITTER , limit : Optional [ int ] = None , ) -> None : \"\"\"Create a `ExponentialBackoff` instance. Args: initial_interval: time to wait for before the first retry, in seconds. max_interval: maximum interval, in seconds. multiplier: exponential increment for interval. jitter: a jitter to add to the retry interval. limit: max number of retries before giving up. `None` means no limit, and `0` means no retry. \"\"\" self . _initial = initial_interval self . _max = max_interval self . _multiplier = multiplier self . _jitter = jitter self . _limit = limit self . _count = 0","title":"__init__()"},{"location":"reference/frequenz/sdk/microgrid/retry/#frequenz.sdk.microgrid.retry.ExponentialBackoff.next_interval","text":"Return the time to wait before the next retry. Returns None if the retry limit has been reached, and no more retries are possible. RETURNS DESCRIPTION Optional [ float ] Time until next retry when below retry limit, and None otherwise. Source code in frequenz/sdk/microgrid/retry.py 148 149 150 151 152 153 154 155 156 157 158 159 160 161 def next_interval ( self ) -> Optional [ float ]: \"\"\"Return the time to wait before the next retry. Returns `None` if the retry limit has been reached, and no more retries are possible. Returns: Time until next retry when below retry limit, and None otherwise. \"\"\" if self . _limit is not None and self . _count >= self . _limit : return None self . _count += 1 exp_backoff_interval = self . _initial * self . _multiplier ** ( self . _count - 1 ) return min ( exp_backoff_interval + random . uniform ( 0.0 , self . _jitter ), self . _max )","title":"next_interval()"},{"location":"reference/frequenz/sdk/microgrid/retry/#frequenz.sdk.microgrid.retry.LinearBackoff","text":"Bases: RetryStrategy Provides methods for calculating the interval between retries. Source code in frequenz/sdk/microgrid/retry.py 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 class LinearBackoff ( RetryStrategy ): \"\"\"Provides methods for calculating the interval between retries.\"\"\" def __init__ ( self , interval : float = DEFAULT_RETRY_INTERVAL , jitter : float = DEFAULT_RETRY_JITTER , limit : Optional [ int ] = None , ) -> None : \"\"\"Create a `LinearBackoff` instance. Args: interval: time to wait for before the next retry, in seconds. jitter: a jitter to add to the retry interval. limit: max number of retries before giving up. `None` means no limit, and `0` means no retry. \"\"\" self . _interval = interval self . _jitter = jitter self . _limit = limit self . _count = 0 def next_interval ( self ) -> Optional [ float ]: \"\"\"Return the time to wait before the next retry. Returns `None` if the retry limit has been reached, and no more retries are possible. Returns: Time until next retry when below retry limit, and None otherwise. \"\"\" if self . _limit is not None and self . _count >= self . _limit : return None self . _count += 1 return self . _interval + random . uniform ( 0.0 , self . _jitter )","title":"LinearBackoff"},{"location":"reference/frequenz/sdk/microgrid/retry/#frequenz.sdk.microgrid.retry.LinearBackoff-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/microgrid/retry/#frequenz.sdk.microgrid.retry.LinearBackoff.__init__","text":"Create a LinearBackoff instance. PARAMETER DESCRIPTION interval time to wait for before the next retry, in seconds. TYPE: float DEFAULT: DEFAULT_RETRY_INTERVAL jitter a jitter to add to the retry interval. TYPE: float DEFAULT: DEFAULT_RETRY_JITTER limit max number of retries before giving up. None means no limit, and 0 means no retry. TYPE: Optional [ int ] DEFAULT: None Source code in frequenz/sdk/microgrid/retry.py 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 def __init__ ( self , interval : float = DEFAULT_RETRY_INTERVAL , jitter : float = DEFAULT_RETRY_JITTER , limit : Optional [ int ] = None , ) -> None : \"\"\"Create a `LinearBackoff` instance. Args: interval: time to wait for before the next retry, in seconds. jitter: a jitter to add to the retry interval. limit: max number of retries before giving up. `None` means no limit, and `0` means no retry. \"\"\" self . _interval = interval self . _jitter = jitter self . _limit = limit self . _count = 0","title":"__init__()"},{"location":"reference/frequenz/sdk/microgrid/retry/#frequenz.sdk.microgrid.retry.LinearBackoff.next_interval","text":"Return the time to wait before the next retry. Returns None if the retry limit has been reached, and no more retries are possible. RETURNS DESCRIPTION Optional [ float ] Time until next retry when below retry limit, and None otherwise. Source code in frequenz/sdk/microgrid/retry.py 98 99 100 101 102 103 104 105 106 107 108 109 110 def next_interval ( self ) -> Optional [ float ]: \"\"\"Return the time to wait before the next retry. Returns `None` if the retry limit has been reached, and no more retries are possible. Returns: Time until next retry when below retry limit, and None otherwise. \"\"\" if self . _limit is not None and self . _count >= self . _limit : return None self . _count += 1 return self . _interval + random . uniform ( 0.0 , self . _jitter )","title":"next_interval()"},{"location":"reference/frequenz/sdk/microgrid/retry/#frequenz.sdk.microgrid.retry.RetryStrategy","text":"Bases: ABC Interface for implementing retry strategies. Source code in frequenz/sdk/microgrid/retry.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 class RetryStrategy ( ABC ): \"\"\"Interface for implementing retry strategies.\"\"\" _limit : Optional [ int ] _count : int @abstractmethod def next_interval ( self ) -> Optional [ float ]: \"\"\"Return the time to wait before the next retry. Returns `None` if the retry limit has been reached, and no more retries are possible. Returns: Time until next retry when below retry limit, and None otherwise. \"\"\" def get_progress ( self ) -> str : \"\"\"Return a string denoting the retry progress. Returns: String denoting retry progress in the form \"(count/limit)\" \"\"\" if self . _limit is None : return f \"( { self . _count } /\u221e)\" return f \"( { self . _count } / { self . _limit } )\" def reset ( self ) -> None : \"\"\"Reset the retry counter. To be called as soon as a connection is successful. \"\"\" self . _count = 0 def copy ( self ) -> RetryStrategy : \"\"\"Create a new instance of `self`. Returns: A deepcopy of `self`. \"\"\" ret = deepcopy ( self ) ret . reset () return ret def __iter__ ( self ) -> Iterator [ float ]: \"\"\"Return an iterator over the retry intervals. Yields: Next retry interval in seconds. \"\"\" while True : interval = self . next_interval () if interval is None : break yield interval","title":"RetryStrategy"},{"location":"reference/frequenz/sdk/microgrid/retry/#frequenz.sdk.microgrid.retry.RetryStrategy-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/microgrid/retry/#frequenz.sdk.microgrid.retry.RetryStrategy.__iter__","text":"Return an iterator over the retry intervals. YIELDS DESCRIPTION Iterator [ float ] Next retry interval in seconds. Source code in frequenz/sdk/microgrid/retry.py 62 63 64 65 66 67 68 69 70 71 72 def __iter__ ( self ) -> Iterator [ float ]: \"\"\"Return an iterator over the retry intervals. Yields: Next retry interval in seconds. \"\"\" while True : interval = self . next_interval () if interval is None : break yield interval","title":"__iter__()"},{"location":"reference/frequenz/sdk/microgrid/retry/#frequenz.sdk.microgrid.retry.RetryStrategy.copy","text":"Create a new instance of self . RETURNS DESCRIPTION RetryStrategy A deepcopy of self . Source code in frequenz/sdk/microgrid/retry.py 52 53 54 55 56 57 58 59 60 def copy ( self ) -> RetryStrategy : \"\"\"Create a new instance of `self`. Returns: A deepcopy of `self`. \"\"\" ret = deepcopy ( self ) ret . reset () return ret","title":"copy()"},{"location":"reference/frequenz/sdk/microgrid/retry/#frequenz.sdk.microgrid.retry.RetryStrategy.get_progress","text":"Return a string denoting the retry progress. RETURNS DESCRIPTION str String denoting retry progress in the form \"(count/limit)\" Source code in frequenz/sdk/microgrid/retry.py 34 35 36 37 38 39 40 41 42 43 def get_progress ( self ) -> str : \"\"\"Return a string denoting the retry progress. Returns: String denoting retry progress in the form \"(count/limit)\" \"\"\" if self . _limit is None : return f \"( { self . _count } /\u221e)\" return f \"( { self . _count } / { self . _limit } )\"","title":"get_progress()"},{"location":"reference/frequenz/sdk/microgrid/retry/#frequenz.sdk.microgrid.retry.RetryStrategy.next_interval","text":"Return the time to wait before the next retry. Returns None if the retry limit has been reached, and no more retries are possible. RETURNS DESCRIPTION Optional [ float ] Time until next retry when below retry limit, and None otherwise. Source code in frequenz/sdk/microgrid/retry.py 23 24 25 26 27 28 29 30 31 32 @abstractmethod def next_interval ( self ) -> Optional [ float ]: \"\"\"Return the time to wait before the next retry. Returns `None` if the retry limit has been reached, and no more retries are possible. Returns: Time until next retry when below retry limit, and None otherwise. \"\"\"","title":"next_interval()"},{"location":"reference/frequenz/sdk/microgrid/retry/#frequenz.sdk.microgrid.retry.RetryStrategy.reset","text":"Reset the retry counter. To be called as soon as a connection is successful. Source code in frequenz/sdk/microgrid/retry.py 45 46 47 48 49 50 def reset ( self ) -> None : \"\"\"Reset the retry counter. To be called as soon as a connection is successful. \"\"\" self . _count = 0","title":"reset()"},{"location":"reference/frequenz/sdk/power_distribution/","text":"frequenz.sdk.power_distribution \u00a4 Distribute power between many batteries. When charge/discharge method is called the power should be distributed so that the SoC in batteries stays at the same level. That way of distribution prevents using only one battery, increasing temperature, and maximize the total amount power to charge/discharge. Classes \u00a4 frequenz.sdk.power_distribution.PowerDistributor \u00a4 Tool to distribute power between batteries in microgrid. The purpose of this tool is to keep equal SoC level in the batteries. PowerDistributor can have many users. Each user should first register in order to get its id, channel for sending request, and channel for receiving response. It is recommended to wait for PowerDistributor output with timeout. Otherwise if the processing function fail then the response will never come. The timeout should be Result:request_timeout_sec + time for processing the request. Edge cases: * If there are 2 requests to be processed for the same subset of batteries, then only the latest request will be processed. Older request will be ignored. User with older request will get response with Result.Status.IGNORED. If there are 2 requests and their subset of batteries is different but they overlap (they have at least one common battery), then then both batteries will be processed. However it is not expected so the proper error log will be printed. Example import grpc.aio as grpcaio from frequenz.sdk.microgrid.graph import _MicrogridComponentGraph from frequenz.sdk.microgrid.component import ComponentCategory from frequenz.sdk.power_distribution import ( PowerDistributor , Request , Result , ) target = f \" { host } : { port } \" grpc_channel = grpcaio . insecure_channel ( target ) api = MicrogridGrpcClient ( grpc_channel , target ) graph = _MicrogridComponentGraph () await graph . refresh_from_api ( api ) batteries = graph . components ( component_category = { ComponentCategory . BATTERY }) batteries_ids = { c . component_id for c in batteries } channel = Bidirectional [ Request , Result ]( \"user1\" , \"power_distributor\" ) power_distributor = PowerDistributor ( mock_api , component_graph , { \"user1\" : channel . service_handle } ) client_handle = channel . client_handle # Set power 1200W to given batteries. request = Request ( power = 1200 , batteries = batteries_ids , request_timeout_sec = 10.0 ) await client_handle . send ( request ) # It is recommended to use timeout when waiting for the response! result : Result = await asyncio . wait_for ( client_handle . receive (), timeout = 10 ) if result . status == Result . Status . SUCCESS : print ( \"Command succeed\" ) elif result . status == Result . Status . FAILED : print ( f \"Some batteries failed, total failed power: { result . failed_power } \" ) elif result . status == Result . Status . IGNORED : print ( f \"Request was ignored, because of newer command\" ) elif result . status == Result . Status . ERROR : print ( f \"Request failed with error: { request . error_message } \" ) Source code in frequenz/sdk/power_distribution/power_distributor.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 @actor class PowerDistributor : # pylint: disable=too-many-instance-attributes \"\"\"Tool to distribute power between batteries in microgrid. The purpose of this tool is to keep equal SoC level in the batteries. PowerDistributor can have many users. Each user should first register in order to get its id, channel for sending request, and channel for receiving response. It is recommended to wait for PowerDistributor output with timeout. Otherwise if the processing function fail then the response will never come. The timeout should be Result:request_timeout_sec + time for processing the request. Edge cases: * If there are 2 requests to be processed for the same subset of batteries, then only the latest request will be processed. Older request will be ignored. User with older request will get response with Result.Status.IGNORED. * If there are 2 requests and their subset of batteries is different but they overlap (they have at least one common battery), then then both batteries will be processed. However it is not expected so the proper error log will be printed. Example: ``` python import grpc.aio as grpcaio from frequenz.sdk.microgrid.graph import _MicrogridComponentGraph from frequenz.sdk.microgrid.component import ComponentCategory from frequenz.sdk.power_distribution import ( PowerDistributor, Request, Result, ) target = f\"{host}:{port}\" grpc_channel = grpcaio.insecure_channel(target) api = MicrogridGrpcClient(grpc_channel, target) graph = _MicrogridComponentGraph() await graph.refresh_from_api(api) batteries = graph.components(component_category={ComponentCategory.BATTERY}) batteries_ids = {c.component_id for c in batteries} channel = Bidirectional[Request, Result](\"user1\", \"power_distributor\") power_distributor = PowerDistributor( mock_api, component_graph, {\"user1\": channel.service_handle} ) client_handle = channel.client_handle # Set power 1200W to given batteries. request = Request(power=1200, batteries=batteries_ids, request_timeout_sec=10.0) await client_handle.send(request) # It is recommended to use timeout when waiting for the response! result: Result = await asyncio.wait_for(client_handle.receive(), timeout=10) if result.status == Result.Status.SUCCESS: print(\"Command succeed\") elif result.status == Result.Status.FAILED: print( f\"Some batteries failed, total failed power: {result.failed_power}\") elif result.status == Result.Status.IGNORED: print(f\"Request was ignored, because of newer command\") elif result.status == Result.Status.ERROR: print(f\"Request failed with error: {request.error_message}\") ``` \"\"\" def __init__ ( self , microgrid_api : MicrogridApiClient , component_graph : ComponentGraph , users_channels : Dict [ str , Bidirectional . Handle [ Result , Request ]], wait_for_data_sec : float = 2 , ) -> None : \"\"\"Create class instance. Args: microgrid_api: api for sending the requests. component_graph: component graph of the given microgrid api. users_channels: BidirectionalHandle for each user. Key should be user id and value should be BidirectionalHandle. wait_for_data_sec: How long actor should wait before processing first request. It is a time needed to collect first components data. \"\"\" self . _api = microgrid_api self . _wait_for_data_sec = wait_for_data_sec # Max permitted time when the component should send any information. # After that timeout the component will be treated as not existing. # Formulas will put 0 in place of data from this components. # This will happen until component starts sending data. self . component_data_timeout_sec : float = 60.0 self . broken_component_timeout_sec : float = 30.0 self . power_distributor_exponent : float = 1.0 # distributor_exponent and timeout_sec should be get from ConfigManager self . distribution_algorithm = DistributionAlgorithm ( self . power_distributor_exponent ) self . _broken_components = BrokenComponents ( self . broken_component_timeout_sec ) self . _bat_inv_map , self . _inv_bat_map = self . _get_components_pairs ( component_graph ) self . _battery_receivers : Dict [ int , Peekable [ BatteryData ]] = {} self . _inverter_receivers : Dict [ int , Peekable [ InverterData ]] = {} # The components in different requests be for the same components, or for # completely different components. They should not overlap. # Otherwise the PowerDistributor has no way to decide what request is more # important. It will execute both. And later request will override the previous # one. # That is why the queue of maxsize = total number of batteries should be enough. self . _request_queue : asyncio . Queue [ Tuple [ Request , User ]] = asyncio . Queue ( maxsize = len ( self . _bat_inv_map ) ) self . _users_channels : Dict [ str , Bidirectional . Handle [ Result , Request ] ] = users_channels self . _create_users_tasks () self . _started = asyncio . Event () def _create_users_tasks ( self ) -> None : \"\"\"For each user create a task to wait for request.\"\"\" for user , handler in self . _users_channels . items (): asyncio . create_task ( self . _wait_for_request ( User ( user , handler ))) def get_upper_bound ( self , batteries : Set [ int ]) -> float : \"\"\"Get total upper bound of power to be set for given batteries. Note, output of that function doesn't guarantee that this bound will be the same when the request is processed. Args: batteries: List of batteries Returns: Upper bound for `set_power` operation. \"\"\" pairs_data : List [ InvBatPair ] = self . _get_components_data ( batteries ) return sum ( min ( battery . power_upper_bound , inverter . active_power_upper_bound ) for battery , inverter in pairs_data ) def get_lower_bound ( self , batteries : Set [ int ]) -> float : \"\"\"Get total lower bound of power to be set for given batteries. Note, output of that function doesn't guarantee that this bound will be the same when the request is processed. Args: batteries: List of batteries Returns: Lower bound for `set_power` operation. \"\"\" pairs_data : List [ InvBatPair ] = self . _get_components_data ( batteries ) return sum ( min ( battery . power_lower_bound , inverter . active_power_lower_bound ) for battery , inverter in pairs_data ) def _within_bounds ( self , request : Request ) -> bool : \"\"\"Check whether the requested power is withing the bounds. Args: request: request Returns: True if power is between the bounds, False otherwise. \"\"\" power = request . power lower_bound = self . get_lower_bound ( request . batteries ) return lower_bound <= power <= self . get_upper_bound ( request . batteries ) async def run ( self ) -> None : \"\"\"Run actor main function. It waits for new requests in task_queue and process it, and send `set_power` request with distributed power. The output of the `set_power` method is processed. Every battery and inverter that failed or didn't respond in time will be marked as broken for some time. \"\"\" await self . _create_channels () # Wait 2 seconds to get data from the channels created above. await asyncio . sleep ( self . _wait_for_data_sec ) self . _started . set () while True : request , user = await self . _request_queue . get () try : pairs_data : List [ InvBatPair ] = self . _get_components_data ( request . batteries ) except KeyError as err : await user . channel . send ( Result ( Result . Status . ERROR , request . power , 0 , str ( err )) ) continue if len ( pairs_data ) == 0 : error_msg = f \"No data for the given batteries { str ( request . batteries ) } \" await user . channel . send ( Result ( Result . Status . ERROR , request . power , 0 , str ( error_msg )) ) continue try : distribution = self . distribution_algorithm . distribute_power ( request . power , pairs_data ) except ValueError as err : error_msg = f \"Couldn't distribute power, error: { str ( err ) } \" await user . channel . send ( Result ( Result . Status . ERROR , request . power , 0 , error_msg ) ) continue distributed_power_value = request . power - distribution . remaining_power _logger . debug ( \" %s : Distributing power %d between the inverters %s \" , user . user_id , distributed_power_value , str ( distribution . distribution ), ) tasks = { inverter_id : asyncio . create_task ( self . _api . set_power ( inverter_id , power ) ) for inverter_id , power in distribution . distribution . items () } _ , pending = await asyncio . wait ( tasks . values (), timeout = request . request_timeout_sec , return_when = ALL_COMPLETED , ) await self . _cancel_tasks ( pending ) any_fail , failed_power = self . _parse_result ( tasks , distribution . distribution , request . request_timeout_sec ) status = Result . Status . FAILED if any_fail else Result . Status . SUCCESS await user . channel . send ( Result ( status , failed_power , distribution . remaining_power ) ) def _check_request ( self , request : Request ) -> Optional [ Result ]: \"\"\"Check whether the given request if correct. Args: request: request to check Returns: Result for the user if the request is wrong, None otherwise. \"\"\" for battery in request . batteries : if battery not in self . _battery_receivers : msg = ( f \"No battery { battery } , available batteries: \" f \" { list ( self . _battery_receivers . keys ()) } \" ) return Result ( Result . Status . ERROR , request . power , 0 , error_message = msg ) if not request . adjust_power and not self . _within_bounds ( request ): return Result ( Result . Status . OUT_OF_BOUND , request . power , 0 ) return None def _remove_duplicated_requests ( self , request : Request , user : User ) -> List [ asyncio . Task [ bool ]]: \"\"\"Remove duplicated requests from the queue. Remove old requests in which set of batteries are the same as in new request. If batteries in new request overlap with batteries in old request but are not equal, then log error and process both messages. Args: request: request to check user: User who sent the request. Returns: Tasks with result sent to the users which requests were duplicated. \"\"\" batteries = request . batteries good_requests : List [ Tuple [ Request , User ]] = [] to_ignore : List [ asyncio . Task [ bool ]] = [] while not self . _request_queue . empty (): prev_request , prev_user = self . _request_queue . get_nowait () # Generators seems to be the fastest if prev_request . batteries == batteries : task = asyncio . create_task ( prev_user . channel . send ( Result ( Result . Status . IGNORED , prev_request . power , 0 ) ) ) to_ignore . append ( task ) # Use generators as generators seems to be the fastest. elif any ( battery_id in prev_request . batteries for battery_id in batteries ): # If that happen PowerDistributor has no way to distinguish what # request is more important. This should not happen _logger . error ( \"Batteries in two requests overlap! Actor: %s requested %s \" \"and Actor: %s requested %s \" , user . user_id , str ( request ), prev_user . user_id , str ( prev_request ), ) good_requests . append (( prev_request , prev_user )) else : good_requests . append (( prev_request , prev_user )) for good_request in good_requests : self . _request_queue . put_nowait ( good_request ) return to_ignore async def _wait_for_request ( self , user : User ) -> None : \"\"\"Wait for the request from user. Check if request is correct. If request is not correct send ERROR response to the user. If request is correct, then add it to the main queue to be process. If main queue has request for the same subset of batteries, then remove older request, and send its user response with Result.Status.IGNORED. Only new request will re processed. If set of batteries are not the same but have common elements, then both batteries will be processed. Args: user: User that sends the requests. \"\"\" while True : request : Optional [ Request ] = await user . channel . receive () if request is None : _logger . info ( \"Send channel for user %s was closed. User will be unregistered.\" , user . user_id , ) self . _users_channels . pop ( user . user_id ) if len ( self . _users_channels ) == 0 : _logger . error ( \"No users in PowerDistributor!\" ) return # Wait for PowerDistributor to start. if not self . _started . is_set (): await self . _started . wait () # We should discover as fast as possible that request is wrong. check_result = self . _check_request ( request ) if check_result is not None : await user . channel . send ( check_result ) continue tasks = self . _remove_duplicated_requests ( request , user ) if self . _request_queue . full (): q_size = ( self . _request_queue . qsize (),) msg = ( f \"Request queue is full { q_size } , can't process this request. \" \"Consider increasing size of the queue.\" ) _logger . error ( msg ) await user . channel . send ( Result ( Result . Status . ERROR , request . power , 0 , msg ) ) else : self . _request_queue . put_nowait (( request , user )) await asyncio . gather ( * tasks ) def _get_components_pairs ( self , component_graph : ComponentGraph ) -> Tuple [ Dict [ int , int ], Dict [ int , int ]]: \"\"\"Create maps between battery and adjacent inverter. Args: component_graph: component graph Returns: Tuple where first element is map between battery and adjacent inverter, second element of the tuple is map between inverter and adjacent battery. \"\"\" bat_inv_map : Dict [ int , int ] = {} inv_bat_map : Dict [ int , int ] = {} batteries : Iterable [ Component ] = component_graph . components ( component_category = { ComponentCategory . BATTERY } ) for battery in batteries : inverters : List [ Component ] = [ component for component in component_graph . predecessors ( battery . component_id ) if component . category == ComponentCategory . INVERTER ] if len ( inverters ) == 0 : _logger . error ( \"No inverters for battery %d \" , battery . component_id ) continue if len ( inverters ) > 1 : _logger . error ( \"Battery %d has more then one inverter. It is not supported now.\" , battery . component_id , ) bat_inv_map [ battery . component_id ] = inverters [ 0 ] . component_id inv_bat_map [ inverters [ 0 ] . component_id ] = battery . component_id return bat_inv_map , inv_bat_map def _get_components_data ( self , batteries : Iterable [ int ]) -> List [ InvBatPair ]: \"\"\"Get data for the given batteries and adjacent inverters. Args: batteries: Batteries that needs data. Raises: KeyError: If any battery in the given list doesn't exists in microgrid. Returns: Pairs of battery and adjacent inverter data. \"\"\" pairs_data : List [ InvBatPair ] = [] for battery_id in batteries : if battery_id not in self . _battery_receivers : raise KeyError ( f \"No battery { battery_id } , \" f \"available batteries: { list ( self . _battery_receivers . keys ()) } \" ) inverter_id : int = self . _bat_inv_map [ battery_id ] if self . _broken_components . is_broken ( battery_id ) or self . _broken_components . is_broken ( inverter_id ): continue battery_data : Optional [ BatteryData ] = self . _battery_receivers [ battery_id ] . peek () if not self . _is_component_data_valid ( battery_id , battery_data ): continue inverter_data : Optional [ InverterData ] = self . _inverter_receivers [ inverter_id ] . peek () if not self . _is_component_data_valid ( inverter_id , inverter_data ): continue # None case already checked but mypy don't see that. if battery_data is not None and inverter_data is not None : pairs_data . append ( InvBatPair ( battery_data , inverter_data )) return pairs_data def _is_component_data_valid ( self , component_id : int , component_data : Union [ None , BatteryData , InverterData ] ) -> bool : \"\"\"Check whether the component data from microgrid are correct. Args: component_id: component id component_data: component data instance Returns: True if data are correct, false otherwise \"\"\" if component_data is None : _logger . warning ( \"No data from component %d .\" , component_id , ) return False now = datetime . now ( timezone . utc ) time_delta = now - component_data . timestamp if time_delta . total_seconds () > self . component_data_timeout_sec : _logger . warning ( \"Component %d data are stale. Last timestamp: %s , now: %s \" , component_id , str ( component_data . timestamp ), str ( now ), ) return False return True async def _create_channels ( self ) -> None : \"\"\"Create channels to get data of components in microgrid.\"\"\" for battery_id , inverter_id in self . _bat_inv_map . items (): bat_recv : Receiver [ BatteryData ] = await self . _api . battery_data ( battery_id ) self . _battery_receivers [ battery_id ] = bat_recv . into_peekable () inv_recv : Receiver [ InverterData ] = await self . _api . inverter_data ( inverter_id ) self . _inverter_receivers [ inverter_id ] = inv_recv . into_peekable () def _parse_result ( self , # type comment to quiet pylint and mypy `unused-import` error tasks , # type: Dict[int, asyncio.Task[Empty]] distribution : Dict [ int , int ], request_timeout_sec : float , ) -> Tuple [ bool , int ]: \"\"\"Parse result of `set_power` requests. Check if any task failed and why. If any task didn't success, then corresponding battery is marked as broken. Args: tasks: Dictionary where key is inverter id and value is task that set power for this inverter. Each tasks should be finished or cancelled. distribution: Dictionary where key is inverter id and value is how much power was set to the corresponding inverter. request_timeout_sec: timeout which has been used for request. Returns: Tuple where first element tells if any task didn't succeed, and the second element is total amount of power that failed. \"\"\" any_fail : bool = False failed_power : int = 0 for inverter_id , aws in tasks . items (): battery_id = self . _inv_bat_map [ inverter_id ] try : aws . result () except grpc . aio . AioRpcError as err : any_fail = True failed_power += distribution [ inverter_id ] if err . code () == grpc . StatusCode . OUT_OF_RANGE : _logger . debug ( \"Set power for battery %d failed, error %s \" , battery_id , str ( err ), ) else : _logger . warning ( \"Set power for battery %d failed, error %s . Mark it as broken.\" , battery_id , str ( err ), ) self . _broken_components . mark_as_broken ( battery_id ) except asyncio . exceptions . CancelledError : any_fail = True failed_power += distribution [ inverter_id ] _logger . warning ( \"Battery %d didn't respond in %f sec. Mark it as broken.\" , battery_id , request_timeout_sec , ) self . _broken_components . mark_as_broken ( battery_id ) return any_fail , failed_power async def _cancel_tasks ( self , tasks : Iterable [ asyncio . Task [ Any ]]) -> None : \"\"\"Cancel given asyncio tasks and wait for them. Args: tasks: tasks to cancel. \"\"\" for aws in tasks : aws . cancel () await asyncio . gather ( * tasks , return_exceptions = True ) Functions \u00a4 __init__ ( microgrid_api , component_graph , users_channels , wait_for_data_sec = 2 ) \u00a4 Create class instance. PARAMETER DESCRIPTION microgrid_api api for sending the requests. TYPE: MicrogridApiClient component_graph component graph of the given microgrid api. TYPE: ComponentGraph users_channels BidirectionalHandle for each user. Key should be user id and value should be BidirectionalHandle. TYPE: Dict [ str , Bidirectional . Handle [ Result , Request ]] wait_for_data_sec How long actor should wait before processing first request. It is a time needed to collect first components data. TYPE: float DEFAULT: 2 Source code in frequenz/sdk/power_distribution/power_distributor.py 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 def __init__ ( self , microgrid_api : MicrogridApiClient , component_graph : ComponentGraph , users_channels : Dict [ str , Bidirectional . Handle [ Result , Request ]], wait_for_data_sec : float = 2 , ) -> None : \"\"\"Create class instance. Args: microgrid_api: api for sending the requests. component_graph: component graph of the given microgrid api. users_channels: BidirectionalHandle for each user. Key should be user id and value should be BidirectionalHandle. wait_for_data_sec: How long actor should wait before processing first request. It is a time needed to collect first components data. \"\"\" self . _api = microgrid_api self . _wait_for_data_sec = wait_for_data_sec # Max permitted time when the component should send any information. # After that timeout the component will be treated as not existing. # Formulas will put 0 in place of data from this components. # This will happen until component starts sending data. self . component_data_timeout_sec : float = 60.0 self . broken_component_timeout_sec : float = 30.0 self . power_distributor_exponent : float = 1.0 # distributor_exponent and timeout_sec should be get from ConfigManager self . distribution_algorithm = DistributionAlgorithm ( self . power_distributor_exponent ) self . _broken_components = BrokenComponents ( self . broken_component_timeout_sec ) self . _bat_inv_map , self . _inv_bat_map = self . _get_components_pairs ( component_graph ) self . _battery_receivers : Dict [ int , Peekable [ BatteryData ]] = {} self . _inverter_receivers : Dict [ int , Peekable [ InverterData ]] = {} # The components in different requests be for the same components, or for # completely different components. They should not overlap. # Otherwise the PowerDistributor has no way to decide what request is more # important. It will execute both. And later request will override the previous # one. # That is why the queue of maxsize = total number of batteries should be enough. self . _request_queue : asyncio . Queue [ Tuple [ Request , User ]] = asyncio . Queue ( maxsize = len ( self . _bat_inv_map ) ) self . _users_channels : Dict [ str , Bidirectional . Handle [ Result , Request ] ] = users_channels self . _create_users_tasks () self . _started = asyncio . Event () get_lower_bound ( batteries ) \u00a4 Get total lower bound of power to be set for given batteries. Note, output of that function doesn't guarantee that this bound will be the same when the request is processed. PARAMETER DESCRIPTION batteries List of batteries TYPE: Set [ int ] RETURNS DESCRIPTION float Lower bound for set_power operation. Source code in frequenz/sdk/power_distribution/power_distributor.py 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 def get_lower_bound ( self , batteries : Set [ int ]) -> float : \"\"\"Get total lower bound of power to be set for given batteries. Note, output of that function doesn't guarantee that this bound will be the same when the request is processed. Args: batteries: List of batteries Returns: Lower bound for `set_power` operation. \"\"\" pairs_data : List [ InvBatPair ] = self . _get_components_data ( batteries ) return sum ( min ( battery . power_lower_bound , inverter . active_power_lower_bound ) for battery , inverter in pairs_data ) get_upper_bound ( batteries ) \u00a4 Get total upper bound of power to be set for given batteries. Note, output of that function doesn't guarantee that this bound will be the same when the request is processed. PARAMETER DESCRIPTION batteries List of batteries TYPE: Set [ int ] RETURNS DESCRIPTION float Upper bound for set_power operation. Source code in frequenz/sdk/power_distribution/power_distributor.py 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 def get_upper_bound ( self , batteries : Set [ int ]) -> float : \"\"\"Get total upper bound of power to be set for given batteries. Note, output of that function doesn't guarantee that this bound will be the same when the request is processed. Args: batteries: List of batteries Returns: Upper bound for `set_power` operation. \"\"\" pairs_data : List [ InvBatPair ] = self . _get_components_data ( batteries ) return sum ( min ( battery . power_upper_bound , inverter . active_power_upper_bound ) for battery , inverter in pairs_data ) run () async \u00a4 Run actor main function. It waits for new requests in task_queue and process it, and send set_power request with distributed power. The output of the set_power method is processed. Every battery and inverter that failed or didn't respond in time will be marked as broken for some time. Source code in frequenz/sdk/power_distribution/power_distributor.py 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 async def run ( self ) -> None : \"\"\"Run actor main function. It waits for new requests in task_queue and process it, and send `set_power` request with distributed power. The output of the `set_power` method is processed. Every battery and inverter that failed or didn't respond in time will be marked as broken for some time. \"\"\" await self . _create_channels () # Wait 2 seconds to get data from the channels created above. await asyncio . sleep ( self . _wait_for_data_sec ) self . _started . set () while True : request , user = await self . _request_queue . get () try : pairs_data : List [ InvBatPair ] = self . _get_components_data ( request . batteries ) except KeyError as err : await user . channel . send ( Result ( Result . Status . ERROR , request . power , 0 , str ( err )) ) continue if len ( pairs_data ) == 0 : error_msg = f \"No data for the given batteries { str ( request . batteries ) } \" await user . channel . send ( Result ( Result . Status . ERROR , request . power , 0 , str ( error_msg )) ) continue try : distribution = self . distribution_algorithm . distribute_power ( request . power , pairs_data ) except ValueError as err : error_msg = f \"Couldn't distribute power, error: { str ( err ) } \" await user . channel . send ( Result ( Result . Status . ERROR , request . power , 0 , error_msg ) ) continue distributed_power_value = request . power - distribution . remaining_power _logger . debug ( \" %s : Distributing power %d between the inverters %s \" , user . user_id , distributed_power_value , str ( distribution . distribution ), ) tasks = { inverter_id : asyncio . create_task ( self . _api . set_power ( inverter_id , power ) ) for inverter_id , power in distribution . distribution . items () } _ , pending = await asyncio . wait ( tasks . values (), timeout = request . request_timeout_sec , return_when = ALL_COMPLETED , ) await self . _cancel_tasks ( pending ) any_fail , failed_power = self . _parse_result ( tasks , distribution . distribution , request . request_timeout_sec ) status = Result . Status . FAILED if any_fail else Result . Status . SUCCESS await user . channel . send ( Result ( status , failed_power , distribution . remaining_power ) ) frequenz.sdk.power_distribution.Request dataclass \u00a4 Request from the user. Source code in frequenz/sdk/power_distribution/utils.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 @dataclass class Request : \"\"\"Request from the user.\"\"\" # How much power to set power : int # In which batteries the power should be set batteries : Set [ int ] # Timeout for the server to respond on the request. request_timeout_sec : float = 5.0 # If True and requested power value is out of bound, then # PowerDistributor will decrease the power to match the bounds and # distribute only decreased power. # If False and the requested power is out of bound, then # PowerDistributor will not process this request and send result with status # Result.Status.OUT_OF_BOUND. adjust_power : bool = True frequenz.sdk.power_distribution.Result dataclass \u00a4 Result on distribution request. Source code in frequenz/sdk/power_distribution/utils.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 @dataclass class Result : \"\"\"Result on distribution request.\"\"\" class Status ( Enum ): \"\"\"Status of the result.\"\"\" FAILED = 0 # If any request for any battery didn't succeed for any reason. SUCCESS = 1 # If all requests for all batteries succeed. IGNORED = 2 # If request was dispossessed by newer request with the same set # of batteries. ERROR = 3 # If any error happened. In this case error_message describes error. OUT_OF_BOUND = 4 # When Request.adjust_power=False and the requested power was # out of the bounds for specified batteries. status : Status # Status of the request. failed_power : float # How much power failed. above_upper_bound : float # How much power was not used because it was beyond the # limits. error_message : Optional [ str ] = None # error_message filled only when status is ERROR Classes \u00a4 Status \u00a4 Bases: Enum Status of the result. Source code in frequenz/sdk/power_distribution/utils.py 45 46 47 48 49 50 51 52 53 class Status ( Enum ): \"\"\"Status of the result.\"\"\" FAILED = 0 # If any request for any battery didn't succeed for any reason. SUCCESS = 1 # If all requests for all batteries succeed. IGNORED = 2 # If request was dispossessed by newer request with the same set # of batteries. ERROR = 3 # If any error happened. In this case error_message describes error. OUT_OF_BOUND = 4 # When Request.adjust_power=False and the requested power was","title":"power_distribution"},{"location":"reference/frequenz/sdk/power_distribution/#frequenz.sdk.power_distribution","text":"Distribute power between many batteries. When charge/discharge method is called the power should be distributed so that the SoC in batteries stays at the same level. That way of distribution prevents using only one battery, increasing temperature, and maximize the total amount power to charge/discharge.","title":"power_distribution"},{"location":"reference/frequenz/sdk/power_distribution/#frequenz.sdk.power_distribution-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/power_distribution/#frequenz.sdk.power_distribution.PowerDistributor","text":"Tool to distribute power between batteries in microgrid. The purpose of this tool is to keep equal SoC level in the batteries. PowerDistributor can have many users. Each user should first register in order to get its id, channel for sending request, and channel for receiving response. It is recommended to wait for PowerDistributor output with timeout. Otherwise if the processing function fail then the response will never come. The timeout should be Result:request_timeout_sec + time for processing the request. Edge cases: * If there are 2 requests to be processed for the same subset of batteries, then only the latest request will be processed. Older request will be ignored. User with older request will get response with Result.Status.IGNORED. If there are 2 requests and their subset of batteries is different but they overlap (they have at least one common battery), then then both batteries will be processed. However it is not expected so the proper error log will be printed. Example import grpc.aio as grpcaio from frequenz.sdk.microgrid.graph import _MicrogridComponentGraph from frequenz.sdk.microgrid.component import ComponentCategory from frequenz.sdk.power_distribution import ( PowerDistributor , Request , Result , ) target = f \" { host } : { port } \" grpc_channel = grpcaio . insecure_channel ( target ) api = MicrogridGrpcClient ( grpc_channel , target ) graph = _MicrogridComponentGraph () await graph . refresh_from_api ( api ) batteries = graph . components ( component_category = { ComponentCategory . BATTERY }) batteries_ids = { c . component_id for c in batteries } channel = Bidirectional [ Request , Result ]( \"user1\" , \"power_distributor\" ) power_distributor = PowerDistributor ( mock_api , component_graph , { \"user1\" : channel . service_handle } ) client_handle = channel . client_handle # Set power 1200W to given batteries. request = Request ( power = 1200 , batteries = batteries_ids , request_timeout_sec = 10.0 ) await client_handle . send ( request ) # It is recommended to use timeout when waiting for the response! result : Result = await asyncio . wait_for ( client_handle . receive (), timeout = 10 ) if result . status == Result . Status . SUCCESS : print ( \"Command succeed\" ) elif result . status == Result . Status . FAILED : print ( f \"Some batteries failed, total failed power: { result . failed_power } \" ) elif result . status == Result . Status . IGNORED : print ( f \"Request was ignored, because of newer command\" ) elif result . status == Result . Status . ERROR : print ( f \"Request failed with error: { request . error_message } \" ) Source code in frequenz/sdk/power_distribution/power_distributor.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 @actor class PowerDistributor : # pylint: disable=too-many-instance-attributes \"\"\"Tool to distribute power between batteries in microgrid. The purpose of this tool is to keep equal SoC level in the batteries. PowerDistributor can have many users. Each user should first register in order to get its id, channel for sending request, and channel for receiving response. It is recommended to wait for PowerDistributor output with timeout. Otherwise if the processing function fail then the response will never come. The timeout should be Result:request_timeout_sec + time for processing the request. Edge cases: * If there are 2 requests to be processed for the same subset of batteries, then only the latest request will be processed. Older request will be ignored. User with older request will get response with Result.Status.IGNORED. * If there are 2 requests and their subset of batteries is different but they overlap (they have at least one common battery), then then both batteries will be processed. However it is not expected so the proper error log will be printed. Example: ``` python import grpc.aio as grpcaio from frequenz.sdk.microgrid.graph import _MicrogridComponentGraph from frequenz.sdk.microgrid.component import ComponentCategory from frequenz.sdk.power_distribution import ( PowerDistributor, Request, Result, ) target = f\"{host}:{port}\" grpc_channel = grpcaio.insecure_channel(target) api = MicrogridGrpcClient(grpc_channel, target) graph = _MicrogridComponentGraph() await graph.refresh_from_api(api) batteries = graph.components(component_category={ComponentCategory.BATTERY}) batteries_ids = {c.component_id for c in batteries} channel = Bidirectional[Request, Result](\"user1\", \"power_distributor\") power_distributor = PowerDistributor( mock_api, component_graph, {\"user1\": channel.service_handle} ) client_handle = channel.client_handle # Set power 1200W to given batteries. request = Request(power=1200, batteries=batteries_ids, request_timeout_sec=10.0) await client_handle.send(request) # It is recommended to use timeout when waiting for the response! result: Result = await asyncio.wait_for(client_handle.receive(), timeout=10) if result.status == Result.Status.SUCCESS: print(\"Command succeed\") elif result.status == Result.Status.FAILED: print( f\"Some batteries failed, total failed power: {result.failed_power}\") elif result.status == Result.Status.IGNORED: print(f\"Request was ignored, because of newer command\") elif result.status == Result.Status.ERROR: print(f\"Request failed with error: {request.error_message}\") ``` \"\"\" def __init__ ( self , microgrid_api : MicrogridApiClient , component_graph : ComponentGraph , users_channels : Dict [ str , Bidirectional . Handle [ Result , Request ]], wait_for_data_sec : float = 2 , ) -> None : \"\"\"Create class instance. Args: microgrid_api: api for sending the requests. component_graph: component graph of the given microgrid api. users_channels: BidirectionalHandle for each user. Key should be user id and value should be BidirectionalHandle. wait_for_data_sec: How long actor should wait before processing first request. It is a time needed to collect first components data. \"\"\" self . _api = microgrid_api self . _wait_for_data_sec = wait_for_data_sec # Max permitted time when the component should send any information. # After that timeout the component will be treated as not existing. # Formulas will put 0 in place of data from this components. # This will happen until component starts sending data. self . component_data_timeout_sec : float = 60.0 self . broken_component_timeout_sec : float = 30.0 self . power_distributor_exponent : float = 1.0 # distributor_exponent and timeout_sec should be get from ConfigManager self . distribution_algorithm = DistributionAlgorithm ( self . power_distributor_exponent ) self . _broken_components = BrokenComponents ( self . broken_component_timeout_sec ) self . _bat_inv_map , self . _inv_bat_map = self . _get_components_pairs ( component_graph ) self . _battery_receivers : Dict [ int , Peekable [ BatteryData ]] = {} self . _inverter_receivers : Dict [ int , Peekable [ InverterData ]] = {} # The components in different requests be for the same components, or for # completely different components. They should not overlap. # Otherwise the PowerDistributor has no way to decide what request is more # important. It will execute both. And later request will override the previous # one. # That is why the queue of maxsize = total number of batteries should be enough. self . _request_queue : asyncio . Queue [ Tuple [ Request , User ]] = asyncio . Queue ( maxsize = len ( self . _bat_inv_map ) ) self . _users_channels : Dict [ str , Bidirectional . Handle [ Result , Request ] ] = users_channels self . _create_users_tasks () self . _started = asyncio . Event () def _create_users_tasks ( self ) -> None : \"\"\"For each user create a task to wait for request.\"\"\" for user , handler in self . _users_channels . items (): asyncio . create_task ( self . _wait_for_request ( User ( user , handler ))) def get_upper_bound ( self , batteries : Set [ int ]) -> float : \"\"\"Get total upper bound of power to be set for given batteries. Note, output of that function doesn't guarantee that this bound will be the same when the request is processed. Args: batteries: List of batteries Returns: Upper bound for `set_power` operation. \"\"\" pairs_data : List [ InvBatPair ] = self . _get_components_data ( batteries ) return sum ( min ( battery . power_upper_bound , inverter . active_power_upper_bound ) for battery , inverter in pairs_data ) def get_lower_bound ( self , batteries : Set [ int ]) -> float : \"\"\"Get total lower bound of power to be set for given batteries. Note, output of that function doesn't guarantee that this bound will be the same when the request is processed. Args: batteries: List of batteries Returns: Lower bound for `set_power` operation. \"\"\" pairs_data : List [ InvBatPair ] = self . _get_components_data ( batteries ) return sum ( min ( battery . power_lower_bound , inverter . active_power_lower_bound ) for battery , inverter in pairs_data ) def _within_bounds ( self , request : Request ) -> bool : \"\"\"Check whether the requested power is withing the bounds. Args: request: request Returns: True if power is between the bounds, False otherwise. \"\"\" power = request . power lower_bound = self . get_lower_bound ( request . batteries ) return lower_bound <= power <= self . get_upper_bound ( request . batteries ) async def run ( self ) -> None : \"\"\"Run actor main function. It waits for new requests in task_queue and process it, and send `set_power` request with distributed power. The output of the `set_power` method is processed. Every battery and inverter that failed or didn't respond in time will be marked as broken for some time. \"\"\" await self . _create_channels () # Wait 2 seconds to get data from the channels created above. await asyncio . sleep ( self . _wait_for_data_sec ) self . _started . set () while True : request , user = await self . _request_queue . get () try : pairs_data : List [ InvBatPair ] = self . _get_components_data ( request . batteries ) except KeyError as err : await user . channel . send ( Result ( Result . Status . ERROR , request . power , 0 , str ( err )) ) continue if len ( pairs_data ) == 0 : error_msg = f \"No data for the given batteries { str ( request . batteries ) } \" await user . channel . send ( Result ( Result . Status . ERROR , request . power , 0 , str ( error_msg )) ) continue try : distribution = self . distribution_algorithm . distribute_power ( request . power , pairs_data ) except ValueError as err : error_msg = f \"Couldn't distribute power, error: { str ( err ) } \" await user . channel . send ( Result ( Result . Status . ERROR , request . power , 0 , error_msg ) ) continue distributed_power_value = request . power - distribution . remaining_power _logger . debug ( \" %s : Distributing power %d between the inverters %s \" , user . user_id , distributed_power_value , str ( distribution . distribution ), ) tasks = { inverter_id : asyncio . create_task ( self . _api . set_power ( inverter_id , power ) ) for inverter_id , power in distribution . distribution . items () } _ , pending = await asyncio . wait ( tasks . values (), timeout = request . request_timeout_sec , return_when = ALL_COMPLETED , ) await self . _cancel_tasks ( pending ) any_fail , failed_power = self . _parse_result ( tasks , distribution . distribution , request . request_timeout_sec ) status = Result . Status . FAILED if any_fail else Result . Status . SUCCESS await user . channel . send ( Result ( status , failed_power , distribution . remaining_power ) ) def _check_request ( self , request : Request ) -> Optional [ Result ]: \"\"\"Check whether the given request if correct. Args: request: request to check Returns: Result for the user if the request is wrong, None otherwise. \"\"\" for battery in request . batteries : if battery not in self . _battery_receivers : msg = ( f \"No battery { battery } , available batteries: \" f \" { list ( self . _battery_receivers . keys ()) } \" ) return Result ( Result . Status . ERROR , request . power , 0 , error_message = msg ) if not request . adjust_power and not self . _within_bounds ( request ): return Result ( Result . Status . OUT_OF_BOUND , request . power , 0 ) return None def _remove_duplicated_requests ( self , request : Request , user : User ) -> List [ asyncio . Task [ bool ]]: \"\"\"Remove duplicated requests from the queue. Remove old requests in which set of batteries are the same as in new request. If batteries in new request overlap with batteries in old request but are not equal, then log error and process both messages. Args: request: request to check user: User who sent the request. Returns: Tasks with result sent to the users which requests were duplicated. \"\"\" batteries = request . batteries good_requests : List [ Tuple [ Request , User ]] = [] to_ignore : List [ asyncio . Task [ bool ]] = [] while not self . _request_queue . empty (): prev_request , prev_user = self . _request_queue . get_nowait () # Generators seems to be the fastest if prev_request . batteries == batteries : task = asyncio . create_task ( prev_user . channel . send ( Result ( Result . Status . IGNORED , prev_request . power , 0 ) ) ) to_ignore . append ( task ) # Use generators as generators seems to be the fastest. elif any ( battery_id in prev_request . batteries for battery_id in batteries ): # If that happen PowerDistributor has no way to distinguish what # request is more important. This should not happen _logger . error ( \"Batteries in two requests overlap! Actor: %s requested %s \" \"and Actor: %s requested %s \" , user . user_id , str ( request ), prev_user . user_id , str ( prev_request ), ) good_requests . append (( prev_request , prev_user )) else : good_requests . append (( prev_request , prev_user )) for good_request in good_requests : self . _request_queue . put_nowait ( good_request ) return to_ignore async def _wait_for_request ( self , user : User ) -> None : \"\"\"Wait for the request from user. Check if request is correct. If request is not correct send ERROR response to the user. If request is correct, then add it to the main queue to be process. If main queue has request for the same subset of batteries, then remove older request, and send its user response with Result.Status.IGNORED. Only new request will re processed. If set of batteries are not the same but have common elements, then both batteries will be processed. Args: user: User that sends the requests. \"\"\" while True : request : Optional [ Request ] = await user . channel . receive () if request is None : _logger . info ( \"Send channel for user %s was closed. User will be unregistered.\" , user . user_id , ) self . _users_channels . pop ( user . user_id ) if len ( self . _users_channels ) == 0 : _logger . error ( \"No users in PowerDistributor!\" ) return # Wait for PowerDistributor to start. if not self . _started . is_set (): await self . _started . wait () # We should discover as fast as possible that request is wrong. check_result = self . _check_request ( request ) if check_result is not None : await user . channel . send ( check_result ) continue tasks = self . _remove_duplicated_requests ( request , user ) if self . _request_queue . full (): q_size = ( self . _request_queue . qsize (),) msg = ( f \"Request queue is full { q_size } , can't process this request. \" \"Consider increasing size of the queue.\" ) _logger . error ( msg ) await user . channel . send ( Result ( Result . Status . ERROR , request . power , 0 , msg ) ) else : self . _request_queue . put_nowait (( request , user )) await asyncio . gather ( * tasks ) def _get_components_pairs ( self , component_graph : ComponentGraph ) -> Tuple [ Dict [ int , int ], Dict [ int , int ]]: \"\"\"Create maps between battery and adjacent inverter. Args: component_graph: component graph Returns: Tuple where first element is map between battery and adjacent inverter, second element of the tuple is map between inverter and adjacent battery. \"\"\" bat_inv_map : Dict [ int , int ] = {} inv_bat_map : Dict [ int , int ] = {} batteries : Iterable [ Component ] = component_graph . components ( component_category = { ComponentCategory . BATTERY } ) for battery in batteries : inverters : List [ Component ] = [ component for component in component_graph . predecessors ( battery . component_id ) if component . category == ComponentCategory . INVERTER ] if len ( inverters ) == 0 : _logger . error ( \"No inverters for battery %d \" , battery . component_id ) continue if len ( inverters ) > 1 : _logger . error ( \"Battery %d has more then one inverter. It is not supported now.\" , battery . component_id , ) bat_inv_map [ battery . component_id ] = inverters [ 0 ] . component_id inv_bat_map [ inverters [ 0 ] . component_id ] = battery . component_id return bat_inv_map , inv_bat_map def _get_components_data ( self , batteries : Iterable [ int ]) -> List [ InvBatPair ]: \"\"\"Get data for the given batteries and adjacent inverters. Args: batteries: Batteries that needs data. Raises: KeyError: If any battery in the given list doesn't exists in microgrid. Returns: Pairs of battery and adjacent inverter data. \"\"\" pairs_data : List [ InvBatPair ] = [] for battery_id in batteries : if battery_id not in self . _battery_receivers : raise KeyError ( f \"No battery { battery_id } , \" f \"available batteries: { list ( self . _battery_receivers . keys ()) } \" ) inverter_id : int = self . _bat_inv_map [ battery_id ] if self . _broken_components . is_broken ( battery_id ) or self . _broken_components . is_broken ( inverter_id ): continue battery_data : Optional [ BatteryData ] = self . _battery_receivers [ battery_id ] . peek () if not self . _is_component_data_valid ( battery_id , battery_data ): continue inverter_data : Optional [ InverterData ] = self . _inverter_receivers [ inverter_id ] . peek () if not self . _is_component_data_valid ( inverter_id , inverter_data ): continue # None case already checked but mypy don't see that. if battery_data is not None and inverter_data is not None : pairs_data . append ( InvBatPair ( battery_data , inverter_data )) return pairs_data def _is_component_data_valid ( self , component_id : int , component_data : Union [ None , BatteryData , InverterData ] ) -> bool : \"\"\"Check whether the component data from microgrid are correct. Args: component_id: component id component_data: component data instance Returns: True if data are correct, false otherwise \"\"\" if component_data is None : _logger . warning ( \"No data from component %d .\" , component_id , ) return False now = datetime . now ( timezone . utc ) time_delta = now - component_data . timestamp if time_delta . total_seconds () > self . component_data_timeout_sec : _logger . warning ( \"Component %d data are stale. Last timestamp: %s , now: %s \" , component_id , str ( component_data . timestamp ), str ( now ), ) return False return True async def _create_channels ( self ) -> None : \"\"\"Create channels to get data of components in microgrid.\"\"\" for battery_id , inverter_id in self . _bat_inv_map . items (): bat_recv : Receiver [ BatteryData ] = await self . _api . battery_data ( battery_id ) self . _battery_receivers [ battery_id ] = bat_recv . into_peekable () inv_recv : Receiver [ InverterData ] = await self . _api . inverter_data ( inverter_id ) self . _inverter_receivers [ inverter_id ] = inv_recv . into_peekable () def _parse_result ( self , # type comment to quiet pylint and mypy `unused-import` error tasks , # type: Dict[int, asyncio.Task[Empty]] distribution : Dict [ int , int ], request_timeout_sec : float , ) -> Tuple [ bool , int ]: \"\"\"Parse result of `set_power` requests. Check if any task failed and why. If any task didn't success, then corresponding battery is marked as broken. Args: tasks: Dictionary where key is inverter id and value is task that set power for this inverter. Each tasks should be finished or cancelled. distribution: Dictionary where key is inverter id and value is how much power was set to the corresponding inverter. request_timeout_sec: timeout which has been used for request. Returns: Tuple where first element tells if any task didn't succeed, and the second element is total amount of power that failed. \"\"\" any_fail : bool = False failed_power : int = 0 for inverter_id , aws in tasks . items (): battery_id = self . _inv_bat_map [ inverter_id ] try : aws . result () except grpc . aio . AioRpcError as err : any_fail = True failed_power += distribution [ inverter_id ] if err . code () == grpc . StatusCode . OUT_OF_RANGE : _logger . debug ( \"Set power for battery %d failed, error %s \" , battery_id , str ( err ), ) else : _logger . warning ( \"Set power for battery %d failed, error %s . Mark it as broken.\" , battery_id , str ( err ), ) self . _broken_components . mark_as_broken ( battery_id ) except asyncio . exceptions . CancelledError : any_fail = True failed_power += distribution [ inverter_id ] _logger . warning ( \"Battery %d didn't respond in %f sec. Mark it as broken.\" , battery_id , request_timeout_sec , ) self . _broken_components . mark_as_broken ( battery_id ) return any_fail , failed_power async def _cancel_tasks ( self , tasks : Iterable [ asyncio . Task [ Any ]]) -> None : \"\"\"Cancel given asyncio tasks and wait for them. Args: tasks: tasks to cancel. \"\"\" for aws in tasks : aws . cancel () await asyncio . gather ( * tasks , return_exceptions = True )","title":"PowerDistributor"},{"location":"reference/frequenz/sdk/power_distribution/#frequenz.sdk.power_distribution.PowerDistributor-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/power_distribution/#frequenz.sdk.power_distribution.power_distributor.PowerDistributor.__init__","text":"Create class instance. PARAMETER DESCRIPTION microgrid_api api for sending the requests. TYPE: MicrogridApiClient component_graph component graph of the given microgrid api. TYPE: ComponentGraph users_channels BidirectionalHandle for each user. Key should be user id and value should be BidirectionalHandle. TYPE: Dict [ str , Bidirectional . Handle [ Result , Request ]] wait_for_data_sec How long actor should wait before processing first request. It is a time needed to collect first components data. TYPE: float DEFAULT: 2 Source code in frequenz/sdk/power_distribution/power_distributor.py 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 def __init__ ( self , microgrid_api : MicrogridApiClient , component_graph : ComponentGraph , users_channels : Dict [ str , Bidirectional . Handle [ Result , Request ]], wait_for_data_sec : float = 2 , ) -> None : \"\"\"Create class instance. Args: microgrid_api: api for sending the requests. component_graph: component graph of the given microgrid api. users_channels: BidirectionalHandle for each user. Key should be user id and value should be BidirectionalHandle. wait_for_data_sec: How long actor should wait before processing first request. It is a time needed to collect first components data. \"\"\" self . _api = microgrid_api self . _wait_for_data_sec = wait_for_data_sec # Max permitted time when the component should send any information. # After that timeout the component will be treated as not existing. # Formulas will put 0 in place of data from this components. # This will happen until component starts sending data. self . component_data_timeout_sec : float = 60.0 self . broken_component_timeout_sec : float = 30.0 self . power_distributor_exponent : float = 1.0 # distributor_exponent and timeout_sec should be get from ConfigManager self . distribution_algorithm = DistributionAlgorithm ( self . power_distributor_exponent ) self . _broken_components = BrokenComponents ( self . broken_component_timeout_sec ) self . _bat_inv_map , self . _inv_bat_map = self . _get_components_pairs ( component_graph ) self . _battery_receivers : Dict [ int , Peekable [ BatteryData ]] = {} self . _inverter_receivers : Dict [ int , Peekable [ InverterData ]] = {} # The components in different requests be for the same components, or for # completely different components. They should not overlap. # Otherwise the PowerDistributor has no way to decide what request is more # important. It will execute both. And later request will override the previous # one. # That is why the queue of maxsize = total number of batteries should be enough. self . _request_queue : asyncio . Queue [ Tuple [ Request , User ]] = asyncio . Queue ( maxsize = len ( self . _bat_inv_map ) ) self . _users_channels : Dict [ str , Bidirectional . Handle [ Result , Request ] ] = users_channels self . _create_users_tasks () self . _started = asyncio . Event ()","title":"__init__()"},{"location":"reference/frequenz/sdk/power_distribution/#frequenz.sdk.power_distribution.power_distributor.PowerDistributor.get_lower_bound","text":"Get total lower bound of power to be set for given batteries. Note, output of that function doesn't guarantee that this bound will be the same when the request is processed. PARAMETER DESCRIPTION batteries List of batteries TYPE: Set [ int ] RETURNS DESCRIPTION float Lower bound for set_power operation. Source code in frequenz/sdk/power_distribution/power_distributor.py 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 def get_lower_bound ( self , batteries : Set [ int ]) -> float : \"\"\"Get total lower bound of power to be set for given batteries. Note, output of that function doesn't guarantee that this bound will be the same when the request is processed. Args: batteries: List of batteries Returns: Lower bound for `set_power` operation. \"\"\" pairs_data : List [ InvBatPair ] = self . _get_components_data ( batteries ) return sum ( min ( battery . power_lower_bound , inverter . active_power_lower_bound ) for battery , inverter in pairs_data )","title":"get_lower_bound()"},{"location":"reference/frequenz/sdk/power_distribution/#frequenz.sdk.power_distribution.power_distributor.PowerDistributor.get_upper_bound","text":"Get total upper bound of power to be set for given batteries. Note, output of that function doesn't guarantee that this bound will be the same when the request is processed. PARAMETER DESCRIPTION batteries List of batteries TYPE: Set [ int ] RETURNS DESCRIPTION float Upper bound for set_power operation. Source code in frequenz/sdk/power_distribution/power_distributor.py 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 def get_upper_bound ( self , batteries : Set [ int ]) -> float : \"\"\"Get total upper bound of power to be set for given batteries. Note, output of that function doesn't guarantee that this bound will be the same when the request is processed. Args: batteries: List of batteries Returns: Upper bound for `set_power` operation. \"\"\" pairs_data : List [ InvBatPair ] = self . _get_components_data ( batteries ) return sum ( min ( battery . power_upper_bound , inverter . active_power_upper_bound ) for battery , inverter in pairs_data )","title":"get_upper_bound()"},{"location":"reference/frequenz/sdk/power_distribution/#frequenz.sdk.power_distribution.power_distributor.PowerDistributor.run","text":"Run actor main function. It waits for new requests in task_queue and process it, and send set_power request with distributed power. The output of the set_power method is processed. Every battery and inverter that failed or didn't respond in time will be marked as broken for some time. Source code in frequenz/sdk/power_distribution/power_distributor.py 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 async def run ( self ) -> None : \"\"\"Run actor main function. It waits for new requests in task_queue and process it, and send `set_power` request with distributed power. The output of the `set_power` method is processed. Every battery and inverter that failed or didn't respond in time will be marked as broken for some time. \"\"\" await self . _create_channels () # Wait 2 seconds to get data from the channels created above. await asyncio . sleep ( self . _wait_for_data_sec ) self . _started . set () while True : request , user = await self . _request_queue . get () try : pairs_data : List [ InvBatPair ] = self . _get_components_data ( request . batteries ) except KeyError as err : await user . channel . send ( Result ( Result . Status . ERROR , request . power , 0 , str ( err )) ) continue if len ( pairs_data ) == 0 : error_msg = f \"No data for the given batteries { str ( request . batteries ) } \" await user . channel . send ( Result ( Result . Status . ERROR , request . power , 0 , str ( error_msg )) ) continue try : distribution = self . distribution_algorithm . distribute_power ( request . power , pairs_data ) except ValueError as err : error_msg = f \"Couldn't distribute power, error: { str ( err ) } \" await user . channel . send ( Result ( Result . Status . ERROR , request . power , 0 , error_msg ) ) continue distributed_power_value = request . power - distribution . remaining_power _logger . debug ( \" %s : Distributing power %d between the inverters %s \" , user . user_id , distributed_power_value , str ( distribution . distribution ), ) tasks = { inverter_id : asyncio . create_task ( self . _api . set_power ( inverter_id , power ) ) for inverter_id , power in distribution . distribution . items () } _ , pending = await asyncio . wait ( tasks . values (), timeout = request . request_timeout_sec , return_when = ALL_COMPLETED , ) await self . _cancel_tasks ( pending ) any_fail , failed_power = self . _parse_result ( tasks , distribution . distribution , request . request_timeout_sec ) status = Result . Status . FAILED if any_fail else Result . Status . SUCCESS await user . channel . send ( Result ( status , failed_power , distribution . remaining_power ) )","title":"run()"},{"location":"reference/frequenz/sdk/power_distribution/#frequenz.sdk.power_distribution.Request","text":"Request from the user. Source code in frequenz/sdk/power_distribution/utils.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 @dataclass class Request : \"\"\"Request from the user.\"\"\" # How much power to set power : int # In which batteries the power should be set batteries : Set [ int ] # Timeout for the server to respond on the request. request_timeout_sec : float = 5.0 # If True and requested power value is out of bound, then # PowerDistributor will decrease the power to match the bounds and # distribute only decreased power. # If False and the requested power is out of bound, then # PowerDistributor will not process this request and send result with status # Result.Status.OUT_OF_BOUND. adjust_power : bool = True","title":"Request"},{"location":"reference/frequenz/sdk/power_distribution/#frequenz.sdk.power_distribution.Result","text":"Result on distribution request. Source code in frequenz/sdk/power_distribution/utils.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 @dataclass class Result : \"\"\"Result on distribution request.\"\"\" class Status ( Enum ): \"\"\"Status of the result.\"\"\" FAILED = 0 # If any request for any battery didn't succeed for any reason. SUCCESS = 1 # If all requests for all batteries succeed. IGNORED = 2 # If request was dispossessed by newer request with the same set # of batteries. ERROR = 3 # If any error happened. In this case error_message describes error. OUT_OF_BOUND = 4 # When Request.adjust_power=False and the requested power was # out of the bounds for specified batteries. status : Status # Status of the request. failed_power : float # How much power failed. above_upper_bound : float # How much power was not used because it was beyond the # limits. error_message : Optional [ str ] = None # error_message filled only when status is ERROR","title":"Result"},{"location":"reference/frequenz/sdk/power_distribution/#frequenz.sdk.power_distribution.Result-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/power_distribution/#frequenz.sdk.power_distribution.utils.Result.Status","text":"Bases: Enum Status of the result. Source code in frequenz/sdk/power_distribution/utils.py 45 46 47 48 49 50 51 52 53 class Status ( Enum ): \"\"\"Status of the result.\"\"\" FAILED = 0 # If any request for any battery didn't succeed for any reason. SUCCESS = 1 # If all requests for all batteries succeed. IGNORED = 2 # If request was dispossessed by newer request with the same set # of batteries. ERROR = 3 # If any error happened. In this case error_message describes error. OUT_OF_BOUND = 4 # When Request.adjust_power=False and the requested power was","title":"Status"},{"location":"reference/frequenz/sdk/power_distribution/distribution_algorithm/","text":"frequenz.sdk.power_distribution.distribution_algorithm \u00a4 Power distribution algorithm. Classes \u00a4 frequenz.sdk.power_distribution.distribution_algorithm.DistributionAlgorithm \u00a4 Distribute power between many components. The purpose of this tool is to keep equal SoC level in the batteries. It takes total power that should be to be set for some subset of battery-inverter pairs. The total power is distributed between given battery-inverter pairs. Distribution is calculated based on data below: Battery current SoC. Battery upper and lower SoC bound. Battery capacity. Battery lower and upper power bound. Inverter lower and upper active power bound. Distribution algorithm \u00a4 Lets assume that: N - number of batteries power_w - power to distribute capacity[i] - capacity of i'th battery available_soc[i] - how much SoC remained to reach: SoC upper bound - if need to distribute power that charges inverters. SoC lower bound - if need to distribute power that discharges inverters. 0 - if SoC is outside SoC bounds. total_capacity - sum(c for c in capacity.values()) capacity_ratio[i] - capacity[i]/total_capacity We would like our distribution to meet the equation: distribution [ i ] = power_w * capacity_ratio [ i ] * x [ i ] where: sum ( capacity_ratio [ i ] * x [ i ] for i in range ( N )) == 1 Let y be our unknown, the proportion to discharge each battery would be (1): x [ i ] = available_soc [ i ] * y We can compute y from equation above (2): sum ( capacity_ratio [ i ] * x [ i ] for i in range ( N )) == 1 # => sum ( capacity_ratio [ i ] * available_soc [ i ] * y for i in range ( N )) == 1 # => y = 1 / sum ( capacity_ratio [ i ] * available_soc [ i ]) Now we know everything and we can compute distribution: distribution [ i ] = power_w * capacity_ratio [ i ] * x [ i ] # from (1) distribution [ i ] = \\ power_w * capacity_ratio [ i ] * available_soc [ i ] * y # from (2) distribution [ i ] = power_w * capacity_ratio [ i ] * available_soc [ i ] * \\ 1 / sum ( capacity_ratio [ i ] * available_soc [ i ]) Let: battery_availability_ratio [ i ] = capacity_ratio [ i ] * available_soc [ i ] total_battery_availability_ratio = sum ( battery_availability_ratio ) Then: distribution [ i ] = power_w * battery_availability_ratio [ i ] \\ / total_battery_availability_ratio Source code in frequenz/sdk/power_distribution/distribution_algorithm.py 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 class DistributionAlgorithm : r \"\"\"Distribute power between many components. The purpose of this tool is to keep equal SoC level in the batteries. It takes total power that should be to be set for some subset of battery-inverter pairs. The total power is distributed between given battery-inverter pairs. Distribution is calculated based on data below: * Battery current SoC. * Battery upper and lower SoC bound. * Battery capacity. * Battery lower and upper power bound. * Inverter lower and upper active power bound. # Distribution algorithm Lets assume that: * `N` - number of batteries * `power_w` - power to distribute * `capacity[i]` - capacity of i'th battery * `available_soc[i]` - how much SoC remained to reach: * SoC upper bound - if need to distribute power that charges inverters. * SoC lower bound - if need to distribute power that discharges inverters. * `0` - if SoC is outside SoC bounds. * `total_capacity` - `sum(c for c in capacity.values())` * `capacity_ratio[i]` - `capacity[i]/total_capacity` We would like our distribution to meet the equation: ``` python distribution[i] = power_w * capacity_ratio[i] * x[i] ``` where: ``` python sum(capacity_ratio[i] * x[i] for i in range(N)) == 1 ``` Let `y` be our unknown, the proportion to discharge each battery would be (1): ``` python x[i] = available_soc[i]*y ``` We can compute `y` from equation above (2): ``` python sum(capacity_ratio[i] * x[i] for i in range(N)) == 1 # => sum(capacity_ratio[i] * available_soc[i] * y for i in range(N)) == 1 # => y = 1 / sum(capacity_ratio[i] * available_soc[i]) ``` Now we know everything and we can compute distribution: ``` python distribution[i] = power_w * capacity_ratio[i] * x[i] # from (1) distribution[i] = \\ power_w * capacity_ratio[i] * available_soc[i] * y # from (2) distribution[i] = power_w * capacity_ratio[i] * available_soc[i] * \\ 1/sum(capacity_ratio[i] * available_soc[i]) ``` Let: ``` python battery_availability_ratio[i] = capacity_ratio[i] * available_soc[i] total_battery_availability_ratio = sum(battery_availability_ratio) ``` Then: ``` python distribution[i] = power_w * battery_availability_ratio[i] \\ / total_battery_availability_ratio ``` \"\"\" def __init__ ( self , distributor_exponent : float = 1 ) -> None : \"\"\"Create distribution algorithm instance. Args: distributor_exponent: How fast the batteries should strive to the equal SoC level. Should be float >= 0. Defaults=1. For example for distributor_exponent equal: * 1 - means that proportion will be linear from SoC. * 2 - means proportion would be like squared from SoC * 3 - means proportion would be like x^3 from SoC. Example: Lets say we have two batteries `Bat1` and `Bat2`. All parameters except SoC are equal. SoC bounds for each battery is `lower = 20`, `upper = 80`. # Example 1 Let: * `Bat1.soc = 70` and `Bat2.soc = 50`. * `Bat1.available_soc = 10`, `Bat2.available_soc = 30` * `Bat1.available_soc / Bat2.available_soc = 3` We need to distribute 8000W. If `distribution_exponent` is: * `0`: distribution for each battery will be the equal. ``` python Bat1.distribution = 4000; Bat2.distribution = 4000 ``` * `1`: then `Bat2` will have 3x more power assigned then `Bat1`. ``` python 10 * x + 30 * x = 8000 x = 200 Bat1.distribution = 2000; Bat2.distribution = 6000 ``` * `2`: then `Bat2` will have 9x more power assigned then `Bat1`. ``` python 10^2 * x + 30^2 * x = 8000 x = 80 Bat1.distribution = 800; Bat2.distribution = 7200 ``` * `3`: then `Bat2` will have 27x more power assigned then `Bat1`. ``` python 10^3 * x + 30^3 * x = 8000 x = 0,285714286 Bat1.distribution = 285; Bat2.distribution = 7715 ``` # Example 2 Let: * `Bat1.soc = 50` and `Bat2.soc = 20`. * `Bat1.available_soc = 30`, `Bat2.available_soc = 60` * `Bat1.available_soc / Bat2.available_soc = 2` We need to distribute 900W. If `distribution_exponent` is: * `0`: distribution for each battery will be the same. ``` python Bat1.distribution = 4500; Bat2.distribution = 450 ``` * `1`: then `Bat2` will have 2x more power assigned then `Bat1`. ``` python 30 * x + 60 * x = 900 x = 100 Bat1.distribution = 300; Bat2.distribution = 600 ``` * `2`: then `Bat2` will have 4x more power assigned then `Bat1`. ``` python 30^2 * x + 60^2 * x = 900 x = 0.2 Bat1.distribution = 180; Bat2.distribution = 720 ``` * `3`: then `Bat2` will have 8x more power assigned then `Bat1`. ``` python 30^3 * x + 60^3 * x = 900 x = 0,003703704 Bat1.distribution = 100; Bat2.distribution = 800 ``` # Example 3 Let: * `Bat1.soc = 44` and `Bat2.soc = 64`. * `Bat1.available_soc = 36 (80 - 44)`, `Bat2.available_soc = 16 (80 - 64)` We need to distribute 900W. If `distribution_exponent` is: * `0`: distribution for each battery will be the equal. ``` python Bat1.distribution = 450; Bat2.distribution = 450 ``` * `0.5`: then `Bat2` will have 6/4x more power assigned then `Bat1`. ``` python sqrt(36) * x + sqrt(16) * x = 900 x = 100 Bat1.distribution = 600; Bat2.distribution = 400 ``` Raises: ValueError: If distributor_exponent < 0 \"\"\" super () . __init__ () if distributor_exponent < 0 : raise ValueError ( \"Distribution factor should be float >= 0.\" ) self . _distributor_exponent : float = distributor_exponent def _total_capacity ( self , components : List [ InvBatPair ]) -> float : \"\"\"Sum capacity between all batteries in the components list. Args: components: list of the components Raises: ValueError: If total capacity is 0. Returns: Sum of all batteries capacity in the components list. \"\"\" total_capacity : float = sum ( bat . capacity for bat , _ in components ) if total_capacity == 0.0 : msg = \"All batteries have capacity 0.\" _logger . error ( msg ) raise ValueError ( msg ) return total_capacity def _compute_battery_availability_ratio ( self , components : List [ InvBatPair ], available_soc : Dict [ int , float ] ) -> Tuple [ List [ Tuple [ InvBatPair , float ]], float ]: r \"\"\"Compute battery ratio and the total sum of all of them. battery_availability_ratio = capacity_ratio[i] * available_soc[i] Where: capacity_ratio[i] = components[i].battery.capacity \\ / sum(battery.capacity for battery, _ in components) Args: components: list of the components available_soc: How much SoC remained to reach * SoC upper bound - if need to distribute consumption power * SoC lower bound - if need to distribute supply power Returns: Tuple where first argument is battery availability ratio for each battery-inverter pair. The list is sorted by ratio in descending order. The second element of the tuple is total sum of all battery ratios in the list. \"\"\" total_capacity = self . _total_capacity ( components ) battery_availability_ratio : List [ Tuple [ InvBatPair , float ]] = [] total_battery_availability_ratio : float = 0.0 for pair in components : battery = pair [ 0 ] capacity_ratio = battery . capacity / total_capacity soc_factor = pow ( available_soc [ battery . component_id ], self . _distributor_exponent ) ratio = capacity_ratio * soc_factor battery_availability_ratio . append (( pair , ratio )) total_battery_availability_ratio += ratio battery_availability_ratio . sort ( key = lambda item : item [ 1 ], reverse = True ) return battery_availability_ratio , total_battery_availability_ratio def _distribute_power ( self , components : List [ InvBatPair ], power_w : int , available_soc : Dict [ int , float ], upper_bounds : Dict [ int , int ], ) -> DistributionResult : # pylint: disable=too-many-locals \"\"\"Distribute power between given components. After this method power should be distributed between batteries in a way that equalize SoC between batteries. Args: components: list of components. power_w: power to distribute available_soc: how much SoC remained to reach: * SoC upper bound - if need to distribute consumption power * SoC lower bound - if need to distribute supply power upper_bounds: Min between upper bound of each pair in the components list: * supply upper bound - if need to distribute consumption power * consumption lower bound - if need to distribute supply power Returns: Distribution result. \"\"\" ( battery_availability_ratio , sum_ratio , ) = self . _compute_battery_availability_ratio ( components , available_soc ) distribution : Dict [ int , int ] = {} # sum_ratio == 0 means that all batteries are fully charged / discharged if sum_ratio == 0.0 : distribution = { inverter . component_id : 0 for _ , inverter in components } return DistributionResult ( distribution , power_w ) distributed_power = 0 power_to_distribute : int = power_w used_ratio : float = 0.0 ratio = sum_ratio for pair , battery_ratio in battery_availability_ratio : inverter = pair [ 1 ] # ratio = 0, means all remaining batteries reach max SoC lvl or have no # capacity if ratio == 0.0 : distribution [ inverter . component_id ] = 0 continue distribution [ inverter . component_id ] = floor ( power_to_distribute * battery_ratio / ratio ) used_ratio += battery_ratio # If the power allocated for that inverter is out of bound, # then we need to distribute more power over all remaining batteries. upper_bound = upper_bounds [ inverter . component_id ] if distribution [ inverter . component_id ] > upper_bound : distribution [ inverter . component_id ] = upper_bound distributed_power += upper_bound # Distribute only the remaining power. power_to_distribute = power_w - distributed_power # Distribute between remaining batteries ratio = sum_ratio - used_ratio else : distributed_power += distribution [ inverter . component_id ] return DistributionResult ( distribution , power_w - distributed_power ) def _greedy_distribute_remaining_power ( self , distribution : Dict [ int , int ], upper_bounds : Dict [ int , int ], remaining_power : int , ) -> DistributionResult : \"\"\"Add remaining power greedily to the given distribution. Distribution for each inverter will not exceed its upper bound. Args: distribution: distribution upper_bounds: upper bounds inverter and adjacent battery in distribution. remaining_power: power to distribute Returns: Return the power for each inverter in given distribution. \"\"\" if remaining_power == 0 : return DistributionResult ( distribution , remaining_power ) new_distribution : Dict [ int , int ] = {} for inverter_id , power in distribution . items (): if remaining_power == 0 or power == 0 : new_distribution [ inverter_id ] = power else : remaining_power_capacity : int = upper_bounds [ inverter_id ] - power to_add = min ( remaining_power_capacity , remaining_power ) new_distribution [ inverter_id ] = power + to_add remaining_power -= to_add return DistributionResult ( new_distribution , remaining_power ) def distribute_power ( self , power : int , components : List [ InvBatPair ] ) -> DistributionResult : \"\"\"Distribute given power between given components. Args: power: Power to distribute components: InvBatPaired components data. Each pair should have data for battery and adjacent inverter. Returns: Distribution result \"\"\" if power >= 0 : return self . _distribute_consume_power ( power , components ) return self . _distribute_supply_power ( power , components ) def _distribute_consume_power ( self , power_w : int , components : List [ InvBatPair ] ) -> DistributionResult : \"\"\"Distribute power between the given components. Distribute power in a way that the SoC level between given components will: * stay on the same level, equal in all given components * will try to align himself to the same level. Args: power_w: power to distribute components: list of components between which the power should be distributed. Returns: Distribution result, batteries with no SoC and capacity won't be used. \"\"\" # If SoC exceeded bound then remaining SoC should be 0. # Otherwise algorithm would try to supply power from that battery # in order to keep equal SoC level. available_soc : Dict [ int , float ] = {} for battery , _ in components : available_soc [ battery . component_id ] = max ( 0.0 , battery . soc_upper_bound - battery . soc ) bounds : Dict [ int , int ] = {} for battery , inverter in components : # We can supply/consume with int only inverter_bound = inverter . active_power_upper_bound battery_bound = battery . power_upper_bound bounds [ inverter . component_id ] = floor ( min ( inverter_bound , battery_bound )) result : DistributionResult = self . _distribute_power ( components , power_w , available_soc , bounds ) return self . _greedy_distribute_remaining_power ( result . distribution , bounds , result . remaining_power ) def _distribute_supply_power ( self , power_w : int , components : List [ InvBatPair ] ) -> DistributionResult : \"\"\"Distribute power between the given components. Distribute power in a way that the SoC level between given components will: * stay on the same level, equal in all given components * will try to align himself to the same level. Args: power_w: power to distribute components: list of components between which the power should be distributed. Returns: Distribution result. \"\"\" available_soc : Dict [ int , float ] = {} for battery , _ in components : available_soc [ battery . component_id ] = max ( 0.0 , battery . soc - battery . soc_lower_bound ) bounds : Dict [ int , int ] = {} for battery , inverter in components : # We can consume with int only inverter_bound = inverter . active_power_lower_bound battery_bound = battery . power_lower_bound bounds [ inverter . component_id ] = - 1 * ceil ( max ( inverter_bound , battery_bound ) ) result : DistributionResult = self . _distribute_power ( components , - 1 * power_w , available_soc , bounds ) result = self . _greedy_distribute_remaining_power ( result . distribution , bounds , result . remaining_power ) for inverter_id in result . distribution . keys (): result . distribution [ inverter_id ] *= - 1 result . remaining_power *= - 1 return result Functions \u00a4 __init__ ( distributor_exponent = 1 ) \u00a4 Create distribution algorithm instance. PARAMETER DESCRIPTION distributor_exponent How fast the batteries should strive to the equal SoC level. Should be float >= 0. Defaults=1. For example for distributor_exponent equal: * 1 - means that proportion will be linear from SoC. * 2 - means proportion would be like squared from SoC * 3 - means proportion would be like x^3 from SoC. TYPE: float DEFAULT: 1 Example Lets say we have two batteries Bat1 and Bat2 . All parameters except SoC are equal. SoC bounds for each battery is lower = 20 , upper = 80 . Example 1 \u00a4 Let: Bat1.soc = 70 and Bat2.soc = 50 . Bat1.available_soc = 10 , Bat2.available_soc = 30 Bat1.available_soc / Bat2.available_soc = 3 We need to distribute 8000W. If distribution_exponent is: 0 : distribution for each battery will be the equal. Bat1 . distribution = 4000 ; Bat2 . distribution = 4000 1 : then Bat2 will have 3x more power assigned then Bat1 . 10 * x + 30 * x = 8000 x = 200 Bat1 . distribution = 2000 ; Bat2 . distribution = 6000 2 : then Bat2 will have 9x more power assigned then Bat1 . 10 ^ 2 * x + 30 ^ 2 * x = 8000 x = 80 Bat1 . distribution = 800 ; Bat2 . distribution = 7200 3 : then Bat2 will have 27x more power assigned then Bat1 . 10 ^ 3 * x + 30 ^ 3 * x = 8000 x = 0 , 285714286 Bat1 . distribution = 285 ; Bat2 . distribution = 7715 Example 2 \u00a4 Let: Bat1.soc = 50 and Bat2.soc = 20 . Bat1.available_soc = 30 , Bat2.available_soc = 60 Bat1.available_soc / Bat2.available_soc = 2 We need to distribute 900W. If distribution_exponent is: 0 : distribution for each battery will be the same. Bat1 . distribution = 4500 ; Bat2 . distribution = 450 1 : then Bat2 will have 2x more power assigned then Bat1 . 30 * x + 60 * x = 900 x = 100 Bat1 . distribution = 300 ; Bat2 . distribution = 600 2 : then Bat2 will have 4x more power assigned then Bat1 . 30 ^ 2 * x + 60 ^ 2 * x = 900 x = 0.2 Bat1 . distribution = 180 ; Bat2 . distribution = 720 3 : then Bat2 will have 8x more power assigned then Bat1 . 30 ^ 3 * x + 60 ^ 3 * x = 900 x = 0 , 003703704 Bat1 . distribution = 100 ; Bat2 . distribution = 800 Example 3 \u00a4 Let: Bat1.soc = 44 and Bat2.soc = 64 . Bat1.available_soc = 36 (80 - 44) , Bat2.available_soc = 16 (80 - 64) We need to distribute 900W. If distribution_exponent is: 0 : distribution for each battery will be the equal. Bat1 . distribution = 450 ; Bat2 . distribution = 450 0.5 : then Bat2 will have 6/4x more power assigned then Bat1 . sqrt ( 36 ) * x + sqrt ( 16 ) * x = 900 x = 100 Bat1 . distribution = 600 ; Bat2 . distribution = 400 RAISES DESCRIPTION ValueError If distributor_exponent < 0 Source code in frequenz/sdk/power_distribution/distribution_algorithm.py 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 def __init__ ( self , distributor_exponent : float = 1 ) -> None : \"\"\"Create distribution algorithm instance. Args: distributor_exponent: How fast the batteries should strive to the equal SoC level. Should be float >= 0. Defaults=1. For example for distributor_exponent equal: * 1 - means that proportion will be linear from SoC. * 2 - means proportion would be like squared from SoC * 3 - means proportion would be like x^3 from SoC. Example: Lets say we have two batteries `Bat1` and `Bat2`. All parameters except SoC are equal. SoC bounds for each battery is `lower = 20`, `upper = 80`. # Example 1 Let: * `Bat1.soc = 70` and `Bat2.soc = 50`. * `Bat1.available_soc = 10`, `Bat2.available_soc = 30` * `Bat1.available_soc / Bat2.available_soc = 3` We need to distribute 8000W. If `distribution_exponent` is: * `0`: distribution for each battery will be the equal. ``` python Bat1.distribution = 4000; Bat2.distribution = 4000 ``` * `1`: then `Bat2` will have 3x more power assigned then `Bat1`. ``` python 10 * x + 30 * x = 8000 x = 200 Bat1.distribution = 2000; Bat2.distribution = 6000 ``` * `2`: then `Bat2` will have 9x more power assigned then `Bat1`. ``` python 10^2 * x + 30^2 * x = 8000 x = 80 Bat1.distribution = 800; Bat2.distribution = 7200 ``` * `3`: then `Bat2` will have 27x more power assigned then `Bat1`. ``` python 10^3 * x + 30^3 * x = 8000 x = 0,285714286 Bat1.distribution = 285; Bat2.distribution = 7715 ``` # Example 2 Let: * `Bat1.soc = 50` and `Bat2.soc = 20`. * `Bat1.available_soc = 30`, `Bat2.available_soc = 60` * `Bat1.available_soc / Bat2.available_soc = 2` We need to distribute 900W. If `distribution_exponent` is: * `0`: distribution for each battery will be the same. ``` python Bat1.distribution = 4500; Bat2.distribution = 450 ``` * `1`: then `Bat2` will have 2x more power assigned then `Bat1`. ``` python 30 * x + 60 * x = 900 x = 100 Bat1.distribution = 300; Bat2.distribution = 600 ``` * `2`: then `Bat2` will have 4x more power assigned then `Bat1`. ``` python 30^2 * x + 60^2 * x = 900 x = 0.2 Bat1.distribution = 180; Bat2.distribution = 720 ``` * `3`: then `Bat2` will have 8x more power assigned then `Bat1`. ``` python 30^3 * x + 60^3 * x = 900 x = 0,003703704 Bat1.distribution = 100; Bat2.distribution = 800 ``` # Example 3 Let: * `Bat1.soc = 44` and `Bat2.soc = 64`. * `Bat1.available_soc = 36 (80 - 44)`, `Bat2.available_soc = 16 (80 - 64)` We need to distribute 900W. If `distribution_exponent` is: * `0`: distribution for each battery will be the equal. ``` python Bat1.distribution = 450; Bat2.distribution = 450 ``` * `0.5`: then `Bat2` will have 6/4x more power assigned then `Bat1`. ``` python sqrt(36) * x + sqrt(16) * x = 900 x = 100 Bat1.distribution = 600; Bat2.distribution = 400 ``` Raises: ValueError: If distributor_exponent < 0 \"\"\" super () . __init__ () if distributor_exponent < 0 : raise ValueError ( \"Distribution factor should be float >= 0.\" ) self . _distributor_exponent : float = distributor_exponent distribute_power ( power , components ) \u00a4 Distribute given power between given components. PARAMETER DESCRIPTION power Power to distribute TYPE: int components InvBatPaired components data. Each pair should have data for battery and adjacent inverter. TYPE: List [ InvBatPair ] RETURNS DESCRIPTION DistributionResult Distribution result Source code in frequenz/sdk/power_distribution/distribution_algorithm.py 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 def distribute_power ( self , power : int , components : List [ InvBatPair ] ) -> DistributionResult : \"\"\"Distribute given power between given components. Args: power: Power to distribute components: InvBatPaired components data. Each pair should have data for battery and adjacent inverter. Returns: Distribution result \"\"\" if power >= 0 : return self . _distribute_consume_power ( power , components ) return self . _distribute_supply_power ( power , components ) frequenz.sdk.power_distribution.distribution_algorithm.DistributionResult dataclass \u00a4 Distribution result. PARAMETER DESCRIPTION distribution power to be set for each inverter. Key is inverter id, value is power that should be set for that inverter. TYPE: Dict [ int , int ] remaining_power Power which could not be distributed, because of bounds. TYPE: int Source code in frequenz/sdk/power_distribution/distribution_algorithm.py 16 17 18 19 20 21 22 23 24 25 26 27 @dataclass class DistributionResult : \"\"\"Distribution result. Args: distribution: power to be set for each inverter. Key is inverter id, value is power that should be set for that inverter. remaining_power: Power which could not be distributed, because of bounds. \"\"\" distribution : Dict [ int , int ] remaining_power : int","title":"distribution_algorithm"},{"location":"reference/frequenz/sdk/power_distribution/distribution_algorithm/#frequenz.sdk.power_distribution.distribution_algorithm","text":"Power distribution algorithm.","title":"distribution_algorithm"},{"location":"reference/frequenz/sdk/power_distribution/distribution_algorithm/#frequenz.sdk.power_distribution.distribution_algorithm-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/power_distribution/distribution_algorithm/#frequenz.sdk.power_distribution.distribution_algorithm.DistributionAlgorithm","text":"Distribute power between many components. The purpose of this tool is to keep equal SoC level in the batteries. It takes total power that should be to be set for some subset of battery-inverter pairs. The total power is distributed between given battery-inverter pairs. Distribution is calculated based on data below: Battery current SoC. Battery upper and lower SoC bound. Battery capacity. Battery lower and upper power bound. Inverter lower and upper active power bound.","title":"DistributionAlgorithm"},{"location":"reference/frequenz/sdk/power_distribution/distribution_algorithm/#frequenz.sdk.power_distribution.distribution_algorithm.DistributionAlgorithm--distribution-algorithm","text":"Lets assume that: N - number of batteries power_w - power to distribute capacity[i] - capacity of i'th battery available_soc[i] - how much SoC remained to reach: SoC upper bound - if need to distribute power that charges inverters. SoC lower bound - if need to distribute power that discharges inverters. 0 - if SoC is outside SoC bounds. total_capacity - sum(c for c in capacity.values()) capacity_ratio[i] - capacity[i]/total_capacity We would like our distribution to meet the equation: distribution [ i ] = power_w * capacity_ratio [ i ] * x [ i ] where: sum ( capacity_ratio [ i ] * x [ i ] for i in range ( N )) == 1 Let y be our unknown, the proportion to discharge each battery would be (1): x [ i ] = available_soc [ i ] * y We can compute y from equation above (2): sum ( capacity_ratio [ i ] * x [ i ] for i in range ( N )) == 1 # => sum ( capacity_ratio [ i ] * available_soc [ i ] * y for i in range ( N )) == 1 # => y = 1 / sum ( capacity_ratio [ i ] * available_soc [ i ]) Now we know everything and we can compute distribution: distribution [ i ] = power_w * capacity_ratio [ i ] * x [ i ] # from (1) distribution [ i ] = \\ power_w * capacity_ratio [ i ] * available_soc [ i ] * y # from (2) distribution [ i ] = power_w * capacity_ratio [ i ] * available_soc [ i ] * \\ 1 / sum ( capacity_ratio [ i ] * available_soc [ i ]) Let: battery_availability_ratio [ i ] = capacity_ratio [ i ] * available_soc [ i ] total_battery_availability_ratio = sum ( battery_availability_ratio ) Then: distribution [ i ] = power_w * battery_availability_ratio [ i ] \\ / total_battery_availability_ratio Source code in frequenz/sdk/power_distribution/distribution_algorithm.py 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 class DistributionAlgorithm : r \"\"\"Distribute power between many components. The purpose of this tool is to keep equal SoC level in the batteries. It takes total power that should be to be set for some subset of battery-inverter pairs. The total power is distributed between given battery-inverter pairs. Distribution is calculated based on data below: * Battery current SoC. * Battery upper and lower SoC bound. * Battery capacity. * Battery lower and upper power bound. * Inverter lower and upper active power bound. # Distribution algorithm Lets assume that: * `N` - number of batteries * `power_w` - power to distribute * `capacity[i]` - capacity of i'th battery * `available_soc[i]` - how much SoC remained to reach: * SoC upper bound - if need to distribute power that charges inverters. * SoC lower bound - if need to distribute power that discharges inverters. * `0` - if SoC is outside SoC bounds. * `total_capacity` - `sum(c for c in capacity.values())` * `capacity_ratio[i]` - `capacity[i]/total_capacity` We would like our distribution to meet the equation: ``` python distribution[i] = power_w * capacity_ratio[i] * x[i] ``` where: ``` python sum(capacity_ratio[i] * x[i] for i in range(N)) == 1 ``` Let `y` be our unknown, the proportion to discharge each battery would be (1): ``` python x[i] = available_soc[i]*y ``` We can compute `y` from equation above (2): ``` python sum(capacity_ratio[i] * x[i] for i in range(N)) == 1 # => sum(capacity_ratio[i] * available_soc[i] * y for i in range(N)) == 1 # => y = 1 / sum(capacity_ratio[i] * available_soc[i]) ``` Now we know everything and we can compute distribution: ``` python distribution[i] = power_w * capacity_ratio[i] * x[i] # from (1) distribution[i] = \\ power_w * capacity_ratio[i] * available_soc[i] * y # from (2) distribution[i] = power_w * capacity_ratio[i] * available_soc[i] * \\ 1/sum(capacity_ratio[i] * available_soc[i]) ``` Let: ``` python battery_availability_ratio[i] = capacity_ratio[i] * available_soc[i] total_battery_availability_ratio = sum(battery_availability_ratio) ``` Then: ``` python distribution[i] = power_w * battery_availability_ratio[i] \\ / total_battery_availability_ratio ``` \"\"\" def __init__ ( self , distributor_exponent : float = 1 ) -> None : \"\"\"Create distribution algorithm instance. Args: distributor_exponent: How fast the batteries should strive to the equal SoC level. Should be float >= 0. Defaults=1. For example for distributor_exponent equal: * 1 - means that proportion will be linear from SoC. * 2 - means proportion would be like squared from SoC * 3 - means proportion would be like x^3 from SoC. Example: Lets say we have two batteries `Bat1` and `Bat2`. All parameters except SoC are equal. SoC bounds for each battery is `lower = 20`, `upper = 80`. # Example 1 Let: * `Bat1.soc = 70` and `Bat2.soc = 50`. * `Bat1.available_soc = 10`, `Bat2.available_soc = 30` * `Bat1.available_soc / Bat2.available_soc = 3` We need to distribute 8000W. If `distribution_exponent` is: * `0`: distribution for each battery will be the equal. ``` python Bat1.distribution = 4000; Bat2.distribution = 4000 ``` * `1`: then `Bat2` will have 3x more power assigned then `Bat1`. ``` python 10 * x + 30 * x = 8000 x = 200 Bat1.distribution = 2000; Bat2.distribution = 6000 ``` * `2`: then `Bat2` will have 9x more power assigned then `Bat1`. ``` python 10^2 * x + 30^2 * x = 8000 x = 80 Bat1.distribution = 800; Bat2.distribution = 7200 ``` * `3`: then `Bat2` will have 27x more power assigned then `Bat1`. ``` python 10^3 * x + 30^3 * x = 8000 x = 0,285714286 Bat1.distribution = 285; Bat2.distribution = 7715 ``` # Example 2 Let: * `Bat1.soc = 50` and `Bat2.soc = 20`. * `Bat1.available_soc = 30`, `Bat2.available_soc = 60` * `Bat1.available_soc / Bat2.available_soc = 2` We need to distribute 900W. If `distribution_exponent` is: * `0`: distribution for each battery will be the same. ``` python Bat1.distribution = 4500; Bat2.distribution = 450 ``` * `1`: then `Bat2` will have 2x more power assigned then `Bat1`. ``` python 30 * x + 60 * x = 900 x = 100 Bat1.distribution = 300; Bat2.distribution = 600 ``` * `2`: then `Bat2` will have 4x more power assigned then `Bat1`. ``` python 30^2 * x + 60^2 * x = 900 x = 0.2 Bat1.distribution = 180; Bat2.distribution = 720 ``` * `3`: then `Bat2` will have 8x more power assigned then `Bat1`. ``` python 30^3 * x + 60^3 * x = 900 x = 0,003703704 Bat1.distribution = 100; Bat2.distribution = 800 ``` # Example 3 Let: * `Bat1.soc = 44` and `Bat2.soc = 64`. * `Bat1.available_soc = 36 (80 - 44)`, `Bat2.available_soc = 16 (80 - 64)` We need to distribute 900W. If `distribution_exponent` is: * `0`: distribution for each battery will be the equal. ``` python Bat1.distribution = 450; Bat2.distribution = 450 ``` * `0.5`: then `Bat2` will have 6/4x more power assigned then `Bat1`. ``` python sqrt(36) * x + sqrt(16) * x = 900 x = 100 Bat1.distribution = 600; Bat2.distribution = 400 ``` Raises: ValueError: If distributor_exponent < 0 \"\"\" super () . __init__ () if distributor_exponent < 0 : raise ValueError ( \"Distribution factor should be float >= 0.\" ) self . _distributor_exponent : float = distributor_exponent def _total_capacity ( self , components : List [ InvBatPair ]) -> float : \"\"\"Sum capacity between all batteries in the components list. Args: components: list of the components Raises: ValueError: If total capacity is 0. Returns: Sum of all batteries capacity in the components list. \"\"\" total_capacity : float = sum ( bat . capacity for bat , _ in components ) if total_capacity == 0.0 : msg = \"All batteries have capacity 0.\" _logger . error ( msg ) raise ValueError ( msg ) return total_capacity def _compute_battery_availability_ratio ( self , components : List [ InvBatPair ], available_soc : Dict [ int , float ] ) -> Tuple [ List [ Tuple [ InvBatPair , float ]], float ]: r \"\"\"Compute battery ratio and the total sum of all of them. battery_availability_ratio = capacity_ratio[i] * available_soc[i] Where: capacity_ratio[i] = components[i].battery.capacity \\ / sum(battery.capacity for battery, _ in components) Args: components: list of the components available_soc: How much SoC remained to reach * SoC upper bound - if need to distribute consumption power * SoC lower bound - if need to distribute supply power Returns: Tuple where first argument is battery availability ratio for each battery-inverter pair. The list is sorted by ratio in descending order. The second element of the tuple is total sum of all battery ratios in the list. \"\"\" total_capacity = self . _total_capacity ( components ) battery_availability_ratio : List [ Tuple [ InvBatPair , float ]] = [] total_battery_availability_ratio : float = 0.0 for pair in components : battery = pair [ 0 ] capacity_ratio = battery . capacity / total_capacity soc_factor = pow ( available_soc [ battery . component_id ], self . _distributor_exponent ) ratio = capacity_ratio * soc_factor battery_availability_ratio . append (( pair , ratio )) total_battery_availability_ratio += ratio battery_availability_ratio . sort ( key = lambda item : item [ 1 ], reverse = True ) return battery_availability_ratio , total_battery_availability_ratio def _distribute_power ( self , components : List [ InvBatPair ], power_w : int , available_soc : Dict [ int , float ], upper_bounds : Dict [ int , int ], ) -> DistributionResult : # pylint: disable=too-many-locals \"\"\"Distribute power between given components. After this method power should be distributed between batteries in a way that equalize SoC between batteries. Args: components: list of components. power_w: power to distribute available_soc: how much SoC remained to reach: * SoC upper bound - if need to distribute consumption power * SoC lower bound - if need to distribute supply power upper_bounds: Min between upper bound of each pair in the components list: * supply upper bound - if need to distribute consumption power * consumption lower bound - if need to distribute supply power Returns: Distribution result. \"\"\" ( battery_availability_ratio , sum_ratio , ) = self . _compute_battery_availability_ratio ( components , available_soc ) distribution : Dict [ int , int ] = {} # sum_ratio == 0 means that all batteries are fully charged / discharged if sum_ratio == 0.0 : distribution = { inverter . component_id : 0 for _ , inverter in components } return DistributionResult ( distribution , power_w ) distributed_power = 0 power_to_distribute : int = power_w used_ratio : float = 0.0 ratio = sum_ratio for pair , battery_ratio in battery_availability_ratio : inverter = pair [ 1 ] # ratio = 0, means all remaining batteries reach max SoC lvl or have no # capacity if ratio == 0.0 : distribution [ inverter . component_id ] = 0 continue distribution [ inverter . component_id ] = floor ( power_to_distribute * battery_ratio / ratio ) used_ratio += battery_ratio # If the power allocated for that inverter is out of bound, # then we need to distribute more power over all remaining batteries. upper_bound = upper_bounds [ inverter . component_id ] if distribution [ inverter . component_id ] > upper_bound : distribution [ inverter . component_id ] = upper_bound distributed_power += upper_bound # Distribute only the remaining power. power_to_distribute = power_w - distributed_power # Distribute between remaining batteries ratio = sum_ratio - used_ratio else : distributed_power += distribution [ inverter . component_id ] return DistributionResult ( distribution , power_w - distributed_power ) def _greedy_distribute_remaining_power ( self , distribution : Dict [ int , int ], upper_bounds : Dict [ int , int ], remaining_power : int , ) -> DistributionResult : \"\"\"Add remaining power greedily to the given distribution. Distribution for each inverter will not exceed its upper bound. Args: distribution: distribution upper_bounds: upper bounds inverter and adjacent battery in distribution. remaining_power: power to distribute Returns: Return the power for each inverter in given distribution. \"\"\" if remaining_power == 0 : return DistributionResult ( distribution , remaining_power ) new_distribution : Dict [ int , int ] = {} for inverter_id , power in distribution . items (): if remaining_power == 0 or power == 0 : new_distribution [ inverter_id ] = power else : remaining_power_capacity : int = upper_bounds [ inverter_id ] - power to_add = min ( remaining_power_capacity , remaining_power ) new_distribution [ inverter_id ] = power + to_add remaining_power -= to_add return DistributionResult ( new_distribution , remaining_power ) def distribute_power ( self , power : int , components : List [ InvBatPair ] ) -> DistributionResult : \"\"\"Distribute given power between given components. Args: power: Power to distribute components: InvBatPaired components data. Each pair should have data for battery and adjacent inverter. Returns: Distribution result \"\"\" if power >= 0 : return self . _distribute_consume_power ( power , components ) return self . _distribute_supply_power ( power , components ) def _distribute_consume_power ( self , power_w : int , components : List [ InvBatPair ] ) -> DistributionResult : \"\"\"Distribute power between the given components. Distribute power in a way that the SoC level between given components will: * stay on the same level, equal in all given components * will try to align himself to the same level. Args: power_w: power to distribute components: list of components between which the power should be distributed. Returns: Distribution result, batteries with no SoC and capacity won't be used. \"\"\" # If SoC exceeded bound then remaining SoC should be 0. # Otherwise algorithm would try to supply power from that battery # in order to keep equal SoC level. available_soc : Dict [ int , float ] = {} for battery , _ in components : available_soc [ battery . component_id ] = max ( 0.0 , battery . soc_upper_bound - battery . soc ) bounds : Dict [ int , int ] = {} for battery , inverter in components : # We can supply/consume with int only inverter_bound = inverter . active_power_upper_bound battery_bound = battery . power_upper_bound bounds [ inverter . component_id ] = floor ( min ( inverter_bound , battery_bound )) result : DistributionResult = self . _distribute_power ( components , power_w , available_soc , bounds ) return self . _greedy_distribute_remaining_power ( result . distribution , bounds , result . remaining_power ) def _distribute_supply_power ( self , power_w : int , components : List [ InvBatPair ] ) -> DistributionResult : \"\"\"Distribute power between the given components. Distribute power in a way that the SoC level between given components will: * stay on the same level, equal in all given components * will try to align himself to the same level. Args: power_w: power to distribute components: list of components between which the power should be distributed. Returns: Distribution result. \"\"\" available_soc : Dict [ int , float ] = {} for battery , _ in components : available_soc [ battery . component_id ] = max ( 0.0 , battery . soc - battery . soc_lower_bound ) bounds : Dict [ int , int ] = {} for battery , inverter in components : # We can consume with int only inverter_bound = inverter . active_power_lower_bound battery_bound = battery . power_lower_bound bounds [ inverter . component_id ] = - 1 * ceil ( max ( inverter_bound , battery_bound ) ) result : DistributionResult = self . _distribute_power ( components , - 1 * power_w , available_soc , bounds ) result = self . _greedy_distribute_remaining_power ( result . distribution , bounds , result . remaining_power ) for inverter_id in result . distribution . keys (): result . distribution [ inverter_id ] *= - 1 result . remaining_power *= - 1 return result","title":"Distribution algorithm"},{"location":"reference/frequenz/sdk/power_distribution/distribution_algorithm/#frequenz.sdk.power_distribution.distribution_algorithm.DistributionAlgorithm-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/power_distribution/distribution_algorithm/#frequenz.sdk.power_distribution.distribution_algorithm.DistributionAlgorithm.__init__","text":"Create distribution algorithm instance. PARAMETER DESCRIPTION distributor_exponent How fast the batteries should strive to the equal SoC level. Should be float >= 0. Defaults=1. For example for distributor_exponent equal: * 1 - means that proportion will be linear from SoC. * 2 - means proportion would be like squared from SoC * 3 - means proportion would be like x^3 from SoC. TYPE: float DEFAULT: 1 Example Lets say we have two batteries Bat1 and Bat2 . All parameters except SoC are equal. SoC bounds for each battery is lower = 20 , upper = 80 .","title":"__init__()"},{"location":"reference/frequenz/sdk/power_distribution/distribution_algorithm/#frequenz.sdk.power_distribution.distribution_algorithm.DistributionAlgorithm.__init__--example-1","text":"Let: Bat1.soc = 70 and Bat2.soc = 50 . Bat1.available_soc = 10 , Bat2.available_soc = 30 Bat1.available_soc / Bat2.available_soc = 3 We need to distribute 8000W. If distribution_exponent is: 0 : distribution for each battery will be the equal. Bat1 . distribution = 4000 ; Bat2 . distribution = 4000 1 : then Bat2 will have 3x more power assigned then Bat1 . 10 * x + 30 * x = 8000 x = 200 Bat1 . distribution = 2000 ; Bat2 . distribution = 6000 2 : then Bat2 will have 9x more power assigned then Bat1 . 10 ^ 2 * x + 30 ^ 2 * x = 8000 x = 80 Bat1 . distribution = 800 ; Bat2 . distribution = 7200 3 : then Bat2 will have 27x more power assigned then Bat1 . 10 ^ 3 * x + 30 ^ 3 * x = 8000 x = 0 , 285714286 Bat1 . distribution = 285 ; Bat2 . distribution = 7715","title":"Example 1"},{"location":"reference/frequenz/sdk/power_distribution/distribution_algorithm/#frequenz.sdk.power_distribution.distribution_algorithm.DistributionAlgorithm.__init__--example-2","text":"Let: Bat1.soc = 50 and Bat2.soc = 20 . Bat1.available_soc = 30 , Bat2.available_soc = 60 Bat1.available_soc / Bat2.available_soc = 2 We need to distribute 900W. If distribution_exponent is: 0 : distribution for each battery will be the same. Bat1 . distribution = 4500 ; Bat2 . distribution = 450 1 : then Bat2 will have 2x more power assigned then Bat1 . 30 * x + 60 * x = 900 x = 100 Bat1 . distribution = 300 ; Bat2 . distribution = 600 2 : then Bat2 will have 4x more power assigned then Bat1 . 30 ^ 2 * x + 60 ^ 2 * x = 900 x = 0.2 Bat1 . distribution = 180 ; Bat2 . distribution = 720 3 : then Bat2 will have 8x more power assigned then Bat1 . 30 ^ 3 * x + 60 ^ 3 * x = 900 x = 0 , 003703704 Bat1 . distribution = 100 ; Bat2 . distribution = 800","title":"Example 2"},{"location":"reference/frequenz/sdk/power_distribution/distribution_algorithm/#frequenz.sdk.power_distribution.distribution_algorithm.DistributionAlgorithm.__init__--example-3","text":"Let: Bat1.soc = 44 and Bat2.soc = 64 . Bat1.available_soc = 36 (80 - 44) , Bat2.available_soc = 16 (80 - 64) We need to distribute 900W. If distribution_exponent is: 0 : distribution for each battery will be the equal. Bat1 . distribution = 450 ; Bat2 . distribution = 450 0.5 : then Bat2 will have 6/4x more power assigned then Bat1 . sqrt ( 36 ) * x + sqrt ( 16 ) * x = 900 x = 100 Bat1 . distribution = 600 ; Bat2 . distribution = 400 RAISES DESCRIPTION ValueError If distributor_exponent < 0 Source code in frequenz/sdk/power_distribution/distribution_algorithm.py 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 def __init__ ( self , distributor_exponent : float = 1 ) -> None : \"\"\"Create distribution algorithm instance. Args: distributor_exponent: How fast the batteries should strive to the equal SoC level. Should be float >= 0. Defaults=1. For example for distributor_exponent equal: * 1 - means that proportion will be linear from SoC. * 2 - means proportion would be like squared from SoC * 3 - means proportion would be like x^3 from SoC. Example: Lets say we have two batteries `Bat1` and `Bat2`. All parameters except SoC are equal. SoC bounds for each battery is `lower = 20`, `upper = 80`. # Example 1 Let: * `Bat1.soc = 70` and `Bat2.soc = 50`. * `Bat1.available_soc = 10`, `Bat2.available_soc = 30` * `Bat1.available_soc / Bat2.available_soc = 3` We need to distribute 8000W. If `distribution_exponent` is: * `0`: distribution for each battery will be the equal. ``` python Bat1.distribution = 4000; Bat2.distribution = 4000 ``` * `1`: then `Bat2` will have 3x more power assigned then `Bat1`. ``` python 10 * x + 30 * x = 8000 x = 200 Bat1.distribution = 2000; Bat2.distribution = 6000 ``` * `2`: then `Bat2` will have 9x more power assigned then `Bat1`. ``` python 10^2 * x + 30^2 * x = 8000 x = 80 Bat1.distribution = 800; Bat2.distribution = 7200 ``` * `3`: then `Bat2` will have 27x more power assigned then `Bat1`. ``` python 10^3 * x + 30^3 * x = 8000 x = 0,285714286 Bat1.distribution = 285; Bat2.distribution = 7715 ``` # Example 2 Let: * `Bat1.soc = 50` and `Bat2.soc = 20`. * `Bat1.available_soc = 30`, `Bat2.available_soc = 60` * `Bat1.available_soc / Bat2.available_soc = 2` We need to distribute 900W. If `distribution_exponent` is: * `0`: distribution for each battery will be the same. ``` python Bat1.distribution = 4500; Bat2.distribution = 450 ``` * `1`: then `Bat2` will have 2x more power assigned then `Bat1`. ``` python 30 * x + 60 * x = 900 x = 100 Bat1.distribution = 300; Bat2.distribution = 600 ``` * `2`: then `Bat2` will have 4x more power assigned then `Bat1`. ``` python 30^2 * x + 60^2 * x = 900 x = 0.2 Bat1.distribution = 180; Bat2.distribution = 720 ``` * `3`: then `Bat2` will have 8x more power assigned then `Bat1`. ``` python 30^3 * x + 60^3 * x = 900 x = 0,003703704 Bat1.distribution = 100; Bat2.distribution = 800 ``` # Example 3 Let: * `Bat1.soc = 44` and `Bat2.soc = 64`. * `Bat1.available_soc = 36 (80 - 44)`, `Bat2.available_soc = 16 (80 - 64)` We need to distribute 900W. If `distribution_exponent` is: * `0`: distribution for each battery will be the equal. ``` python Bat1.distribution = 450; Bat2.distribution = 450 ``` * `0.5`: then `Bat2` will have 6/4x more power assigned then `Bat1`. ``` python sqrt(36) * x + sqrt(16) * x = 900 x = 100 Bat1.distribution = 600; Bat2.distribution = 400 ``` Raises: ValueError: If distributor_exponent < 0 \"\"\" super () . __init__ () if distributor_exponent < 0 : raise ValueError ( \"Distribution factor should be float >= 0.\" ) self . _distributor_exponent : float = distributor_exponent","title":"Example 3"},{"location":"reference/frequenz/sdk/power_distribution/distribution_algorithm/#frequenz.sdk.power_distribution.distribution_algorithm.DistributionAlgorithm.distribute_power","text":"Distribute given power between given components. PARAMETER DESCRIPTION power Power to distribute TYPE: int components InvBatPaired components data. Each pair should have data for battery and adjacent inverter. TYPE: List [ InvBatPair ] RETURNS DESCRIPTION DistributionResult Distribution result Source code in frequenz/sdk/power_distribution/distribution_algorithm.py 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 def distribute_power ( self , power : int , components : List [ InvBatPair ] ) -> DistributionResult : \"\"\"Distribute given power between given components. Args: power: Power to distribute components: InvBatPaired components data. Each pair should have data for battery and adjacent inverter. Returns: Distribution result \"\"\" if power >= 0 : return self . _distribute_consume_power ( power , components ) return self . _distribute_supply_power ( power , components )","title":"distribute_power()"},{"location":"reference/frequenz/sdk/power_distribution/distribution_algorithm/#frequenz.sdk.power_distribution.distribution_algorithm.DistributionResult","text":"Distribution result. PARAMETER DESCRIPTION distribution power to be set for each inverter. Key is inverter id, value is power that should be set for that inverter. TYPE: Dict [ int , int ] remaining_power Power which could not be distributed, because of bounds. TYPE: int Source code in frequenz/sdk/power_distribution/distribution_algorithm.py 16 17 18 19 20 21 22 23 24 25 26 27 @dataclass class DistributionResult : \"\"\"Distribution result. Args: distribution: power to be set for each inverter. Key is inverter id, value is power that should be set for that inverter. remaining_power: Power which could not be distributed, because of bounds. \"\"\" distribution : Dict [ int , int ] remaining_power : int","title":"DistributionResult"},{"location":"reference/frequenz/sdk/power_distribution/power_distributor/","text":"frequenz.sdk.power_distribution.power_distributor \u00a4 Tool to distribute power between batteries. Purpose of this tool is to keep SoC level of each component at the equal level. Classes \u00a4 frequenz.sdk.power_distribution.power_distributor.PowerDistributor \u00a4 Tool to distribute power between batteries in microgrid. The purpose of this tool is to keep equal SoC level in the batteries. PowerDistributor can have many users. Each user should first register in order to get its id, channel for sending request, and channel for receiving response. It is recommended to wait for PowerDistributor output with timeout. Otherwise if the processing function fail then the response will never come. The timeout should be Result:request_timeout_sec + time for processing the request. Edge cases: * If there are 2 requests to be processed for the same subset of batteries, then only the latest request will be processed. Older request will be ignored. User with older request will get response with Result.Status.IGNORED. If there are 2 requests and their subset of batteries is different but they overlap (they have at least one common battery), then then both batteries will be processed. However it is not expected so the proper error log will be printed. Example import grpc.aio as grpcaio from frequenz.sdk.microgrid.graph import _MicrogridComponentGraph from frequenz.sdk.microgrid.component import ComponentCategory from frequenz.sdk.power_distribution import ( PowerDistributor , Request , Result , ) target = f \" { host } : { port } \" grpc_channel = grpcaio . insecure_channel ( target ) api = MicrogridGrpcClient ( grpc_channel , target ) graph = _MicrogridComponentGraph () await graph . refresh_from_api ( api ) batteries = graph . components ( component_category = { ComponentCategory . BATTERY }) batteries_ids = { c . component_id for c in batteries } channel = Bidirectional [ Request , Result ]( \"user1\" , \"power_distributor\" ) power_distributor = PowerDistributor ( mock_api , component_graph , { \"user1\" : channel . service_handle } ) client_handle = channel . client_handle # Set power 1200W to given batteries. request = Request ( power = 1200 , batteries = batteries_ids , request_timeout_sec = 10.0 ) await client_handle . send ( request ) # It is recommended to use timeout when waiting for the response! result : Result = await asyncio . wait_for ( client_handle . receive (), timeout = 10 ) if result . status == Result . Status . SUCCESS : print ( \"Command succeed\" ) elif result . status == Result . Status . FAILED : print ( f \"Some batteries failed, total failed power: { result . failed_power } \" ) elif result . status == Result . Status . IGNORED : print ( f \"Request was ignored, because of newer command\" ) elif result . status == Result . Status . ERROR : print ( f \"Request failed with error: { request . error_message } \" ) Source code in frequenz/sdk/power_distribution/power_distributor.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 @actor class PowerDistributor : # pylint: disable=too-many-instance-attributes \"\"\"Tool to distribute power between batteries in microgrid. The purpose of this tool is to keep equal SoC level in the batteries. PowerDistributor can have many users. Each user should first register in order to get its id, channel for sending request, and channel for receiving response. It is recommended to wait for PowerDistributor output with timeout. Otherwise if the processing function fail then the response will never come. The timeout should be Result:request_timeout_sec + time for processing the request. Edge cases: * If there are 2 requests to be processed for the same subset of batteries, then only the latest request will be processed. Older request will be ignored. User with older request will get response with Result.Status.IGNORED. * If there are 2 requests and their subset of batteries is different but they overlap (they have at least one common battery), then then both batteries will be processed. However it is not expected so the proper error log will be printed. Example: ``` python import grpc.aio as grpcaio from frequenz.sdk.microgrid.graph import _MicrogridComponentGraph from frequenz.sdk.microgrid.component import ComponentCategory from frequenz.sdk.power_distribution import ( PowerDistributor, Request, Result, ) target = f\"{host}:{port}\" grpc_channel = grpcaio.insecure_channel(target) api = MicrogridGrpcClient(grpc_channel, target) graph = _MicrogridComponentGraph() await graph.refresh_from_api(api) batteries = graph.components(component_category={ComponentCategory.BATTERY}) batteries_ids = {c.component_id for c in batteries} channel = Bidirectional[Request, Result](\"user1\", \"power_distributor\") power_distributor = PowerDistributor( mock_api, component_graph, {\"user1\": channel.service_handle} ) client_handle = channel.client_handle # Set power 1200W to given batteries. request = Request(power=1200, batteries=batteries_ids, request_timeout_sec=10.0) await client_handle.send(request) # It is recommended to use timeout when waiting for the response! result: Result = await asyncio.wait_for(client_handle.receive(), timeout=10) if result.status == Result.Status.SUCCESS: print(\"Command succeed\") elif result.status == Result.Status.FAILED: print( f\"Some batteries failed, total failed power: {result.failed_power}\") elif result.status == Result.Status.IGNORED: print(f\"Request was ignored, because of newer command\") elif result.status == Result.Status.ERROR: print(f\"Request failed with error: {request.error_message}\") ``` \"\"\" def __init__ ( self , microgrid_api : MicrogridApiClient , component_graph : ComponentGraph , users_channels : Dict [ str , Bidirectional . Handle [ Result , Request ]], wait_for_data_sec : float = 2 , ) -> None : \"\"\"Create class instance. Args: microgrid_api: api for sending the requests. component_graph: component graph of the given microgrid api. users_channels: BidirectionalHandle for each user. Key should be user id and value should be BidirectionalHandle. wait_for_data_sec: How long actor should wait before processing first request. It is a time needed to collect first components data. \"\"\" self . _api = microgrid_api self . _wait_for_data_sec = wait_for_data_sec # Max permitted time when the component should send any information. # After that timeout the component will be treated as not existing. # Formulas will put 0 in place of data from this components. # This will happen until component starts sending data. self . component_data_timeout_sec : float = 60.0 self . broken_component_timeout_sec : float = 30.0 self . power_distributor_exponent : float = 1.0 # distributor_exponent and timeout_sec should be get from ConfigManager self . distribution_algorithm = DistributionAlgorithm ( self . power_distributor_exponent ) self . _broken_components = BrokenComponents ( self . broken_component_timeout_sec ) self . _bat_inv_map , self . _inv_bat_map = self . _get_components_pairs ( component_graph ) self . _battery_receivers : Dict [ int , Peekable [ BatteryData ]] = {} self . _inverter_receivers : Dict [ int , Peekable [ InverterData ]] = {} # The components in different requests be for the same components, or for # completely different components. They should not overlap. # Otherwise the PowerDistributor has no way to decide what request is more # important. It will execute both. And later request will override the previous # one. # That is why the queue of maxsize = total number of batteries should be enough. self . _request_queue : asyncio . Queue [ Tuple [ Request , User ]] = asyncio . Queue ( maxsize = len ( self . _bat_inv_map ) ) self . _users_channels : Dict [ str , Bidirectional . Handle [ Result , Request ] ] = users_channels self . _create_users_tasks () self . _started = asyncio . Event () def _create_users_tasks ( self ) -> None : \"\"\"For each user create a task to wait for request.\"\"\" for user , handler in self . _users_channels . items (): asyncio . create_task ( self . _wait_for_request ( User ( user , handler ))) def get_upper_bound ( self , batteries : Set [ int ]) -> float : \"\"\"Get total upper bound of power to be set for given batteries. Note, output of that function doesn't guarantee that this bound will be the same when the request is processed. Args: batteries: List of batteries Returns: Upper bound for `set_power` operation. \"\"\" pairs_data : List [ InvBatPair ] = self . _get_components_data ( batteries ) return sum ( min ( battery . power_upper_bound , inverter . active_power_upper_bound ) for battery , inverter in pairs_data ) def get_lower_bound ( self , batteries : Set [ int ]) -> float : \"\"\"Get total lower bound of power to be set for given batteries. Note, output of that function doesn't guarantee that this bound will be the same when the request is processed. Args: batteries: List of batteries Returns: Lower bound for `set_power` operation. \"\"\" pairs_data : List [ InvBatPair ] = self . _get_components_data ( batteries ) return sum ( min ( battery . power_lower_bound , inverter . active_power_lower_bound ) for battery , inverter in pairs_data ) def _within_bounds ( self , request : Request ) -> bool : \"\"\"Check whether the requested power is withing the bounds. Args: request: request Returns: True if power is between the bounds, False otherwise. \"\"\" power = request . power lower_bound = self . get_lower_bound ( request . batteries ) return lower_bound <= power <= self . get_upper_bound ( request . batteries ) async def run ( self ) -> None : \"\"\"Run actor main function. It waits for new requests in task_queue and process it, and send `set_power` request with distributed power. The output of the `set_power` method is processed. Every battery and inverter that failed or didn't respond in time will be marked as broken for some time. \"\"\" await self . _create_channels () # Wait 2 seconds to get data from the channels created above. await asyncio . sleep ( self . _wait_for_data_sec ) self . _started . set () while True : request , user = await self . _request_queue . get () try : pairs_data : List [ InvBatPair ] = self . _get_components_data ( request . batteries ) except KeyError as err : await user . channel . send ( Result ( Result . Status . ERROR , request . power , 0 , str ( err )) ) continue if len ( pairs_data ) == 0 : error_msg = f \"No data for the given batteries { str ( request . batteries ) } \" await user . channel . send ( Result ( Result . Status . ERROR , request . power , 0 , str ( error_msg )) ) continue try : distribution = self . distribution_algorithm . distribute_power ( request . power , pairs_data ) except ValueError as err : error_msg = f \"Couldn't distribute power, error: { str ( err ) } \" await user . channel . send ( Result ( Result . Status . ERROR , request . power , 0 , error_msg ) ) continue distributed_power_value = request . power - distribution . remaining_power _logger . debug ( \" %s : Distributing power %d between the inverters %s \" , user . user_id , distributed_power_value , str ( distribution . distribution ), ) tasks = { inverter_id : asyncio . create_task ( self . _api . set_power ( inverter_id , power ) ) for inverter_id , power in distribution . distribution . items () } _ , pending = await asyncio . wait ( tasks . values (), timeout = request . request_timeout_sec , return_when = ALL_COMPLETED , ) await self . _cancel_tasks ( pending ) any_fail , failed_power = self . _parse_result ( tasks , distribution . distribution , request . request_timeout_sec ) status = Result . Status . FAILED if any_fail else Result . Status . SUCCESS await user . channel . send ( Result ( status , failed_power , distribution . remaining_power ) ) def _check_request ( self , request : Request ) -> Optional [ Result ]: \"\"\"Check whether the given request if correct. Args: request: request to check Returns: Result for the user if the request is wrong, None otherwise. \"\"\" for battery in request . batteries : if battery not in self . _battery_receivers : msg = ( f \"No battery { battery } , available batteries: \" f \" { list ( self . _battery_receivers . keys ()) } \" ) return Result ( Result . Status . ERROR , request . power , 0 , error_message = msg ) if not request . adjust_power and not self . _within_bounds ( request ): return Result ( Result . Status . OUT_OF_BOUND , request . power , 0 ) return None def _remove_duplicated_requests ( self , request : Request , user : User ) -> List [ asyncio . Task [ bool ]]: \"\"\"Remove duplicated requests from the queue. Remove old requests in which set of batteries are the same as in new request. If batteries in new request overlap with batteries in old request but are not equal, then log error and process both messages. Args: request: request to check user: User who sent the request. Returns: Tasks with result sent to the users which requests were duplicated. \"\"\" batteries = request . batteries good_requests : List [ Tuple [ Request , User ]] = [] to_ignore : List [ asyncio . Task [ bool ]] = [] while not self . _request_queue . empty (): prev_request , prev_user = self . _request_queue . get_nowait () # Generators seems to be the fastest if prev_request . batteries == batteries : task = asyncio . create_task ( prev_user . channel . send ( Result ( Result . Status . IGNORED , prev_request . power , 0 ) ) ) to_ignore . append ( task ) # Use generators as generators seems to be the fastest. elif any ( battery_id in prev_request . batteries for battery_id in batteries ): # If that happen PowerDistributor has no way to distinguish what # request is more important. This should not happen _logger . error ( \"Batteries in two requests overlap! Actor: %s requested %s \" \"and Actor: %s requested %s \" , user . user_id , str ( request ), prev_user . user_id , str ( prev_request ), ) good_requests . append (( prev_request , prev_user )) else : good_requests . append (( prev_request , prev_user )) for good_request in good_requests : self . _request_queue . put_nowait ( good_request ) return to_ignore async def _wait_for_request ( self , user : User ) -> None : \"\"\"Wait for the request from user. Check if request is correct. If request is not correct send ERROR response to the user. If request is correct, then add it to the main queue to be process. If main queue has request for the same subset of batteries, then remove older request, and send its user response with Result.Status.IGNORED. Only new request will re processed. If set of batteries are not the same but have common elements, then both batteries will be processed. Args: user: User that sends the requests. \"\"\" while True : request : Optional [ Request ] = await user . channel . receive () if request is None : _logger . info ( \"Send channel for user %s was closed. User will be unregistered.\" , user . user_id , ) self . _users_channels . pop ( user . user_id ) if len ( self . _users_channels ) == 0 : _logger . error ( \"No users in PowerDistributor!\" ) return # Wait for PowerDistributor to start. if not self . _started . is_set (): await self . _started . wait () # We should discover as fast as possible that request is wrong. check_result = self . _check_request ( request ) if check_result is not None : await user . channel . send ( check_result ) continue tasks = self . _remove_duplicated_requests ( request , user ) if self . _request_queue . full (): q_size = ( self . _request_queue . qsize (),) msg = ( f \"Request queue is full { q_size } , can't process this request. \" \"Consider increasing size of the queue.\" ) _logger . error ( msg ) await user . channel . send ( Result ( Result . Status . ERROR , request . power , 0 , msg ) ) else : self . _request_queue . put_nowait (( request , user )) await asyncio . gather ( * tasks ) def _get_components_pairs ( self , component_graph : ComponentGraph ) -> Tuple [ Dict [ int , int ], Dict [ int , int ]]: \"\"\"Create maps between battery and adjacent inverter. Args: component_graph: component graph Returns: Tuple where first element is map between battery and adjacent inverter, second element of the tuple is map between inverter and adjacent battery. \"\"\" bat_inv_map : Dict [ int , int ] = {} inv_bat_map : Dict [ int , int ] = {} batteries : Iterable [ Component ] = component_graph . components ( component_category = { ComponentCategory . BATTERY } ) for battery in batteries : inverters : List [ Component ] = [ component for component in component_graph . predecessors ( battery . component_id ) if component . category == ComponentCategory . INVERTER ] if len ( inverters ) == 0 : _logger . error ( \"No inverters for battery %d \" , battery . component_id ) continue if len ( inverters ) > 1 : _logger . error ( \"Battery %d has more then one inverter. It is not supported now.\" , battery . component_id , ) bat_inv_map [ battery . component_id ] = inverters [ 0 ] . component_id inv_bat_map [ inverters [ 0 ] . component_id ] = battery . component_id return bat_inv_map , inv_bat_map def _get_components_data ( self , batteries : Iterable [ int ]) -> List [ InvBatPair ]: \"\"\"Get data for the given batteries and adjacent inverters. Args: batteries: Batteries that needs data. Raises: KeyError: If any battery in the given list doesn't exists in microgrid. Returns: Pairs of battery and adjacent inverter data. \"\"\" pairs_data : List [ InvBatPair ] = [] for battery_id in batteries : if battery_id not in self . _battery_receivers : raise KeyError ( f \"No battery { battery_id } , \" f \"available batteries: { list ( self . _battery_receivers . keys ()) } \" ) inverter_id : int = self . _bat_inv_map [ battery_id ] if self . _broken_components . is_broken ( battery_id ) or self . _broken_components . is_broken ( inverter_id ): continue battery_data : Optional [ BatteryData ] = self . _battery_receivers [ battery_id ] . peek () if not self . _is_component_data_valid ( battery_id , battery_data ): continue inverter_data : Optional [ InverterData ] = self . _inverter_receivers [ inverter_id ] . peek () if not self . _is_component_data_valid ( inverter_id , inverter_data ): continue # None case already checked but mypy don't see that. if battery_data is not None and inverter_data is not None : pairs_data . append ( InvBatPair ( battery_data , inverter_data )) return pairs_data def _is_component_data_valid ( self , component_id : int , component_data : Union [ None , BatteryData , InverterData ] ) -> bool : \"\"\"Check whether the component data from microgrid are correct. Args: component_id: component id component_data: component data instance Returns: True if data are correct, false otherwise \"\"\" if component_data is None : _logger . warning ( \"No data from component %d .\" , component_id , ) return False now = datetime . now ( timezone . utc ) time_delta = now - component_data . timestamp if time_delta . total_seconds () > self . component_data_timeout_sec : _logger . warning ( \"Component %d data are stale. Last timestamp: %s , now: %s \" , component_id , str ( component_data . timestamp ), str ( now ), ) return False return True async def _create_channels ( self ) -> None : \"\"\"Create channels to get data of components in microgrid.\"\"\" for battery_id , inverter_id in self . _bat_inv_map . items (): bat_recv : Receiver [ BatteryData ] = await self . _api . battery_data ( battery_id ) self . _battery_receivers [ battery_id ] = bat_recv . into_peekable () inv_recv : Receiver [ InverterData ] = await self . _api . inverter_data ( inverter_id ) self . _inverter_receivers [ inverter_id ] = inv_recv . into_peekable () def _parse_result ( self , # type comment to quiet pylint and mypy `unused-import` error tasks , # type: Dict[int, asyncio.Task[Empty]] distribution : Dict [ int , int ], request_timeout_sec : float , ) -> Tuple [ bool , int ]: \"\"\"Parse result of `set_power` requests. Check if any task failed and why. If any task didn't success, then corresponding battery is marked as broken. Args: tasks: Dictionary where key is inverter id and value is task that set power for this inverter. Each tasks should be finished or cancelled. distribution: Dictionary where key is inverter id and value is how much power was set to the corresponding inverter. request_timeout_sec: timeout which has been used for request. Returns: Tuple where first element tells if any task didn't succeed, and the second element is total amount of power that failed. \"\"\" any_fail : bool = False failed_power : int = 0 for inverter_id , aws in tasks . items (): battery_id = self . _inv_bat_map [ inverter_id ] try : aws . result () except grpc . aio . AioRpcError as err : any_fail = True failed_power += distribution [ inverter_id ] if err . code () == grpc . StatusCode . OUT_OF_RANGE : _logger . debug ( \"Set power for battery %d failed, error %s \" , battery_id , str ( err ), ) else : _logger . warning ( \"Set power for battery %d failed, error %s . Mark it as broken.\" , battery_id , str ( err ), ) self . _broken_components . mark_as_broken ( battery_id ) except asyncio . exceptions . CancelledError : any_fail = True failed_power += distribution [ inverter_id ] _logger . warning ( \"Battery %d didn't respond in %f sec. Mark it as broken.\" , battery_id , request_timeout_sec , ) self . _broken_components . mark_as_broken ( battery_id ) return any_fail , failed_power async def _cancel_tasks ( self , tasks : Iterable [ asyncio . Task [ Any ]]) -> None : \"\"\"Cancel given asyncio tasks and wait for them. Args: tasks: tasks to cancel. \"\"\" for aws in tasks : aws . cancel () await asyncio . gather ( * tasks , return_exceptions = True ) Functions \u00a4 __init__ ( microgrid_api , component_graph , users_channels , wait_for_data_sec = 2 ) \u00a4 Create class instance. PARAMETER DESCRIPTION microgrid_api api for sending the requests. TYPE: MicrogridApiClient component_graph component graph of the given microgrid api. TYPE: ComponentGraph users_channels BidirectionalHandle for each user. Key should be user id and value should be BidirectionalHandle. TYPE: Dict [ str , Bidirectional . Handle [ Result , Request ]] wait_for_data_sec How long actor should wait before processing first request. It is a time needed to collect first components data. TYPE: float DEFAULT: 2 Source code in frequenz/sdk/power_distribution/power_distributor.py 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 def __init__ ( self , microgrid_api : MicrogridApiClient , component_graph : ComponentGraph , users_channels : Dict [ str , Bidirectional . Handle [ Result , Request ]], wait_for_data_sec : float = 2 , ) -> None : \"\"\"Create class instance. Args: microgrid_api: api for sending the requests. component_graph: component graph of the given microgrid api. users_channels: BidirectionalHandle for each user. Key should be user id and value should be BidirectionalHandle. wait_for_data_sec: How long actor should wait before processing first request. It is a time needed to collect first components data. \"\"\" self . _api = microgrid_api self . _wait_for_data_sec = wait_for_data_sec # Max permitted time when the component should send any information. # After that timeout the component will be treated as not existing. # Formulas will put 0 in place of data from this components. # This will happen until component starts sending data. self . component_data_timeout_sec : float = 60.0 self . broken_component_timeout_sec : float = 30.0 self . power_distributor_exponent : float = 1.0 # distributor_exponent and timeout_sec should be get from ConfigManager self . distribution_algorithm = DistributionAlgorithm ( self . power_distributor_exponent ) self . _broken_components = BrokenComponents ( self . broken_component_timeout_sec ) self . _bat_inv_map , self . _inv_bat_map = self . _get_components_pairs ( component_graph ) self . _battery_receivers : Dict [ int , Peekable [ BatteryData ]] = {} self . _inverter_receivers : Dict [ int , Peekable [ InverterData ]] = {} # The components in different requests be for the same components, or for # completely different components. They should not overlap. # Otherwise the PowerDistributor has no way to decide what request is more # important. It will execute both. And later request will override the previous # one. # That is why the queue of maxsize = total number of batteries should be enough. self . _request_queue : asyncio . Queue [ Tuple [ Request , User ]] = asyncio . Queue ( maxsize = len ( self . _bat_inv_map ) ) self . _users_channels : Dict [ str , Bidirectional . Handle [ Result , Request ] ] = users_channels self . _create_users_tasks () self . _started = asyncio . Event () get_lower_bound ( batteries ) \u00a4 Get total lower bound of power to be set for given batteries. Note, output of that function doesn't guarantee that this bound will be the same when the request is processed. PARAMETER DESCRIPTION batteries List of batteries TYPE: Set [ int ] RETURNS DESCRIPTION float Lower bound for set_power operation. Source code in frequenz/sdk/power_distribution/power_distributor.py 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 def get_lower_bound ( self , batteries : Set [ int ]) -> float : \"\"\"Get total lower bound of power to be set for given batteries. Note, output of that function doesn't guarantee that this bound will be the same when the request is processed. Args: batteries: List of batteries Returns: Lower bound for `set_power` operation. \"\"\" pairs_data : List [ InvBatPair ] = self . _get_components_data ( batteries ) return sum ( min ( battery . power_lower_bound , inverter . active_power_lower_bound ) for battery , inverter in pairs_data ) get_upper_bound ( batteries ) \u00a4 Get total upper bound of power to be set for given batteries. Note, output of that function doesn't guarantee that this bound will be the same when the request is processed. PARAMETER DESCRIPTION batteries List of batteries TYPE: Set [ int ] RETURNS DESCRIPTION float Upper bound for set_power operation. Source code in frequenz/sdk/power_distribution/power_distributor.py 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 def get_upper_bound ( self , batteries : Set [ int ]) -> float : \"\"\"Get total upper bound of power to be set for given batteries. Note, output of that function doesn't guarantee that this bound will be the same when the request is processed. Args: batteries: List of batteries Returns: Upper bound for `set_power` operation. \"\"\" pairs_data : List [ InvBatPair ] = self . _get_components_data ( batteries ) return sum ( min ( battery . power_upper_bound , inverter . active_power_upper_bound ) for battery , inverter in pairs_data ) run () async \u00a4 Run actor main function. It waits for new requests in task_queue and process it, and send set_power request with distributed power. The output of the set_power method is processed. Every battery and inverter that failed or didn't respond in time will be marked as broken for some time. Source code in frequenz/sdk/power_distribution/power_distributor.py 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 async def run ( self ) -> None : \"\"\"Run actor main function. It waits for new requests in task_queue and process it, and send `set_power` request with distributed power. The output of the `set_power` method is processed. Every battery and inverter that failed or didn't respond in time will be marked as broken for some time. \"\"\" await self . _create_channels () # Wait 2 seconds to get data from the channels created above. await asyncio . sleep ( self . _wait_for_data_sec ) self . _started . set () while True : request , user = await self . _request_queue . get () try : pairs_data : List [ InvBatPair ] = self . _get_components_data ( request . batteries ) except KeyError as err : await user . channel . send ( Result ( Result . Status . ERROR , request . power , 0 , str ( err )) ) continue if len ( pairs_data ) == 0 : error_msg = f \"No data for the given batteries { str ( request . batteries ) } \" await user . channel . send ( Result ( Result . Status . ERROR , request . power , 0 , str ( error_msg )) ) continue try : distribution = self . distribution_algorithm . distribute_power ( request . power , pairs_data ) except ValueError as err : error_msg = f \"Couldn't distribute power, error: { str ( err ) } \" await user . channel . send ( Result ( Result . Status . ERROR , request . power , 0 , error_msg ) ) continue distributed_power_value = request . power - distribution . remaining_power _logger . debug ( \" %s : Distributing power %d between the inverters %s \" , user . user_id , distributed_power_value , str ( distribution . distribution ), ) tasks = { inverter_id : asyncio . create_task ( self . _api . set_power ( inverter_id , power ) ) for inverter_id , power in distribution . distribution . items () } _ , pending = await asyncio . wait ( tasks . values (), timeout = request . request_timeout_sec , return_when = ALL_COMPLETED , ) await self . _cancel_tasks ( pending ) any_fail , failed_power = self . _parse_result ( tasks , distribution . distribution , request . request_timeout_sec ) status = Result . Status . FAILED if any_fail else Result . Status . SUCCESS await user . channel . send ( Result ( status , failed_power , distribution . remaining_power ) ) Functions \u00a4","title":"power_distributor"},{"location":"reference/frequenz/sdk/power_distribution/power_distributor/#frequenz.sdk.power_distribution.power_distributor","text":"Tool to distribute power between batteries. Purpose of this tool is to keep SoC level of each component at the equal level.","title":"power_distributor"},{"location":"reference/frequenz/sdk/power_distribution/power_distributor/#frequenz.sdk.power_distribution.power_distributor-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/power_distribution/power_distributor/#frequenz.sdk.power_distribution.power_distributor.PowerDistributor","text":"Tool to distribute power between batteries in microgrid. The purpose of this tool is to keep equal SoC level in the batteries. PowerDistributor can have many users. Each user should first register in order to get its id, channel for sending request, and channel for receiving response. It is recommended to wait for PowerDistributor output with timeout. Otherwise if the processing function fail then the response will never come. The timeout should be Result:request_timeout_sec + time for processing the request. Edge cases: * If there are 2 requests to be processed for the same subset of batteries, then only the latest request will be processed. Older request will be ignored. User with older request will get response with Result.Status.IGNORED. If there are 2 requests and their subset of batteries is different but they overlap (they have at least one common battery), then then both batteries will be processed. However it is not expected so the proper error log will be printed. Example import grpc.aio as grpcaio from frequenz.sdk.microgrid.graph import _MicrogridComponentGraph from frequenz.sdk.microgrid.component import ComponentCategory from frequenz.sdk.power_distribution import ( PowerDistributor , Request , Result , ) target = f \" { host } : { port } \" grpc_channel = grpcaio . insecure_channel ( target ) api = MicrogridGrpcClient ( grpc_channel , target ) graph = _MicrogridComponentGraph () await graph . refresh_from_api ( api ) batteries = graph . components ( component_category = { ComponentCategory . BATTERY }) batteries_ids = { c . component_id for c in batteries } channel = Bidirectional [ Request , Result ]( \"user1\" , \"power_distributor\" ) power_distributor = PowerDistributor ( mock_api , component_graph , { \"user1\" : channel . service_handle } ) client_handle = channel . client_handle # Set power 1200W to given batteries. request = Request ( power = 1200 , batteries = batteries_ids , request_timeout_sec = 10.0 ) await client_handle . send ( request ) # It is recommended to use timeout when waiting for the response! result : Result = await asyncio . wait_for ( client_handle . receive (), timeout = 10 ) if result . status == Result . Status . SUCCESS : print ( \"Command succeed\" ) elif result . status == Result . Status . FAILED : print ( f \"Some batteries failed, total failed power: { result . failed_power } \" ) elif result . status == Result . Status . IGNORED : print ( f \"Request was ignored, because of newer command\" ) elif result . status == Result . Status . ERROR : print ( f \"Request failed with error: { request . error_message } \" ) Source code in frequenz/sdk/power_distribution/power_distributor.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 @actor class PowerDistributor : # pylint: disable=too-many-instance-attributes \"\"\"Tool to distribute power between batteries in microgrid. The purpose of this tool is to keep equal SoC level in the batteries. PowerDistributor can have many users. Each user should first register in order to get its id, channel for sending request, and channel for receiving response. It is recommended to wait for PowerDistributor output with timeout. Otherwise if the processing function fail then the response will never come. The timeout should be Result:request_timeout_sec + time for processing the request. Edge cases: * If there are 2 requests to be processed for the same subset of batteries, then only the latest request will be processed. Older request will be ignored. User with older request will get response with Result.Status.IGNORED. * If there are 2 requests and their subset of batteries is different but they overlap (they have at least one common battery), then then both batteries will be processed. However it is not expected so the proper error log will be printed. Example: ``` python import grpc.aio as grpcaio from frequenz.sdk.microgrid.graph import _MicrogridComponentGraph from frequenz.sdk.microgrid.component import ComponentCategory from frequenz.sdk.power_distribution import ( PowerDistributor, Request, Result, ) target = f\"{host}:{port}\" grpc_channel = grpcaio.insecure_channel(target) api = MicrogridGrpcClient(grpc_channel, target) graph = _MicrogridComponentGraph() await graph.refresh_from_api(api) batteries = graph.components(component_category={ComponentCategory.BATTERY}) batteries_ids = {c.component_id for c in batteries} channel = Bidirectional[Request, Result](\"user1\", \"power_distributor\") power_distributor = PowerDistributor( mock_api, component_graph, {\"user1\": channel.service_handle} ) client_handle = channel.client_handle # Set power 1200W to given batteries. request = Request(power=1200, batteries=batteries_ids, request_timeout_sec=10.0) await client_handle.send(request) # It is recommended to use timeout when waiting for the response! result: Result = await asyncio.wait_for(client_handle.receive(), timeout=10) if result.status == Result.Status.SUCCESS: print(\"Command succeed\") elif result.status == Result.Status.FAILED: print( f\"Some batteries failed, total failed power: {result.failed_power}\") elif result.status == Result.Status.IGNORED: print(f\"Request was ignored, because of newer command\") elif result.status == Result.Status.ERROR: print(f\"Request failed with error: {request.error_message}\") ``` \"\"\" def __init__ ( self , microgrid_api : MicrogridApiClient , component_graph : ComponentGraph , users_channels : Dict [ str , Bidirectional . Handle [ Result , Request ]], wait_for_data_sec : float = 2 , ) -> None : \"\"\"Create class instance. Args: microgrid_api: api for sending the requests. component_graph: component graph of the given microgrid api. users_channels: BidirectionalHandle for each user. Key should be user id and value should be BidirectionalHandle. wait_for_data_sec: How long actor should wait before processing first request. It is a time needed to collect first components data. \"\"\" self . _api = microgrid_api self . _wait_for_data_sec = wait_for_data_sec # Max permitted time when the component should send any information. # After that timeout the component will be treated as not existing. # Formulas will put 0 in place of data from this components. # This will happen until component starts sending data. self . component_data_timeout_sec : float = 60.0 self . broken_component_timeout_sec : float = 30.0 self . power_distributor_exponent : float = 1.0 # distributor_exponent and timeout_sec should be get from ConfigManager self . distribution_algorithm = DistributionAlgorithm ( self . power_distributor_exponent ) self . _broken_components = BrokenComponents ( self . broken_component_timeout_sec ) self . _bat_inv_map , self . _inv_bat_map = self . _get_components_pairs ( component_graph ) self . _battery_receivers : Dict [ int , Peekable [ BatteryData ]] = {} self . _inverter_receivers : Dict [ int , Peekable [ InverterData ]] = {} # The components in different requests be for the same components, or for # completely different components. They should not overlap. # Otherwise the PowerDistributor has no way to decide what request is more # important. It will execute both. And later request will override the previous # one. # That is why the queue of maxsize = total number of batteries should be enough. self . _request_queue : asyncio . Queue [ Tuple [ Request , User ]] = asyncio . Queue ( maxsize = len ( self . _bat_inv_map ) ) self . _users_channels : Dict [ str , Bidirectional . Handle [ Result , Request ] ] = users_channels self . _create_users_tasks () self . _started = asyncio . Event () def _create_users_tasks ( self ) -> None : \"\"\"For each user create a task to wait for request.\"\"\" for user , handler in self . _users_channels . items (): asyncio . create_task ( self . _wait_for_request ( User ( user , handler ))) def get_upper_bound ( self , batteries : Set [ int ]) -> float : \"\"\"Get total upper bound of power to be set for given batteries. Note, output of that function doesn't guarantee that this bound will be the same when the request is processed. Args: batteries: List of batteries Returns: Upper bound for `set_power` operation. \"\"\" pairs_data : List [ InvBatPair ] = self . _get_components_data ( batteries ) return sum ( min ( battery . power_upper_bound , inverter . active_power_upper_bound ) for battery , inverter in pairs_data ) def get_lower_bound ( self , batteries : Set [ int ]) -> float : \"\"\"Get total lower bound of power to be set for given batteries. Note, output of that function doesn't guarantee that this bound will be the same when the request is processed. Args: batteries: List of batteries Returns: Lower bound for `set_power` operation. \"\"\" pairs_data : List [ InvBatPair ] = self . _get_components_data ( batteries ) return sum ( min ( battery . power_lower_bound , inverter . active_power_lower_bound ) for battery , inverter in pairs_data ) def _within_bounds ( self , request : Request ) -> bool : \"\"\"Check whether the requested power is withing the bounds. Args: request: request Returns: True if power is between the bounds, False otherwise. \"\"\" power = request . power lower_bound = self . get_lower_bound ( request . batteries ) return lower_bound <= power <= self . get_upper_bound ( request . batteries ) async def run ( self ) -> None : \"\"\"Run actor main function. It waits for new requests in task_queue and process it, and send `set_power` request with distributed power. The output of the `set_power` method is processed. Every battery and inverter that failed or didn't respond in time will be marked as broken for some time. \"\"\" await self . _create_channels () # Wait 2 seconds to get data from the channels created above. await asyncio . sleep ( self . _wait_for_data_sec ) self . _started . set () while True : request , user = await self . _request_queue . get () try : pairs_data : List [ InvBatPair ] = self . _get_components_data ( request . batteries ) except KeyError as err : await user . channel . send ( Result ( Result . Status . ERROR , request . power , 0 , str ( err )) ) continue if len ( pairs_data ) == 0 : error_msg = f \"No data for the given batteries { str ( request . batteries ) } \" await user . channel . send ( Result ( Result . Status . ERROR , request . power , 0 , str ( error_msg )) ) continue try : distribution = self . distribution_algorithm . distribute_power ( request . power , pairs_data ) except ValueError as err : error_msg = f \"Couldn't distribute power, error: { str ( err ) } \" await user . channel . send ( Result ( Result . Status . ERROR , request . power , 0 , error_msg ) ) continue distributed_power_value = request . power - distribution . remaining_power _logger . debug ( \" %s : Distributing power %d between the inverters %s \" , user . user_id , distributed_power_value , str ( distribution . distribution ), ) tasks = { inverter_id : asyncio . create_task ( self . _api . set_power ( inverter_id , power ) ) for inverter_id , power in distribution . distribution . items () } _ , pending = await asyncio . wait ( tasks . values (), timeout = request . request_timeout_sec , return_when = ALL_COMPLETED , ) await self . _cancel_tasks ( pending ) any_fail , failed_power = self . _parse_result ( tasks , distribution . distribution , request . request_timeout_sec ) status = Result . Status . FAILED if any_fail else Result . Status . SUCCESS await user . channel . send ( Result ( status , failed_power , distribution . remaining_power ) ) def _check_request ( self , request : Request ) -> Optional [ Result ]: \"\"\"Check whether the given request if correct. Args: request: request to check Returns: Result for the user if the request is wrong, None otherwise. \"\"\" for battery in request . batteries : if battery not in self . _battery_receivers : msg = ( f \"No battery { battery } , available batteries: \" f \" { list ( self . _battery_receivers . keys ()) } \" ) return Result ( Result . Status . ERROR , request . power , 0 , error_message = msg ) if not request . adjust_power and not self . _within_bounds ( request ): return Result ( Result . Status . OUT_OF_BOUND , request . power , 0 ) return None def _remove_duplicated_requests ( self , request : Request , user : User ) -> List [ asyncio . Task [ bool ]]: \"\"\"Remove duplicated requests from the queue. Remove old requests in which set of batteries are the same as in new request. If batteries in new request overlap with batteries in old request but are not equal, then log error and process both messages. Args: request: request to check user: User who sent the request. Returns: Tasks with result sent to the users which requests were duplicated. \"\"\" batteries = request . batteries good_requests : List [ Tuple [ Request , User ]] = [] to_ignore : List [ asyncio . Task [ bool ]] = [] while not self . _request_queue . empty (): prev_request , prev_user = self . _request_queue . get_nowait () # Generators seems to be the fastest if prev_request . batteries == batteries : task = asyncio . create_task ( prev_user . channel . send ( Result ( Result . Status . IGNORED , prev_request . power , 0 ) ) ) to_ignore . append ( task ) # Use generators as generators seems to be the fastest. elif any ( battery_id in prev_request . batteries for battery_id in batteries ): # If that happen PowerDistributor has no way to distinguish what # request is more important. This should not happen _logger . error ( \"Batteries in two requests overlap! Actor: %s requested %s \" \"and Actor: %s requested %s \" , user . user_id , str ( request ), prev_user . user_id , str ( prev_request ), ) good_requests . append (( prev_request , prev_user )) else : good_requests . append (( prev_request , prev_user )) for good_request in good_requests : self . _request_queue . put_nowait ( good_request ) return to_ignore async def _wait_for_request ( self , user : User ) -> None : \"\"\"Wait for the request from user. Check if request is correct. If request is not correct send ERROR response to the user. If request is correct, then add it to the main queue to be process. If main queue has request for the same subset of batteries, then remove older request, and send its user response with Result.Status.IGNORED. Only new request will re processed. If set of batteries are not the same but have common elements, then both batteries will be processed. Args: user: User that sends the requests. \"\"\" while True : request : Optional [ Request ] = await user . channel . receive () if request is None : _logger . info ( \"Send channel for user %s was closed. User will be unregistered.\" , user . user_id , ) self . _users_channels . pop ( user . user_id ) if len ( self . _users_channels ) == 0 : _logger . error ( \"No users in PowerDistributor!\" ) return # Wait for PowerDistributor to start. if not self . _started . is_set (): await self . _started . wait () # We should discover as fast as possible that request is wrong. check_result = self . _check_request ( request ) if check_result is not None : await user . channel . send ( check_result ) continue tasks = self . _remove_duplicated_requests ( request , user ) if self . _request_queue . full (): q_size = ( self . _request_queue . qsize (),) msg = ( f \"Request queue is full { q_size } , can't process this request. \" \"Consider increasing size of the queue.\" ) _logger . error ( msg ) await user . channel . send ( Result ( Result . Status . ERROR , request . power , 0 , msg ) ) else : self . _request_queue . put_nowait (( request , user )) await asyncio . gather ( * tasks ) def _get_components_pairs ( self , component_graph : ComponentGraph ) -> Tuple [ Dict [ int , int ], Dict [ int , int ]]: \"\"\"Create maps between battery and adjacent inverter. Args: component_graph: component graph Returns: Tuple where first element is map between battery and adjacent inverter, second element of the tuple is map between inverter and adjacent battery. \"\"\" bat_inv_map : Dict [ int , int ] = {} inv_bat_map : Dict [ int , int ] = {} batteries : Iterable [ Component ] = component_graph . components ( component_category = { ComponentCategory . BATTERY } ) for battery in batteries : inverters : List [ Component ] = [ component for component in component_graph . predecessors ( battery . component_id ) if component . category == ComponentCategory . INVERTER ] if len ( inverters ) == 0 : _logger . error ( \"No inverters for battery %d \" , battery . component_id ) continue if len ( inverters ) > 1 : _logger . error ( \"Battery %d has more then one inverter. It is not supported now.\" , battery . component_id , ) bat_inv_map [ battery . component_id ] = inverters [ 0 ] . component_id inv_bat_map [ inverters [ 0 ] . component_id ] = battery . component_id return bat_inv_map , inv_bat_map def _get_components_data ( self , batteries : Iterable [ int ]) -> List [ InvBatPair ]: \"\"\"Get data for the given batteries and adjacent inverters. Args: batteries: Batteries that needs data. Raises: KeyError: If any battery in the given list doesn't exists in microgrid. Returns: Pairs of battery and adjacent inverter data. \"\"\" pairs_data : List [ InvBatPair ] = [] for battery_id in batteries : if battery_id not in self . _battery_receivers : raise KeyError ( f \"No battery { battery_id } , \" f \"available batteries: { list ( self . _battery_receivers . keys ()) } \" ) inverter_id : int = self . _bat_inv_map [ battery_id ] if self . _broken_components . is_broken ( battery_id ) or self . _broken_components . is_broken ( inverter_id ): continue battery_data : Optional [ BatteryData ] = self . _battery_receivers [ battery_id ] . peek () if not self . _is_component_data_valid ( battery_id , battery_data ): continue inverter_data : Optional [ InverterData ] = self . _inverter_receivers [ inverter_id ] . peek () if not self . _is_component_data_valid ( inverter_id , inverter_data ): continue # None case already checked but mypy don't see that. if battery_data is not None and inverter_data is not None : pairs_data . append ( InvBatPair ( battery_data , inverter_data )) return pairs_data def _is_component_data_valid ( self , component_id : int , component_data : Union [ None , BatteryData , InverterData ] ) -> bool : \"\"\"Check whether the component data from microgrid are correct. Args: component_id: component id component_data: component data instance Returns: True if data are correct, false otherwise \"\"\" if component_data is None : _logger . warning ( \"No data from component %d .\" , component_id , ) return False now = datetime . now ( timezone . utc ) time_delta = now - component_data . timestamp if time_delta . total_seconds () > self . component_data_timeout_sec : _logger . warning ( \"Component %d data are stale. Last timestamp: %s , now: %s \" , component_id , str ( component_data . timestamp ), str ( now ), ) return False return True async def _create_channels ( self ) -> None : \"\"\"Create channels to get data of components in microgrid.\"\"\" for battery_id , inverter_id in self . _bat_inv_map . items (): bat_recv : Receiver [ BatteryData ] = await self . _api . battery_data ( battery_id ) self . _battery_receivers [ battery_id ] = bat_recv . into_peekable () inv_recv : Receiver [ InverterData ] = await self . _api . inverter_data ( inverter_id ) self . _inverter_receivers [ inverter_id ] = inv_recv . into_peekable () def _parse_result ( self , # type comment to quiet pylint and mypy `unused-import` error tasks , # type: Dict[int, asyncio.Task[Empty]] distribution : Dict [ int , int ], request_timeout_sec : float , ) -> Tuple [ bool , int ]: \"\"\"Parse result of `set_power` requests. Check if any task failed and why. If any task didn't success, then corresponding battery is marked as broken. Args: tasks: Dictionary where key is inverter id and value is task that set power for this inverter. Each tasks should be finished or cancelled. distribution: Dictionary where key is inverter id and value is how much power was set to the corresponding inverter. request_timeout_sec: timeout which has been used for request. Returns: Tuple where first element tells if any task didn't succeed, and the second element is total amount of power that failed. \"\"\" any_fail : bool = False failed_power : int = 0 for inverter_id , aws in tasks . items (): battery_id = self . _inv_bat_map [ inverter_id ] try : aws . result () except grpc . aio . AioRpcError as err : any_fail = True failed_power += distribution [ inverter_id ] if err . code () == grpc . StatusCode . OUT_OF_RANGE : _logger . debug ( \"Set power for battery %d failed, error %s \" , battery_id , str ( err ), ) else : _logger . warning ( \"Set power for battery %d failed, error %s . Mark it as broken.\" , battery_id , str ( err ), ) self . _broken_components . mark_as_broken ( battery_id ) except asyncio . exceptions . CancelledError : any_fail = True failed_power += distribution [ inverter_id ] _logger . warning ( \"Battery %d didn't respond in %f sec. Mark it as broken.\" , battery_id , request_timeout_sec , ) self . _broken_components . mark_as_broken ( battery_id ) return any_fail , failed_power async def _cancel_tasks ( self , tasks : Iterable [ asyncio . Task [ Any ]]) -> None : \"\"\"Cancel given asyncio tasks and wait for them. Args: tasks: tasks to cancel. \"\"\" for aws in tasks : aws . cancel () await asyncio . gather ( * tasks , return_exceptions = True )","title":"PowerDistributor"},{"location":"reference/frequenz/sdk/power_distribution/power_distributor/#frequenz.sdk.power_distribution.power_distributor.PowerDistributor-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/power_distribution/power_distributor/#frequenz.sdk.power_distribution.power_distributor.PowerDistributor.__init__","text":"Create class instance. PARAMETER DESCRIPTION microgrid_api api for sending the requests. TYPE: MicrogridApiClient component_graph component graph of the given microgrid api. TYPE: ComponentGraph users_channels BidirectionalHandle for each user. Key should be user id and value should be BidirectionalHandle. TYPE: Dict [ str , Bidirectional . Handle [ Result , Request ]] wait_for_data_sec How long actor should wait before processing first request. It is a time needed to collect first components data. TYPE: float DEFAULT: 2 Source code in frequenz/sdk/power_distribution/power_distributor.py 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 def __init__ ( self , microgrid_api : MicrogridApiClient , component_graph : ComponentGraph , users_channels : Dict [ str , Bidirectional . Handle [ Result , Request ]], wait_for_data_sec : float = 2 , ) -> None : \"\"\"Create class instance. Args: microgrid_api: api for sending the requests. component_graph: component graph of the given microgrid api. users_channels: BidirectionalHandle for each user. Key should be user id and value should be BidirectionalHandle. wait_for_data_sec: How long actor should wait before processing first request. It is a time needed to collect first components data. \"\"\" self . _api = microgrid_api self . _wait_for_data_sec = wait_for_data_sec # Max permitted time when the component should send any information. # After that timeout the component will be treated as not existing. # Formulas will put 0 in place of data from this components. # This will happen until component starts sending data. self . component_data_timeout_sec : float = 60.0 self . broken_component_timeout_sec : float = 30.0 self . power_distributor_exponent : float = 1.0 # distributor_exponent and timeout_sec should be get from ConfigManager self . distribution_algorithm = DistributionAlgorithm ( self . power_distributor_exponent ) self . _broken_components = BrokenComponents ( self . broken_component_timeout_sec ) self . _bat_inv_map , self . _inv_bat_map = self . _get_components_pairs ( component_graph ) self . _battery_receivers : Dict [ int , Peekable [ BatteryData ]] = {} self . _inverter_receivers : Dict [ int , Peekable [ InverterData ]] = {} # The components in different requests be for the same components, or for # completely different components. They should not overlap. # Otherwise the PowerDistributor has no way to decide what request is more # important. It will execute both. And later request will override the previous # one. # That is why the queue of maxsize = total number of batteries should be enough. self . _request_queue : asyncio . Queue [ Tuple [ Request , User ]] = asyncio . Queue ( maxsize = len ( self . _bat_inv_map ) ) self . _users_channels : Dict [ str , Bidirectional . Handle [ Result , Request ] ] = users_channels self . _create_users_tasks () self . _started = asyncio . Event ()","title":"__init__()"},{"location":"reference/frequenz/sdk/power_distribution/power_distributor/#frequenz.sdk.power_distribution.power_distributor.PowerDistributor.get_lower_bound","text":"Get total lower bound of power to be set for given batteries. Note, output of that function doesn't guarantee that this bound will be the same when the request is processed. PARAMETER DESCRIPTION batteries List of batteries TYPE: Set [ int ] RETURNS DESCRIPTION float Lower bound for set_power operation. Source code in frequenz/sdk/power_distribution/power_distributor.py 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 def get_lower_bound ( self , batteries : Set [ int ]) -> float : \"\"\"Get total lower bound of power to be set for given batteries. Note, output of that function doesn't guarantee that this bound will be the same when the request is processed. Args: batteries: List of batteries Returns: Lower bound for `set_power` operation. \"\"\" pairs_data : List [ InvBatPair ] = self . _get_components_data ( batteries ) return sum ( min ( battery . power_lower_bound , inverter . active_power_lower_bound ) for battery , inverter in pairs_data )","title":"get_lower_bound()"},{"location":"reference/frequenz/sdk/power_distribution/power_distributor/#frequenz.sdk.power_distribution.power_distributor.PowerDistributor.get_upper_bound","text":"Get total upper bound of power to be set for given batteries. Note, output of that function doesn't guarantee that this bound will be the same when the request is processed. PARAMETER DESCRIPTION batteries List of batteries TYPE: Set [ int ] RETURNS DESCRIPTION float Upper bound for set_power operation. Source code in frequenz/sdk/power_distribution/power_distributor.py 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 def get_upper_bound ( self , batteries : Set [ int ]) -> float : \"\"\"Get total upper bound of power to be set for given batteries. Note, output of that function doesn't guarantee that this bound will be the same when the request is processed. Args: batteries: List of batteries Returns: Upper bound for `set_power` operation. \"\"\" pairs_data : List [ InvBatPair ] = self . _get_components_data ( batteries ) return sum ( min ( battery . power_upper_bound , inverter . active_power_upper_bound ) for battery , inverter in pairs_data )","title":"get_upper_bound()"},{"location":"reference/frequenz/sdk/power_distribution/power_distributor/#frequenz.sdk.power_distribution.power_distributor.PowerDistributor.run","text":"Run actor main function. It waits for new requests in task_queue and process it, and send set_power request with distributed power. The output of the set_power method is processed. Every battery and inverter that failed or didn't respond in time will be marked as broken for some time. Source code in frequenz/sdk/power_distribution/power_distributor.py 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 async def run ( self ) -> None : \"\"\"Run actor main function. It waits for new requests in task_queue and process it, and send `set_power` request with distributed power. The output of the `set_power` method is processed. Every battery and inverter that failed or didn't respond in time will be marked as broken for some time. \"\"\" await self . _create_channels () # Wait 2 seconds to get data from the channels created above. await asyncio . sleep ( self . _wait_for_data_sec ) self . _started . set () while True : request , user = await self . _request_queue . get () try : pairs_data : List [ InvBatPair ] = self . _get_components_data ( request . batteries ) except KeyError as err : await user . channel . send ( Result ( Result . Status . ERROR , request . power , 0 , str ( err )) ) continue if len ( pairs_data ) == 0 : error_msg = f \"No data for the given batteries { str ( request . batteries ) } \" await user . channel . send ( Result ( Result . Status . ERROR , request . power , 0 , str ( error_msg )) ) continue try : distribution = self . distribution_algorithm . distribute_power ( request . power , pairs_data ) except ValueError as err : error_msg = f \"Couldn't distribute power, error: { str ( err ) } \" await user . channel . send ( Result ( Result . Status . ERROR , request . power , 0 , error_msg ) ) continue distributed_power_value = request . power - distribution . remaining_power _logger . debug ( \" %s : Distributing power %d between the inverters %s \" , user . user_id , distributed_power_value , str ( distribution . distribution ), ) tasks = { inverter_id : asyncio . create_task ( self . _api . set_power ( inverter_id , power ) ) for inverter_id , power in distribution . distribution . items () } _ , pending = await asyncio . wait ( tasks . values (), timeout = request . request_timeout_sec , return_when = ALL_COMPLETED , ) await self . _cancel_tasks ( pending ) any_fail , failed_power = self . _parse_result ( tasks , distribution . distribution , request . request_timeout_sec ) status = Result . Status . FAILED if any_fail else Result . Status . SUCCESS await user . channel . send ( Result ( status , failed_power , distribution . remaining_power ) )","title":"run()"},{"location":"reference/frequenz/sdk/power_distribution/power_distributor/#frequenz.sdk.power_distribution.power_distributor-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/power_distribution/utils/","text":"frequenz.sdk.power_distribution.utils \u00a4 All helpers used to distribute power. Classes \u00a4 frequenz.sdk.power_distribution.utils.BrokenComponents \u00a4 Store components marked as broken. Source code in frequenz/sdk/power_distribution/utils.py 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 class BrokenComponents : \"\"\"Store components marked as broken.\"\"\" def __init__ ( self , timeout_sec : float ) -> None : \"\"\"Create object instance. Args: timeout_sec: How long the component should be marked as broken. \"\"\" self . _broken : Dict [ int , datetime ] = {} self . _timeout_sec = timeout_sec def mark_as_broken ( self , component_id : int ) -> None : \"\"\"Mark component as broken. After marking component as broken it would be considered as broken for self._timeout_sec. Args: component_id: component id \"\"\" self . _broken [ component_id ] = datetime . now ( timezone . utc ) def update_retry ( self , timeout_sec : float ) -> None : \"\"\"Change how long the component should be marked as broken. Args: timeout_sec: New retry time after sec. \"\"\" self . _timeout_sec = timeout_sec def is_broken ( self , component_id : int ) -> bool : \"\"\"Check if component is marked as broken. Args: component_id: component id Returns: True if component is broken, False otherwise. \"\"\" if component_id in self . _broken : last_broken = self . _broken [ component_id ] if ( datetime . now ( timezone . utc ) - last_broken ) . total_seconds () < self . _timeout_sec : return True del self . _broken [ component_id ] return False Functions \u00a4 __init__ ( timeout_sec ) \u00a4 Create object instance. PARAMETER DESCRIPTION timeout_sec How long the component should be marked as broken. TYPE: float Source code in frequenz/sdk/power_distribution/utils.py 81 82 83 84 85 86 87 88 def __init__ ( self , timeout_sec : float ) -> None : \"\"\"Create object instance. Args: timeout_sec: How long the component should be marked as broken. \"\"\" self . _broken : Dict [ int , datetime ] = {} self . _timeout_sec = timeout_sec is_broken ( component_id ) \u00a4 Check if component is marked as broken. PARAMETER DESCRIPTION component_id component id TYPE: int RETURNS DESCRIPTION bool True if component is broken, False otherwise. Source code in frequenz/sdk/power_distribution/utils.py 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 def is_broken ( self , component_id : int ) -> bool : \"\"\"Check if component is marked as broken. Args: component_id: component id Returns: True if component is broken, False otherwise. \"\"\" if component_id in self . _broken : last_broken = self . _broken [ component_id ] if ( datetime . now ( timezone . utc ) - last_broken ) . total_seconds () < self . _timeout_sec : return True del self . _broken [ component_id ] return False mark_as_broken ( component_id ) \u00a4 Mark component as broken. After marking component as broken it would be considered as broken for self._timeout_sec. PARAMETER DESCRIPTION component_id component id TYPE: int Source code in frequenz/sdk/power_distribution/utils.py 90 91 92 93 94 95 96 97 98 99 def mark_as_broken ( self , component_id : int ) -> None : \"\"\"Mark component as broken. After marking component as broken it would be considered as broken for self._timeout_sec. Args: component_id: component id \"\"\" self . _broken [ component_id ] = datetime . now ( timezone . utc ) update_retry ( timeout_sec ) \u00a4 Change how long the component should be marked as broken. PARAMETER DESCRIPTION timeout_sec New retry time after sec. TYPE: float Source code in frequenz/sdk/power_distribution/utils.py 101 102 103 104 105 106 107 def update_retry ( self , timeout_sec : float ) -> None : \"\"\"Change how long the component should be marked as broken. Args: timeout_sec: New retry time after sec. \"\"\" self . _timeout_sec = timeout_sec frequenz.sdk.power_distribution.utils.InvBatPair \u00a4 Bases: NamedTuple InvBatPair with inverter and adjacent battery data. Source code in frequenz/sdk/power_distribution/utils.py 15 16 17 18 19 class InvBatPair ( NamedTuple ): \"\"\"InvBatPair with inverter and adjacent battery data.\"\"\" battery : BatteryData inverter : InverterData frequenz.sdk.power_distribution.utils.Request dataclass \u00a4 Request from the user. Source code in frequenz/sdk/power_distribution/utils.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 @dataclass class Request : \"\"\"Request from the user.\"\"\" # How much power to set power : int # In which batteries the power should be set batteries : Set [ int ] # Timeout for the server to respond on the request. request_timeout_sec : float = 5.0 # If True and requested power value is out of bound, then # PowerDistributor will decrease the power to match the bounds and # distribute only decreased power. # If False and the requested power is out of bound, then # PowerDistributor will not process this request and send result with status # Result.Status.OUT_OF_BOUND. adjust_power : bool = True frequenz.sdk.power_distribution.utils.Result dataclass \u00a4 Result on distribution request. Source code in frequenz/sdk/power_distribution/utils.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 @dataclass class Result : \"\"\"Result on distribution request.\"\"\" class Status ( Enum ): \"\"\"Status of the result.\"\"\" FAILED = 0 # If any request for any battery didn't succeed for any reason. SUCCESS = 1 # If all requests for all batteries succeed. IGNORED = 2 # If request was dispossessed by newer request with the same set # of batteries. ERROR = 3 # If any error happened. In this case error_message describes error. OUT_OF_BOUND = 4 # When Request.adjust_power=False and the requested power was # out of the bounds for specified batteries. status : Status # Status of the request. failed_power : float # How much power failed. above_upper_bound : float # How much power was not used because it was beyond the # limits. error_message : Optional [ str ] = None # error_message filled only when status is ERROR Classes \u00a4 Status \u00a4 Bases: Enum Status of the result. Source code in frequenz/sdk/power_distribution/utils.py 45 46 47 48 49 50 51 52 53 class Status ( Enum ): \"\"\"Status of the result.\"\"\" FAILED = 0 # If any request for any battery didn't succeed for any reason. SUCCESS = 1 # If all requests for all batteries succeed. IGNORED = 2 # If request was dispossessed by newer request with the same set # of batteries. ERROR = 3 # If any error happened. In this case error_message describes error. OUT_OF_BOUND = 4 # When Request.adjust_power=False and the requested power was frequenz.sdk.power_distribution.utils.User dataclass \u00a4 User definitions. Only for internal use. Source code in frequenz/sdk/power_distribution/utils.py 68 69 70 71 72 73 74 75 @dataclass class User : \"\"\"User definitions. Only for internal use.\"\"\" # User id user_id : str # Channel for the communication channel : Bidirectional . Handle [ Result , Request ]","title":"utils"},{"location":"reference/frequenz/sdk/power_distribution/utils/#frequenz.sdk.power_distribution.utils","text":"All helpers used to distribute power.","title":"utils"},{"location":"reference/frequenz/sdk/power_distribution/utils/#frequenz.sdk.power_distribution.utils-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/power_distribution/utils/#frequenz.sdk.power_distribution.utils.BrokenComponents","text":"Store components marked as broken. Source code in frequenz/sdk/power_distribution/utils.py 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 class BrokenComponents : \"\"\"Store components marked as broken.\"\"\" def __init__ ( self , timeout_sec : float ) -> None : \"\"\"Create object instance. Args: timeout_sec: How long the component should be marked as broken. \"\"\" self . _broken : Dict [ int , datetime ] = {} self . _timeout_sec = timeout_sec def mark_as_broken ( self , component_id : int ) -> None : \"\"\"Mark component as broken. After marking component as broken it would be considered as broken for self._timeout_sec. Args: component_id: component id \"\"\" self . _broken [ component_id ] = datetime . now ( timezone . utc ) def update_retry ( self , timeout_sec : float ) -> None : \"\"\"Change how long the component should be marked as broken. Args: timeout_sec: New retry time after sec. \"\"\" self . _timeout_sec = timeout_sec def is_broken ( self , component_id : int ) -> bool : \"\"\"Check if component is marked as broken. Args: component_id: component id Returns: True if component is broken, False otherwise. \"\"\" if component_id in self . _broken : last_broken = self . _broken [ component_id ] if ( datetime . now ( timezone . utc ) - last_broken ) . total_seconds () < self . _timeout_sec : return True del self . _broken [ component_id ] return False","title":"BrokenComponents"},{"location":"reference/frequenz/sdk/power_distribution/utils/#frequenz.sdk.power_distribution.utils.BrokenComponents-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/power_distribution/utils/#frequenz.sdk.power_distribution.utils.BrokenComponents.__init__","text":"Create object instance. PARAMETER DESCRIPTION timeout_sec How long the component should be marked as broken. TYPE: float Source code in frequenz/sdk/power_distribution/utils.py 81 82 83 84 85 86 87 88 def __init__ ( self , timeout_sec : float ) -> None : \"\"\"Create object instance. Args: timeout_sec: How long the component should be marked as broken. \"\"\" self . _broken : Dict [ int , datetime ] = {} self . _timeout_sec = timeout_sec","title":"__init__()"},{"location":"reference/frequenz/sdk/power_distribution/utils/#frequenz.sdk.power_distribution.utils.BrokenComponents.is_broken","text":"Check if component is marked as broken. PARAMETER DESCRIPTION component_id component id TYPE: int RETURNS DESCRIPTION bool True if component is broken, False otherwise. Source code in frequenz/sdk/power_distribution/utils.py 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 def is_broken ( self , component_id : int ) -> bool : \"\"\"Check if component is marked as broken. Args: component_id: component id Returns: True if component is broken, False otherwise. \"\"\" if component_id in self . _broken : last_broken = self . _broken [ component_id ] if ( datetime . now ( timezone . utc ) - last_broken ) . total_seconds () < self . _timeout_sec : return True del self . _broken [ component_id ] return False","title":"is_broken()"},{"location":"reference/frequenz/sdk/power_distribution/utils/#frequenz.sdk.power_distribution.utils.BrokenComponents.mark_as_broken","text":"Mark component as broken. After marking component as broken it would be considered as broken for self._timeout_sec. PARAMETER DESCRIPTION component_id component id TYPE: int Source code in frequenz/sdk/power_distribution/utils.py 90 91 92 93 94 95 96 97 98 99 def mark_as_broken ( self , component_id : int ) -> None : \"\"\"Mark component as broken. After marking component as broken it would be considered as broken for self._timeout_sec. Args: component_id: component id \"\"\" self . _broken [ component_id ] = datetime . now ( timezone . utc )","title":"mark_as_broken()"},{"location":"reference/frequenz/sdk/power_distribution/utils/#frequenz.sdk.power_distribution.utils.BrokenComponents.update_retry","text":"Change how long the component should be marked as broken. PARAMETER DESCRIPTION timeout_sec New retry time after sec. TYPE: float Source code in frequenz/sdk/power_distribution/utils.py 101 102 103 104 105 106 107 def update_retry ( self , timeout_sec : float ) -> None : \"\"\"Change how long the component should be marked as broken. Args: timeout_sec: New retry time after sec. \"\"\" self . _timeout_sec = timeout_sec","title":"update_retry()"},{"location":"reference/frequenz/sdk/power_distribution/utils/#frequenz.sdk.power_distribution.utils.InvBatPair","text":"Bases: NamedTuple InvBatPair with inverter and adjacent battery data. Source code in frequenz/sdk/power_distribution/utils.py 15 16 17 18 19 class InvBatPair ( NamedTuple ): \"\"\"InvBatPair with inverter and adjacent battery data.\"\"\" battery : BatteryData inverter : InverterData","title":"InvBatPair"},{"location":"reference/frequenz/sdk/power_distribution/utils/#frequenz.sdk.power_distribution.utils.Request","text":"Request from the user. Source code in frequenz/sdk/power_distribution/utils.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 @dataclass class Request : \"\"\"Request from the user.\"\"\" # How much power to set power : int # In which batteries the power should be set batteries : Set [ int ] # Timeout for the server to respond on the request. request_timeout_sec : float = 5.0 # If True and requested power value is out of bound, then # PowerDistributor will decrease the power to match the bounds and # distribute only decreased power. # If False and the requested power is out of bound, then # PowerDistributor will not process this request and send result with status # Result.Status.OUT_OF_BOUND. adjust_power : bool = True","title":"Request"},{"location":"reference/frequenz/sdk/power_distribution/utils/#frequenz.sdk.power_distribution.utils.Result","text":"Result on distribution request. Source code in frequenz/sdk/power_distribution/utils.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 @dataclass class Result : \"\"\"Result on distribution request.\"\"\" class Status ( Enum ): \"\"\"Status of the result.\"\"\" FAILED = 0 # If any request for any battery didn't succeed for any reason. SUCCESS = 1 # If all requests for all batteries succeed. IGNORED = 2 # If request was dispossessed by newer request with the same set # of batteries. ERROR = 3 # If any error happened. In this case error_message describes error. OUT_OF_BOUND = 4 # When Request.adjust_power=False and the requested power was # out of the bounds for specified batteries. status : Status # Status of the request. failed_power : float # How much power failed. above_upper_bound : float # How much power was not used because it was beyond the # limits. error_message : Optional [ str ] = None # error_message filled only when status is ERROR","title":"Result"},{"location":"reference/frequenz/sdk/power_distribution/utils/#frequenz.sdk.power_distribution.utils.Result-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/power_distribution/utils/#frequenz.sdk.power_distribution.utils.Result.Status","text":"Bases: Enum Status of the result. Source code in frequenz/sdk/power_distribution/utils.py 45 46 47 48 49 50 51 52 53 class Status ( Enum ): \"\"\"Status of the result.\"\"\" FAILED = 0 # If any request for any battery didn't succeed for any reason. SUCCESS = 1 # If all requests for all batteries succeed. IGNORED = 2 # If request was dispossessed by newer request with the same set # of batteries. ERROR = 3 # If any error happened. In this case error_message describes error. OUT_OF_BOUND = 4 # When Request.adjust_power=False and the requested power was","title":"Status"},{"location":"reference/frequenz/sdk/power_distribution/utils/#frequenz.sdk.power_distribution.utils.User","text":"User definitions. Only for internal use. Source code in frequenz/sdk/power_distribution/utils.py 68 69 70 71 72 73 74 75 @dataclass class User : \"\"\"User definitions. Only for internal use.\"\"\" # User id user_id : str # Channel for the communication channel : Bidirectional . Handle [ Result , Request ]","title":"User"},{"location":"reference/frequenz/sdk/timeseries/","text":"frequenz.sdk.timeseries \u00a4 Handling of timeseries streams. A timeseries is a stream (normally an async iterator) of samples . This module provides tools to operate on timeseries. Attributes \u00a4 frequenz . sdk . timeseries . ResamplingFunction = Callable [[ Sequence [ Sample ], float ], float ] module-attribute \u00a4 Resampling function type. A resampling function produces a new sample based on a list of pre-existing samples. It can do \"upsampling\" when there data rate of the input_samples period is smaller than the resampling_period_s , or \"downsampling\" if it is bigger. In general a resampling window is the same as the resampling_period_s , and this function might receive input samples from multiple windows in the past to enable extrapolation, but no samples from the future (so the timestamp of the new sample that is going to be produced will always be bigger than the biggest timestamp in the input data). PARAMETER DESCRIPTION input_samples the sequence of pre-existing samples. TYPE: Sequence [ Sample ] resampling_period_s the period in seconds (i.e. how ofter a new sample is produced. TYPE: float RETURNS DESCRIPTION new_sample The value of new sample produced after the resampling. TYPE: float Classes \u00a4 frequenz.sdk.timeseries.GroupResampler \u00a4 Ingests samples and produces resampled data for a group of timeseries. Like the Resampler but handles a group of timeseries. Source code in frequenz/sdk/timeseries/_resampler.py 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 class GroupResampler : \"\"\"Ingests samples and produces resampled data for a group of timeseries. Like the [Resampler][frequenz.sdk.timeseries.Resampler] but handles a group of timeseries. \"\"\" def __init__ ( self , * , resampling_period_s : float , initial_resampling_function : ResamplingFunction , max_data_age_in_periods : float = 3.0 , ) -> None : \"\"\"Initialize the ComponentMetricGroupResampler. Args: resampling_period_s: value describing how often resampling should be performed, in seconds initial_resampling_function: function to be applied to a sequence of samples within a resampling period to produce a single output sample max_data_age_in_periods: max age that samples shouldn't exceed in order to be used in the resampling function \"\"\" self . _resampling_period_s = resampling_period_s self . _max_data_age_in_periods : float = max_data_age_in_periods self . _initial_resampling_function : ResamplingFunction = ( initial_resampling_function ) self . _resamplers : Dict [ str , Resampler ] = {} def add_time_series ( self , time_series_id : str ) -> None : \"\"\"Create a new resampler for a specific time series. If resampler already exists for the provided `time_series_id`, it will be used without creating a new one. Args: time_series_id: time series id \"\"\" if time_series_id in self . _resamplers : return self . _resamplers [ time_series_id ] = Resampler ( resampling_period_s = self . _resampling_period_s , max_data_age_in_periods = self . _max_data_age_in_periods , resampling_function = self . _initial_resampling_function , ) def remove_timeseries ( self , time_series_id : str ) -> None : \"\"\"Remove a resampler for a specific time series. Args: time_series_id: time series id, for which to remove the resampler Raises: KeyError: if resampler for the provided timer_series_id doesn't exist \"\"\" try : del self . _resamplers [ time_series_id ] except KeyError as err : raise KeyError ( f \"No resampler for time series { time_series_id } found!\" ) from err def add_sample ( self , time_series_id : str , sample : Sample ) -> None : \"\"\"Add a sample for a specific time series. Args: time_series_id: time series id, which the sample should be added to sample: sample to be added Raises: KeyError: if resampler for the provided timer_series_id doesn't exist \"\"\" try : self . _resamplers [ time_series_id ] . add_sample ( sample ) except KeyError as err : raise KeyError ( f \"No resampler for time series { time_series_id } found!\" ) from err def resample ( self , timestamp : Optional [ datetime ] = None ) -> Generator [ Tuple [ str , Sample ], None , None ]: \"\"\"Resample samples for all time series. Args: timestamp: the timestamp to use to emit the new samples (and to consider stored samples relevant for resampling. If `None`, the current datetime (in UTC) will be used. Yields: iterator of time series ids and their newly resampled samples \"\"\" if timestamp is None : timestamp = datetime . now ( timezone . utc ) for time_series_id , resampler in self . _resamplers . items (): yield time_series_id , Sample ( timestamp = timestamp , value = resampler . resample ( timestamp ) ) Functions \u00a4 __init__ ( * , resampling_period_s , initial_resampling_function , max_data_age_in_periods = 3.0 ) \u00a4 Initialize the ComponentMetricGroupResampler. PARAMETER DESCRIPTION resampling_period_s value describing how often resampling should be performed, in seconds TYPE: float initial_resampling_function function to be applied to a sequence of samples within a resampling period to produce a single output sample TYPE: ResamplingFunction max_data_age_in_periods max age that samples shouldn't exceed in order to be used in the resampling function TYPE: float DEFAULT: 3.0 Source code in frequenz/sdk/timeseries/_resampler.py 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 def __init__ ( self , * , resampling_period_s : float , initial_resampling_function : ResamplingFunction , max_data_age_in_periods : float = 3.0 , ) -> None : \"\"\"Initialize the ComponentMetricGroupResampler. Args: resampling_period_s: value describing how often resampling should be performed, in seconds initial_resampling_function: function to be applied to a sequence of samples within a resampling period to produce a single output sample max_data_age_in_periods: max age that samples shouldn't exceed in order to be used in the resampling function \"\"\" self . _resampling_period_s = resampling_period_s self . _max_data_age_in_periods : float = max_data_age_in_periods self . _initial_resampling_function : ResamplingFunction = ( initial_resampling_function ) self . _resamplers : Dict [ str , Resampler ] = {} add_sample ( time_series_id , sample ) \u00a4 Add a sample for a specific time series. PARAMETER DESCRIPTION time_series_id time series id, which the sample should be added to TYPE: str sample sample to be added TYPE: Sample RAISES DESCRIPTION KeyError if resampler for the provided timer_series_id doesn't exist Source code in frequenz/sdk/timeseries/_resampler.py 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 def add_sample ( self , time_series_id : str , sample : Sample ) -> None : \"\"\"Add a sample for a specific time series. Args: time_series_id: time series id, which the sample should be added to sample: sample to be added Raises: KeyError: if resampler for the provided timer_series_id doesn't exist \"\"\" try : self . _resamplers [ time_series_id ] . add_sample ( sample ) except KeyError as err : raise KeyError ( f \"No resampler for time series { time_series_id } found!\" ) from err add_time_series ( time_series_id ) \u00a4 Create a new resampler for a specific time series. If resampler already exists for the provided time_series_id , it will be used without creating a new one. PARAMETER DESCRIPTION time_series_id time series id TYPE: str Source code in frequenz/sdk/timeseries/_resampler.py 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 def add_time_series ( self , time_series_id : str ) -> None : \"\"\"Create a new resampler for a specific time series. If resampler already exists for the provided `time_series_id`, it will be used without creating a new one. Args: time_series_id: time series id \"\"\" if time_series_id in self . _resamplers : return self . _resamplers [ time_series_id ] = Resampler ( resampling_period_s = self . _resampling_period_s , max_data_age_in_periods = self . _max_data_age_in_periods , resampling_function = self . _initial_resampling_function , ) remove_timeseries ( time_series_id ) \u00a4 Remove a resampler for a specific time series. PARAMETER DESCRIPTION time_series_id time series id, for which to remove the resampler TYPE: str RAISES DESCRIPTION KeyError if resampler for the provided timer_series_id doesn't exist Source code in frequenz/sdk/timeseries/_resampler.py 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 def remove_timeseries ( self , time_series_id : str ) -> None : \"\"\"Remove a resampler for a specific time series. Args: time_series_id: time series id, for which to remove the resampler Raises: KeyError: if resampler for the provided timer_series_id doesn't exist \"\"\" try : del self . _resamplers [ time_series_id ] except KeyError as err : raise KeyError ( f \"No resampler for time series { time_series_id } found!\" ) from err resample ( timestamp = None ) \u00a4 Resample samples for all time series. PARAMETER DESCRIPTION timestamp the timestamp to use to emit the new samples (and to consider stored samples relevant for resampling. If None , the current datetime (in UTC) will be used. TYPE: Optional [ datetime ] DEFAULT: None YIELDS DESCRIPTION Generator [ Tuple [ str , Sample ], None, None] iterator of time series ids and their newly resampled samples Source code in frequenz/sdk/timeseries/_resampler.py 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 def resample ( self , timestamp : Optional [ datetime ] = None ) -> Generator [ Tuple [ str , Sample ], None , None ]: \"\"\"Resample samples for all time series. Args: timestamp: the timestamp to use to emit the new samples (and to consider stored samples relevant for resampling. If `None`, the current datetime (in UTC) will be used. Yields: iterator of time series ids and their newly resampled samples \"\"\" if timestamp is None : timestamp = datetime . now ( timezone . utc ) for time_series_id , resampler in self . _resamplers . items (): yield time_series_id , Sample ( timestamp = timestamp , value = resampler . resample ( timestamp ) ) frequenz.sdk.timeseries.Resampler \u00a4 Ingests samples and produces resampled data for one timeseries. Samples are stored in an internal ring buffer. All collected samples that are newer than resampling_period_s * max_data_age_in_periods seconds will be passed to the provided ResamplingFunction . Source code in frequenz/sdk/timeseries/_resampler.py 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 class Resampler : \"\"\"Ingests samples and produces resampled data for one timeseries. Samples are stored in an internal ring buffer. All collected samples that are newer than `resampling_period_s * max_data_age_in_periods` seconds will be passed to the provided [ResamplingFunction][frequenz.sdk.timeseries.ResamplingFunction]. \"\"\" def __init__ ( self , resampling_period_s : float , max_data_age_in_periods : float , resampling_function : ResamplingFunction , ) -> None : \"\"\"Initialize the ComponentMetricResampler. Args: resampling_period_s: value describing how often resampling should be performed, in seconds max_data_age_in_periods: max age that samples shouldn't exceed in order to be used in the resampling function resampling_function: function to be applied to a sequence of samples within a resampling period to produce a single output sample \"\"\" self . _resampling_period_s = resampling_period_s self . _max_data_age_in_periods : float = max_data_age_in_periods self . _buffer : Deque [ Sample ] = deque () self . _resampling_function : ResamplingFunction = resampling_function def add_sample ( self , sample : Sample ) -> None : \"\"\"Add a new sample. Args: sample: sample to be added to the buffer \"\"\" self . _buffer . append ( sample ) def _remove_outdated_samples ( self , threshold : datetime ) -> None : \"\"\"Remove samples that are older than the provided time threshold. It is assumed that items in the buffer are in a sorted order (ascending order by timestamp). The removal works by traversing the buffer starting from the oldest sample (smallest timestamp) and comparing sample's timestamp with the threshold. If the sample's threshold is smaller than `threshold`, it means that the sample is outdated and it is removed from the buffer. This continues until the first sample that is with timestamp greater or equal to `threshold` is encountered, then buffer is considered up to date. Args: threshold: samples whose timestamp is older than the threshold are considered outdated and should be remove from the buffer \"\"\" while self . _buffer : sample : Sample = self . _buffer [ 0 ] if sample . timestamp >= threshold : return self . _buffer . popleft () def resample ( self , timestamp : Optional [ datetime ] = None ) -> Optional [ float ]: \"\"\"Resample samples from the buffer and produce a single sample. Args: timestamp: the timestamp to use to as the current resampling timestamp when calculating which stored past samples are relevant to pass to the resampling function. If `None`, the current datetime (in UTC) will be used. Returns: Samples resampled into a single sample or `None` if the `resampling_function` cannot produce a valid Sample. \"\"\" if timestamp is None : timestamp = datetime . now ( timezone . utc ) threshold = timestamp - timedelta ( seconds = self . _max_data_age_in_periods * self . _resampling_period_s ) self . _remove_outdated_samples ( threshold = threshold ) if len ( self . _buffer ) == 0 : return None return self . _resampling_function ( self . _buffer , self . _resampling_period_s ) Functions \u00a4 __init__ ( resampling_period_s , max_data_age_in_periods , resampling_function ) \u00a4 Initialize the ComponentMetricResampler. PARAMETER DESCRIPTION resampling_period_s value describing how often resampling should be performed, in seconds TYPE: float max_data_age_in_periods max age that samples shouldn't exceed in order to be used in the resampling function TYPE: float resampling_function function to be applied to a sequence of samples within a resampling period to produce a single output sample TYPE: ResamplingFunction Source code in frequenz/sdk/timeseries/_resampler.py 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 def __init__ ( self , resampling_period_s : float , max_data_age_in_periods : float , resampling_function : ResamplingFunction , ) -> None : \"\"\"Initialize the ComponentMetricResampler. Args: resampling_period_s: value describing how often resampling should be performed, in seconds max_data_age_in_periods: max age that samples shouldn't exceed in order to be used in the resampling function resampling_function: function to be applied to a sequence of samples within a resampling period to produce a single output sample \"\"\" self . _resampling_period_s = resampling_period_s self . _max_data_age_in_periods : float = max_data_age_in_periods self . _buffer : Deque [ Sample ] = deque () self . _resampling_function : ResamplingFunction = resampling_function add_sample ( sample ) \u00a4 Add a new sample. PARAMETER DESCRIPTION sample sample to be added to the buffer TYPE: Sample Source code in frequenz/sdk/timeseries/_resampler.py 70 71 72 73 74 75 76 def add_sample ( self , sample : Sample ) -> None : \"\"\"Add a new sample. Args: sample: sample to be added to the buffer \"\"\" self . _buffer . append ( sample ) resample ( timestamp = None ) \u00a4 Resample samples from the buffer and produce a single sample. PARAMETER DESCRIPTION timestamp the timestamp to use to as the current resampling timestamp when calculating which stored past samples are relevant to pass to the resampling function. If None , the current datetime (in UTC) will be used. TYPE: Optional [ datetime ] DEFAULT: None RETURNS DESCRIPTION Optional [ float ] Samples resampled into a single sample or None if the resampling_function cannot produce a valid Sample. Source code in frequenz/sdk/timeseries/_resampler.py 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 def resample ( self , timestamp : Optional [ datetime ] = None ) -> Optional [ float ]: \"\"\"Resample samples from the buffer and produce a single sample. Args: timestamp: the timestamp to use to as the current resampling timestamp when calculating which stored past samples are relevant to pass to the resampling function. If `None`, the current datetime (in UTC) will be used. Returns: Samples resampled into a single sample or `None` if the `resampling_function` cannot produce a valid Sample. \"\"\" if timestamp is None : timestamp = datetime . now ( timezone . utc ) threshold = timestamp - timedelta ( seconds = self . _max_data_age_in_periods * self . _resampling_period_s ) self . _remove_outdated_samples ( threshold = threshold ) if len ( self . _buffer ) == 0 : return None return self . _resampling_function ( self . _buffer , self . _resampling_period_s ) frequenz.sdk.timeseries.Sample dataclass \u00a4 A measurement taken at a particular point in time. The value could be None if a component is malfunctioning or data is lacking for another reason, but a sample still needs to be sent to have a coherent view on a group of component metrics for a particular timestamp. Source code in frequenz/sdk/timeseries/sample.py 11 12 13 14 15 16 17 18 19 20 21 @dataclass ( frozen = True ) class Sample : \"\"\"A measurement taken at a particular point in time. The `value` could be `None` if a component is malfunctioning or data is lacking for another reason, but a sample still needs to be sent to have a coherent view on a group of component metrics for a particular timestamp. \"\"\" timestamp : datetime value : Optional [ float ] = None","title":"timeseries"},{"location":"reference/frequenz/sdk/timeseries/#frequenz.sdk.timeseries","text":"Handling of timeseries streams. A timeseries is a stream (normally an async iterator) of samples . This module provides tools to operate on timeseries.","title":"timeseries"},{"location":"reference/frequenz/sdk/timeseries/#frequenz.sdk.timeseries-attributes","text":"","title":"Attributes"},{"location":"reference/frequenz/sdk/timeseries/#frequenz.sdk.timeseries.ResamplingFunction","text":"Resampling function type. A resampling function produces a new sample based on a list of pre-existing samples. It can do \"upsampling\" when there data rate of the input_samples period is smaller than the resampling_period_s , or \"downsampling\" if it is bigger. In general a resampling window is the same as the resampling_period_s , and this function might receive input samples from multiple windows in the past to enable extrapolation, but no samples from the future (so the timestamp of the new sample that is going to be produced will always be bigger than the biggest timestamp in the input data). PARAMETER DESCRIPTION input_samples the sequence of pre-existing samples. TYPE: Sequence [ Sample ] resampling_period_s the period in seconds (i.e. how ofter a new sample is produced. TYPE: float RETURNS DESCRIPTION new_sample The value of new sample produced after the resampling. TYPE: float","title":"ResamplingFunction"},{"location":"reference/frequenz/sdk/timeseries/#frequenz.sdk.timeseries-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/timeseries/#frequenz.sdk.timeseries.GroupResampler","text":"Ingests samples and produces resampled data for a group of timeseries. Like the Resampler but handles a group of timeseries. Source code in frequenz/sdk/timeseries/_resampler.py 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 class GroupResampler : \"\"\"Ingests samples and produces resampled data for a group of timeseries. Like the [Resampler][frequenz.sdk.timeseries.Resampler] but handles a group of timeseries. \"\"\" def __init__ ( self , * , resampling_period_s : float , initial_resampling_function : ResamplingFunction , max_data_age_in_periods : float = 3.0 , ) -> None : \"\"\"Initialize the ComponentMetricGroupResampler. Args: resampling_period_s: value describing how often resampling should be performed, in seconds initial_resampling_function: function to be applied to a sequence of samples within a resampling period to produce a single output sample max_data_age_in_periods: max age that samples shouldn't exceed in order to be used in the resampling function \"\"\" self . _resampling_period_s = resampling_period_s self . _max_data_age_in_periods : float = max_data_age_in_periods self . _initial_resampling_function : ResamplingFunction = ( initial_resampling_function ) self . _resamplers : Dict [ str , Resampler ] = {} def add_time_series ( self , time_series_id : str ) -> None : \"\"\"Create a new resampler for a specific time series. If resampler already exists for the provided `time_series_id`, it will be used without creating a new one. Args: time_series_id: time series id \"\"\" if time_series_id in self . _resamplers : return self . _resamplers [ time_series_id ] = Resampler ( resampling_period_s = self . _resampling_period_s , max_data_age_in_periods = self . _max_data_age_in_periods , resampling_function = self . _initial_resampling_function , ) def remove_timeseries ( self , time_series_id : str ) -> None : \"\"\"Remove a resampler for a specific time series. Args: time_series_id: time series id, for which to remove the resampler Raises: KeyError: if resampler for the provided timer_series_id doesn't exist \"\"\" try : del self . _resamplers [ time_series_id ] except KeyError as err : raise KeyError ( f \"No resampler for time series { time_series_id } found!\" ) from err def add_sample ( self , time_series_id : str , sample : Sample ) -> None : \"\"\"Add a sample for a specific time series. Args: time_series_id: time series id, which the sample should be added to sample: sample to be added Raises: KeyError: if resampler for the provided timer_series_id doesn't exist \"\"\" try : self . _resamplers [ time_series_id ] . add_sample ( sample ) except KeyError as err : raise KeyError ( f \"No resampler for time series { time_series_id } found!\" ) from err def resample ( self , timestamp : Optional [ datetime ] = None ) -> Generator [ Tuple [ str , Sample ], None , None ]: \"\"\"Resample samples for all time series. Args: timestamp: the timestamp to use to emit the new samples (and to consider stored samples relevant for resampling. If `None`, the current datetime (in UTC) will be used. Yields: iterator of time series ids and their newly resampled samples \"\"\" if timestamp is None : timestamp = datetime . now ( timezone . utc ) for time_series_id , resampler in self . _resamplers . items (): yield time_series_id , Sample ( timestamp = timestamp , value = resampler . resample ( timestamp ) )","title":"GroupResampler"},{"location":"reference/frequenz/sdk/timeseries/#frequenz.sdk.timeseries.GroupResampler-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/timeseries/#frequenz.sdk.timeseries._resampler.GroupResampler.__init__","text":"Initialize the ComponentMetricGroupResampler. PARAMETER DESCRIPTION resampling_period_s value describing how often resampling should be performed, in seconds TYPE: float initial_resampling_function function to be applied to a sequence of samples within a resampling period to produce a single output sample TYPE: ResamplingFunction max_data_age_in_periods max age that samples shouldn't exceed in order to be used in the resampling function TYPE: float DEFAULT: 3.0 Source code in frequenz/sdk/timeseries/_resampler.py 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 def __init__ ( self , * , resampling_period_s : float , initial_resampling_function : ResamplingFunction , max_data_age_in_periods : float = 3.0 , ) -> None : \"\"\"Initialize the ComponentMetricGroupResampler. Args: resampling_period_s: value describing how often resampling should be performed, in seconds initial_resampling_function: function to be applied to a sequence of samples within a resampling period to produce a single output sample max_data_age_in_periods: max age that samples shouldn't exceed in order to be used in the resampling function \"\"\" self . _resampling_period_s = resampling_period_s self . _max_data_age_in_periods : float = max_data_age_in_periods self . _initial_resampling_function : ResamplingFunction = ( initial_resampling_function ) self . _resamplers : Dict [ str , Resampler ] = {}","title":"__init__()"},{"location":"reference/frequenz/sdk/timeseries/#frequenz.sdk.timeseries._resampler.GroupResampler.add_sample","text":"Add a sample for a specific time series. PARAMETER DESCRIPTION time_series_id time series id, which the sample should be added to TYPE: str sample sample to be added TYPE: Sample RAISES DESCRIPTION KeyError if resampler for the provided timer_series_id doesn't exist Source code in frequenz/sdk/timeseries/_resampler.py 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 def add_sample ( self , time_series_id : str , sample : Sample ) -> None : \"\"\"Add a sample for a specific time series. Args: time_series_id: time series id, which the sample should be added to sample: sample to be added Raises: KeyError: if resampler for the provided timer_series_id doesn't exist \"\"\" try : self . _resamplers [ time_series_id ] . add_sample ( sample ) except KeyError as err : raise KeyError ( f \"No resampler for time series { time_series_id } found!\" ) from err","title":"add_sample()"},{"location":"reference/frequenz/sdk/timeseries/#frequenz.sdk.timeseries._resampler.GroupResampler.add_time_series","text":"Create a new resampler for a specific time series. If resampler already exists for the provided time_series_id , it will be used without creating a new one. PARAMETER DESCRIPTION time_series_id time series id TYPE: str Source code in frequenz/sdk/timeseries/_resampler.py 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 def add_time_series ( self , time_series_id : str ) -> None : \"\"\"Create a new resampler for a specific time series. If resampler already exists for the provided `time_series_id`, it will be used without creating a new one. Args: time_series_id: time series id \"\"\" if time_series_id in self . _resamplers : return self . _resamplers [ time_series_id ] = Resampler ( resampling_period_s = self . _resampling_period_s , max_data_age_in_periods = self . _max_data_age_in_periods , resampling_function = self . _initial_resampling_function , )","title":"add_time_series()"},{"location":"reference/frequenz/sdk/timeseries/#frequenz.sdk.timeseries._resampler.GroupResampler.remove_timeseries","text":"Remove a resampler for a specific time series. PARAMETER DESCRIPTION time_series_id time series id, for which to remove the resampler TYPE: str RAISES DESCRIPTION KeyError if resampler for the provided timer_series_id doesn't exist Source code in frequenz/sdk/timeseries/_resampler.py 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 def remove_timeseries ( self , time_series_id : str ) -> None : \"\"\"Remove a resampler for a specific time series. Args: time_series_id: time series id, for which to remove the resampler Raises: KeyError: if resampler for the provided timer_series_id doesn't exist \"\"\" try : del self . _resamplers [ time_series_id ] except KeyError as err : raise KeyError ( f \"No resampler for time series { time_series_id } found!\" ) from err","title":"remove_timeseries()"},{"location":"reference/frequenz/sdk/timeseries/#frequenz.sdk.timeseries._resampler.GroupResampler.resample","text":"Resample samples for all time series. PARAMETER DESCRIPTION timestamp the timestamp to use to emit the new samples (and to consider stored samples relevant for resampling. If None , the current datetime (in UTC) will be used. TYPE: Optional [ datetime ] DEFAULT: None YIELDS DESCRIPTION Generator [ Tuple [ str , Sample ], None, None] iterator of time series ids and their newly resampled samples Source code in frequenz/sdk/timeseries/_resampler.py 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 def resample ( self , timestamp : Optional [ datetime ] = None ) -> Generator [ Tuple [ str , Sample ], None , None ]: \"\"\"Resample samples for all time series. Args: timestamp: the timestamp to use to emit the new samples (and to consider stored samples relevant for resampling. If `None`, the current datetime (in UTC) will be used. Yields: iterator of time series ids and their newly resampled samples \"\"\" if timestamp is None : timestamp = datetime . now ( timezone . utc ) for time_series_id , resampler in self . _resamplers . items (): yield time_series_id , Sample ( timestamp = timestamp , value = resampler . resample ( timestamp ) )","title":"resample()"},{"location":"reference/frequenz/sdk/timeseries/#frequenz.sdk.timeseries.Resampler","text":"Ingests samples and produces resampled data for one timeseries. Samples are stored in an internal ring buffer. All collected samples that are newer than resampling_period_s * max_data_age_in_periods seconds will be passed to the provided ResamplingFunction . Source code in frequenz/sdk/timeseries/_resampler.py 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 class Resampler : \"\"\"Ingests samples and produces resampled data for one timeseries. Samples are stored in an internal ring buffer. All collected samples that are newer than `resampling_period_s * max_data_age_in_periods` seconds will be passed to the provided [ResamplingFunction][frequenz.sdk.timeseries.ResamplingFunction]. \"\"\" def __init__ ( self , resampling_period_s : float , max_data_age_in_periods : float , resampling_function : ResamplingFunction , ) -> None : \"\"\"Initialize the ComponentMetricResampler. Args: resampling_period_s: value describing how often resampling should be performed, in seconds max_data_age_in_periods: max age that samples shouldn't exceed in order to be used in the resampling function resampling_function: function to be applied to a sequence of samples within a resampling period to produce a single output sample \"\"\" self . _resampling_period_s = resampling_period_s self . _max_data_age_in_periods : float = max_data_age_in_periods self . _buffer : Deque [ Sample ] = deque () self . _resampling_function : ResamplingFunction = resampling_function def add_sample ( self , sample : Sample ) -> None : \"\"\"Add a new sample. Args: sample: sample to be added to the buffer \"\"\" self . _buffer . append ( sample ) def _remove_outdated_samples ( self , threshold : datetime ) -> None : \"\"\"Remove samples that are older than the provided time threshold. It is assumed that items in the buffer are in a sorted order (ascending order by timestamp). The removal works by traversing the buffer starting from the oldest sample (smallest timestamp) and comparing sample's timestamp with the threshold. If the sample's threshold is smaller than `threshold`, it means that the sample is outdated and it is removed from the buffer. This continues until the first sample that is with timestamp greater or equal to `threshold` is encountered, then buffer is considered up to date. Args: threshold: samples whose timestamp is older than the threshold are considered outdated and should be remove from the buffer \"\"\" while self . _buffer : sample : Sample = self . _buffer [ 0 ] if sample . timestamp >= threshold : return self . _buffer . popleft () def resample ( self , timestamp : Optional [ datetime ] = None ) -> Optional [ float ]: \"\"\"Resample samples from the buffer and produce a single sample. Args: timestamp: the timestamp to use to as the current resampling timestamp when calculating which stored past samples are relevant to pass to the resampling function. If `None`, the current datetime (in UTC) will be used. Returns: Samples resampled into a single sample or `None` if the `resampling_function` cannot produce a valid Sample. \"\"\" if timestamp is None : timestamp = datetime . now ( timezone . utc ) threshold = timestamp - timedelta ( seconds = self . _max_data_age_in_periods * self . _resampling_period_s ) self . _remove_outdated_samples ( threshold = threshold ) if len ( self . _buffer ) == 0 : return None return self . _resampling_function ( self . _buffer , self . _resampling_period_s )","title":"Resampler"},{"location":"reference/frequenz/sdk/timeseries/#frequenz.sdk.timeseries.Resampler-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/timeseries/#frequenz.sdk.timeseries._resampler.Resampler.__init__","text":"Initialize the ComponentMetricResampler. PARAMETER DESCRIPTION resampling_period_s value describing how often resampling should be performed, in seconds TYPE: float max_data_age_in_periods max age that samples shouldn't exceed in order to be used in the resampling function TYPE: float resampling_function function to be applied to a sequence of samples within a resampling period to produce a single output sample TYPE: ResamplingFunction Source code in frequenz/sdk/timeseries/_resampler.py 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 def __init__ ( self , resampling_period_s : float , max_data_age_in_periods : float , resampling_function : ResamplingFunction , ) -> None : \"\"\"Initialize the ComponentMetricResampler. Args: resampling_period_s: value describing how often resampling should be performed, in seconds max_data_age_in_periods: max age that samples shouldn't exceed in order to be used in the resampling function resampling_function: function to be applied to a sequence of samples within a resampling period to produce a single output sample \"\"\" self . _resampling_period_s = resampling_period_s self . _max_data_age_in_periods : float = max_data_age_in_periods self . _buffer : Deque [ Sample ] = deque () self . _resampling_function : ResamplingFunction = resampling_function","title":"__init__()"},{"location":"reference/frequenz/sdk/timeseries/#frequenz.sdk.timeseries._resampler.Resampler.add_sample","text":"Add a new sample. PARAMETER DESCRIPTION sample sample to be added to the buffer TYPE: Sample Source code in frequenz/sdk/timeseries/_resampler.py 70 71 72 73 74 75 76 def add_sample ( self , sample : Sample ) -> None : \"\"\"Add a new sample. Args: sample: sample to be added to the buffer \"\"\" self . _buffer . append ( sample )","title":"add_sample()"},{"location":"reference/frequenz/sdk/timeseries/#frequenz.sdk.timeseries._resampler.Resampler.resample","text":"Resample samples from the buffer and produce a single sample. PARAMETER DESCRIPTION timestamp the timestamp to use to as the current resampling timestamp when calculating which stored past samples are relevant to pass to the resampling function. If None , the current datetime (in UTC) will be used. TYPE: Optional [ datetime ] DEFAULT: None RETURNS DESCRIPTION Optional [ float ] Samples resampled into a single sample or None if the resampling_function cannot produce a valid Sample. Source code in frequenz/sdk/timeseries/_resampler.py 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 def resample ( self , timestamp : Optional [ datetime ] = None ) -> Optional [ float ]: \"\"\"Resample samples from the buffer and produce a single sample. Args: timestamp: the timestamp to use to as the current resampling timestamp when calculating which stored past samples are relevant to pass to the resampling function. If `None`, the current datetime (in UTC) will be used. Returns: Samples resampled into a single sample or `None` if the `resampling_function` cannot produce a valid Sample. \"\"\" if timestamp is None : timestamp = datetime . now ( timezone . utc ) threshold = timestamp - timedelta ( seconds = self . _max_data_age_in_periods * self . _resampling_period_s ) self . _remove_outdated_samples ( threshold = threshold ) if len ( self . _buffer ) == 0 : return None return self . _resampling_function ( self . _buffer , self . _resampling_period_s )","title":"resample()"},{"location":"reference/frequenz/sdk/timeseries/#frequenz.sdk.timeseries.Sample","text":"A measurement taken at a particular point in time. The value could be None if a component is malfunctioning or data is lacking for another reason, but a sample still needs to be sent to have a coherent view on a group of component metrics for a particular timestamp. Source code in frequenz/sdk/timeseries/sample.py 11 12 13 14 15 16 17 18 19 20 21 @dataclass ( frozen = True ) class Sample : \"\"\"A measurement taken at a particular point in time. The `value` could be `None` if a component is malfunctioning or data is lacking for another reason, but a sample still needs to be sent to have a coherent view on a group of component metrics for a particular timestamp. \"\"\" timestamp : datetime value : Optional [ float ] = None","title":"Sample"},{"location":"reference/frequenz/sdk/timeseries/sample/","text":"frequenz.sdk.timeseries.sample \u00a4 Common types for the Data Pipeline. Classes \u00a4 frequenz.sdk.timeseries.sample.Sample dataclass \u00a4 A measurement taken at a particular point in time. The value could be None if a component is malfunctioning or data is lacking for another reason, but a sample still needs to be sent to have a coherent view on a group of component metrics for a particular timestamp. Source code in frequenz/sdk/timeseries/sample.py 11 12 13 14 15 16 17 18 19 20 21 @dataclass ( frozen = True ) class Sample : \"\"\"A measurement taken at a particular point in time. The `value` could be `None` if a component is malfunctioning or data is lacking for another reason, but a sample still needs to be sent to have a coherent view on a group of component metrics for a particular timestamp. \"\"\" timestamp : datetime value : Optional [ float ] = None","title":"sample"},{"location":"reference/frequenz/sdk/timeseries/sample/#frequenz.sdk.timeseries.sample","text":"Common types for the Data Pipeline.","title":"sample"},{"location":"reference/frequenz/sdk/timeseries/sample/#frequenz.sdk.timeseries.sample-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/timeseries/sample/#frequenz.sdk.timeseries.sample.Sample","text":"A measurement taken at a particular point in time. The value could be None if a component is malfunctioning or data is lacking for another reason, but a sample still needs to be sent to have a coherent view on a group of component metrics for a particular timestamp. Source code in frequenz/sdk/timeseries/sample.py 11 12 13 14 15 16 17 18 19 20 21 @dataclass ( frozen = True ) class Sample : \"\"\"A measurement taken at a particular point in time. The `value` could be `None` if a component is malfunctioning or data is lacking for another reason, but a sample still needs to be sent to have a coherent view on a group of component metrics for a particular timestamp. \"\"\" timestamp : datetime value : Optional [ float ] = None","title":"Sample"}]}