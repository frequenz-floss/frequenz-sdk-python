{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Frequenz Python SDK \u00a4 A development kit to interact with the Frequenz development platform. Supported Python versions \u00a4 For x86_64 Python 3.8 - 3.10 are supported (tested). For arm64 only Python 3.8 is supported (due to some dependencies that only support 3.8). Contributing \u00a4 If you want to know how to build this project and contribute to it, please check out the Contributing Guide .","title":"Home"},{"location":"#frequenz-python-sdk","text":"A development kit to interact with the Frequenz development platform.","title":"Frequenz Python SDK"},{"location":"#supported-python-versions","text":"For x86_64 Python 3.8 - 3.10 are supported (tested). For arm64 only Python 3.8 is supported (due to some dependencies that only support 3.8).","title":"Supported Python versions"},{"location":"#contributing","text":"If you want to know how to build this project and contribute to it, please check out the Contributing Guide .","title":"Contributing"},{"location":"CONTRIBUTING/","text":"Contributing to frequenz-sdk \u00a4 Build \u00a4 You can use build to simply build the source and binary distribution: python -m pip install build python -m build Local development \u00a4 You can use editable installs to develop the project locally (it will install all the dependencies too): python -m pip install -e . You can also use nox to run the tests and other checks: python -m pip install nox nox You can also use nox -R to reuse the current testing environment to speed up test at the expense of a higher chance to end up with a dirty test environment. Running tests individually \u00a4 For a better development test cycle you can install the runtime and test dependencies and run pytest manually. python -m pip install . python -m pip install pytest pytest-asyncio # And for example pytest tests/test_sdk.py To build the documentation, first install the dependencies: python -m pip install -e . [ docs ] Then you can build the documentation (it will be written in the site/ directory): mkdocs build Or you can just serve the documentation without building it using: mkdocs serve Your site will be updated live when you change your files (provided that you used pip install -e . , beware of a common pitfall of using pip install without -e , in that case the API reference won't change unless you do a new pip install ). To build multi-version documentation, we use mike . If you want to see how the multi-version sites looks like locally, you can use: mike deploy my-version mike set-default my-version mike serve mike works in mysterious ways. Some basic information: mike deploy will do a mike build and write the results to your local gh-pages branch. my-version is an arbitrary name for the local version you want to preview. mike set-default is needed so when you serve the documentation, it goes to your newly produced documentation by default. mike serve will serve the contents of your local gh-pages branch. Be aware that, unlike mkdocs serve , changes to the sources won't be shown live, as the mike deploy step is needed to refresh them. Be careful not to use --push with mike deploy , otherwise it will push your local gh-pages branch to the origin remote. That said, if you want to test the actual website in your fork , you can always use mike deploy --push --remote your-fork-remote , and then access the GitHub pages produced for your fork. Releasing \u00a4 These are the steps to create a new release: Get the latest head you want to create a release from. Update the RELEASE_NOTES.md file if it is not complete, up to date, and clean from template comments ( <!-- ... -> ) and empty sections. Submit a pull request if an update is needed, wait until it is merged, and update the latest head you want to create a release from to get the new merged pull request. Create a new signed tag using the release notes and a semver compatible version number with a v prefix, for example: git tag -s -F RELEASE_NOTES.md v0.0.1 Push the new tag. A GitHub action will test the tag and if all goes well it will create a GitHub Release , create a new announcement about the release, and upload a new package to PyPI automatically. Once this is done, reset the RELEASE_NOTES.md with the template: cp .github/RELEASE_NOTES.template.md RELEASE_NOTES.md Commit the new release notes and create a PR (this step should be automated eventually too). Celebrate!","title":"Development"},{"location":"CONTRIBUTING/#contributing-to-frequenz-sdk","text":"","title":"Contributing to frequenz-sdk"},{"location":"CONTRIBUTING/#build","text":"You can use build to simply build the source and binary distribution: python -m pip install build python -m build","title":"Build"},{"location":"CONTRIBUTING/#local-development","text":"You can use editable installs to develop the project locally (it will install all the dependencies too): python -m pip install -e . You can also use nox to run the tests and other checks: python -m pip install nox nox You can also use nox -R to reuse the current testing environment to speed up test at the expense of a higher chance to end up with a dirty test environment.","title":"Local development"},{"location":"CONTRIBUTING/#running-tests-individually","text":"For a better development test cycle you can install the runtime and test dependencies and run pytest manually. python -m pip install . python -m pip install pytest pytest-asyncio # And for example pytest tests/test_sdk.py To build the documentation, first install the dependencies: python -m pip install -e . [ docs ] Then you can build the documentation (it will be written in the site/ directory): mkdocs build Or you can just serve the documentation without building it using: mkdocs serve Your site will be updated live when you change your files (provided that you used pip install -e . , beware of a common pitfall of using pip install without -e , in that case the API reference won't change unless you do a new pip install ). To build multi-version documentation, we use mike . If you want to see how the multi-version sites looks like locally, you can use: mike deploy my-version mike set-default my-version mike serve mike works in mysterious ways. Some basic information: mike deploy will do a mike build and write the results to your local gh-pages branch. my-version is an arbitrary name for the local version you want to preview. mike set-default is needed so when you serve the documentation, it goes to your newly produced documentation by default. mike serve will serve the contents of your local gh-pages branch. Be aware that, unlike mkdocs serve , changes to the sources won't be shown live, as the mike deploy step is needed to refresh them. Be careful not to use --push with mike deploy , otherwise it will push your local gh-pages branch to the origin remote. That said, if you want to test the actual website in your fork , you can always use mike deploy --push --remote your-fork-remote , and then access the GitHub pages produced for your fork.","title":"Running tests individually"},{"location":"CONTRIBUTING/#releasing","text":"These are the steps to create a new release: Get the latest head you want to create a release from. Update the RELEASE_NOTES.md file if it is not complete, up to date, and clean from template comments ( <!-- ... -> ) and empty sections. Submit a pull request if an update is needed, wait until it is merged, and update the latest head you want to create a release from to get the new merged pull request. Create a new signed tag using the release notes and a semver compatible version number with a v prefix, for example: git tag -s -F RELEASE_NOTES.md v0.0.1 Push the new tag. A GitHub action will test the tag and if all goes well it will create a GitHub Release , create a new announcement about the release, and upload a new package to PyPI automatically. Once this is done, reset the RELEASE_NOTES.md with the template: cp .github/RELEASE_NOTES.template.md RELEASE_NOTES.md Commit the new release notes and create a PR (this step should be automated eventually too). Celebrate!","title":"Releasing"},{"location":"SUMMARY/","text":"Home API Reference Development","title":"SUMMARY"},{"location":"reference/SUMMARY/","text":"frequenz sdk actor power_distributing config microgrid client component power timeseries logical_meter","title":"SUMMARY"},{"location":"reference/frequenz/sdk/","text":"frequenz.sdk \u00a4 Frequenz Python SDK.","title":"sdk"},{"location":"reference/frequenz/sdk/#frequenz.sdk","text":"Frequenz Python SDK.","title":"sdk"},{"location":"reference/frequenz/sdk/actor/","text":"frequenz.sdk.actor \u00a4 A base class for creating simple composable actors. Classes \u00a4 frequenz.sdk.actor.ChannelRegistry \u00a4 Dynamically creates, own and provide access to channels. It can be used by actors to dynamically establish a communication channel between each other. Channels are identified by string names. Source code in frequenz/sdk/actor/_channel_registry.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 class ChannelRegistry : \"\"\"Dynamically creates, own and provide access to channels. It can be used by actors to dynamically establish a communication channel between each other. Channels are identified by string names. \"\"\" def __init__ ( self , * , name : str ) -> None : \"\"\"Create a `ChannelRegistry` instance. Args: name: A unique name for the registry. \"\"\" self . _name = name self . _channels : Dict [ str , Broadcast [ Any ]] = {} def new_sender ( self , key : str ) -> Sender [ Any ]: \"\"\"Get a sender to a dynamically created channel with the given key. Args: key: A key to identify the channel. Returns: A sender to a dynamically created channel with the given key. \"\"\" if key not in self . _channels : self . _channels [ key ] = Broadcast ( f \" { self . _name } - { key } \" ) return self . _channels [ key ] . new_sender () def new_receiver ( self , key : str ) -> Receiver [ Any ]: \"\"\"Get a receiver to a dynamically created channel with the given key. Args: key: A key to identify the channel. Returns: A receiver for a dynamically created channel with the given key. \"\"\" if key not in self . _channels : self . _channels [ key ] = Broadcast ( f \" { self . _name } - { key } \" ) return self . _channels [ key ] . new_receiver () Functions \u00a4 __init__ ( * , name ) \u00a4 Create a ChannelRegistry instance. PARAMETER DESCRIPTION name A unique name for the registry. TYPE: str Source code in frequenz/sdk/actor/_channel_registry.py 18 19 20 21 22 23 24 25 def __init__ ( self , * , name : str ) -> None : \"\"\"Create a `ChannelRegistry` instance. Args: name: A unique name for the registry. \"\"\" self . _name = name self . _channels : Dict [ str , Broadcast [ Any ]] = {} new_receiver ( key ) \u00a4 Get a receiver to a dynamically created channel with the given key. PARAMETER DESCRIPTION key A key to identify the channel. TYPE: str RETURNS DESCRIPTION Receiver [ Any ] A receiver for a dynamically created channel with the given key. Source code in frequenz/sdk/actor/_channel_registry.py 40 41 42 43 44 45 46 47 48 49 50 51 def new_receiver ( self , key : str ) -> Receiver [ Any ]: \"\"\"Get a receiver to a dynamically created channel with the given key. Args: key: A key to identify the channel. Returns: A receiver for a dynamically created channel with the given key. \"\"\" if key not in self . _channels : self . _channels [ key ] = Broadcast ( f \" { self . _name } - { key } \" ) return self . _channels [ key ] . new_receiver () new_sender ( key ) \u00a4 Get a sender to a dynamically created channel with the given key. PARAMETER DESCRIPTION key A key to identify the channel. TYPE: str RETURNS DESCRIPTION Sender [ Any ] A sender to a dynamically created channel with the given key. Source code in frequenz/sdk/actor/_channel_registry.py 27 28 29 30 31 32 33 34 35 36 37 38 def new_sender ( self , key : str ) -> Sender [ Any ]: \"\"\"Get a sender to a dynamically created channel with the given key. Args: key: A key to identify the channel. Returns: A sender to a dynamically created channel with the given key. \"\"\" if key not in self . _channels : self . _channels [ key ] = Broadcast ( f \" { self . _name } - { key } \" ) return self . _channels [ key ] . new_sender () frequenz.sdk.actor.ComponentMetricRequest dataclass \u00a4 A request object to start streaming a metric for a component. Source code in frequenz/sdk/actor/_data_sourcing/microgrid_api_source.py 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 @dataclass class ComponentMetricRequest : \"\"\"A request object to start streaming a metric for a component.\"\"\" namespace : str \"\"\"The namespace that this request belongs to. Metric requests with a shared namespace enable the reuse of channels within that namespace. If for example, an actor making a multiple requests, uses the name of the actor as the namespace, then requests from the actor will get reused when possible. \"\"\" component_id : int \"\"\"The ID of the requested component.\"\"\" metric_id : ComponentMetricId \"\"\"The ID of the requested component's metric.\"\"\" start_time : Optional [ datetime ] \"\"\"The start time from which data is required. When None, we will stream only live data. \"\"\" def get_channel_name ( self ) -> str : \"\"\"Return a channel name constructed from Self. This channel name can be used by the sending side and receiving sides to identify the right channel from the ChannelRegistry. Returns: A string denoting a channel name. \"\"\" return f \" { self . component_id } :: { self . metric_id . name } :: { self . start_time } :: { self . namespace } \" Attributes \u00a4 component_id : int class-attribute \u00a4 The ID of the requested component. metric_id : ComponentMetricId class-attribute \u00a4 The ID of the requested component's metric. namespace : str class-attribute \u00a4 The namespace that this request belongs to. Metric requests with a shared namespace enable the reuse of channels within that namespace. If for example, an actor making a multiple requests, uses the name of the actor as the namespace, then requests from the actor will get reused when possible. start_time : Optional [ datetime ] class-attribute \u00a4 The start time from which data is required. When None, we will stream only live data. Functions \u00a4 get_channel_name () \u00a4 Return a channel name constructed from Self. This channel name can be used by the sending side and receiving sides to identify the right channel from the ChannelRegistry. RETURNS DESCRIPTION str A string denoting a channel name. Source code in frequenz/sdk/actor/_data_sourcing/microgrid_api_source.py 54 55 56 57 58 59 60 61 62 63 def get_channel_name ( self ) -> str : \"\"\"Return a channel name constructed from Self. This channel name can be used by the sending side and receiving sides to identify the right channel from the ChannelRegistry. Returns: A string denoting a channel name. \"\"\" return f \" { self . component_id } :: { self . metric_id . name } :: { self . start_time } :: { self . namespace } \" frequenz.sdk.actor.ComponentMetricsResamplingActor \u00a4 ComponentMetricsResamplingActor used to ingest component data and resample it. Source code in frequenz/sdk/actor/_resampling.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 @actor class ComponentMetricsResamplingActor : \"\"\"ComponentMetricsResamplingActor used to ingest component data and resample it.\"\"\" def __init__ ( # pylint: disable=too-many-arguments self , channel_registry : ChannelRegistry , subscription_sender : Sender [ ComponentMetricRequest ], subscription_receiver : Receiver [ ComponentMetricRequest ], resampling_period_s : float = 0.2 , max_data_age_in_periods : float = 3.0 , resampling_function : ResamplingFunction = average , ) -> None : \"\"\"Initialize the ComponentMetricsResamplingActor. Args: channel_registry: global channel registry used for receiving component data from DataSource and for sending resampled samples downstream subscription_sender: channel for sending component metric requests to the DataSourcing actor subscription_receiver: channel for receiving component metric requests resampling_period_s: value describing how often resampling should be performed, in seconds max_data_age_in_periods: max age that samples shouldn't exceed in order to be used in the resampling function resampling_function: function to be applied to a sequence of samples within a resampling period to produce a single output sample Example: ```python async def run() -> None: await microgrid_api.initialize(HOST, PORT) channel_registry = ChannelRegistry(name=\"Microgrid Channel Registry\") data_source_request_channel = Broadcast[ComponentMetricRequest]( \"Data Source Request Channel\" ) data_source_request_sender = data_source_request_channel.new_sender() data_source_request_receiver = data_source_request_channel.new_receiver() resampling_actor_request_channel = Broadcast[ComponentMetricRequest]( \"Resampling Actor Request Channel\" ) resampling_actor_request_sender = resampling_actor_request_channel.new_sender() resampling_actor_request_receiver = resampling_actor_request_channel.new_receiver() _data_sourcing_actor = DataSourcingActor( request_receiver=data_source_request_receiver, registry=channel_registry ) _resampling_actor = ComponentMetricsResamplingActor( channel_registry=channel_registry, subscription_sender=data_source_request_sender, subscription_receiver=resampling_actor_request_receiver, resampling_period_s=1.0, ) components = await microgrid_api.get().microgrid_api_client.components() battery_ids = [ comp.component_id for comp in components if comp.category == ComponentCategory.BATTERY ] subscription_requests = [ ComponentMetricRequest( namespace=\"Resampling\", component_id=component_id, metric_id=ComponentMetricId.SOC, start_time=None, ) for component_id in battery_ids ] await asyncio.gather( *[ resampling_actor_request_sender.send(request) for request in subscription_requests ] ) sample_receiver = MergeNamed( **{ channel_name: channel_registry.new_receiver(channel_name) for channel_name in map( lambda req: req.get_channel_name(), subscription_requests ) } ) async for channel_name, msg in sample_receiver: print(msg) asyncio.run(run()) ``` \"\"\" self . _channel_registry = channel_registry self . _subscription_sender = subscription_sender self . _subscription_receiver = subscription_receiver self . _resampling_period_s = resampling_period_s self . _max_data_age_in_periods : float = max_data_age_in_periods self . _resampling_function : ResamplingFunction = resampling_function self . _resampler = GroupResampler ( resampling_period_s = resampling_period_s , max_data_age_in_periods = max_data_age_in_periods , initial_resampling_function = resampling_function , ) self . _input_receivers : Dict [ str , Receiver [ Sample ]] = {} self . _output_senders : Dict [ str , Sender [ Sample ]] = {} self . _resampling_timer = Timer ( interval = self . _resampling_period_s ) async def _subscribe ( self , request : ComponentMetricRequest ) -> None : \"\"\"Subscribe for data for a specific time series. Args: request: subscription request for a specific component metric \"\"\" channel_name = request . get_channel_name () data_source_request = dataclasses . replace ( request , ** dict ( namespace = \"Source\" )) data_source_channel_name = data_source_request . get_channel_name () if channel_name not in self . _input_receivers : await self . _subscription_sender . send ( data_source_request ) receiver : Receiver [ Sample ] = self . _channel_registry . new_receiver ( data_source_channel_name ) self . _input_receivers [ data_source_channel_name ] = receiver self . _resampler . add_time_series ( time_series_id = data_source_channel_name ) if channel_name not in self . _output_senders : sender : Sender [ Sample ] = self . _channel_registry . new_sender ( channel_name ) # This means that the `sender` will be sending samples to the channel with # name `channel_name` based on samples collected from the channel named # `data_source_channel_name` self . _output_senders [ data_source_channel_name ] = sender def _is_sample_valid ( self , sample : Sample ) -> bool : \"\"\"Check if the provided sample is valid. Args: sample: sample to be validated Returns: True if the sample is valid, False otherwise \"\"\" if sample . value is None or math . isnan ( sample . value ): return False return True async def run ( self ) -> None : \"\"\"Run the actor. Raises: ConnectionError: When the provider of the subscription channel closes the connection \"\"\" while True : select = Select ( resampling_timer = self . _resampling_timer , subscription_receiver = self . _subscription_receiver , component_data_receiver = MergeNamed ( ** self . _input_receivers ), ) while await select . ready (): if msg := select . resampling_timer : assert msg . inner is not None , \"The timer should never be 'closed'\" timestamp = msg . inner awaitables = [ self . _output_senders [ channel_name ] . send ( sample ) for channel_name , sample in self . _resampler . resample ( timestamp ) ] await asyncio . gather ( * awaitables ) if msg := select . component_data_receiver : if msg . inner is None : # When this happens, then DataSourcingActor has closed the channel # for sending data for a specific `ComponentMetricRequest`, # which may need to be handled properly here, e.g. unsubscribe continue channel_name , sample = msg . inner if self . _is_sample_valid ( sample = sample ): self . _resampler . add_sample ( time_series_id = channel_name , sample = sample , ) if msg := select . subscription_receiver : if msg . inner is None : raise ConnectionError ( \"Subscription channel connection has been closed!\" ) await self . _subscribe ( request = msg . inner ) # Breaking out from the loop is required to regenerate # component_data_receivers to be able to fulfil this # subscription (later can be optimized by checking if # an output channel already existed in the `subscribe()` method) break Functions \u00a4 __init__ ( channel_registry , subscription_sender , subscription_receiver , resampling_period_s = 0.2 , max_data_age_in_periods = 3.0 , resampling_function = average ) \u00a4 Initialize the ComponentMetricsResamplingActor. PARAMETER DESCRIPTION channel_registry global channel registry used for receiving component data from DataSource and for sending resampled samples downstream TYPE: ChannelRegistry subscription_sender channel for sending component metric requests to the DataSourcing actor TYPE: Sender [ ComponentMetricRequest ] subscription_receiver channel for receiving component metric requests TYPE: Receiver [ ComponentMetricRequest ] resampling_period_s value describing how often resampling should be performed, in seconds TYPE: float DEFAULT: 0.2 max_data_age_in_periods max age that samples shouldn't exceed in order to be used in the resampling function TYPE: float DEFAULT: 3.0 resampling_function function to be applied to a sequence of samples within a resampling period to produce a single output sample TYPE: ResamplingFunction DEFAULT: average Example async def run () -> None : await microgrid_api . initialize ( HOST , PORT ) channel_registry = ChannelRegistry ( name = \"Microgrid Channel Registry\" ) data_source_request_channel = Broadcast [ ComponentMetricRequest ]( \"Data Source Request Channel\" ) data_source_request_sender = data_source_request_channel . new_sender () data_source_request_receiver = data_source_request_channel . new_receiver () resampling_actor_request_channel = Broadcast [ ComponentMetricRequest ]( \"Resampling Actor Request Channel\" ) resampling_actor_request_sender = resampling_actor_request_channel . new_sender () resampling_actor_request_receiver = resampling_actor_request_channel . new_receiver () _data_sourcing_actor = DataSourcingActor ( request_receiver = data_source_request_receiver , registry = channel_registry ) _resampling_actor = ComponentMetricsResamplingActor ( channel_registry = channel_registry , subscription_sender = data_source_request_sender , subscription_receiver = resampling_actor_request_receiver , resampling_period_s = 1.0 , ) components = await microgrid_api . get () . microgrid_api_client . components () battery_ids = [ comp . component_id for comp in components if comp . category == ComponentCategory . BATTERY ] subscription_requests = [ ComponentMetricRequest ( namespace = \"Resampling\" , component_id = component_id , metric_id = ComponentMetricId . SOC , start_time = None , ) for component_id in battery_ids ] await asyncio . gather ( * [ resampling_actor_request_sender . send ( request ) for request in subscription_requests ] ) sample_receiver = MergeNamed ( ** { channel_name : channel_registry . new_receiver ( channel_name ) for channel_name in map ( lambda req : req . get_channel_name (), subscription_requests ) } ) async for channel_name , msg in sample_receiver : print ( msg ) asyncio . run ( run ()) Source code in frequenz/sdk/actor/_resampling.py 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 def __init__ ( # pylint: disable=too-many-arguments self , channel_registry : ChannelRegistry , subscription_sender : Sender [ ComponentMetricRequest ], subscription_receiver : Receiver [ ComponentMetricRequest ], resampling_period_s : float = 0.2 , max_data_age_in_periods : float = 3.0 , resampling_function : ResamplingFunction = average , ) -> None : \"\"\"Initialize the ComponentMetricsResamplingActor. Args: channel_registry: global channel registry used for receiving component data from DataSource and for sending resampled samples downstream subscription_sender: channel for sending component metric requests to the DataSourcing actor subscription_receiver: channel for receiving component metric requests resampling_period_s: value describing how often resampling should be performed, in seconds max_data_age_in_periods: max age that samples shouldn't exceed in order to be used in the resampling function resampling_function: function to be applied to a sequence of samples within a resampling period to produce a single output sample Example: ```python async def run() -> None: await microgrid_api.initialize(HOST, PORT) channel_registry = ChannelRegistry(name=\"Microgrid Channel Registry\") data_source_request_channel = Broadcast[ComponentMetricRequest]( \"Data Source Request Channel\" ) data_source_request_sender = data_source_request_channel.new_sender() data_source_request_receiver = data_source_request_channel.new_receiver() resampling_actor_request_channel = Broadcast[ComponentMetricRequest]( \"Resampling Actor Request Channel\" ) resampling_actor_request_sender = resampling_actor_request_channel.new_sender() resampling_actor_request_receiver = resampling_actor_request_channel.new_receiver() _data_sourcing_actor = DataSourcingActor( request_receiver=data_source_request_receiver, registry=channel_registry ) _resampling_actor = ComponentMetricsResamplingActor( channel_registry=channel_registry, subscription_sender=data_source_request_sender, subscription_receiver=resampling_actor_request_receiver, resampling_period_s=1.0, ) components = await microgrid_api.get().microgrid_api_client.components() battery_ids = [ comp.component_id for comp in components if comp.category == ComponentCategory.BATTERY ] subscription_requests = [ ComponentMetricRequest( namespace=\"Resampling\", component_id=component_id, metric_id=ComponentMetricId.SOC, start_time=None, ) for component_id in battery_ids ] await asyncio.gather( *[ resampling_actor_request_sender.send(request) for request in subscription_requests ] ) sample_receiver = MergeNamed( **{ channel_name: channel_registry.new_receiver(channel_name) for channel_name in map( lambda req: req.get_channel_name(), subscription_requests ) } ) async for channel_name, msg in sample_receiver: print(msg) asyncio.run(run()) ``` \"\"\" self . _channel_registry = channel_registry self . _subscription_sender = subscription_sender self . _subscription_receiver = subscription_receiver self . _resampling_period_s = resampling_period_s self . _max_data_age_in_periods : float = max_data_age_in_periods self . _resampling_function : ResamplingFunction = resampling_function self . _resampler = GroupResampler ( resampling_period_s = resampling_period_s , max_data_age_in_periods = max_data_age_in_periods , initial_resampling_function = resampling_function , ) self . _input_receivers : Dict [ str , Receiver [ Sample ]] = {} self . _output_senders : Dict [ str , Sender [ Sample ]] = {} self . _resampling_timer = Timer ( interval = self . _resampling_period_s ) run () async \u00a4 Run the actor. RAISES DESCRIPTION ConnectionError When the provider of the subscription channel closes the connection Source code in frequenz/sdk/actor/_resampling.py 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 async def run ( self ) -> None : \"\"\"Run the actor. Raises: ConnectionError: When the provider of the subscription channel closes the connection \"\"\" while True : select = Select ( resampling_timer = self . _resampling_timer , subscription_receiver = self . _subscription_receiver , component_data_receiver = MergeNamed ( ** self . _input_receivers ), ) while await select . ready (): if msg := select . resampling_timer : assert msg . inner is not None , \"The timer should never be 'closed'\" timestamp = msg . inner awaitables = [ self . _output_senders [ channel_name ] . send ( sample ) for channel_name , sample in self . _resampler . resample ( timestamp ) ] await asyncio . gather ( * awaitables ) if msg := select . component_data_receiver : if msg . inner is None : # When this happens, then DataSourcingActor has closed the channel # for sending data for a specific `ComponentMetricRequest`, # which may need to be handled properly here, e.g. unsubscribe continue channel_name , sample = msg . inner if self . _is_sample_valid ( sample = sample ): self . _resampler . add_sample ( time_series_id = channel_name , sample = sample , ) if msg := select . subscription_receiver : if msg . inner is None : raise ConnectionError ( \"Subscription channel connection has been closed!\" ) await self . _subscribe ( request = msg . inner ) # Breaking out from the loop is required to regenerate # component_data_receivers to be able to fulfil this # subscription (later can be optimized by checking if # an output channel already existed in the `subscribe()` method) break frequenz.sdk.actor.ConfigManagingActor \u00a4 Manages config variables. Config variables are read from file. Only single file can be read. If new file is read, then previous configs will be forgotten. Source code in frequenz/sdk/actor/_config_managing.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 @actor class ConfigManagingActor : \"\"\" Manages config variables. Config variables are read from file. Only single file can be read. If new file is read, then previous configs will be forgotten. \"\"\" def __init__ ( self , conf_file : str , output : Sender [ Config ], event_types : Optional [ Set [ FileWatcher . EventType ]] = None , ) -> None : \"\"\"Read config variables from the file. Args: conf_file: Path to file with config variables. output: Channel to publish updates to. event_types: Which types of events should update the config and trigger a notification. \"\"\" self . _conf_file : str = conf_file self . _conf_dir : str = os . path . dirname ( conf_file ) self . _file_watcher = FileWatcher ( paths = [ self . _conf_dir ], event_types = event_types ) self . _output = output def _read_config ( self ) -> Dict [ str , Any ]: \"\"\"Read the contents of the config file. Raises: ValueError: if config file cannot be read. Returns: A dictionary containing configuration variables. \"\"\" try : return toml . load ( self . _conf_file ) except ValueError as err : logging . error ( \"Can't read config file, err: %s \" , err ) raise async def send_config ( self ) -> None : \"\"\"Send config file using a broadcast channel.\"\"\" conf_vars = self . _read_config () config = Config ( conf_vars ) await self . _output . send ( config ) async def run ( self ) -> None : \"\"\"Watch config file and update when modified. At startup, the Config Manager sends the current config so that it can be cache in the Broadcast channel and served to receivers even if there hasn't been any change to the config file itself. \"\"\" await self . send_config () async for path in self . _file_watcher : if str ( path ) == self . _conf_file : logger . info ( \"Update configs, because file %s was modified.\" , self . _conf_file , ) await self . send_config () logger . debug ( \"ConfigManager stopped.\" ) Functions \u00a4 __init__ ( conf_file , output , event_types = None ) \u00a4 Read config variables from the file. PARAMETER DESCRIPTION conf_file Path to file with config variables. TYPE: str output Channel to publish updates to. TYPE: Sender [ Config ] event_types Which types of events should update the config and trigger a notification. TYPE: Optional [ Set [ FileWatcher . EventType ]] DEFAULT: None Source code in frequenz/sdk/actor/_config_managing.py 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def __init__ ( self , conf_file : str , output : Sender [ Config ], event_types : Optional [ Set [ FileWatcher . EventType ]] = None , ) -> None : \"\"\"Read config variables from the file. Args: conf_file: Path to file with config variables. output: Channel to publish updates to. event_types: Which types of events should update the config and trigger a notification. \"\"\" self . _conf_file : str = conf_file self . _conf_dir : str = os . path . dirname ( conf_file ) self . _file_watcher = FileWatcher ( paths = [ self . _conf_dir ], event_types = event_types ) self . _output = output run () async \u00a4 Watch config file and update when modified. At startup, the Config Manager sends the current config so that it can be cache in the Broadcast channel and served to receivers even if there hasn't been any change to the config file itself. Source code in frequenz/sdk/actor/_config_managing.py 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 async def run ( self ) -> None : \"\"\"Watch config file and update when modified. At startup, the Config Manager sends the current config so that it can be cache in the Broadcast channel and served to receivers even if there hasn't been any change to the config file itself. \"\"\" await self . send_config () async for path in self . _file_watcher : if str ( path ) == self . _conf_file : logger . info ( \"Update configs, because file %s was modified.\" , self . _conf_file , ) await self . send_config () logger . debug ( \"ConfigManager stopped.\" ) send_config () async \u00a4 Send config file using a broadcast channel. Source code in frequenz/sdk/actor/_config_managing.py 66 67 68 69 70 async def send_config ( self ) -> None : \"\"\"Send config file using a broadcast channel.\"\"\" conf_vars = self . _read_config () config = Config ( conf_vars ) await self . _output . send ( config ) frequenz.sdk.actor.DataSourcingActor \u00a4 An actor that provides data streams of metrics as time series. Source code in frequenz/sdk/actor/_data_sourcing/data_sourcing.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 @actor class DataSourcingActor : \"\"\"An actor that provides data streams of metrics as time series.\"\"\" def __init__ ( self , request_receiver : Receiver [ ComponentMetricRequest ], registry : ChannelRegistry , ) -> None : \"\"\"Create a `DataSourcingActor` instance. Args: request_receiver: A channel receiver to accept metric requests from. registry: A channel registry. To be replaced by a singleton instance. \"\"\" self . _request_receiver = request_receiver self . _microgrid_api_source = MicrogridApiSource ( registry ) async def run ( self ) -> None : \"\"\"Run the actor.\"\"\" async for request in self . _request_receiver : await self . _microgrid_api_source . add_metric ( request ) Functions \u00a4 __init__ ( request_receiver , registry ) \u00a4 Create a DataSourcingActor instance. PARAMETER DESCRIPTION request_receiver A channel receiver to accept metric requests from. TYPE: Receiver [ ComponentMetricRequest ] registry A channel registry. To be replaced by a singleton instance. TYPE: ChannelRegistry Source code in frequenz/sdk/actor/_data_sourcing/data_sourcing.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 def __init__ ( self , request_receiver : Receiver [ ComponentMetricRequest ], registry : ChannelRegistry , ) -> None : \"\"\"Create a `DataSourcingActor` instance. Args: request_receiver: A channel receiver to accept metric requests from. registry: A channel registry. To be replaced by a singleton instance. \"\"\" self . _request_receiver = request_receiver self . _microgrid_api_source = MicrogridApiSource ( registry ) run () async \u00a4 Run the actor. Source code in frequenz/sdk/actor/_data_sourcing/data_sourcing.py 32 33 34 35 async def run ( self ) -> None : \"\"\"Run the actor.\"\"\" async for request in self . _request_receiver : await self . _microgrid_api_source . add_metric ( request ) Functions \u00a4 frequenz . sdk . actor . actor ( cls ) \u00a4 Decorate a class into a simple composable actor. A actor using the actor decorator should define an async def run(self) method, that loops over incoming data, and sends results out. Channels can be used to implement communication between actors, as shown in the examples below. PARAMETER DESCRIPTION cls the class to decorate. TYPE: Type [ Any ] RETURNS DESCRIPTION Type [ Any ] The decorated class. RAISES DESCRIPTION TypeError when the class doesn't have a run method as per spec. Example (one actor receiving from two receivers): @actor class EchoActor : def __init__ ( self , name : str , recv1 : Receiver [ bool ], recv2 : Receiver [ bool ], output : Sender [ bool ], ) -> None : self . name = name self . _recv1 = recv1 self . _recv2 = recv2 self . _output = output async def run ( self ) -> None : select = Select ( channel_1 = self . _recv1 , channel_2 = self . _recv2 ) while await select . ready (): if msg := select . channel_1 : await self . _output . send ( msg . inner ) elif msg := select . channel_2 : await self . _output . send ( msg . inner ) input_chan_1 : Broadcast [ bool ] = Broadcast ( \"input_chan_1\" ) input_chan_2 : Broadcast [ bool ] = Broadcast ( \"input_chan_2\" ) echo_chan : Broadcast [ bool ] = Broadcast ( \"EchoChannel\" ) echo_actor = EchoActor ( \"EchoActor\" , recv1 = input_chan_1 . new_receiver (), recv2 = input_chan_2 . new_receiver (), output = echo_chan . new_sender (), ) echo_rx = echo_chan . new_receiver () await input_chan_2 . new_sender () . send ( True ) msg = await echo_rx . receive () Example (two Actors composed): @actor class Actor1 : def __init__ ( self , name : str , recv : Receiver [ bool ], output : Sender [ bool ], ) -> None : self . name = name self . _recv = recv self . _output = output async def run ( self ) -> None : async for msg in self . _recv : await self . _output . send ( msg ) @actor class Actor2 : def __init__ ( self , name : str , recv : Receiver [ bool ], output : Sender [ bool ], ) -> None : self . name = name self . _recv = recv self . _output = output async def run ( self ) -> None : async for msg in self . _recv : await self . _output . send ( msg ) input_chan : Broadcast [ bool ] = Broadcast ( \"Input to A1\" ) a1_chan : Broadcast [ bool ] = Broadcast [ \"A1 stream\" ] a2_chan : Broadcast [ bool ] = Broadcast [ \"A2 stream\" ] a1 = Actor1 ( name = \"ActorOne\" , recv = input_chan . new_receiver (), output = a1_chan . new_sender (), ) a2 = Actor2 ( name = \"ActorTwo\" , recv = a1_chan . new_receiver (), output = a2_chan . new_sender (), ) a2_rx = a2_chan . new_receiver () await input_chan . new_sender () . send ( True ) msg = await a2_rx . receive () Source code in frequenz/sdk/actor/_decorator.py 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 def actor ( cls : Type [ Any ]) -> Type [ Any ]: \"\"\"Decorate a class into a simple composable actor. A actor using the `actor` decorator should define an `async def run(self)` method, that loops over incoming data, and sends results out. Channels can be used to implement communication between actors, as shown in the examples below. Args: cls: the class to decorate. Returns: The decorated class. Raises: TypeError: when the class doesn't have a `run` method as per spec. Example (one actor receiving from two receivers): ``` python @actor class EchoActor: def __init__( self, name: str, recv1: Receiver[bool], recv2: Receiver[bool], output: Sender[bool], ) -> None: self.name = name self._recv1 = recv1 self._recv2 = recv2 self._output = output async def run(self) -> None: select = Select(channel_1=self._recv1, channel_2=self._recv2) while await select.ready(): if msg := select.channel_1: await self._output.send(msg.inner) elif msg := select.channel_2: await self._output.send(msg.inner) input_chan_1: Broadcast[bool] = Broadcast(\"input_chan_1\") input_chan_2: Broadcast[bool] = Broadcast(\"input_chan_2\") echo_chan: Broadcast[bool] = Broadcast(\"EchoChannel\") echo_actor = EchoActor( \"EchoActor\", recv1=input_chan_1.new_receiver(), recv2=input_chan_2.new_receiver(), output=echo_chan.new_sender(), ) echo_rx = echo_chan.new_receiver() await input_chan_2.new_sender().send(True) msg = await echo_rx.receive() ``` Example (two Actors composed): ``` python @actor class Actor1: def __init__( self, name: str, recv: Receiver[bool], output: Sender[bool], ) -> None: self.name = name self._recv = recv self._output = output async def run(self) -> None: async for msg in self._recv: await self._output.send(msg) @actor class Actor2: def __init__( self, name: str, recv: Receiver[bool], output: Sender[bool], ) -> None: self.name = name self._recv = recv self._output = output async def run(self) -> None: async for msg in self._recv: await self._output.send(msg) input_chan: Broadcast[bool] = Broadcast(\"Input to A1\") a1_chan: Broadcast[bool] = Broadcast[\"A1 stream\"] a2_chan: Broadcast[bool] = Broadcast[\"A2 stream\"] a1 = Actor1( name=\"ActorOne\", recv=input_chan.new_receiver(), output=a1_chan.new_sender(), ) a2 = Actor2( name=\"ActorTwo\", recv=a1_chan.new_receiver(), output=a2_chan.new_sender(), ) a2_rx = a2_chan.new_receiver() await input_chan.new_sender().send(True) msg = await a2_rx.receive() ``` \"\"\" if not inspect . isclass ( cls ): raise TypeError ( \"The `@actor` decorator can only be applied for classes.\" ) _check_run_method_exists ( cls ) class ActorClass ( cls , BaseActor , Generic [ OT ]): # type: ignore \"\"\"A wrapper class to make an actor.\"\"\" def __init__ ( self , * args : Any , ** kwargs : Any ) -> None : \"\"\"Create an `ActorClass` instance. Also call __init__ on `cls`. Args: *args: Any positional arguments to `cls.__init__`. **kwargs: Any keyword arguments to `cls.__init__`. \"\"\" super () . __init__ ( * args , ** kwargs ) self . _actor_task = asyncio . create_task ( self . _start_actor ()) async def _start_actor ( self ) -> None : \"\"\"Run the main logic of the actor as a coroutine. Raises: asyncio.CancelledError: when the actor's task gets cancelled. \"\"\" logger . debug ( \"Starting actor: %s \" , cls . __name__ ) number_of_restarts = 0 while True : try : await super () . run () except asyncio . CancelledError : logger . debug ( \"Cancelling actor: %s \" , cls . __name__ ) raise except Exception as err : # pylint: disable=broad-except logger . exception ( \"Actor ( %s ) crashed with error: %s \" , cls . __name__ , err ) if ( self . restart_limit is None or number_of_restarts < self . restart_limit ): number_of_restarts += 1 logger . info ( \"Restarting actor: %s \" , cls . __name__ ) else : logger . info ( \"Shutting down actor: %s \" , cls . __name__ ) break async def _stop ( self ) -> None : \"\"\"Stop an running actor.\"\"\" self . _actor_task . cancel () try : await self . _actor_task except asyncio . CancelledError : pass async def join ( self ) -> None : \"\"\"Await the actor's task, and return when the task completes.\"\"\" await self . _actor_task return ActorClass","title":"actor"},{"location":"reference/frequenz/sdk/actor/#frequenz.sdk.actor","text":"A base class for creating simple composable actors.","title":"actor"},{"location":"reference/frequenz/sdk/actor/#frequenz.sdk.actor-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/actor/#frequenz.sdk.actor.ChannelRegistry","text":"Dynamically creates, own and provide access to channels. It can be used by actors to dynamically establish a communication channel between each other. Channels are identified by string names. Source code in frequenz/sdk/actor/_channel_registry.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 class ChannelRegistry : \"\"\"Dynamically creates, own and provide access to channels. It can be used by actors to dynamically establish a communication channel between each other. Channels are identified by string names. \"\"\" def __init__ ( self , * , name : str ) -> None : \"\"\"Create a `ChannelRegistry` instance. Args: name: A unique name for the registry. \"\"\" self . _name = name self . _channels : Dict [ str , Broadcast [ Any ]] = {} def new_sender ( self , key : str ) -> Sender [ Any ]: \"\"\"Get a sender to a dynamically created channel with the given key. Args: key: A key to identify the channel. Returns: A sender to a dynamically created channel with the given key. \"\"\" if key not in self . _channels : self . _channels [ key ] = Broadcast ( f \" { self . _name } - { key } \" ) return self . _channels [ key ] . new_sender () def new_receiver ( self , key : str ) -> Receiver [ Any ]: \"\"\"Get a receiver to a dynamically created channel with the given key. Args: key: A key to identify the channel. Returns: A receiver for a dynamically created channel with the given key. \"\"\" if key not in self . _channels : self . _channels [ key ] = Broadcast ( f \" { self . _name } - { key } \" ) return self . _channels [ key ] . new_receiver ()","title":"ChannelRegistry"},{"location":"reference/frequenz/sdk/actor/#frequenz.sdk.actor.ChannelRegistry-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/actor/#frequenz.sdk.actor._channel_registry.ChannelRegistry.__init__","text":"Create a ChannelRegistry instance. PARAMETER DESCRIPTION name A unique name for the registry. TYPE: str Source code in frequenz/sdk/actor/_channel_registry.py 18 19 20 21 22 23 24 25 def __init__ ( self , * , name : str ) -> None : \"\"\"Create a `ChannelRegistry` instance. Args: name: A unique name for the registry. \"\"\" self . _name = name self . _channels : Dict [ str , Broadcast [ Any ]] = {}","title":"__init__()"},{"location":"reference/frequenz/sdk/actor/#frequenz.sdk.actor._channel_registry.ChannelRegistry.new_receiver","text":"Get a receiver to a dynamically created channel with the given key. PARAMETER DESCRIPTION key A key to identify the channel. TYPE: str RETURNS DESCRIPTION Receiver [ Any ] A receiver for a dynamically created channel with the given key. Source code in frequenz/sdk/actor/_channel_registry.py 40 41 42 43 44 45 46 47 48 49 50 51 def new_receiver ( self , key : str ) -> Receiver [ Any ]: \"\"\"Get a receiver to a dynamically created channel with the given key. Args: key: A key to identify the channel. Returns: A receiver for a dynamically created channel with the given key. \"\"\" if key not in self . _channels : self . _channels [ key ] = Broadcast ( f \" { self . _name } - { key } \" ) return self . _channels [ key ] . new_receiver ()","title":"new_receiver()"},{"location":"reference/frequenz/sdk/actor/#frequenz.sdk.actor._channel_registry.ChannelRegistry.new_sender","text":"Get a sender to a dynamically created channel with the given key. PARAMETER DESCRIPTION key A key to identify the channel. TYPE: str RETURNS DESCRIPTION Sender [ Any ] A sender to a dynamically created channel with the given key. Source code in frequenz/sdk/actor/_channel_registry.py 27 28 29 30 31 32 33 34 35 36 37 38 def new_sender ( self , key : str ) -> Sender [ Any ]: \"\"\"Get a sender to a dynamically created channel with the given key. Args: key: A key to identify the channel. Returns: A sender to a dynamically created channel with the given key. \"\"\" if key not in self . _channels : self . _channels [ key ] = Broadcast ( f \" { self . _name } - { key } \" ) return self . _channels [ key ] . new_sender ()","title":"new_sender()"},{"location":"reference/frequenz/sdk/actor/#frequenz.sdk.actor.ComponentMetricRequest","text":"A request object to start streaming a metric for a component. Source code in frequenz/sdk/actor/_data_sourcing/microgrid_api_source.py 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 @dataclass class ComponentMetricRequest : \"\"\"A request object to start streaming a metric for a component.\"\"\" namespace : str \"\"\"The namespace that this request belongs to. Metric requests with a shared namespace enable the reuse of channels within that namespace. If for example, an actor making a multiple requests, uses the name of the actor as the namespace, then requests from the actor will get reused when possible. \"\"\" component_id : int \"\"\"The ID of the requested component.\"\"\" metric_id : ComponentMetricId \"\"\"The ID of the requested component's metric.\"\"\" start_time : Optional [ datetime ] \"\"\"The start time from which data is required. When None, we will stream only live data. \"\"\" def get_channel_name ( self ) -> str : \"\"\"Return a channel name constructed from Self. This channel name can be used by the sending side and receiving sides to identify the right channel from the ChannelRegistry. Returns: A string denoting a channel name. \"\"\" return f \" { self . component_id } :: { self . metric_id . name } :: { self . start_time } :: { self . namespace } \"","title":"ComponentMetricRequest"},{"location":"reference/frequenz/sdk/actor/#frequenz.sdk.actor.ComponentMetricRequest-attributes","text":"","title":"Attributes"},{"location":"reference/frequenz/sdk/actor/#frequenz.sdk.actor._data_sourcing.microgrid_api_source.ComponentMetricRequest.component_id","text":"The ID of the requested component.","title":"component_id"},{"location":"reference/frequenz/sdk/actor/#frequenz.sdk.actor._data_sourcing.microgrid_api_source.ComponentMetricRequest.metric_id","text":"The ID of the requested component's metric.","title":"metric_id"},{"location":"reference/frequenz/sdk/actor/#frequenz.sdk.actor._data_sourcing.microgrid_api_source.ComponentMetricRequest.namespace","text":"The namespace that this request belongs to. Metric requests with a shared namespace enable the reuse of channels within that namespace. If for example, an actor making a multiple requests, uses the name of the actor as the namespace, then requests from the actor will get reused when possible.","title":"namespace"},{"location":"reference/frequenz/sdk/actor/#frequenz.sdk.actor._data_sourcing.microgrid_api_source.ComponentMetricRequest.start_time","text":"The start time from which data is required. When None, we will stream only live data.","title":"start_time"},{"location":"reference/frequenz/sdk/actor/#frequenz.sdk.actor.ComponentMetricRequest-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/actor/#frequenz.sdk.actor._data_sourcing.microgrid_api_source.ComponentMetricRequest.get_channel_name","text":"Return a channel name constructed from Self. This channel name can be used by the sending side and receiving sides to identify the right channel from the ChannelRegistry. RETURNS DESCRIPTION str A string denoting a channel name. Source code in frequenz/sdk/actor/_data_sourcing/microgrid_api_source.py 54 55 56 57 58 59 60 61 62 63 def get_channel_name ( self ) -> str : \"\"\"Return a channel name constructed from Self. This channel name can be used by the sending side and receiving sides to identify the right channel from the ChannelRegistry. Returns: A string denoting a channel name. \"\"\" return f \" { self . component_id } :: { self . metric_id . name } :: { self . start_time } :: { self . namespace } \"","title":"get_channel_name()"},{"location":"reference/frequenz/sdk/actor/#frequenz.sdk.actor.ComponentMetricsResamplingActor","text":"ComponentMetricsResamplingActor used to ingest component data and resample it. Source code in frequenz/sdk/actor/_resampling.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 @actor class ComponentMetricsResamplingActor : \"\"\"ComponentMetricsResamplingActor used to ingest component data and resample it.\"\"\" def __init__ ( # pylint: disable=too-many-arguments self , channel_registry : ChannelRegistry , subscription_sender : Sender [ ComponentMetricRequest ], subscription_receiver : Receiver [ ComponentMetricRequest ], resampling_period_s : float = 0.2 , max_data_age_in_periods : float = 3.0 , resampling_function : ResamplingFunction = average , ) -> None : \"\"\"Initialize the ComponentMetricsResamplingActor. Args: channel_registry: global channel registry used for receiving component data from DataSource and for sending resampled samples downstream subscription_sender: channel for sending component metric requests to the DataSourcing actor subscription_receiver: channel for receiving component metric requests resampling_period_s: value describing how often resampling should be performed, in seconds max_data_age_in_periods: max age that samples shouldn't exceed in order to be used in the resampling function resampling_function: function to be applied to a sequence of samples within a resampling period to produce a single output sample Example: ```python async def run() -> None: await microgrid_api.initialize(HOST, PORT) channel_registry = ChannelRegistry(name=\"Microgrid Channel Registry\") data_source_request_channel = Broadcast[ComponentMetricRequest]( \"Data Source Request Channel\" ) data_source_request_sender = data_source_request_channel.new_sender() data_source_request_receiver = data_source_request_channel.new_receiver() resampling_actor_request_channel = Broadcast[ComponentMetricRequest]( \"Resampling Actor Request Channel\" ) resampling_actor_request_sender = resampling_actor_request_channel.new_sender() resampling_actor_request_receiver = resampling_actor_request_channel.new_receiver() _data_sourcing_actor = DataSourcingActor( request_receiver=data_source_request_receiver, registry=channel_registry ) _resampling_actor = ComponentMetricsResamplingActor( channel_registry=channel_registry, subscription_sender=data_source_request_sender, subscription_receiver=resampling_actor_request_receiver, resampling_period_s=1.0, ) components = await microgrid_api.get().microgrid_api_client.components() battery_ids = [ comp.component_id for comp in components if comp.category == ComponentCategory.BATTERY ] subscription_requests = [ ComponentMetricRequest( namespace=\"Resampling\", component_id=component_id, metric_id=ComponentMetricId.SOC, start_time=None, ) for component_id in battery_ids ] await asyncio.gather( *[ resampling_actor_request_sender.send(request) for request in subscription_requests ] ) sample_receiver = MergeNamed( **{ channel_name: channel_registry.new_receiver(channel_name) for channel_name in map( lambda req: req.get_channel_name(), subscription_requests ) } ) async for channel_name, msg in sample_receiver: print(msg) asyncio.run(run()) ``` \"\"\" self . _channel_registry = channel_registry self . _subscription_sender = subscription_sender self . _subscription_receiver = subscription_receiver self . _resampling_period_s = resampling_period_s self . _max_data_age_in_periods : float = max_data_age_in_periods self . _resampling_function : ResamplingFunction = resampling_function self . _resampler = GroupResampler ( resampling_period_s = resampling_period_s , max_data_age_in_periods = max_data_age_in_periods , initial_resampling_function = resampling_function , ) self . _input_receivers : Dict [ str , Receiver [ Sample ]] = {} self . _output_senders : Dict [ str , Sender [ Sample ]] = {} self . _resampling_timer = Timer ( interval = self . _resampling_period_s ) async def _subscribe ( self , request : ComponentMetricRequest ) -> None : \"\"\"Subscribe for data for a specific time series. Args: request: subscription request for a specific component metric \"\"\" channel_name = request . get_channel_name () data_source_request = dataclasses . replace ( request , ** dict ( namespace = \"Source\" )) data_source_channel_name = data_source_request . get_channel_name () if channel_name not in self . _input_receivers : await self . _subscription_sender . send ( data_source_request ) receiver : Receiver [ Sample ] = self . _channel_registry . new_receiver ( data_source_channel_name ) self . _input_receivers [ data_source_channel_name ] = receiver self . _resampler . add_time_series ( time_series_id = data_source_channel_name ) if channel_name not in self . _output_senders : sender : Sender [ Sample ] = self . _channel_registry . new_sender ( channel_name ) # This means that the `sender` will be sending samples to the channel with # name `channel_name` based on samples collected from the channel named # `data_source_channel_name` self . _output_senders [ data_source_channel_name ] = sender def _is_sample_valid ( self , sample : Sample ) -> bool : \"\"\"Check if the provided sample is valid. Args: sample: sample to be validated Returns: True if the sample is valid, False otherwise \"\"\" if sample . value is None or math . isnan ( sample . value ): return False return True async def run ( self ) -> None : \"\"\"Run the actor. Raises: ConnectionError: When the provider of the subscription channel closes the connection \"\"\" while True : select = Select ( resampling_timer = self . _resampling_timer , subscription_receiver = self . _subscription_receiver , component_data_receiver = MergeNamed ( ** self . _input_receivers ), ) while await select . ready (): if msg := select . resampling_timer : assert msg . inner is not None , \"The timer should never be 'closed'\" timestamp = msg . inner awaitables = [ self . _output_senders [ channel_name ] . send ( sample ) for channel_name , sample in self . _resampler . resample ( timestamp ) ] await asyncio . gather ( * awaitables ) if msg := select . component_data_receiver : if msg . inner is None : # When this happens, then DataSourcingActor has closed the channel # for sending data for a specific `ComponentMetricRequest`, # which may need to be handled properly here, e.g. unsubscribe continue channel_name , sample = msg . inner if self . _is_sample_valid ( sample = sample ): self . _resampler . add_sample ( time_series_id = channel_name , sample = sample , ) if msg := select . subscription_receiver : if msg . inner is None : raise ConnectionError ( \"Subscription channel connection has been closed!\" ) await self . _subscribe ( request = msg . inner ) # Breaking out from the loop is required to regenerate # component_data_receivers to be able to fulfil this # subscription (later can be optimized by checking if # an output channel already existed in the `subscribe()` method) break","title":"ComponentMetricsResamplingActor"},{"location":"reference/frequenz/sdk/actor/#frequenz.sdk.actor.ComponentMetricsResamplingActor-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/actor/#frequenz.sdk.actor._resampling.ComponentMetricsResamplingActor.__init__","text":"Initialize the ComponentMetricsResamplingActor. PARAMETER DESCRIPTION channel_registry global channel registry used for receiving component data from DataSource and for sending resampled samples downstream TYPE: ChannelRegistry subscription_sender channel for sending component metric requests to the DataSourcing actor TYPE: Sender [ ComponentMetricRequest ] subscription_receiver channel for receiving component metric requests TYPE: Receiver [ ComponentMetricRequest ] resampling_period_s value describing how often resampling should be performed, in seconds TYPE: float DEFAULT: 0.2 max_data_age_in_periods max age that samples shouldn't exceed in order to be used in the resampling function TYPE: float DEFAULT: 3.0 resampling_function function to be applied to a sequence of samples within a resampling period to produce a single output sample TYPE: ResamplingFunction DEFAULT: average Example async def run () -> None : await microgrid_api . initialize ( HOST , PORT ) channel_registry = ChannelRegistry ( name = \"Microgrid Channel Registry\" ) data_source_request_channel = Broadcast [ ComponentMetricRequest ]( \"Data Source Request Channel\" ) data_source_request_sender = data_source_request_channel . new_sender () data_source_request_receiver = data_source_request_channel . new_receiver () resampling_actor_request_channel = Broadcast [ ComponentMetricRequest ]( \"Resampling Actor Request Channel\" ) resampling_actor_request_sender = resampling_actor_request_channel . new_sender () resampling_actor_request_receiver = resampling_actor_request_channel . new_receiver () _data_sourcing_actor = DataSourcingActor ( request_receiver = data_source_request_receiver , registry = channel_registry ) _resampling_actor = ComponentMetricsResamplingActor ( channel_registry = channel_registry , subscription_sender = data_source_request_sender , subscription_receiver = resampling_actor_request_receiver , resampling_period_s = 1.0 , ) components = await microgrid_api . get () . microgrid_api_client . components () battery_ids = [ comp . component_id for comp in components if comp . category == ComponentCategory . BATTERY ] subscription_requests = [ ComponentMetricRequest ( namespace = \"Resampling\" , component_id = component_id , metric_id = ComponentMetricId . SOC , start_time = None , ) for component_id in battery_ids ] await asyncio . gather ( * [ resampling_actor_request_sender . send ( request ) for request in subscription_requests ] ) sample_receiver = MergeNamed ( ** { channel_name : channel_registry . new_receiver ( channel_name ) for channel_name in map ( lambda req : req . get_channel_name (), subscription_requests ) } ) async for channel_name , msg in sample_receiver : print ( msg ) asyncio . run ( run ()) Source code in frequenz/sdk/actor/_resampling.py 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 def __init__ ( # pylint: disable=too-many-arguments self , channel_registry : ChannelRegistry , subscription_sender : Sender [ ComponentMetricRequest ], subscription_receiver : Receiver [ ComponentMetricRequest ], resampling_period_s : float = 0.2 , max_data_age_in_periods : float = 3.0 , resampling_function : ResamplingFunction = average , ) -> None : \"\"\"Initialize the ComponentMetricsResamplingActor. Args: channel_registry: global channel registry used for receiving component data from DataSource and for sending resampled samples downstream subscription_sender: channel for sending component metric requests to the DataSourcing actor subscription_receiver: channel for receiving component metric requests resampling_period_s: value describing how often resampling should be performed, in seconds max_data_age_in_periods: max age that samples shouldn't exceed in order to be used in the resampling function resampling_function: function to be applied to a sequence of samples within a resampling period to produce a single output sample Example: ```python async def run() -> None: await microgrid_api.initialize(HOST, PORT) channel_registry = ChannelRegistry(name=\"Microgrid Channel Registry\") data_source_request_channel = Broadcast[ComponentMetricRequest]( \"Data Source Request Channel\" ) data_source_request_sender = data_source_request_channel.new_sender() data_source_request_receiver = data_source_request_channel.new_receiver() resampling_actor_request_channel = Broadcast[ComponentMetricRequest]( \"Resampling Actor Request Channel\" ) resampling_actor_request_sender = resampling_actor_request_channel.new_sender() resampling_actor_request_receiver = resampling_actor_request_channel.new_receiver() _data_sourcing_actor = DataSourcingActor( request_receiver=data_source_request_receiver, registry=channel_registry ) _resampling_actor = ComponentMetricsResamplingActor( channel_registry=channel_registry, subscription_sender=data_source_request_sender, subscription_receiver=resampling_actor_request_receiver, resampling_period_s=1.0, ) components = await microgrid_api.get().microgrid_api_client.components() battery_ids = [ comp.component_id for comp in components if comp.category == ComponentCategory.BATTERY ] subscription_requests = [ ComponentMetricRequest( namespace=\"Resampling\", component_id=component_id, metric_id=ComponentMetricId.SOC, start_time=None, ) for component_id in battery_ids ] await asyncio.gather( *[ resampling_actor_request_sender.send(request) for request in subscription_requests ] ) sample_receiver = MergeNamed( **{ channel_name: channel_registry.new_receiver(channel_name) for channel_name in map( lambda req: req.get_channel_name(), subscription_requests ) } ) async for channel_name, msg in sample_receiver: print(msg) asyncio.run(run()) ``` \"\"\" self . _channel_registry = channel_registry self . _subscription_sender = subscription_sender self . _subscription_receiver = subscription_receiver self . _resampling_period_s = resampling_period_s self . _max_data_age_in_periods : float = max_data_age_in_periods self . _resampling_function : ResamplingFunction = resampling_function self . _resampler = GroupResampler ( resampling_period_s = resampling_period_s , max_data_age_in_periods = max_data_age_in_periods , initial_resampling_function = resampling_function , ) self . _input_receivers : Dict [ str , Receiver [ Sample ]] = {} self . _output_senders : Dict [ str , Sender [ Sample ]] = {} self . _resampling_timer = Timer ( interval = self . _resampling_period_s )","title":"__init__()"},{"location":"reference/frequenz/sdk/actor/#frequenz.sdk.actor._resampling.ComponentMetricsResamplingActor.run","text":"Run the actor. RAISES DESCRIPTION ConnectionError When the provider of the subscription channel closes the connection Source code in frequenz/sdk/actor/_resampling.py 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 async def run ( self ) -> None : \"\"\"Run the actor. Raises: ConnectionError: When the provider of the subscription channel closes the connection \"\"\" while True : select = Select ( resampling_timer = self . _resampling_timer , subscription_receiver = self . _subscription_receiver , component_data_receiver = MergeNamed ( ** self . _input_receivers ), ) while await select . ready (): if msg := select . resampling_timer : assert msg . inner is not None , \"The timer should never be 'closed'\" timestamp = msg . inner awaitables = [ self . _output_senders [ channel_name ] . send ( sample ) for channel_name , sample in self . _resampler . resample ( timestamp ) ] await asyncio . gather ( * awaitables ) if msg := select . component_data_receiver : if msg . inner is None : # When this happens, then DataSourcingActor has closed the channel # for sending data for a specific `ComponentMetricRequest`, # which may need to be handled properly here, e.g. unsubscribe continue channel_name , sample = msg . inner if self . _is_sample_valid ( sample = sample ): self . _resampler . add_sample ( time_series_id = channel_name , sample = sample , ) if msg := select . subscription_receiver : if msg . inner is None : raise ConnectionError ( \"Subscription channel connection has been closed!\" ) await self . _subscribe ( request = msg . inner ) # Breaking out from the loop is required to regenerate # component_data_receivers to be able to fulfil this # subscription (later can be optimized by checking if # an output channel already existed in the `subscribe()` method) break","title":"run()"},{"location":"reference/frequenz/sdk/actor/#frequenz.sdk.actor.ConfigManagingActor","text":"Manages config variables. Config variables are read from file. Only single file can be read. If new file is read, then previous configs will be forgotten. Source code in frequenz/sdk/actor/_config_managing.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 @actor class ConfigManagingActor : \"\"\" Manages config variables. Config variables are read from file. Only single file can be read. If new file is read, then previous configs will be forgotten. \"\"\" def __init__ ( self , conf_file : str , output : Sender [ Config ], event_types : Optional [ Set [ FileWatcher . EventType ]] = None , ) -> None : \"\"\"Read config variables from the file. Args: conf_file: Path to file with config variables. output: Channel to publish updates to. event_types: Which types of events should update the config and trigger a notification. \"\"\" self . _conf_file : str = conf_file self . _conf_dir : str = os . path . dirname ( conf_file ) self . _file_watcher = FileWatcher ( paths = [ self . _conf_dir ], event_types = event_types ) self . _output = output def _read_config ( self ) -> Dict [ str , Any ]: \"\"\"Read the contents of the config file. Raises: ValueError: if config file cannot be read. Returns: A dictionary containing configuration variables. \"\"\" try : return toml . load ( self . _conf_file ) except ValueError as err : logging . error ( \"Can't read config file, err: %s \" , err ) raise async def send_config ( self ) -> None : \"\"\"Send config file using a broadcast channel.\"\"\" conf_vars = self . _read_config () config = Config ( conf_vars ) await self . _output . send ( config ) async def run ( self ) -> None : \"\"\"Watch config file and update when modified. At startup, the Config Manager sends the current config so that it can be cache in the Broadcast channel and served to receivers even if there hasn't been any change to the config file itself. \"\"\" await self . send_config () async for path in self . _file_watcher : if str ( path ) == self . _conf_file : logger . info ( \"Update configs, because file %s was modified.\" , self . _conf_file , ) await self . send_config () logger . debug ( \"ConfigManager stopped.\" )","title":"ConfigManagingActor"},{"location":"reference/frequenz/sdk/actor/#frequenz.sdk.actor.ConfigManagingActor-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/actor/#frequenz.sdk.actor._config_managing.ConfigManagingActor.__init__","text":"Read config variables from the file. PARAMETER DESCRIPTION conf_file Path to file with config variables. TYPE: str output Channel to publish updates to. TYPE: Sender [ Config ] event_types Which types of events should update the config and trigger a notification. TYPE: Optional [ Set [ FileWatcher . EventType ]] DEFAULT: None Source code in frequenz/sdk/actor/_config_managing.py 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def __init__ ( self , conf_file : str , output : Sender [ Config ], event_types : Optional [ Set [ FileWatcher . EventType ]] = None , ) -> None : \"\"\"Read config variables from the file. Args: conf_file: Path to file with config variables. output: Channel to publish updates to. event_types: Which types of events should update the config and trigger a notification. \"\"\" self . _conf_file : str = conf_file self . _conf_dir : str = os . path . dirname ( conf_file ) self . _file_watcher = FileWatcher ( paths = [ self . _conf_dir ], event_types = event_types ) self . _output = output","title":"__init__()"},{"location":"reference/frequenz/sdk/actor/#frequenz.sdk.actor._config_managing.ConfigManagingActor.run","text":"Watch config file and update when modified. At startup, the Config Manager sends the current config so that it can be cache in the Broadcast channel and served to receivers even if there hasn't been any change to the config file itself. Source code in frequenz/sdk/actor/_config_managing.py 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 async def run ( self ) -> None : \"\"\"Watch config file and update when modified. At startup, the Config Manager sends the current config so that it can be cache in the Broadcast channel and served to receivers even if there hasn't been any change to the config file itself. \"\"\" await self . send_config () async for path in self . _file_watcher : if str ( path ) == self . _conf_file : logger . info ( \"Update configs, because file %s was modified.\" , self . _conf_file , ) await self . send_config () logger . debug ( \"ConfigManager stopped.\" )","title":"run()"},{"location":"reference/frequenz/sdk/actor/#frequenz.sdk.actor._config_managing.ConfigManagingActor.send_config","text":"Send config file using a broadcast channel. Source code in frequenz/sdk/actor/_config_managing.py 66 67 68 69 70 async def send_config ( self ) -> None : \"\"\"Send config file using a broadcast channel.\"\"\" conf_vars = self . _read_config () config = Config ( conf_vars ) await self . _output . send ( config )","title":"send_config()"},{"location":"reference/frequenz/sdk/actor/#frequenz.sdk.actor.DataSourcingActor","text":"An actor that provides data streams of metrics as time series. Source code in frequenz/sdk/actor/_data_sourcing/data_sourcing.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 @actor class DataSourcingActor : \"\"\"An actor that provides data streams of metrics as time series.\"\"\" def __init__ ( self , request_receiver : Receiver [ ComponentMetricRequest ], registry : ChannelRegistry , ) -> None : \"\"\"Create a `DataSourcingActor` instance. Args: request_receiver: A channel receiver to accept metric requests from. registry: A channel registry. To be replaced by a singleton instance. \"\"\" self . _request_receiver = request_receiver self . _microgrid_api_source = MicrogridApiSource ( registry ) async def run ( self ) -> None : \"\"\"Run the actor.\"\"\" async for request in self . _request_receiver : await self . _microgrid_api_source . add_metric ( request )","title":"DataSourcingActor"},{"location":"reference/frequenz/sdk/actor/#frequenz.sdk.actor.DataSourcingActor-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/actor/#frequenz.sdk.actor._data_sourcing.data_sourcing.DataSourcingActor.__init__","text":"Create a DataSourcingActor instance. PARAMETER DESCRIPTION request_receiver A channel receiver to accept metric requests from. TYPE: Receiver [ ComponentMetricRequest ] registry A channel registry. To be replaced by a singleton instance. TYPE: ChannelRegistry Source code in frequenz/sdk/actor/_data_sourcing/data_sourcing.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 def __init__ ( self , request_receiver : Receiver [ ComponentMetricRequest ], registry : ChannelRegistry , ) -> None : \"\"\"Create a `DataSourcingActor` instance. Args: request_receiver: A channel receiver to accept metric requests from. registry: A channel registry. To be replaced by a singleton instance. \"\"\" self . _request_receiver = request_receiver self . _microgrid_api_source = MicrogridApiSource ( registry )","title":"__init__()"},{"location":"reference/frequenz/sdk/actor/#frequenz.sdk.actor._data_sourcing.data_sourcing.DataSourcingActor.run","text":"Run the actor. Source code in frequenz/sdk/actor/_data_sourcing/data_sourcing.py 32 33 34 35 async def run ( self ) -> None : \"\"\"Run the actor.\"\"\" async for request in self . _request_receiver : await self . _microgrid_api_source . add_metric ( request )","title":"run()"},{"location":"reference/frequenz/sdk/actor/#frequenz.sdk.actor-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/actor/#frequenz.sdk.actor.actor","text":"Decorate a class into a simple composable actor. A actor using the actor decorator should define an async def run(self) method, that loops over incoming data, and sends results out. Channels can be used to implement communication between actors, as shown in the examples below. PARAMETER DESCRIPTION cls the class to decorate. TYPE: Type [ Any ] RETURNS DESCRIPTION Type [ Any ] The decorated class. RAISES DESCRIPTION TypeError when the class doesn't have a run method as per spec. Example (one actor receiving from two receivers): @actor class EchoActor : def __init__ ( self , name : str , recv1 : Receiver [ bool ], recv2 : Receiver [ bool ], output : Sender [ bool ], ) -> None : self . name = name self . _recv1 = recv1 self . _recv2 = recv2 self . _output = output async def run ( self ) -> None : select = Select ( channel_1 = self . _recv1 , channel_2 = self . _recv2 ) while await select . ready (): if msg := select . channel_1 : await self . _output . send ( msg . inner ) elif msg := select . channel_2 : await self . _output . send ( msg . inner ) input_chan_1 : Broadcast [ bool ] = Broadcast ( \"input_chan_1\" ) input_chan_2 : Broadcast [ bool ] = Broadcast ( \"input_chan_2\" ) echo_chan : Broadcast [ bool ] = Broadcast ( \"EchoChannel\" ) echo_actor = EchoActor ( \"EchoActor\" , recv1 = input_chan_1 . new_receiver (), recv2 = input_chan_2 . new_receiver (), output = echo_chan . new_sender (), ) echo_rx = echo_chan . new_receiver () await input_chan_2 . new_sender () . send ( True ) msg = await echo_rx . receive () Example (two Actors composed): @actor class Actor1 : def __init__ ( self , name : str , recv : Receiver [ bool ], output : Sender [ bool ], ) -> None : self . name = name self . _recv = recv self . _output = output async def run ( self ) -> None : async for msg in self . _recv : await self . _output . send ( msg ) @actor class Actor2 : def __init__ ( self , name : str , recv : Receiver [ bool ], output : Sender [ bool ], ) -> None : self . name = name self . _recv = recv self . _output = output async def run ( self ) -> None : async for msg in self . _recv : await self . _output . send ( msg ) input_chan : Broadcast [ bool ] = Broadcast ( \"Input to A1\" ) a1_chan : Broadcast [ bool ] = Broadcast [ \"A1 stream\" ] a2_chan : Broadcast [ bool ] = Broadcast [ \"A2 stream\" ] a1 = Actor1 ( name = \"ActorOne\" , recv = input_chan . new_receiver (), output = a1_chan . new_sender (), ) a2 = Actor2 ( name = \"ActorTwo\" , recv = a1_chan . new_receiver (), output = a2_chan . new_sender (), ) a2_rx = a2_chan . new_receiver () await input_chan . new_sender () . send ( True ) msg = await a2_rx . receive () Source code in frequenz/sdk/actor/_decorator.py 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 def actor ( cls : Type [ Any ]) -> Type [ Any ]: \"\"\"Decorate a class into a simple composable actor. A actor using the `actor` decorator should define an `async def run(self)` method, that loops over incoming data, and sends results out. Channels can be used to implement communication between actors, as shown in the examples below. Args: cls: the class to decorate. Returns: The decorated class. Raises: TypeError: when the class doesn't have a `run` method as per spec. Example (one actor receiving from two receivers): ``` python @actor class EchoActor: def __init__( self, name: str, recv1: Receiver[bool], recv2: Receiver[bool], output: Sender[bool], ) -> None: self.name = name self._recv1 = recv1 self._recv2 = recv2 self._output = output async def run(self) -> None: select = Select(channel_1=self._recv1, channel_2=self._recv2) while await select.ready(): if msg := select.channel_1: await self._output.send(msg.inner) elif msg := select.channel_2: await self._output.send(msg.inner) input_chan_1: Broadcast[bool] = Broadcast(\"input_chan_1\") input_chan_2: Broadcast[bool] = Broadcast(\"input_chan_2\") echo_chan: Broadcast[bool] = Broadcast(\"EchoChannel\") echo_actor = EchoActor( \"EchoActor\", recv1=input_chan_1.new_receiver(), recv2=input_chan_2.new_receiver(), output=echo_chan.new_sender(), ) echo_rx = echo_chan.new_receiver() await input_chan_2.new_sender().send(True) msg = await echo_rx.receive() ``` Example (two Actors composed): ``` python @actor class Actor1: def __init__( self, name: str, recv: Receiver[bool], output: Sender[bool], ) -> None: self.name = name self._recv = recv self._output = output async def run(self) -> None: async for msg in self._recv: await self._output.send(msg) @actor class Actor2: def __init__( self, name: str, recv: Receiver[bool], output: Sender[bool], ) -> None: self.name = name self._recv = recv self._output = output async def run(self) -> None: async for msg in self._recv: await self._output.send(msg) input_chan: Broadcast[bool] = Broadcast(\"Input to A1\") a1_chan: Broadcast[bool] = Broadcast[\"A1 stream\"] a2_chan: Broadcast[bool] = Broadcast[\"A2 stream\"] a1 = Actor1( name=\"ActorOne\", recv=input_chan.new_receiver(), output=a1_chan.new_sender(), ) a2 = Actor2( name=\"ActorTwo\", recv=a1_chan.new_receiver(), output=a2_chan.new_sender(), ) a2_rx = a2_chan.new_receiver() await input_chan.new_sender().send(True) msg = await a2_rx.receive() ``` \"\"\" if not inspect . isclass ( cls ): raise TypeError ( \"The `@actor` decorator can only be applied for classes.\" ) _check_run_method_exists ( cls ) class ActorClass ( cls , BaseActor , Generic [ OT ]): # type: ignore \"\"\"A wrapper class to make an actor.\"\"\" def __init__ ( self , * args : Any , ** kwargs : Any ) -> None : \"\"\"Create an `ActorClass` instance. Also call __init__ on `cls`. Args: *args: Any positional arguments to `cls.__init__`. **kwargs: Any keyword arguments to `cls.__init__`. \"\"\" super () . __init__ ( * args , ** kwargs ) self . _actor_task = asyncio . create_task ( self . _start_actor ()) async def _start_actor ( self ) -> None : \"\"\"Run the main logic of the actor as a coroutine. Raises: asyncio.CancelledError: when the actor's task gets cancelled. \"\"\" logger . debug ( \"Starting actor: %s \" , cls . __name__ ) number_of_restarts = 0 while True : try : await super () . run () except asyncio . CancelledError : logger . debug ( \"Cancelling actor: %s \" , cls . __name__ ) raise except Exception as err : # pylint: disable=broad-except logger . exception ( \"Actor ( %s ) crashed with error: %s \" , cls . __name__ , err ) if ( self . restart_limit is None or number_of_restarts < self . restart_limit ): number_of_restarts += 1 logger . info ( \"Restarting actor: %s \" , cls . __name__ ) else : logger . info ( \"Shutting down actor: %s \" , cls . __name__ ) break async def _stop ( self ) -> None : \"\"\"Stop an running actor.\"\"\" self . _actor_task . cancel () try : await self . _actor_task except asyncio . CancelledError : pass async def join ( self ) -> None : \"\"\"Await the actor's task, and return when the task completes.\"\"\" await self . _actor_task return ActorClass","title":"actor()"},{"location":"reference/frequenz/sdk/actor/power_distributing/","text":"frequenz.sdk.actor.power_distributing \u00a4 Actor to distribute power between batteries. When charge/discharge method is called the power should be distributed so that the SoC in batteries stays at the same level. That way of distribution prevents using only one battery, increasing temperature, and maximize the total amount power to charge/discharge. Purpose of this actor is to keep SoC level of each component at the equal level. Classes \u00a4 frequenz.sdk.actor.power_distributing.PowerDistributingActor \u00a4 Tool to distribute power between batteries in microgrid. The purpose of this tool is to keep equal SoC level in the batteries. PowerDistributor can have many users. Each user should first register in order to get its id, channel for sending request, and channel for receiving response. It is recommended to wait for PowerDistributor output with timeout. Otherwise if the processing function fail then the response will never come. The timeout should be Result:request_timeout_sec + time for processing the request. Edge cases: * If there are 2 requests to be processed for the same subset of batteries, then only the latest request will be processed. Older request will be ignored. User with older request will get response with Result.Status.IGNORED. If there are 2 requests and their subset of batteries is different but they overlap (they have at least one common battery), then then both batteries will be processed. However it is not expected so the proper error log will be printed. Example import grpc.aio as grpcaio from frequenz.sdk.microgrid.graph import _MicrogridComponentGraph from frequenz.sdk.microgrid.component import ComponentCategory from frequenz.sdk.power_distribution import ( PowerDistributor , Request , Result , ) target = f \" { host } : { port } \" grpc_channel = grpcaio . insecure_channel ( target ) api = MicrogridGrpcClient ( grpc_channel , target ) graph = _MicrogridComponentGraph () await graph . refresh_from_api ( api ) batteries = graph . components ( component_category = { ComponentCategory . BATTERY }) batteries_ids = { c . component_id for c in batteries } channel = Bidirectional [ Request , Result ]( \"user1\" , \"power_distributor\" ) power_distributor = PowerDistributor ( mock_api , component_graph , { \"user1\" : channel . service_handle } ) client_handle = channel . client_handle # Set power 1200W to given batteries. request = Request ( power = 1200 , batteries = batteries_ids , request_timeout_sec = 10.0 ) await client_handle . send ( request ) # It is recommended to use timeout when waiting for the response! result : Result = await asyncio . wait_for ( client_handle . receive (), timeout = 10 ) if result . status == Result . Status . SUCCESS : print ( \"Command succeed\" ) elif result . status == Result . Status . FAILED : print ( f \"Some batteries failed, total failed power: { result . failed_power } \" ) elif result . status == Result . Status . IGNORED : print ( f \"Request was ignored, because of newer command\" ) elif result . status == Result . Status . ERROR : print ( f \"Request failed with error: { request . error_message } \" ) Source code in frequenz/sdk/actor/power_distributing.py 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 @actor class PowerDistributingActor : # pylint: disable=too-many-instance-attributes \"\"\"Tool to distribute power between batteries in microgrid. The purpose of this tool is to keep equal SoC level in the batteries. PowerDistributor can have many users. Each user should first register in order to get its id, channel for sending request, and channel for receiving response. It is recommended to wait for PowerDistributor output with timeout. Otherwise if the processing function fail then the response will never come. The timeout should be Result:request_timeout_sec + time for processing the request. Edge cases: * If there are 2 requests to be processed for the same subset of batteries, then only the latest request will be processed. Older request will be ignored. User with older request will get response with Result.Status.IGNORED. * If there are 2 requests and their subset of batteries is different but they overlap (they have at least one common battery), then then both batteries will be processed. However it is not expected so the proper error log will be printed. Example: ``` python import grpc.aio as grpcaio from frequenz.sdk.microgrid.graph import _MicrogridComponentGraph from frequenz.sdk.microgrid.component import ComponentCategory from frequenz.sdk.power_distribution import ( PowerDistributor, Request, Result, ) target = f\"{host}:{port}\" grpc_channel = grpcaio.insecure_channel(target) api = MicrogridGrpcClient(grpc_channel, target) graph = _MicrogridComponentGraph() await graph.refresh_from_api(api) batteries = graph.components(component_category={ComponentCategory.BATTERY}) batteries_ids = {c.component_id for c in batteries} channel = Bidirectional[Request, Result](\"user1\", \"power_distributor\") power_distributor = PowerDistributor( mock_api, component_graph, {\"user1\": channel.service_handle} ) client_handle = channel.client_handle # Set power 1200W to given batteries. request = Request(power=1200, batteries=batteries_ids, request_timeout_sec=10.0) await client_handle.send(request) # It is recommended to use timeout when waiting for the response! result: Result = await asyncio.wait_for(client_handle.receive(), timeout=10) if result.status == Result.Status.SUCCESS: print(\"Command succeed\") elif result.status == Result.Status.FAILED: print( f\"Some batteries failed, total failed power: {result.failed_power}\") elif result.status == Result.Status.IGNORED: print(f\"Request was ignored, because of newer command\") elif result.status == Result.Status.ERROR: print(f\"Request failed with error: {request.error_message}\") ``` \"\"\" def __init__ ( self , microgrid_api : MicrogridApiClient , component_graph : ComponentGraph , users_channels : Dict [ str , Bidirectional . Handle [ Result , Request ]], wait_for_data_sec : float = 2 , ) -> None : \"\"\"Create class instance. Args: microgrid_api: api for sending the requests. component_graph: component graph of the given microgrid api. users_channels: BidirectionalHandle for each user. Key should be user id and value should be BidirectionalHandle. wait_for_data_sec: How long actor should wait before processing first request. It is a time needed to collect first components data. \"\"\" self . _api = microgrid_api self . _wait_for_data_sec = wait_for_data_sec # Max permitted time when the component should send any information. # After that timeout the component will be treated as not existing. # Formulas will put 0 in place of data from this components. # This will happen until component starts sending data. self . component_data_timeout_sec : float = 60.0 self . broken_component_timeout_sec : float = 30.0 self . power_distributor_exponent : float = 1.0 # distributor_exponent and timeout_sec should be get from ConfigManager self . distribution_algorithm = DistributionAlgorithm ( self . power_distributor_exponent ) self . _broken_components = _BrokenComponents ( self . broken_component_timeout_sec ) self . _bat_inv_map , self . _inv_bat_map = self . _get_components_pairs ( component_graph ) self . _battery_receivers : Dict [ int , Peekable [ BatteryData ]] = {} self . _inverter_receivers : Dict [ int , Peekable [ InverterData ]] = {} # The components in different requests be for the same components, or for # completely different components. They should not overlap. # Otherwise the PowerDistributor has no way to decide what request is more # important. It will execute both. And later request will override the previous # one. # That is why the queue of maxsize = total number of batteries should be enough. self . _request_queue : asyncio . Queue [ Tuple [ Request , _User ]] = asyncio . Queue ( maxsize = len ( self . _bat_inv_map ) ) self . _users_channels : Dict [ str , Bidirectional . Handle [ Result , Request ] ] = users_channels self . _create_users_tasks () self . _started = asyncio . Event () def _create_users_tasks ( self ) -> None : \"\"\"For each user create a task to wait for request.\"\"\" for user , handler in self . _users_channels . items (): asyncio . create_task ( self . _wait_for_request ( _User ( user , handler ))) def get_upper_bound ( self , batteries : Set [ int ]) -> float : \"\"\"Get total upper bound of power to be set for given batteries. Note, output of that function doesn't guarantee that this bound will be the same when the request is processed. Args: batteries: List of batteries Returns: Upper bound for `set_power` operation. \"\"\" pairs_data : List [ InvBatPair ] = self . _get_components_data ( batteries ) return sum ( min ( battery . power_upper_bound , inverter . active_power_upper_bound ) for battery , inverter in pairs_data ) def get_lower_bound ( self , batteries : Set [ int ]) -> float : \"\"\"Get total lower bound of power to be set for given batteries. Note, output of that function doesn't guarantee that this bound will be the same when the request is processed. Args: batteries: List of batteries Returns: Lower bound for `set_power` operation. \"\"\" pairs_data : List [ InvBatPair ] = self . _get_components_data ( batteries ) return sum ( min ( battery . power_lower_bound , inverter . active_power_lower_bound ) for battery , inverter in pairs_data ) def _within_bounds ( self , request : Request ) -> bool : \"\"\"Check whether the requested power is withing the bounds. Args: request: request Returns: True if power is between the bounds, False otherwise. \"\"\" power = request . power lower_bound = self . get_lower_bound ( request . batteries ) return lower_bound <= power <= self . get_upper_bound ( request . batteries ) async def run ( self ) -> None : \"\"\"Run actor main function. It waits for new requests in task_queue and process it, and send `set_power` request with distributed power. The output of the `set_power` method is processed. Every battery and inverter that failed or didn't respond in time will be marked as broken for some time. \"\"\" await self . _create_channels () # Wait 2 seconds to get data from the channels created above. await asyncio . sleep ( self . _wait_for_data_sec ) self . _started . set () while True : request , user = await self . _request_queue . get () try : pairs_data : List [ InvBatPair ] = self . _get_components_data ( request . batteries ) except KeyError as err : await user . channel . send ( Result ( Result . Status . ERROR , request . power , 0 , str ( err )) ) continue if len ( pairs_data ) == 0 : error_msg = f \"No data for the given batteries { str ( request . batteries ) } \" await user . channel . send ( Result ( Result . Status . ERROR , request . power , 0 , str ( error_msg )) ) continue try : distribution = self . distribution_algorithm . distribute_power ( request . power , pairs_data ) except ValueError as err : error_msg = f \"Couldn't distribute power, error: { str ( err ) } \" await user . channel . send ( Result ( Result . Status . ERROR , request . power , 0 , error_msg ) ) continue distributed_power_value = request . power - distribution . remaining_power _logger . debug ( \" %s : Distributing power %d between the inverters %s \" , user . user_id , distributed_power_value , str ( distribution . distribution ), ) tasks = { inverter_id : asyncio . create_task ( self . _api . set_power ( inverter_id , power ) ) for inverter_id , power in distribution . distribution . items () } _ , pending = await asyncio . wait ( tasks . values (), timeout = request . request_timeout_sec , return_when = ALL_COMPLETED , ) await self . _cancel_tasks ( pending ) any_fail , failed_power = self . _parse_result ( tasks , distribution . distribution , request . request_timeout_sec ) status = Result . Status . FAILED if any_fail else Result . Status . SUCCESS await user . channel . send ( Result ( status , failed_power , distribution . remaining_power ) ) def _check_request ( self , request : Request ) -> Optional [ Result ]: \"\"\"Check whether the given request if correct. Args: request: request to check Returns: Result for the user if the request is wrong, None otherwise. \"\"\" for battery in request . batteries : if battery not in self . _battery_receivers : msg = ( f \"No battery { battery } , available batteries: \" f \" { list ( self . _battery_receivers . keys ()) } \" ) return Result ( Result . Status . ERROR , request . power , 0 , error_message = msg ) if not request . adjust_power and not self . _within_bounds ( request ): return Result ( Result . Status . OUT_OF_BOUND , request . power , 0 ) return None def _remove_duplicated_requests ( self , request : Request , user : _User ) -> List [ asyncio . Task [ bool ]]: \"\"\"Remove duplicated requests from the queue. Remove old requests in which set of batteries are the same as in new request. If batteries in new request overlap with batteries in old request but are not equal, then log error and process both messages. Args: request: request to check user: User who sent the request. Returns: Tasks with result sent to the users which requests were duplicated. \"\"\" batteries = request . batteries good_requests : List [ Tuple [ Request , _User ]] = [] to_ignore : List [ asyncio . Task [ bool ]] = [] while not self . _request_queue . empty (): prev_request , prev_user = self . _request_queue . get_nowait () # Generators seems to be the fastest if prev_request . batteries == batteries : task = asyncio . create_task ( prev_user . channel . send ( Result ( Result . Status . IGNORED , prev_request . power , 0 ) ) ) to_ignore . append ( task ) # Use generators as generators seems to be the fastest. elif any ( battery_id in prev_request . batteries for battery_id in batteries ): # If that happen PowerDistributor has no way to distinguish what # request is more important. This should not happen _logger . error ( \"Batteries in two requests overlap! Actor: %s requested %s \" \"and Actor: %s requested %s \" , user . user_id , str ( request ), prev_user . user_id , str ( prev_request ), ) good_requests . append (( prev_request , prev_user )) else : good_requests . append (( prev_request , prev_user )) for good_request in good_requests : self . _request_queue . put_nowait ( good_request ) return to_ignore async def _wait_for_request ( self , user : _User ) -> None : \"\"\"Wait for the request from user. Check if request is correct. If request is not correct send ERROR response to the user. If request is correct, then add it to the main queue to be process. If main queue has request for the same subset of batteries, then remove older request, and send its user response with Result.Status.IGNORED. Only new request will re processed. If set of batteries are not the same but have common elements, then both batteries will be processed. Args: user: User that sends the requests. \"\"\" while True : request : Optional [ Request ] = await user . channel . receive () if request is None : _logger . info ( \"Send channel for user %s was closed. User will be unregistered.\" , user . user_id , ) self . _users_channels . pop ( user . user_id ) if len ( self . _users_channels ) == 0 : _logger . error ( \"No users in PowerDistributor!\" ) return # Wait for PowerDistributor to start. if not self . _started . is_set (): await self . _started . wait () # We should discover as fast as possible that request is wrong. check_result = self . _check_request ( request ) if check_result is not None : await user . channel . send ( check_result ) continue tasks = self . _remove_duplicated_requests ( request , user ) if self . _request_queue . full (): q_size = ( self . _request_queue . qsize (),) msg = ( f \"Request queue is full { q_size } , can't process this request. \" \"Consider increasing size of the queue.\" ) _logger . error ( msg ) await user . channel . send ( Result ( Result . Status . ERROR , request . power , 0 , msg ) ) else : self . _request_queue . put_nowait (( request , user )) await asyncio . gather ( * tasks ) def _get_components_pairs ( self , component_graph : ComponentGraph ) -> Tuple [ Dict [ int , int ], Dict [ int , int ]]: \"\"\"Create maps between battery and adjacent inverter. Args: component_graph: component graph Returns: Tuple where first element is map between battery and adjacent inverter, second element of the tuple is map between inverter and adjacent battery. \"\"\" bat_inv_map : Dict [ int , int ] = {} inv_bat_map : Dict [ int , int ] = {} batteries : Iterable [ Component ] = component_graph . components ( component_category = { ComponentCategory . BATTERY } ) for battery in batteries : inverters : List [ Component ] = [ component for component in component_graph . predecessors ( battery . component_id ) if component . category == ComponentCategory . INVERTER ] if len ( inverters ) == 0 : _logger . error ( \"No inverters for battery %d \" , battery . component_id ) continue if len ( inverters ) > 1 : _logger . error ( \"Battery %d has more then one inverter. It is not supported now.\" , battery . component_id , ) bat_inv_map [ battery . component_id ] = inverters [ 0 ] . component_id inv_bat_map [ inverters [ 0 ] . component_id ] = battery . component_id return bat_inv_map , inv_bat_map def _get_components_data ( self , batteries : Iterable [ int ]) -> List [ InvBatPair ]: \"\"\"Get data for the given batteries and adjacent inverters. Args: batteries: Batteries that needs data. Raises: KeyError: If any battery in the given list doesn't exists in microgrid. Returns: Pairs of battery and adjacent inverter data. \"\"\" pairs_data : List [ InvBatPair ] = [] for battery_id in batteries : if battery_id not in self . _battery_receivers : raise KeyError ( f \"No battery { battery_id } , \" f \"available batteries: { list ( self . _battery_receivers . keys ()) } \" ) inverter_id : int = self . _bat_inv_map [ battery_id ] if self . _broken_components . is_broken ( battery_id ) or self . _broken_components . is_broken ( inverter_id ): continue battery_data : Optional [ BatteryData ] = self . _battery_receivers [ battery_id ] . peek () if not self . _is_component_data_valid ( battery_id , battery_data ): continue inverter_data : Optional [ InverterData ] = self . _inverter_receivers [ inverter_id ] . peek () if not self . _is_component_data_valid ( inverter_id , inverter_data ): continue # None case already checked but mypy don't see that. if battery_data is not None and inverter_data is not None : pairs_data . append ( InvBatPair ( battery_data , inverter_data )) return pairs_data def _is_component_data_valid ( self , component_id : int , component_data : Union [ None , BatteryData , InverterData ] ) -> bool : \"\"\"Check whether the component data from microgrid are correct. Args: component_id: component id component_data: component data instance Returns: True if data are correct, false otherwise \"\"\" if component_data is None : _logger . warning ( \"No data from component %d .\" , component_id , ) return False now = datetime . now ( timezone . utc ) time_delta = now - component_data . timestamp if time_delta . total_seconds () > self . component_data_timeout_sec : _logger . warning ( \"Component %d data are stale. Last timestamp: %s , now: %s \" , component_id , str ( component_data . timestamp ), str ( now ), ) return False return True async def _create_channels ( self ) -> None : \"\"\"Create channels to get data of components in microgrid.\"\"\" for battery_id , inverter_id in self . _bat_inv_map . items (): bat_recv : Receiver [ BatteryData ] = await self . _api . battery_data ( battery_id ) self . _battery_receivers [ battery_id ] = bat_recv . into_peekable () inv_recv : Receiver [ InverterData ] = await self . _api . inverter_data ( inverter_id ) self . _inverter_receivers [ inverter_id ] = inv_recv . into_peekable () def _parse_result ( self , # type comment to quiet pylint and mypy `unused-import` error tasks , # type: Dict[int, asyncio.Task[Empty]] distribution : Dict [ int , int ], request_timeout_sec : float , ) -> Tuple [ bool , int ]: \"\"\"Parse result of `set_power` requests. Check if any task failed and why. If any task didn't success, then corresponding battery is marked as broken. Args: tasks: Dictionary where key is inverter id and value is task that set power for this inverter. Each tasks should be finished or cancelled. distribution: Dictionary where key is inverter id and value is how much power was set to the corresponding inverter. request_timeout_sec: timeout which has been used for request. Returns: Tuple where first element tells if any task didn't succeed, and the second element is total amount of power that failed. \"\"\" any_fail : bool = False failed_power : int = 0 for inverter_id , aws in tasks . items (): battery_id = self . _inv_bat_map [ inverter_id ] try : aws . result () except grpc . aio . AioRpcError as err : any_fail = True failed_power += distribution [ inverter_id ] if err . code () == grpc . StatusCode . OUT_OF_RANGE : _logger . debug ( \"Set power for battery %d failed, error %s \" , battery_id , str ( err ), ) else : _logger . warning ( \"Set power for battery %d failed, error %s . Mark it as broken.\" , battery_id , str ( err ), ) self . _broken_components . mark_as_broken ( battery_id ) except asyncio . exceptions . CancelledError : any_fail = True failed_power += distribution [ inverter_id ] _logger . warning ( \"Battery %d didn't respond in %f sec. Mark it as broken.\" , battery_id , request_timeout_sec , ) self . _broken_components . mark_as_broken ( battery_id ) return any_fail , failed_power async def _cancel_tasks ( self , tasks : Iterable [ asyncio . Task [ Any ]]) -> None : \"\"\"Cancel given asyncio tasks and wait for them. Args: tasks: tasks to cancel. \"\"\" for aws in tasks : aws . cancel () await asyncio . gather ( * tasks , return_exceptions = True ) Functions \u00a4 __init__ ( microgrid_api , component_graph , users_channels , wait_for_data_sec = 2 ) \u00a4 Create class instance. PARAMETER DESCRIPTION microgrid_api api for sending the requests. TYPE: MicrogridApiClient component_graph component graph of the given microgrid api. TYPE: ComponentGraph users_channels BidirectionalHandle for each user. Key should be user id and value should be BidirectionalHandle. TYPE: Dict [ str , Bidirectional . Handle [ Result , Request ]] wait_for_data_sec How long actor should wait before processing first request. It is a time needed to collect first components data. TYPE: float DEFAULT: 2 Source code in frequenz/sdk/actor/power_distributing.py 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 def __init__ ( self , microgrid_api : MicrogridApiClient , component_graph : ComponentGraph , users_channels : Dict [ str , Bidirectional . Handle [ Result , Request ]], wait_for_data_sec : float = 2 , ) -> None : \"\"\"Create class instance. Args: microgrid_api: api for sending the requests. component_graph: component graph of the given microgrid api. users_channels: BidirectionalHandle for each user. Key should be user id and value should be BidirectionalHandle. wait_for_data_sec: How long actor should wait before processing first request. It is a time needed to collect first components data. \"\"\" self . _api = microgrid_api self . _wait_for_data_sec = wait_for_data_sec # Max permitted time when the component should send any information. # After that timeout the component will be treated as not existing. # Formulas will put 0 in place of data from this components. # This will happen until component starts sending data. self . component_data_timeout_sec : float = 60.0 self . broken_component_timeout_sec : float = 30.0 self . power_distributor_exponent : float = 1.0 # distributor_exponent and timeout_sec should be get from ConfigManager self . distribution_algorithm = DistributionAlgorithm ( self . power_distributor_exponent ) self . _broken_components = _BrokenComponents ( self . broken_component_timeout_sec ) self . _bat_inv_map , self . _inv_bat_map = self . _get_components_pairs ( component_graph ) self . _battery_receivers : Dict [ int , Peekable [ BatteryData ]] = {} self . _inverter_receivers : Dict [ int , Peekable [ InverterData ]] = {} # The components in different requests be for the same components, or for # completely different components. They should not overlap. # Otherwise the PowerDistributor has no way to decide what request is more # important. It will execute both. And later request will override the previous # one. # That is why the queue of maxsize = total number of batteries should be enough. self . _request_queue : asyncio . Queue [ Tuple [ Request , _User ]] = asyncio . Queue ( maxsize = len ( self . _bat_inv_map ) ) self . _users_channels : Dict [ str , Bidirectional . Handle [ Result , Request ] ] = users_channels self . _create_users_tasks () self . _started = asyncio . Event () get_lower_bound ( batteries ) \u00a4 Get total lower bound of power to be set for given batteries. Note, output of that function doesn't guarantee that this bound will be the same when the request is processed. PARAMETER DESCRIPTION batteries List of batteries TYPE: Set [ int ] RETURNS DESCRIPTION float Lower bound for set_power operation. Source code in frequenz/sdk/actor/power_distributing.py 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 def get_lower_bound ( self , batteries : Set [ int ]) -> float : \"\"\"Get total lower bound of power to be set for given batteries. Note, output of that function doesn't guarantee that this bound will be the same when the request is processed. Args: batteries: List of batteries Returns: Lower bound for `set_power` operation. \"\"\" pairs_data : List [ InvBatPair ] = self . _get_components_data ( batteries ) return sum ( min ( battery . power_lower_bound , inverter . active_power_lower_bound ) for battery , inverter in pairs_data ) get_upper_bound ( batteries ) \u00a4 Get total upper bound of power to be set for given batteries. Note, output of that function doesn't guarantee that this bound will be the same when the request is processed. PARAMETER DESCRIPTION batteries List of batteries TYPE: Set [ int ] RETURNS DESCRIPTION float Upper bound for set_power operation. Source code in frequenz/sdk/actor/power_distributing.py 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 def get_upper_bound ( self , batteries : Set [ int ]) -> float : \"\"\"Get total upper bound of power to be set for given batteries. Note, output of that function doesn't guarantee that this bound will be the same when the request is processed. Args: batteries: List of batteries Returns: Upper bound for `set_power` operation. \"\"\" pairs_data : List [ InvBatPair ] = self . _get_components_data ( batteries ) return sum ( min ( battery . power_upper_bound , inverter . active_power_upper_bound ) for battery , inverter in pairs_data ) run () async \u00a4 Run actor main function. It waits for new requests in task_queue and process it, and send set_power request with distributed power. The output of the set_power method is processed. Every battery and inverter that failed or didn't respond in time will be marked as broken for some time. Source code in frequenz/sdk/actor/power_distributing.py 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 async def run ( self ) -> None : \"\"\"Run actor main function. It waits for new requests in task_queue and process it, and send `set_power` request with distributed power. The output of the `set_power` method is processed. Every battery and inverter that failed or didn't respond in time will be marked as broken for some time. \"\"\" await self . _create_channels () # Wait 2 seconds to get data from the channels created above. await asyncio . sleep ( self . _wait_for_data_sec ) self . _started . set () while True : request , user = await self . _request_queue . get () try : pairs_data : List [ InvBatPair ] = self . _get_components_data ( request . batteries ) except KeyError as err : await user . channel . send ( Result ( Result . Status . ERROR , request . power , 0 , str ( err )) ) continue if len ( pairs_data ) == 0 : error_msg = f \"No data for the given batteries { str ( request . batteries ) } \" await user . channel . send ( Result ( Result . Status . ERROR , request . power , 0 , str ( error_msg )) ) continue try : distribution = self . distribution_algorithm . distribute_power ( request . power , pairs_data ) except ValueError as err : error_msg = f \"Couldn't distribute power, error: { str ( err ) } \" await user . channel . send ( Result ( Result . Status . ERROR , request . power , 0 , error_msg ) ) continue distributed_power_value = request . power - distribution . remaining_power _logger . debug ( \" %s : Distributing power %d between the inverters %s \" , user . user_id , distributed_power_value , str ( distribution . distribution ), ) tasks = { inverter_id : asyncio . create_task ( self . _api . set_power ( inverter_id , power ) ) for inverter_id , power in distribution . distribution . items () } _ , pending = await asyncio . wait ( tasks . values (), timeout = request . request_timeout_sec , return_when = ALL_COMPLETED , ) await self . _cancel_tasks ( pending ) any_fail , failed_power = self . _parse_result ( tasks , distribution . distribution , request . request_timeout_sec ) status = Result . Status . FAILED if any_fail else Result . Status . SUCCESS await user . channel . send ( Result ( status , failed_power , distribution . remaining_power ) ) frequenz.sdk.actor.power_distributing.Request dataclass \u00a4 Request from the user. Source code in frequenz/sdk/actor/power_distributing.py 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 @dataclass class Request : \"\"\"Request from the user.\"\"\" # How much power to set power : int # In which batteries the power should be set batteries : Set [ int ] # Timeout for the server to respond on the request. request_timeout_sec : float = 5.0 # If True and requested power value is out of bound, then # PowerDistributor will decrease the power to match the bounds and # distribute only decreased power. # If False and the requested power is out of bound, then # PowerDistributor will not process this request and send result with status # Result.Status.OUT_OF_BOUND. adjust_power : bool = True frequenz.sdk.actor.power_distributing.Result dataclass \u00a4 Result on distribution request. Source code in frequenz/sdk/actor/power_distributing.py 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 @dataclass class Result : \"\"\"Result on distribution request.\"\"\" class Status ( Enum ): \"\"\"Status of the result.\"\"\" FAILED = 0 # If any request for any battery didn't succeed for any reason. SUCCESS = 1 # If all requests for all batteries succeed. IGNORED = 2 # If request was dispossessed by newer request with the same set # of batteries. ERROR = 3 # If any error happened. In this case error_message describes error. OUT_OF_BOUND = 4 # When Request.adjust_power=False and the requested power was # out of the bounds for specified batteries. status : Status # Status of the request. failed_power : float # How much power failed. above_upper_bound : float # How much power was not used because it was beyond the # limits. error_message : Optional [ str ] = None # error_message filled only when status is ERROR Classes \u00a4 Status \u00a4 Bases: Enum Status of the result. Source code in frequenz/sdk/actor/power_distributing.py 137 138 139 140 141 142 143 144 145 class Status ( Enum ): \"\"\"Status of the result.\"\"\" FAILED = 0 # If any request for any battery didn't succeed for any reason. SUCCESS = 1 # If all requests for all batteries succeed. IGNORED = 2 # If request was dispossessed by newer request with the same set # of batteries. ERROR = 3 # If any error happened. In this case error_message describes error. OUT_OF_BOUND = 4 # When Request.adjust_power=False and the requested power was Functions \u00a4","title":"power_distributing"},{"location":"reference/frequenz/sdk/actor/power_distributing/#frequenz.sdk.actor.power_distributing","text":"Actor to distribute power between batteries. When charge/discharge method is called the power should be distributed so that the SoC in batteries stays at the same level. That way of distribution prevents using only one battery, increasing temperature, and maximize the total amount power to charge/discharge. Purpose of this actor is to keep SoC level of each component at the equal level.","title":"power_distributing"},{"location":"reference/frequenz/sdk/actor/power_distributing/#frequenz.sdk.actor.power_distributing-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/actor/power_distributing/#frequenz.sdk.actor.power_distributing.PowerDistributingActor","text":"Tool to distribute power between batteries in microgrid. The purpose of this tool is to keep equal SoC level in the batteries. PowerDistributor can have many users. Each user should first register in order to get its id, channel for sending request, and channel for receiving response. It is recommended to wait for PowerDistributor output with timeout. Otherwise if the processing function fail then the response will never come. The timeout should be Result:request_timeout_sec + time for processing the request. Edge cases: * If there are 2 requests to be processed for the same subset of batteries, then only the latest request will be processed. Older request will be ignored. User with older request will get response with Result.Status.IGNORED. If there are 2 requests and their subset of batteries is different but they overlap (they have at least one common battery), then then both batteries will be processed. However it is not expected so the proper error log will be printed. Example import grpc.aio as grpcaio from frequenz.sdk.microgrid.graph import _MicrogridComponentGraph from frequenz.sdk.microgrid.component import ComponentCategory from frequenz.sdk.power_distribution import ( PowerDistributor , Request , Result , ) target = f \" { host } : { port } \" grpc_channel = grpcaio . insecure_channel ( target ) api = MicrogridGrpcClient ( grpc_channel , target ) graph = _MicrogridComponentGraph () await graph . refresh_from_api ( api ) batteries = graph . components ( component_category = { ComponentCategory . BATTERY }) batteries_ids = { c . component_id for c in batteries } channel = Bidirectional [ Request , Result ]( \"user1\" , \"power_distributor\" ) power_distributor = PowerDistributor ( mock_api , component_graph , { \"user1\" : channel . service_handle } ) client_handle = channel . client_handle # Set power 1200W to given batteries. request = Request ( power = 1200 , batteries = batteries_ids , request_timeout_sec = 10.0 ) await client_handle . send ( request ) # It is recommended to use timeout when waiting for the response! result : Result = await asyncio . wait_for ( client_handle . receive (), timeout = 10 ) if result . status == Result . Status . SUCCESS : print ( \"Command succeed\" ) elif result . status == Result . Status . FAILED : print ( f \"Some batteries failed, total failed power: { result . failed_power } \" ) elif result . status == Result . Status . IGNORED : print ( f \"Request was ignored, because of newer command\" ) elif result . status == Result . Status . ERROR : print ( f \"Request failed with error: { request . error_message } \" ) Source code in frequenz/sdk/actor/power_distributing.py 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 @actor class PowerDistributingActor : # pylint: disable=too-many-instance-attributes \"\"\"Tool to distribute power between batteries in microgrid. The purpose of this tool is to keep equal SoC level in the batteries. PowerDistributor can have many users. Each user should first register in order to get its id, channel for sending request, and channel for receiving response. It is recommended to wait for PowerDistributor output with timeout. Otherwise if the processing function fail then the response will never come. The timeout should be Result:request_timeout_sec + time for processing the request. Edge cases: * If there are 2 requests to be processed for the same subset of batteries, then only the latest request will be processed. Older request will be ignored. User with older request will get response with Result.Status.IGNORED. * If there are 2 requests and their subset of batteries is different but they overlap (they have at least one common battery), then then both batteries will be processed. However it is not expected so the proper error log will be printed. Example: ``` python import grpc.aio as grpcaio from frequenz.sdk.microgrid.graph import _MicrogridComponentGraph from frequenz.sdk.microgrid.component import ComponentCategory from frequenz.sdk.power_distribution import ( PowerDistributor, Request, Result, ) target = f\"{host}:{port}\" grpc_channel = grpcaio.insecure_channel(target) api = MicrogridGrpcClient(grpc_channel, target) graph = _MicrogridComponentGraph() await graph.refresh_from_api(api) batteries = graph.components(component_category={ComponentCategory.BATTERY}) batteries_ids = {c.component_id for c in batteries} channel = Bidirectional[Request, Result](\"user1\", \"power_distributor\") power_distributor = PowerDistributor( mock_api, component_graph, {\"user1\": channel.service_handle} ) client_handle = channel.client_handle # Set power 1200W to given batteries. request = Request(power=1200, batteries=batteries_ids, request_timeout_sec=10.0) await client_handle.send(request) # It is recommended to use timeout when waiting for the response! result: Result = await asyncio.wait_for(client_handle.receive(), timeout=10) if result.status == Result.Status.SUCCESS: print(\"Command succeed\") elif result.status == Result.Status.FAILED: print( f\"Some batteries failed, total failed power: {result.failed_power}\") elif result.status == Result.Status.IGNORED: print(f\"Request was ignored, because of newer command\") elif result.status == Result.Status.ERROR: print(f\"Request failed with error: {request.error_message}\") ``` \"\"\" def __init__ ( self , microgrid_api : MicrogridApiClient , component_graph : ComponentGraph , users_channels : Dict [ str , Bidirectional . Handle [ Result , Request ]], wait_for_data_sec : float = 2 , ) -> None : \"\"\"Create class instance. Args: microgrid_api: api for sending the requests. component_graph: component graph of the given microgrid api. users_channels: BidirectionalHandle for each user. Key should be user id and value should be BidirectionalHandle. wait_for_data_sec: How long actor should wait before processing first request. It is a time needed to collect first components data. \"\"\" self . _api = microgrid_api self . _wait_for_data_sec = wait_for_data_sec # Max permitted time when the component should send any information. # After that timeout the component will be treated as not existing. # Formulas will put 0 in place of data from this components. # This will happen until component starts sending data. self . component_data_timeout_sec : float = 60.0 self . broken_component_timeout_sec : float = 30.0 self . power_distributor_exponent : float = 1.0 # distributor_exponent and timeout_sec should be get from ConfigManager self . distribution_algorithm = DistributionAlgorithm ( self . power_distributor_exponent ) self . _broken_components = _BrokenComponents ( self . broken_component_timeout_sec ) self . _bat_inv_map , self . _inv_bat_map = self . _get_components_pairs ( component_graph ) self . _battery_receivers : Dict [ int , Peekable [ BatteryData ]] = {} self . _inverter_receivers : Dict [ int , Peekable [ InverterData ]] = {} # The components in different requests be for the same components, or for # completely different components. They should not overlap. # Otherwise the PowerDistributor has no way to decide what request is more # important. It will execute both. And later request will override the previous # one. # That is why the queue of maxsize = total number of batteries should be enough. self . _request_queue : asyncio . Queue [ Tuple [ Request , _User ]] = asyncio . Queue ( maxsize = len ( self . _bat_inv_map ) ) self . _users_channels : Dict [ str , Bidirectional . Handle [ Result , Request ] ] = users_channels self . _create_users_tasks () self . _started = asyncio . Event () def _create_users_tasks ( self ) -> None : \"\"\"For each user create a task to wait for request.\"\"\" for user , handler in self . _users_channels . items (): asyncio . create_task ( self . _wait_for_request ( _User ( user , handler ))) def get_upper_bound ( self , batteries : Set [ int ]) -> float : \"\"\"Get total upper bound of power to be set for given batteries. Note, output of that function doesn't guarantee that this bound will be the same when the request is processed. Args: batteries: List of batteries Returns: Upper bound for `set_power` operation. \"\"\" pairs_data : List [ InvBatPair ] = self . _get_components_data ( batteries ) return sum ( min ( battery . power_upper_bound , inverter . active_power_upper_bound ) for battery , inverter in pairs_data ) def get_lower_bound ( self , batteries : Set [ int ]) -> float : \"\"\"Get total lower bound of power to be set for given batteries. Note, output of that function doesn't guarantee that this bound will be the same when the request is processed. Args: batteries: List of batteries Returns: Lower bound for `set_power` operation. \"\"\" pairs_data : List [ InvBatPair ] = self . _get_components_data ( batteries ) return sum ( min ( battery . power_lower_bound , inverter . active_power_lower_bound ) for battery , inverter in pairs_data ) def _within_bounds ( self , request : Request ) -> bool : \"\"\"Check whether the requested power is withing the bounds. Args: request: request Returns: True if power is between the bounds, False otherwise. \"\"\" power = request . power lower_bound = self . get_lower_bound ( request . batteries ) return lower_bound <= power <= self . get_upper_bound ( request . batteries ) async def run ( self ) -> None : \"\"\"Run actor main function. It waits for new requests in task_queue and process it, and send `set_power` request with distributed power. The output of the `set_power` method is processed. Every battery and inverter that failed or didn't respond in time will be marked as broken for some time. \"\"\" await self . _create_channels () # Wait 2 seconds to get data from the channels created above. await asyncio . sleep ( self . _wait_for_data_sec ) self . _started . set () while True : request , user = await self . _request_queue . get () try : pairs_data : List [ InvBatPair ] = self . _get_components_data ( request . batteries ) except KeyError as err : await user . channel . send ( Result ( Result . Status . ERROR , request . power , 0 , str ( err )) ) continue if len ( pairs_data ) == 0 : error_msg = f \"No data for the given batteries { str ( request . batteries ) } \" await user . channel . send ( Result ( Result . Status . ERROR , request . power , 0 , str ( error_msg )) ) continue try : distribution = self . distribution_algorithm . distribute_power ( request . power , pairs_data ) except ValueError as err : error_msg = f \"Couldn't distribute power, error: { str ( err ) } \" await user . channel . send ( Result ( Result . Status . ERROR , request . power , 0 , error_msg ) ) continue distributed_power_value = request . power - distribution . remaining_power _logger . debug ( \" %s : Distributing power %d between the inverters %s \" , user . user_id , distributed_power_value , str ( distribution . distribution ), ) tasks = { inverter_id : asyncio . create_task ( self . _api . set_power ( inverter_id , power ) ) for inverter_id , power in distribution . distribution . items () } _ , pending = await asyncio . wait ( tasks . values (), timeout = request . request_timeout_sec , return_when = ALL_COMPLETED , ) await self . _cancel_tasks ( pending ) any_fail , failed_power = self . _parse_result ( tasks , distribution . distribution , request . request_timeout_sec ) status = Result . Status . FAILED if any_fail else Result . Status . SUCCESS await user . channel . send ( Result ( status , failed_power , distribution . remaining_power ) ) def _check_request ( self , request : Request ) -> Optional [ Result ]: \"\"\"Check whether the given request if correct. Args: request: request to check Returns: Result for the user if the request is wrong, None otherwise. \"\"\" for battery in request . batteries : if battery not in self . _battery_receivers : msg = ( f \"No battery { battery } , available batteries: \" f \" { list ( self . _battery_receivers . keys ()) } \" ) return Result ( Result . Status . ERROR , request . power , 0 , error_message = msg ) if not request . adjust_power and not self . _within_bounds ( request ): return Result ( Result . Status . OUT_OF_BOUND , request . power , 0 ) return None def _remove_duplicated_requests ( self , request : Request , user : _User ) -> List [ asyncio . Task [ bool ]]: \"\"\"Remove duplicated requests from the queue. Remove old requests in which set of batteries are the same as in new request. If batteries in new request overlap with batteries in old request but are not equal, then log error and process both messages. Args: request: request to check user: User who sent the request. Returns: Tasks with result sent to the users which requests were duplicated. \"\"\" batteries = request . batteries good_requests : List [ Tuple [ Request , _User ]] = [] to_ignore : List [ asyncio . Task [ bool ]] = [] while not self . _request_queue . empty (): prev_request , prev_user = self . _request_queue . get_nowait () # Generators seems to be the fastest if prev_request . batteries == batteries : task = asyncio . create_task ( prev_user . channel . send ( Result ( Result . Status . IGNORED , prev_request . power , 0 ) ) ) to_ignore . append ( task ) # Use generators as generators seems to be the fastest. elif any ( battery_id in prev_request . batteries for battery_id in batteries ): # If that happen PowerDistributor has no way to distinguish what # request is more important. This should not happen _logger . error ( \"Batteries in two requests overlap! Actor: %s requested %s \" \"and Actor: %s requested %s \" , user . user_id , str ( request ), prev_user . user_id , str ( prev_request ), ) good_requests . append (( prev_request , prev_user )) else : good_requests . append (( prev_request , prev_user )) for good_request in good_requests : self . _request_queue . put_nowait ( good_request ) return to_ignore async def _wait_for_request ( self , user : _User ) -> None : \"\"\"Wait for the request from user. Check if request is correct. If request is not correct send ERROR response to the user. If request is correct, then add it to the main queue to be process. If main queue has request for the same subset of batteries, then remove older request, and send its user response with Result.Status.IGNORED. Only new request will re processed. If set of batteries are not the same but have common elements, then both batteries will be processed. Args: user: User that sends the requests. \"\"\" while True : request : Optional [ Request ] = await user . channel . receive () if request is None : _logger . info ( \"Send channel for user %s was closed. User will be unregistered.\" , user . user_id , ) self . _users_channels . pop ( user . user_id ) if len ( self . _users_channels ) == 0 : _logger . error ( \"No users in PowerDistributor!\" ) return # Wait for PowerDistributor to start. if not self . _started . is_set (): await self . _started . wait () # We should discover as fast as possible that request is wrong. check_result = self . _check_request ( request ) if check_result is not None : await user . channel . send ( check_result ) continue tasks = self . _remove_duplicated_requests ( request , user ) if self . _request_queue . full (): q_size = ( self . _request_queue . qsize (),) msg = ( f \"Request queue is full { q_size } , can't process this request. \" \"Consider increasing size of the queue.\" ) _logger . error ( msg ) await user . channel . send ( Result ( Result . Status . ERROR , request . power , 0 , msg ) ) else : self . _request_queue . put_nowait (( request , user )) await asyncio . gather ( * tasks ) def _get_components_pairs ( self , component_graph : ComponentGraph ) -> Tuple [ Dict [ int , int ], Dict [ int , int ]]: \"\"\"Create maps between battery and adjacent inverter. Args: component_graph: component graph Returns: Tuple where first element is map between battery and adjacent inverter, second element of the tuple is map between inverter and adjacent battery. \"\"\" bat_inv_map : Dict [ int , int ] = {} inv_bat_map : Dict [ int , int ] = {} batteries : Iterable [ Component ] = component_graph . components ( component_category = { ComponentCategory . BATTERY } ) for battery in batteries : inverters : List [ Component ] = [ component for component in component_graph . predecessors ( battery . component_id ) if component . category == ComponentCategory . INVERTER ] if len ( inverters ) == 0 : _logger . error ( \"No inverters for battery %d \" , battery . component_id ) continue if len ( inverters ) > 1 : _logger . error ( \"Battery %d has more then one inverter. It is not supported now.\" , battery . component_id , ) bat_inv_map [ battery . component_id ] = inverters [ 0 ] . component_id inv_bat_map [ inverters [ 0 ] . component_id ] = battery . component_id return bat_inv_map , inv_bat_map def _get_components_data ( self , batteries : Iterable [ int ]) -> List [ InvBatPair ]: \"\"\"Get data for the given batteries and adjacent inverters. Args: batteries: Batteries that needs data. Raises: KeyError: If any battery in the given list doesn't exists in microgrid. Returns: Pairs of battery and adjacent inverter data. \"\"\" pairs_data : List [ InvBatPair ] = [] for battery_id in batteries : if battery_id not in self . _battery_receivers : raise KeyError ( f \"No battery { battery_id } , \" f \"available batteries: { list ( self . _battery_receivers . keys ()) } \" ) inverter_id : int = self . _bat_inv_map [ battery_id ] if self . _broken_components . is_broken ( battery_id ) or self . _broken_components . is_broken ( inverter_id ): continue battery_data : Optional [ BatteryData ] = self . _battery_receivers [ battery_id ] . peek () if not self . _is_component_data_valid ( battery_id , battery_data ): continue inverter_data : Optional [ InverterData ] = self . _inverter_receivers [ inverter_id ] . peek () if not self . _is_component_data_valid ( inverter_id , inverter_data ): continue # None case already checked but mypy don't see that. if battery_data is not None and inverter_data is not None : pairs_data . append ( InvBatPair ( battery_data , inverter_data )) return pairs_data def _is_component_data_valid ( self , component_id : int , component_data : Union [ None , BatteryData , InverterData ] ) -> bool : \"\"\"Check whether the component data from microgrid are correct. Args: component_id: component id component_data: component data instance Returns: True if data are correct, false otherwise \"\"\" if component_data is None : _logger . warning ( \"No data from component %d .\" , component_id , ) return False now = datetime . now ( timezone . utc ) time_delta = now - component_data . timestamp if time_delta . total_seconds () > self . component_data_timeout_sec : _logger . warning ( \"Component %d data are stale. Last timestamp: %s , now: %s \" , component_id , str ( component_data . timestamp ), str ( now ), ) return False return True async def _create_channels ( self ) -> None : \"\"\"Create channels to get data of components in microgrid.\"\"\" for battery_id , inverter_id in self . _bat_inv_map . items (): bat_recv : Receiver [ BatteryData ] = await self . _api . battery_data ( battery_id ) self . _battery_receivers [ battery_id ] = bat_recv . into_peekable () inv_recv : Receiver [ InverterData ] = await self . _api . inverter_data ( inverter_id ) self . _inverter_receivers [ inverter_id ] = inv_recv . into_peekable () def _parse_result ( self , # type comment to quiet pylint and mypy `unused-import` error tasks , # type: Dict[int, asyncio.Task[Empty]] distribution : Dict [ int , int ], request_timeout_sec : float , ) -> Tuple [ bool , int ]: \"\"\"Parse result of `set_power` requests. Check if any task failed and why. If any task didn't success, then corresponding battery is marked as broken. Args: tasks: Dictionary where key is inverter id and value is task that set power for this inverter. Each tasks should be finished or cancelled. distribution: Dictionary where key is inverter id and value is how much power was set to the corresponding inverter. request_timeout_sec: timeout which has been used for request. Returns: Tuple where first element tells if any task didn't succeed, and the second element is total amount of power that failed. \"\"\" any_fail : bool = False failed_power : int = 0 for inverter_id , aws in tasks . items (): battery_id = self . _inv_bat_map [ inverter_id ] try : aws . result () except grpc . aio . AioRpcError as err : any_fail = True failed_power += distribution [ inverter_id ] if err . code () == grpc . StatusCode . OUT_OF_RANGE : _logger . debug ( \"Set power for battery %d failed, error %s \" , battery_id , str ( err ), ) else : _logger . warning ( \"Set power for battery %d failed, error %s . Mark it as broken.\" , battery_id , str ( err ), ) self . _broken_components . mark_as_broken ( battery_id ) except asyncio . exceptions . CancelledError : any_fail = True failed_power += distribution [ inverter_id ] _logger . warning ( \"Battery %d didn't respond in %f sec. Mark it as broken.\" , battery_id , request_timeout_sec , ) self . _broken_components . mark_as_broken ( battery_id ) return any_fail , failed_power async def _cancel_tasks ( self , tasks : Iterable [ asyncio . Task [ Any ]]) -> None : \"\"\"Cancel given asyncio tasks and wait for them. Args: tasks: tasks to cancel. \"\"\" for aws in tasks : aws . cancel () await asyncio . gather ( * tasks , return_exceptions = True )","title":"PowerDistributingActor"},{"location":"reference/frequenz/sdk/actor/power_distributing/#frequenz.sdk.actor.power_distributing.PowerDistributingActor-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/actor/power_distributing/#frequenz.sdk.actor.power_distributing.PowerDistributingActor.__init__","text":"Create class instance. PARAMETER DESCRIPTION microgrid_api api for sending the requests. TYPE: MicrogridApiClient component_graph component graph of the given microgrid api. TYPE: ComponentGraph users_channels BidirectionalHandle for each user. Key should be user id and value should be BidirectionalHandle. TYPE: Dict [ str , Bidirectional . Handle [ Result , Request ]] wait_for_data_sec How long actor should wait before processing first request. It is a time needed to collect first components data. TYPE: float DEFAULT: 2 Source code in frequenz/sdk/actor/power_distributing.py 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 def __init__ ( self , microgrid_api : MicrogridApiClient , component_graph : ComponentGraph , users_channels : Dict [ str , Bidirectional . Handle [ Result , Request ]], wait_for_data_sec : float = 2 , ) -> None : \"\"\"Create class instance. Args: microgrid_api: api for sending the requests. component_graph: component graph of the given microgrid api. users_channels: BidirectionalHandle for each user. Key should be user id and value should be BidirectionalHandle. wait_for_data_sec: How long actor should wait before processing first request. It is a time needed to collect first components data. \"\"\" self . _api = microgrid_api self . _wait_for_data_sec = wait_for_data_sec # Max permitted time when the component should send any information. # After that timeout the component will be treated as not existing. # Formulas will put 0 in place of data from this components. # This will happen until component starts sending data. self . component_data_timeout_sec : float = 60.0 self . broken_component_timeout_sec : float = 30.0 self . power_distributor_exponent : float = 1.0 # distributor_exponent and timeout_sec should be get from ConfigManager self . distribution_algorithm = DistributionAlgorithm ( self . power_distributor_exponent ) self . _broken_components = _BrokenComponents ( self . broken_component_timeout_sec ) self . _bat_inv_map , self . _inv_bat_map = self . _get_components_pairs ( component_graph ) self . _battery_receivers : Dict [ int , Peekable [ BatteryData ]] = {} self . _inverter_receivers : Dict [ int , Peekable [ InverterData ]] = {} # The components in different requests be for the same components, or for # completely different components. They should not overlap. # Otherwise the PowerDistributor has no way to decide what request is more # important. It will execute both. And later request will override the previous # one. # That is why the queue of maxsize = total number of batteries should be enough. self . _request_queue : asyncio . Queue [ Tuple [ Request , _User ]] = asyncio . Queue ( maxsize = len ( self . _bat_inv_map ) ) self . _users_channels : Dict [ str , Bidirectional . Handle [ Result , Request ] ] = users_channels self . _create_users_tasks () self . _started = asyncio . Event ()","title":"__init__()"},{"location":"reference/frequenz/sdk/actor/power_distributing/#frequenz.sdk.actor.power_distributing.PowerDistributingActor.get_lower_bound","text":"Get total lower bound of power to be set for given batteries. Note, output of that function doesn't guarantee that this bound will be the same when the request is processed. PARAMETER DESCRIPTION batteries List of batteries TYPE: Set [ int ] RETURNS DESCRIPTION float Lower bound for set_power operation. Source code in frequenz/sdk/actor/power_distributing.py 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 def get_lower_bound ( self , batteries : Set [ int ]) -> float : \"\"\"Get total lower bound of power to be set for given batteries. Note, output of that function doesn't guarantee that this bound will be the same when the request is processed. Args: batteries: List of batteries Returns: Lower bound for `set_power` operation. \"\"\" pairs_data : List [ InvBatPair ] = self . _get_components_data ( batteries ) return sum ( min ( battery . power_lower_bound , inverter . active_power_lower_bound ) for battery , inverter in pairs_data )","title":"get_lower_bound()"},{"location":"reference/frequenz/sdk/actor/power_distributing/#frequenz.sdk.actor.power_distributing.PowerDistributingActor.get_upper_bound","text":"Get total upper bound of power to be set for given batteries. Note, output of that function doesn't guarantee that this bound will be the same when the request is processed. PARAMETER DESCRIPTION batteries List of batteries TYPE: Set [ int ] RETURNS DESCRIPTION float Upper bound for set_power operation. Source code in frequenz/sdk/actor/power_distributing.py 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 def get_upper_bound ( self , batteries : Set [ int ]) -> float : \"\"\"Get total upper bound of power to be set for given batteries. Note, output of that function doesn't guarantee that this bound will be the same when the request is processed. Args: batteries: List of batteries Returns: Upper bound for `set_power` operation. \"\"\" pairs_data : List [ InvBatPair ] = self . _get_components_data ( batteries ) return sum ( min ( battery . power_upper_bound , inverter . active_power_upper_bound ) for battery , inverter in pairs_data )","title":"get_upper_bound()"},{"location":"reference/frequenz/sdk/actor/power_distributing/#frequenz.sdk.actor.power_distributing.PowerDistributingActor.run","text":"Run actor main function. It waits for new requests in task_queue and process it, and send set_power request with distributed power. The output of the set_power method is processed. Every battery and inverter that failed or didn't respond in time will be marked as broken for some time. Source code in frequenz/sdk/actor/power_distributing.py 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 async def run ( self ) -> None : \"\"\"Run actor main function. It waits for new requests in task_queue and process it, and send `set_power` request with distributed power. The output of the `set_power` method is processed. Every battery and inverter that failed or didn't respond in time will be marked as broken for some time. \"\"\" await self . _create_channels () # Wait 2 seconds to get data from the channels created above. await asyncio . sleep ( self . _wait_for_data_sec ) self . _started . set () while True : request , user = await self . _request_queue . get () try : pairs_data : List [ InvBatPair ] = self . _get_components_data ( request . batteries ) except KeyError as err : await user . channel . send ( Result ( Result . Status . ERROR , request . power , 0 , str ( err )) ) continue if len ( pairs_data ) == 0 : error_msg = f \"No data for the given batteries { str ( request . batteries ) } \" await user . channel . send ( Result ( Result . Status . ERROR , request . power , 0 , str ( error_msg )) ) continue try : distribution = self . distribution_algorithm . distribute_power ( request . power , pairs_data ) except ValueError as err : error_msg = f \"Couldn't distribute power, error: { str ( err ) } \" await user . channel . send ( Result ( Result . Status . ERROR , request . power , 0 , error_msg ) ) continue distributed_power_value = request . power - distribution . remaining_power _logger . debug ( \" %s : Distributing power %d between the inverters %s \" , user . user_id , distributed_power_value , str ( distribution . distribution ), ) tasks = { inverter_id : asyncio . create_task ( self . _api . set_power ( inverter_id , power ) ) for inverter_id , power in distribution . distribution . items () } _ , pending = await asyncio . wait ( tasks . values (), timeout = request . request_timeout_sec , return_when = ALL_COMPLETED , ) await self . _cancel_tasks ( pending ) any_fail , failed_power = self . _parse_result ( tasks , distribution . distribution , request . request_timeout_sec ) status = Result . Status . FAILED if any_fail else Result . Status . SUCCESS await user . channel . send ( Result ( status , failed_power , distribution . remaining_power ) )","title":"run()"},{"location":"reference/frequenz/sdk/actor/power_distributing/#frequenz.sdk.actor.power_distributing.Request","text":"Request from the user. Source code in frequenz/sdk/actor/power_distributing.py 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 @dataclass class Request : \"\"\"Request from the user.\"\"\" # How much power to set power : int # In which batteries the power should be set batteries : Set [ int ] # Timeout for the server to respond on the request. request_timeout_sec : float = 5.0 # If True and requested power value is out of bound, then # PowerDistributor will decrease the power to match the bounds and # distribute only decreased power. # If False and the requested power is out of bound, then # PowerDistributor will not process this request and send result with status # Result.Status.OUT_OF_BOUND. adjust_power : bool = True","title":"Request"},{"location":"reference/frequenz/sdk/actor/power_distributing/#frequenz.sdk.actor.power_distributing.Result","text":"Result on distribution request. Source code in frequenz/sdk/actor/power_distributing.py 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 @dataclass class Result : \"\"\"Result on distribution request.\"\"\" class Status ( Enum ): \"\"\"Status of the result.\"\"\" FAILED = 0 # If any request for any battery didn't succeed for any reason. SUCCESS = 1 # If all requests for all batteries succeed. IGNORED = 2 # If request was dispossessed by newer request with the same set # of batteries. ERROR = 3 # If any error happened. In this case error_message describes error. OUT_OF_BOUND = 4 # When Request.adjust_power=False and the requested power was # out of the bounds for specified batteries. status : Status # Status of the request. failed_power : float # How much power failed. above_upper_bound : float # How much power was not used because it was beyond the # limits. error_message : Optional [ str ] = None # error_message filled only when status is ERROR","title":"Result"},{"location":"reference/frequenz/sdk/actor/power_distributing/#frequenz.sdk.actor.power_distributing.Result-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/actor/power_distributing/#frequenz.sdk.actor.power_distributing.Result.Status","text":"Bases: Enum Status of the result. Source code in frequenz/sdk/actor/power_distributing.py 137 138 139 140 141 142 143 144 145 class Status ( Enum ): \"\"\"Status of the result.\"\"\" FAILED = 0 # If any request for any battery didn't succeed for any reason. SUCCESS = 1 # If all requests for all batteries succeed. IGNORED = 2 # If request was dispossessed by newer request with the same set # of batteries. ERROR = 3 # If any error happened. In this case error_message describes error. OUT_OF_BOUND = 4 # When Request.adjust_power=False and the requested power was","title":"Status"},{"location":"reference/frequenz/sdk/actor/power_distributing/#frequenz.sdk.actor.power_distributing-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/config/","text":"frequenz.sdk.config \u00a4 Config interface. Classes \u00a4 frequenz.sdk.config.Config \u00a4 Stores config variables. Config variables are read from a file. Only single file can be read. If new file is read, then previous configs will be forgotten. Source code in frequenz/sdk/config/_config.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 class Config : \"\"\" Stores config variables. Config variables are read from a file. Only single file can be read. If new file is read, then previous configs will be forgotten. \"\"\" def __init__ ( self , conf_vars : Dict [ str , Any ]): \"\"\"Instantiate the config store and read config variables from the file. Args: conf_vars: Dict containing configuration variables \"\"\" self . _conf_store : Dict [ str , Any ] = conf_vars def get ( self , key : str , default : Any = None ) -> Any : \"\"\"Get the value for the specified key. If the key is not in the configs, then return default. Args: key: Key to be searched. default: Value to be returned if the key is not found. Defaults to None. Returns: value in str format or default. \"\"\" return self . _conf_store . get ( key , default ) def get_dict ( self , key_prefix : str , expected_values_type : Optional [ T ] ) -> Dict [ str , Any ]: \"\"\"Get a dictionary based on config key prefixes. For example, if key_prefix is \"my_dict\", then the following config store: { 'some_key': 'some_value', 'my_dict_key1': 'value1', 'my_dict_key2': 'value2', } Will return: { 'key1': 'value1', 'key2': 'value2', } Args: key_prefix: Only get configuration variables starting with this prefix. expected_values_type: If provided, the value will be validated against this type. Returns: A dictionary containing the keys prefixed with `key_prefix` as keys (but with the prefix removed) and the values as values. \"\"\" result : Dict [ str , Any ] = {} for key , value in self . _conf_store . items (): if key . startswith ( key_prefix ): new_key = key [ len ( key_prefix ) :] if expected_values_type is not None : value = self . get_as ( key , expected_values_type ) result [ new_key ] = value return result def get_as ( self , key : str , expected_type : Any ) -> Any : \"\"\"Get and convert the value to specified type. Check if type of the value is as expected. If type is correct, then return converted value. Otherwise Raise ValueError. Type can be: * Any typing module type. * Any pydantic strict types (e.g. pydantic.StrictInt) Args: key: Key to be search expected_type: type for the value Raises: ValueError: If can't convert value to the expected type. KeyError: If specified key is not in config. Returns: Value for the specified key, converted to specified type. Example: For `var1='[1, 2.0, 3.5]'`: * `get_as(\"var1\", List[int])` -> `[1,2,3]` * `get_as(\"var1\", List[float])` -> `[1.0,2.0,3.5]` * `get_as(\"var1\", List[pydantic.StrictInt])` -> [ValueError][] * `get_as(\"var1\", List[pydantic.StrictFloat])` -> [ValueError][] For `var1='[1,2,3]'`: * `get_as(\"var1\", List[pydantic.StrictInt])` -> `[1,2,3]` \"\"\" value = self [ key ] if str is expected_type : return value try : parsed_value : Any = parse_raw_as ( expected_type , value ) except ( ValidationError , ValueError ) as err : raise ValueError ( f \"Could not convert config variable: { key } = ' { value } ' \" f \"to type { str ( expected_type ) } , err:\" + str ( err ) ) from err return parsed_value def __getitem__ ( self , key : str ) -> Any : \"\"\"Get the value for the specified key. If the key is not in the configs, then raise KeyError. Args: key: key to be searched. Raises: KeyError: If key is not in found. Returns: Dictionary if the corresponding value is a subsection in the .toml file or a primitive type it is a simple value. \"\"\" value = self . _conf_store . get ( key , None ) if value is None : raise KeyError ( f \"Unknown config name { key } \" ) return value def __contains__ ( self , key : str ) -> bool : \"\"\"Return whether the specified key is in the storage. Args: key: Config variable name. Returns: True if key is in the storage, otherwise returns False. \"\"\" return key in self . _conf_store Functions \u00a4 __contains__ ( key ) \u00a4 Return whether the specified key is in the storage. PARAMETER DESCRIPTION key Config variable name. TYPE: str RETURNS DESCRIPTION bool True if key is in the storage, otherwise returns False. Source code in frequenz/sdk/config/_config.py 152 153 154 155 156 157 158 159 160 161 def __contains__ ( self , key : str ) -> bool : \"\"\"Return whether the specified key is in the storage. Args: key: Config variable name. Returns: True if key is in the storage, otherwise returns False. \"\"\" return key in self . _conf_store __getitem__ ( key ) \u00a4 Get the value for the specified key. If the key is not in the configs, then raise KeyError. PARAMETER DESCRIPTION key key to be searched. TYPE: str RAISES DESCRIPTION KeyError If key is not in found. RETURNS DESCRIPTION Any Dictionary if the corresponding value is a subsection in the .toml file or a primitive type it is a simple value. Source code in frequenz/sdk/config/_config.py 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 def __getitem__ ( self , key : str ) -> Any : \"\"\"Get the value for the specified key. If the key is not in the configs, then raise KeyError. Args: key: key to be searched. Raises: KeyError: If key is not in found. Returns: Dictionary if the corresponding value is a subsection in the .toml file or a primitive type it is a simple value. \"\"\" value = self . _conf_store . get ( key , None ) if value is None : raise KeyError ( f \"Unknown config name { key } \" ) return value __init__ ( conf_vars ) \u00a4 Instantiate the config store and read config variables from the file. PARAMETER DESCRIPTION conf_vars Dict containing configuration variables TYPE: Dict [ str , Any ] Source code in frequenz/sdk/config/_config.py 25 26 27 28 29 30 31 def __init__ ( self , conf_vars : Dict [ str , Any ]): \"\"\"Instantiate the config store and read config variables from the file. Args: conf_vars: Dict containing configuration variables \"\"\" self . _conf_store : Dict [ str , Any ] = conf_vars get ( key , default = None ) \u00a4 Get the value for the specified key. If the key is not in the configs, then return default. PARAMETER DESCRIPTION key Key to be searched. TYPE: str default Value to be returned if the key is not found. Defaults to None. TYPE: Any DEFAULT: None RETURNS DESCRIPTION Any value in str format or default. Source code in frequenz/sdk/config/_config.py 33 34 35 36 37 38 39 40 41 42 43 44 45 46 def get ( self , key : str , default : Any = None ) -> Any : \"\"\"Get the value for the specified key. If the key is not in the configs, then return default. Args: key: Key to be searched. default: Value to be returned if the key is not found. Defaults to None. Returns: value in str format or default. \"\"\" return self . _conf_store . get ( key , default ) get_as ( key , expected_type ) \u00a4 Get and convert the value to specified type. Check if type of the value is as expected. If type is correct, then return converted value. Otherwise Raise ValueError. Type can be Any typing module type. Any pydantic strict types (e.g. pydantic.StrictInt) PARAMETER DESCRIPTION key Key to be search TYPE: str expected_type type for the value TYPE: Any RAISES DESCRIPTION ValueError If can't convert value to the expected type. KeyError If specified key is not in config. RETURNS DESCRIPTION Any Value for the specified key, converted to specified type. Example For var1='[1, 2.0, 3.5]' : * get_as(\"var1\", List[int]) -> [1,2,3] * get_as(\"var1\", List[float]) -> [1.0,2.0,3.5] * get_as(\"var1\", List[pydantic.StrictInt]) -> ValueError * get_as(\"var1\", List[pydantic.StrictFloat]) -> ValueError For var1='[1,2,3]' : * get_as(\"var1\", List[pydantic.StrictInt]) -> [1,2,3] Source code in frequenz/sdk/config/_config.py 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 def get_as ( self , key : str , expected_type : Any ) -> Any : \"\"\"Get and convert the value to specified type. Check if type of the value is as expected. If type is correct, then return converted value. Otherwise Raise ValueError. Type can be: * Any typing module type. * Any pydantic strict types (e.g. pydantic.StrictInt) Args: key: Key to be search expected_type: type for the value Raises: ValueError: If can't convert value to the expected type. KeyError: If specified key is not in config. Returns: Value for the specified key, converted to specified type. Example: For `var1='[1, 2.0, 3.5]'`: * `get_as(\"var1\", List[int])` -> `[1,2,3]` * `get_as(\"var1\", List[float])` -> `[1.0,2.0,3.5]` * `get_as(\"var1\", List[pydantic.StrictInt])` -> [ValueError][] * `get_as(\"var1\", List[pydantic.StrictFloat])` -> [ValueError][] For `var1='[1,2,3]'`: * `get_as(\"var1\", List[pydantic.StrictInt])` -> `[1,2,3]` \"\"\" value = self [ key ] if str is expected_type : return value try : parsed_value : Any = parse_raw_as ( expected_type , value ) except ( ValidationError , ValueError ) as err : raise ValueError ( f \"Could not convert config variable: { key } = ' { value } ' \" f \"to type { str ( expected_type ) } , err:\" + str ( err ) ) from err return parsed_value get_dict ( key_prefix , expected_values_type ) \u00a4 Get a dictionary based on config key prefixes. For example, if key_prefix is \"my_dict\", then the following config store: { 'some_key': 'some_value', 'my_dict_key1': 'value1', 'my_dict_key2': 'value2', } Will return { 'key1': 'value1', 'key2': 'value2', } PARAMETER DESCRIPTION key_prefix Only get configuration variables starting with this prefix. TYPE: str expected_values_type If provided, the value will be validated against this type. TYPE: Optional [ T ] RETURNS DESCRIPTION Dict [ str , Any ] A dictionary containing the keys prefixed with key_prefix as keys (but with the prefix removed) and the values as values. Source code in frequenz/sdk/config/_config.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 def get_dict ( self , key_prefix : str , expected_values_type : Optional [ T ] ) -> Dict [ str , Any ]: \"\"\"Get a dictionary based on config key prefixes. For example, if key_prefix is \"my_dict\", then the following config store: { 'some_key': 'some_value', 'my_dict_key1': 'value1', 'my_dict_key2': 'value2', } Will return: { 'key1': 'value1', 'key2': 'value2', } Args: key_prefix: Only get configuration variables starting with this prefix. expected_values_type: If provided, the value will be validated against this type. Returns: A dictionary containing the keys prefixed with `key_prefix` as keys (but with the prefix removed) and the values as values. \"\"\" result : Dict [ str , Any ] = {} for key , value in self . _conf_store . items (): if key . startswith ( key_prefix ): new_key = key [ len ( key_prefix ) :] if expected_values_type is not None : value = self . get_as ( key , expected_values_type ) result [ new_key ] = value return result","title":"config"},{"location":"reference/frequenz/sdk/config/#frequenz.sdk.config","text":"Config interface.","title":"config"},{"location":"reference/frequenz/sdk/config/#frequenz.sdk.config-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/config/#frequenz.sdk.config.Config","text":"Stores config variables. Config variables are read from a file. Only single file can be read. If new file is read, then previous configs will be forgotten. Source code in frequenz/sdk/config/_config.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 class Config : \"\"\" Stores config variables. Config variables are read from a file. Only single file can be read. If new file is read, then previous configs will be forgotten. \"\"\" def __init__ ( self , conf_vars : Dict [ str , Any ]): \"\"\"Instantiate the config store and read config variables from the file. Args: conf_vars: Dict containing configuration variables \"\"\" self . _conf_store : Dict [ str , Any ] = conf_vars def get ( self , key : str , default : Any = None ) -> Any : \"\"\"Get the value for the specified key. If the key is not in the configs, then return default. Args: key: Key to be searched. default: Value to be returned if the key is not found. Defaults to None. Returns: value in str format or default. \"\"\" return self . _conf_store . get ( key , default ) def get_dict ( self , key_prefix : str , expected_values_type : Optional [ T ] ) -> Dict [ str , Any ]: \"\"\"Get a dictionary based on config key prefixes. For example, if key_prefix is \"my_dict\", then the following config store: { 'some_key': 'some_value', 'my_dict_key1': 'value1', 'my_dict_key2': 'value2', } Will return: { 'key1': 'value1', 'key2': 'value2', } Args: key_prefix: Only get configuration variables starting with this prefix. expected_values_type: If provided, the value will be validated against this type. Returns: A dictionary containing the keys prefixed with `key_prefix` as keys (but with the prefix removed) and the values as values. \"\"\" result : Dict [ str , Any ] = {} for key , value in self . _conf_store . items (): if key . startswith ( key_prefix ): new_key = key [ len ( key_prefix ) :] if expected_values_type is not None : value = self . get_as ( key , expected_values_type ) result [ new_key ] = value return result def get_as ( self , key : str , expected_type : Any ) -> Any : \"\"\"Get and convert the value to specified type. Check if type of the value is as expected. If type is correct, then return converted value. Otherwise Raise ValueError. Type can be: * Any typing module type. * Any pydantic strict types (e.g. pydantic.StrictInt) Args: key: Key to be search expected_type: type for the value Raises: ValueError: If can't convert value to the expected type. KeyError: If specified key is not in config. Returns: Value for the specified key, converted to specified type. Example: For `var1='[1, 2.0, 3.5]'`: * `get_as(\"var1\", List[int])` -> `[1,2,3]` * `get_as(\"var1\", List[float])` -> `[1.0,2.0,3.5]` * `get_as(\"var1\", List[pydantic.StrictInt])` -> [ValueError][] * `get_as(\"var1\", List[pydantic.StrictFloat])` -> [ValueError][] For `var1='[1,2,3]'`: * `get_as(\"var1\", List[pydantic.StrictInt])` -> `[1,2,3]` \"\"\" value = self [ key ] if str is expected_type : return value try : parsed_value : Any = parse_raw_as ( expected_type , value ) except ( ValidationError , ValueError ) as err : raise ValueError ( f \"Could not convert config variable: { key } = ' { value } ' \" f \"to type { str ( expected_type ) } , err:\" + str ( err ) ) from err return parsed_value def __getitem__ ( self , key : str ) -> Any : \"\"\"Get the value for the specified key. If the key is not in the configs, then raise KeyError. Args: key: key to be searched. Raises: KeyError: If key is not in found. Returns: Dictionary if the corresponding value is a subsection in the .toml file or a primitive type it is a simple value. \"\"\" value = self . _conf_store . get ( key , None ) if value is None : raise KeyError ( f \"Unknown config name { key } \" ) return value def __contains__ ( self , key : str ) -> bool : \"\"\"Return whether the specified key is in the storage. Args: key: Config variable name. Returns: True if key is in the storage, otherwise returns False. \"\"\" return key in self . _conf_store","title":"Config"},{"location":"reference/frequenz/sdk/config/#frequenz.sdk.config.Config-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/config/#frequenz.sdk.config._config.Config.__contains__","text":"Return whether the specified key is in the storage. PARAMETER DESCRIPTION key Config variable name. TYPE: str RETURNS DESCRIPTION bool True if key is in the storage, otherwise returns False. Source code in frequenz/sdk/config/_config.py 152 153 154 155 156 157 158 159 160 161 def __contains__ ( self , key : str ) -> bool : \"\"\"Return whether the specified key is in the storage. Args: key: Config variable name. Returns: True if key is in the storage, otherwise returns False. \"\"\" return key in self . _conf_store","title":"__contains__()"},{"location":"reference/frequenz/sdk/config/#frequenz.sdk.config._config.Config.__getitem__","text":"Get the value for the specified key. If the key is not in the configs, then raise KeyError. PARAMETER DESCRIPTION key key to be searched. TYPE: str RAISES DESCRIPTION KeyError If key is not in found. RETURNS DESCRIPTION Any Dictionary if the corresponding value is a subsection in the .toml file or a primitive type it is a simple value. Source code in frequenz/sdk/config/_config.py 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 def __getitem__ ( self , key : str ) -> Any : \"\"\"Get the value for the specified key. If the key is not in the configs, then raise KeyError. Args: key: key to be searched. Raises: KeyError: If key is not in found. Returns: Dictionary if the corresponding value is a subsection in the .toml file or a primitive type it is a simple value. \"\"\" value = self . _conf_store . get ( key , None ) if value is None : raise KeyError ( f \"Unknown config name { key } \" ) return value","title":"__getitem__()"},{"location":"reference/frequenz/sdk/config/#frequenz.sdk.config._config.Config.__init__","text":"Instantiate the config store and read config variables from the file. PARAMETER DESCRIPTION conf_vars Dict containing configuration variables TYPE: Dict [ str , Any ] Source code in frequenz/sdk/config/_config.py 25 26 27 28 29 30 31 def __init__ ( self , conf_vars : Dict [ str , Any ]): \"\"\"Instantiate the config store and read config variables from the file. Args: conf_vars: Dict containing configuration variables \"\"\" self . _conf_store : Dict [ str , Any ] = conf_vars","title":"__init__()"},{"location":"reference/frequenz/sdk/config/#frequenz.sdk.config._config.Config.get","text":"Get the value for the specified key. If the key is not in the configs, then return default. PARAMETER DESCRIPTION key Key to be searched. TYPE: str default Value to be returned if the key is not found. Defaults to None. TYPE: Any DEFAULT: None RETURNS DESCRIPTION Any value in str format or default. Source code in frequenz/sdk/config/_config.py 33 34 35 36 37 38 39 40 41 42 43 44 45 46 def get ( self , key : str , default : Any = None ) -> Any : \"\"\"Get the value for the specified key. If the key is not in the configs, then return default. Args: key: Key to be searched. default: Value to be returned if the key is not found. Defaults to None. Returns: value in str format or default. \"\"\" return self . _conf_store . get ( key , default )","title":"get()"},{"location":"reference/frequenz/sdk/config/#frequenz.sdk.config._config.Config.get_as","text":"Get and convert the value to specified type. Check if type of the value is as expected. If type is correct, then return converted value. Otherwise Raise ValueError. Type can be Any typing module type. Any pydantic strict types (e.g. pydantic.StrictInt) PARAMETER DESCRIPTION key Key to be search TYPE: str expected_type type for the value TYPE: Any RAISES DESCRIPTION ValueError If can't convert value to the expected type. KeyError If specified key is not in config. RETURNS DESCRIPTION Any Value for the specified key, converted to specified type. Example For var1='[1, 2.0, 3.5]' : * get_as(\"var1\", List[int]) -> [1,2,3] * get_as(\"var1\", List[float]) -> [1.0,2.0,3.5] * get_as(\"var1\", List[pydantic.StrictInt]) -> ValueError * get_as(\"var1\", List[pydantic.StrictFloat]) -> ValueError For var1='[1,2,3]' : * get_as(\"var1\", List[pydantic.StrictInt]) -> [1,2,3] Source code in frequenz/sdk/config/_config.py 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 def get_as ( self , key : str , expected_type : Any ) -> Any : \"\"\"Get and convert the value to specified type. Check if type of the value is as expected. If type is correct, then return converted value. Otherwise Raise ValueError. Type can be: * Any typing module type. * Any pydantic strict types (e.g. pydantic.StrictInt) Args: key: Key to be search expected_type: type for the value Raises: ValueError: If can't convert value to the expected type. KeyError: If specified key is not in config. Returns: Value for the specified key, converted to specified type. Example: For `var1='[1, 2.0, 3.5]'`: * `get_as(\"var1\", List[int])` -> `[1,2,3]` * `get_as(\"var1\", List[float])` -> `[1.0,2.0,3.5]` * `get_as(\"var1\", List[pydantic.StrictInt])` -> [ValueError][] * `get_as(\"var1\", List[pydantic.StrictFloat])` -> [ValueError][] For `var1='[1,2,3]'`: * `get_as(\"var1\", List[pydantic.StrictInt])` -> `[1,2,3]` \"\"\" value = self [ key ] if str is expected_type : return value try : parsed_value : Any = parse_raw_as ( expected_type , value ) except ( ValidationError , ValueError ) as err : raise ValueError ( f \"Could not convert config variable: { key } = ' { value } ' \" f \"to type { str ( expected_type ) } , err:\" + str ( err ) ) from err return parsed_value","title":"get_as()"},{"location":"reference/frequenz/sdk/config/#frequenz.sdk.config._config.Config.get_dict","text":"Get a dictionary based on config key prefixes. For example, if key_prefix is \"my_dict\", then the following config store: { 'some_key': 'some_value', 'my_dict_key1': 'value1', 'my_dict_key2': 'value2', } Will return { 'key1': 'value1', 'key2': 'value2', } PARAMETER DESCRIPTION key_prefix Only get configuration variables starting with this prefix. TYPE: str expected_values_type If provided, the value will be validated against this type. TYPE: Optional [ T ] RETURNS DESCRIPTION Dict [ str , Any ] A dictionary containing the keys prefixed with key_prefix as keys (but with the prefix removed) and the values as values. Source code in frequenz/sdk/config/_config.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 def get_dict ( self , key_prefix : str , expected_values_type : Optional [ T ] ) -> Dict [ str , Any ]: \"\"\"Get a dictionary based on config key prefixes. For example, if key_prefix is \"my_dict\", then the following config store: { 'some_key': 'some_value', 'my_dict_key1': 'value1', 'my_dict_key2': 'value2', } Will return: { 'key1': 'value1', 'key2': 'value2', } Args: key_prefix: Only get configuration variables starting with this prefix. expected_values_type: If provided, the value will be validated against this type. Returns: A dictionary containing the keys prefixed with `key_prefix` as keys (but with the prefix removed) and the values as values. \"\"\" result : Dict [ str , Any ] = {} for key , value in self . _conf_store . items (): if key . startswith ( key_prefix ): new_key = key [ len ( key_prefix ) :] if expected_values_type is not None : value = self . get_as ( key , expected_values_type ) result [ new_key ] = value return result","title":"get_dict()"},{"location":"reference/frequenz/sdk/microgrid/","text":"frequenz.sdk.microgrid \u00a4 Microgrid monitoring and control system. This package provides a complete suite of data structures and functionality for monitoring and adjusting the state of a microgrid. Classes \u00a4 frequenz.sdk.microgrid.ComponentGraph \u00a4 Bases: ABC Interface for component graph implementations. Source code in frequenz/sdk/microgrid/_graph.py 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 class ComponentGraph ( ABC ): \"\"\"Interface for component graph implementations.\"\"\" @abstractmethod def components ( self , component_id : Optional [ Set [ int ]] = None , component_category : Optional [ Set [ ComponentCategory ]] = None , ) -> Set [ Component ]: \"\"\"Fetch the components of the microgrid. Args: component_id: filter out any components not matching one of the provided IDs component_category: filter out any components not matching one of the provided types Returns: Set of the components currently connected to the microgrid, filtered by the provided `component_id` and `component_category` values. \"\"\" @abstractmethod def connections ( self , start : Optional [ Set [ int ]] = None , end : Optional [ Set [ int ]] = None , ) -> Set [ Connection ]: \"\"\"Fetch the connections between microgrid components. Args: start: filter out any connections whose `start` does not match one of these component IDs end: filter out any connections whose `end` does not match one of these component IDs Returns: Set of the connections between components in the microgrid, filtered by the provided `start`/`end` choices. \"\"\" @abstractmethod def predecessors ( self , component_id : int ) -> Set [ Component ]: \"\"\"Fetch the graph predecessors of the specified component. Args: component_id: numerical ID of the component whose predecessors should be fetched Returns: Set of IDs of the components that are predecessors of `component_id`, i.e. for which there is a connection from each of these components to `component_id`. Raises: KeyError: if the specified `component_id` is not in the graph \"\"\" @abstractmethod def successors ( self , component_id : int ) -> Set [ Component ]: \"\"\"Fetch the graph successors of the specified component. Args: component_id: numerical ID of the component whose successors should be fetched Returns: Set of IDs of the components that are successors of `component_id`, i.e. for which there is a connection from `component_id` to each of these components. Raises: KeyError: if the specified `component_id` is not in the graph \"\"\" Functions \u00a4 components ( component_id = None , component_category = None ) abstractmethod \u00a4 Fetch the components of the microgrid. PARAMETER DESCRIPTION component_id filter out any components not matching one of the provided IDs TYPE: Optional [ Set [ int ]] DEFAULT: None component_category filter out any components not matching one of the provided types TYPE: Optional [ Set [ ComponentCategory ]] DEFAULT: None RETURNS DESCRIPTION Set [ Component ] Set of the components currently connected to the microgrid, filtered by the provided component_id and component_category values. Source code in frequenz/sdk/microgrid/_graph.py 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 @abstractmethod def components ( self , component_id : Optional [ Set [ int ]] = None , component_category : Optional [ Set [ ComponentCategory ]] = None , ) -> Set [ Component ]: \"\"\"Fetch the components of the microgrid. Args: component_id: filter out any components not matching one of the provided IDs component_category: filter out any components not matching one of the provided types Returns: Set of the components currently connected to the microgrid, filtered by the provided `component_id` and `component_category` values. \"\"\" connections ( start = None , end = None ) abstractmethod \u00a4 Fetch the connections between microgrid components. PARAMETER DESCRIPTION start filter out any connections whose start does not match one of these component IDs TYPE: Optional [ Set [ int ]] DEFAULT: None end filter out any connections whose end does not match one of these component IDs TYPE: Optional [ Set [ int ]] DEFAULT: None RETURNS DESCRIPTION Set [ Connection ] Set of the connections between components in the microgrid, filtered by the provided start / end choices. Source code in frequenz/sdk/microgrid/_graph.py 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 @abstractmethod def connections ( self , start : Optional [ Set [ int ]] = None , end : Optional [ Set [ int ]] = None , ) -> Set [ Connection ]: \"\"\"Fetch the connections between microgrid components. Args: start: filter out any connections whose `start` does not match one of these component IDs end: filter out any connections whose `end` does not match one of these component IDs Returns: Set of the connections between components in the microgrid, filtered by the provided `start`/`end` choices. \"\"\" predecessors ( component_id ) abstractmethod \u00a4 Fetch the graph predecessors of the specified component. PARAMETER DESCRIPTION component_id numerical ID of the component whose predecessors should be fetched TYPE: int RETURNS DESCRIPTION Set [ Component ] Set of IDs of the components that are predecessors of component_id , i.e. for which there is a connection from each of these components to component_id . RAISES DESCRIPTION KeyError if the specified component_id is not in the graph Source code in frequenz/sdk/microgrid/_graph.py 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 @abstractmethod def predecessors ( self , component_id : int ) -> Set [ Component ]: \"\"\"Fetch the graph predecessors of the specified component. Args: component_id: numerical ID of the component whose predecessors should be fetched Returns: Set of IDs of the components that are predecessors of `component_id`, i.e. for which there is a connection from each of these components to `component_id`. Raises: KeyError: if the specified `component_id` is not in the graph \"\"\" successors ( component_id ) abstractmethod \u00a4 Fetch the graph successors of the specified component. PARAMETER DESCRIPTION component_id numerical ID of the component whose successors should be fetched TYPE: int RETURNS DESCRIPTION Set [ Component ] Set of IDs of the components that are successors of component_id , i.e. for which there is a connection from component_id to each of these components. RAISES DESCRIPTION KeyError if the specified component_id is not in the graph Source code in frequenz/sdk/microgrid/_graph.py 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 @abstractmethod def successors ( self , component_id : int ) -> Set [ Component ]: \"\"\"Fetch the graph successors of the specified component. Args: component_id: numerical ID of the component whose successors should be fetched Returns: Set of IDs of the components that are successors of `component_id`, i.e. for which there is a connection from `component_id` to each of these components. Raises: KeyError: if the specified `component_id` is not in the graph \"\"\" frequenz.sdk.microgrid.Microgrid \u00a4 Bases: ABC Creates and stores core features. Source code in frequenz/sdk/microgrid/_microgrid.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 class Microgrid ( ABC ): \"\"\"Creates and stores core features.\"\"\" def __init__ ( self , host : str , port : int ) -> None : \"\"\"Create object instance. Args: host: server host port: server port \"\"\" super () . __init__ () self . _host : str = host self . _port : int = port @property def host ( self ) -> str : \"\"\"Get host of the currently connected server. Returns: host \"\"\" return self . _host @property def port ( self ) -> int : \"\"\"Get port of the currently connected server. Returns: port \"\"\" return self . _port @property @abstractmethod def api_client ( self ) -> MicrogridApiClient : \"\"\"Get MicrogridApiClient. Returns: api client \"\"\" @property @abstractmethod def component_graph ( self ) -> ComponentGraph : \"\"\"Get component graph. Returns: component graph \"\"\" async def _update_api ( self , host : str , port : int ) -> None : self . _host = host self . _port = port @abstractmethod async def _initialize ( self ) -> None : \"\"\"Initialize the object. This function should be called only once.\"\"\" Functions \u00a4 __init__ ( host , port ) \u00a4 Create object instance. PARAMETER DESCRIPTION host server host TYPE: str port server port TYPE: int Source code in frequenz/sdk/microgrid/_microgrid.py 28 29 30 31 32 33 34 35 36 37 def __init__ ( self , host : str , port : int ) -> None : \"\"\"Create object instance. Args: host: server host port: server port \"\"\" super () . __init__ () self . _host : str = host self . _port : int = port api_client () property abstractmethod \u00a4 Get MicrogridApiClient. RETURNS DESCRIPTION MicrogridApiClient api client Source code in frequenz/sdk/microgrid/_microgrid.py 57 58 59 60 61 62 63 64 @property @abstractmethod def api_client ( self ) -> MicrogridApiClient : \"\"\"Get MicrogridApiClient. Returns: api client \"\"\" component_graph () property abstractmethod \u00a4 Get component graph. RETURNS DESCRIPTION ComponentGraph component graph Source code in frequenz/sdk/microgrid/_microgrid.py 66 67 68 69 70 71 72 73 @property @abstractmethod def component_graph ( self ) -> ComponentGraph : \"\"\"Get component graph. Returns: component graph \"\"\" host () property \u00a4 Get host of the currently connected server. RETURNS DESCRIPTION str host Source code in frequenz/sdk/microgrid/_microgrid.py 39 40 41 42 43 44 45 46 @property def host ( self ) -> str : \"\"\"Get host of the currently connected server. Returns: host \"\"\" return self . _host port () property \u00a4 Get port of the currently connected server. RETURNS DESCRIPTION int port Source code in frequenz/sdk/microgrid/_microgrid.py 48 49 50 51 52 53 54 55 @property def port ( self ) -> int : \"\"\"Get port of the currently connected server. Returns: port \"\"\" return self . _port Functions \u00a4 frequenz . sdk . microgrid . get () \u00a4 Get the MicrogridApi instance created by initialize(). This function should be only called after initialize(). RAISES DESCRIPTION RuntimeError Raised when: * If initialize() method was not called before this call. * If initialize() methods was called but was not awaited and instance was not created yet. RETURNS DESCRIPTION Microgrid MicrogridApi instance. Source code in frequenz/sdk/microgrid/_microgrid.py 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 def get () -> Microgrid : \"\"\"Get the MicrogridApi instance created by initialize(). This function should be only called after initialize(). Raises: RuntimeError: Raised when: * If `initialize()` method was not called before this call. * If `initialize()` methods was called but was not awaited and instance was not created yet. Returns: MicrogridApi instance. \"\"\" if _MICROGRID is None : raise RuntimeError ( \"MicrogridApi is not initialized (or the initialization didn't \" \"finished yet). Call and/or await for initialize() to finish.\" ) return _MICROGRID frequenz . sdk . microgrid . initialize ( host , port ) async \u00a4 Initialize the MicrogridApi. This function should be called only once. PARAMETER DESCRIPTION host Microgrid host TYPE: str port Microgrid port TYPE: int RAISES DESCRIPTION AssertionError If method was called more then once. Source code in frequenz/sdk/microgrid/_microgrid.py 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 async def initialize ( host : str , port : int ) -> None : \"\"\"Initialize the MicrogridApi. This function should be called only once. Args: host: Microgrid host port: Microgrid port Raises: AssertionError: If method was called more then once. \"\"\" # From Doc: pylint just try to discourage this usage. # That doesn't mean you cannot use it. global _MICROGRID # pylint: disable=global-statement if _MICROGRID is not None : raise AssertionError ( \"MicrogridApi was already initialized.\" ) microgrid_api = _MicrogridInsecure ( host , port ) await microgrid_api . _initialize () # pylint: disable=protected-access # Check again that _MICROGRID_API is None in case somebody had the great idea of # calling initialize() twice and in parallel. if _MICROGRID is not None : raise AssertionError ( \"MicrogridApi was already initialized.\" ) _MICROGRID = microgrid_api","title":"microgrid"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid","text":"Microgrid monitoring and control system. This package provides a complete suite of data structures and functionality for monitoring and adjusting the state of a microgrid.","title":"microgrid"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid.ComponentGraph","text":"Bases: ABC Interface for component graph implementations. Source code in frequenz/sdk/microgrid/_graph.py 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 class ComponentGraph ( ABC ): \"\"\"Interface for component graph implementations.\"\"\" @abstractmethod def components ( self , component_id : Optional [ Set [ int ]] = None , component_category : Optional [ Set [ ComponentCategory ]] = None , ) -> Set [ Component ]: \"\"\"Fetch the components of the microgrid. Args: component_id: filter out any components not matching one of the provided IDs component_category: filter out any components not matching one of the provided types Returns: Set of the components currently connected to the microgrid, filtered by the provided `component_id` and `component_category` values. \"\"\" @abstractmethod def connections ( self , start : Optional [ Set [ int ]] = None , end : Optional [ Set [ int ]] = None , ) -> Set [ Connection ]: \"\"\"Fetch the connections between microgrid components. Args: start: filter out any connections whose `start` does not match one of these component IDs end: filter out any connections whose `end` does not match one of these component IDs Returns: Set of the connections between components in the microgrid, filtered by the provided `start`/`end` choices. \"\"\" @abstractmethod def predecessors ( self , component_id : int ) -> Set [ Component ]: \"\"\"Fetch the graph predecessors of the specified component. Args: component_id: numerical ID of the component whose predecessors should be fetched Returns: Set of IDs of the components that are predecessors of `component_id`, i.e. for which there is a connection from each of these components to `component_id`. Raises: KeyError: if the specified `component_id` is not in the graph \"\"\" @abstractmethod def successors ( self , component_id : int ) -> Set [ Component ]: \"\"\"Fetch the graph successors of the specified component. Args: component_id: numerical ID of the component whose successors should be fetched Returns: Set of IDs of the components that are successors of `component_id`, i.e. for which there is a connection from `component_id` to each of these components. Raises: KeyError: if the specified `component_id` is not in the graph \"\"\"","title":"ComponentGraph"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid.ComponentGraph-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid._graph.ComponentGraph.components","text":"Fetch the components of the microgrid. PARAMETER DESCRIPTION component_id filter out any components not matching one of the provided IDs TYPE: Optional [ Set [ int ]] DEFAULT: None component_category filter out any components not matching one of the provided types TYPE: Optional [ Set [ ComponentCategory ]] DEFAULT: None RETURNS DESCRIPTION Set [ Component ] Set of the components currently connected to the microgrid, filtered by the provided component_id and component_category values. Source code in frequenz/sdk/microgrid/_graph.py 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 @abstractmethod def components ( self , component_id : Optional [ Set [ int ]] = None , component_category : Optional [ Set [ ComponentCategory ]] = None , ) -> Set [ Component ]: \"\"\"Fetch the components of the microgrid. Args: component_id: filter out any components not matching one of the provided IDs component_category: filter out any components not matching one of the provided types Returns: Set of the components currently connected to the microgrid, filtered by the provided `component_id` and `component_category` values. \"\"\"","title":"components()"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid._graph.ComponentGraph.connections","text":"Fetch the connections between microgrid components. PARAMETER DESCRIPTION start filter out any connections whose start does not match one of these component IDs TYPE: Optional [ Set [ int ]] DEFAULT: None end filter out any connections whose end does not match one of these component IDs TYPE: Optional [ Set [ int ]] DEFAULT: None RETURNS DESCRIPTION Set [ Connection ] Set of the connections between components in the microgrid, filtered by the provided start / end choices. Source code in frequenz/sdk/microgrid/_graph.py 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 @abstractmethod def connections ( self , start : Optional [ Set [ int ]] = None , end : Optional [ Set [ int ]] = None , ) -> Set [ Connection ]: \"\"\"Fetch the connections between microgrid components. Args: start: filter out any connections whose `start` does not match one of these component IDs end: filter out any connections whose `end` does not match one of these component IDs Returns: Set of the connections between components in the microgrid, filtered by the provided `start`/`end` choices. \"\"\"","title":"connections()"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid._graph.ComponentGraph.predecessors","text":"Fetch the graph predecessors of the specified component. PARAMETER DESCRIPTION component_id numerical ID of the component whose predecessors should be fetched TYPE: int RETURNS DESCRIPTION Set [ Component ] Set of IDs of the components that are predecessors of component_id , i.e. for which there is a connection from each of these components to component_id . RAISES DESCRIPTION KeyError if the specified component_id is not in the graph Source code in frequenz/sdk/microgrid/_graph.py 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 @abstractmethod def predecessors ( self , component_id : int ) -> Set [ Component ]: \"\"\"Fetch the graph predecessors of the specified component. Args: component_id: numerical ID of the component whose predecessors should be fetched Returns: Set of IDs of the components that are predecessors of `component_id`, i.e. for which there is a connection from each of these components to `component_id`. Raises: KeyError: if the specified `component_id` is not in the graph \"\"\"","title":"predecessors()"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid._graph.ComponentGraph.successors","text":"Fetch the graph successors of the specified component. PARAMETER DESCRIPTION component_id numerical ID of the component whose successors should be fetched TYPE: int RETURNS DESCRIPTION Set [ Component ] Set of IDs of the components that are successors of component_id , i.e. for which there is a connection from component_id to each of these components. RAISES DESCRIPTION KeyError if the specified component_id is not in the graph Source code in frequenz/sdk/microgrid/_graph.py 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 @abstractmethod def successors ( self , component_id : int ) -> Set [ Component ]: \"\"\"Fetch the graph successors of the specified component. Args: component_id: numerical ID of the component whose successors should be fetched Returns: Set of IDs of the components that are successors of `component_id`, i.e. for which there is a connection from `component_id` to each of these components. Raises: KeyError: if the specified `component_id` is not in the graph \"\"\"","title":"successors()"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid.Microgrid","text":"Bases: ABC Creates and stores core features. Source code in frequenz/sdk/microgrid/_microgrid.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 class Microgrid ( ABC ): \"\"\"Creates and stores core features.\"\"\" def __init__ ( self , host : str , port : int ) -> None : \"\"\"Create object instance. Args: host: server host port: server port \"\"\" super () . __init__ () self . _host : str = host self . _port : int = port @property def host ( self ) -> str : \"\"\"Get host of the currently connected server. Returns: host \"\"\" return self . _host @property def port ( self ) -> int : \"\"\"Get port of the currently connected server. Returns: port \"\"\" return self . _port @property @abstractmethod def api_client ( self ) -> MicrogridApiClient : \"\"\"Get MicrogridApiClient. Returns: api client \"\"\" @property @abstractmethod def component_graph ( self ) -> ComponentGraph : \"\"\"Get component graph. Returns: component graph \"\"\" async def _update_api ( self , host : str , port : int ) -> None : self . _host = host self . _port = port @abstractmethod async def _initialize ( self ) -> None : \"\"\"Initialize the object. This function should be called only once.\"\"\"","title":"Microgrid"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid.Microgrid-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid._microgrid.Microgrid.__init__","text":"Create object instance. PARAMETER DESCRIPTION host server host TYPE: str port server port TYPE: int Source code in frequenz/sdk/microgrid/_microgrid.py 28 29 30 31 32 33 34 35 36 37 def __init__ ( self , host : str , port : int ) -> None : \"\"\"Create object instance. Args: host: server host port: server port \"\"\" super () . __init__ () self . _host : str = host self . _port : int = port","title":"__init__()"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid._microgrid.Microgrid.api_client","text":"Get MicrogridApiClient. RETURNS DESCRIPTION MicrogridApiClient api client Source code in frequenz/sdk/microgrid/_microgrid.py 57 58 59 60 61 62 63 64 @property @abstractmethod def api_client ( self ) -> MicrogridApiClient : \"\"\"Get MicrogridApiClient. Returns: api client \"\"\"","title":"api_client()"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid._microgrid.Microgrid.component_graph","text":"Get component graph. RETURNS DESCRIPTION ComponentGraph component graph Source code in frequenz/sdk/microgrid/_microgrid.py 66 67 68 69 70 71 72 73 @property @abstractmethod def component_graph ( self ) -> ComponentGraph : \"\"\"Get component graph. Returns: component graph \"\"\"","title":"component_graph()"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid._microgrid.Microgrid.host","text":"Get host of the currently connected server. RETURNS DESCRIPTION str host Source code in frequenz/sdk/microgrid/_microgrid.py 39 40 41 42 43 44 45 46 @property def host ( self ) -> str : \"\"\"Get host of the currently connected server. Returns: host \"\"\" return self . _host","title":"host()"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid._microgrid.Microgrid.port","text":"Get port of the currently connected server. RETURNS DESCRIPTION int port Source code in frequenz/sdk/microgrid/_microgrid.py 48 49 50 51 52 53 54 55 @property def port ( self ) -> int : \"\"\"Get port of the currently connected server. Returns: port \"\"\" return self . _port","title":"port()"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid.get","text":"Get the MicrogridApi instance created by initialize(). This function should be only called after initialize(). RAISES DESCRIPTION RuntimeError Raised when: * If initialize() method was not called before this call. * If initialize() methods was called but was not awaited and instance was not created yet. RETURNS DESCRIPTION Microgrid MicrogridApi instance. Source code in frequenz/sdk/microgrid/_microgrid.py 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 def get () -> Microgrid : \"\"\"Get the MicrogridApi instance created by initialize(). This function should be only called after initialize(). Raises: RuntimeError: Raised when: * If `initialize()` method was not called before this call. * If `initialize()` methods was called but was not awaited and instance was not created yet. Returns: MicrogridApi instance. \"\"\" if _MICROGRID is None : raise RuntimeError ( \"MicrogridApi is not initialized (or the initialization didn't \" \"finished yet). Call and/or await for initialize() to finish.\" ) return _MICROGRID","title":"get()"},{"location":"reference/frequenz/sdk/microgrid/#frequenz.sdk.microgrid.initialize","text":"Initialize the MicrogridApi. This function should be called only once. PARAMETER DESCRIPTION host Microgrid host TYPE: str port Microgrid port TYPE: int RAISES DESCRIPTION AssertionError If method was called more then once. Source code in frequenz/sdk/microgrid/_microgrid.py 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 async def initialize ( host : str , port : int ) -> None : \"\"\"Initialize the MicrogridApi. This function should be called only once. Args: host: Microgrid host port: Microgrid port Raises: AssertionError: If method was called more then once. \"\"\" # From Doc: pylint just try to discourage this usage. # That doesn't mean you cannot use it. global _MICROGRID # pylint: disable=global-statement if _MICROGRID is not None : raise AssertionError ( \"MicrogridApi was already initialized.\" ) microgrid_api = _MicrogridInsecure ( host , port ) await microgrid_api . _initialize () # pylint: disable=protected-access # Check again that _MICROGRID_API is None in case somebody had the great idea of # calling initialize() twice and in parallel. if _MICROGRID is not None : raise AssertionError ( \"MicrogridApi was already initialized.\" ) _MICROGRID = microgrid_api","title":"initialize()"},{"location":"reference/frequenz/sdk/microgrid/client/","text":"frequenz.sdk.microgrid.client \u00a4 Microgrid API client. This package provides an easy way to connect to the microgrid API. Classes \u00a4 frequenz.sdk.microgrid.client.Connection \u00a4 Bases: NamedTuple Metadata for a connection between microgrid components. Source code in frequenz/sdk/microgrid/client/_connection.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 class Connection ( NamedTuple ): \"\"\"Metadata for a connection between microgrid components.\"\"\" start : int end : int def is_valid ( self ) -> bool : \"\"\"Check if this instance contains valid data. Returns: `True` if `start >= 0`, `end > 0`, and `start != end`, `False` otherwise. \"\"\" return self . start >= 0 and self . end > 0 and self . start != self . end Functions \u00a4 is_valid () \u00a4 Check if this instance contains valid data. RETURNS DESCRIPTION bool True if start >= 0 , end > 0 , and start != end , False otherwise. Source code in frequenz/sdk/microgrid/client/_connection.py 15 16 17 18 19 20 21 22 def is_valid ( self ) -> bool : \"\"\"Check if this instance contains valid data. Returns: `True` if `start >= 0`, `end > 0`, and `start != end`, `False` otherwise. \"\"\" return self . start >= 0 and self . end > 0 and self . start != self . end frequenz.sdk.microgrid.client.ExponentialBackoff \u00a4 Bases: RetryStrategy Provides methods for calculating the exponential interval between retries. Source code in frequenz/sdk/microgrid/client/_retry.py 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 class ExponentialBackoff ( RetryStrategy ): \"\"\"Provides methods for calculating the exponential interval between retries.\"\"\" DEFAULT_INTERVAL = DEFAULT_RETRY_INTERVAL DEFAULT_MAX_INTERVAL = 60.0 DEFAULT_MULTIPLIER = 2.0 # pylint: disable=too-many-arguments def __init__ ( self , initial_interval : float = DEFAULT_INTERVAL , max_interval : float = DEFAULT_MAX_INTERVAL , multiplier : float = DEFAULT_MULTIPLIER , jitter : float = DEFAULT_RETRY_JITTER , limit : Optional [ int ] = None , ) -> None : \"\"\"Create a `ExponentialBackoff` instance. Args: initial_interval: time to wait for before the first retry, in seconds. max_interval: maximum interval, in seconds. multiplier: exponential increment for interval. jitter: a jitter to add to the retry interval. limit: max number of retries before giving up. `None` means no limit, and `0` means no retry. \"\"\" self . _initial = initial_interval self . _max = max_interval self . _multiplier = multiplier self . _jitter = jitter self . _limit = limit self . _count = 0 def next_interval ( self ) -> Optional [ float ]: \"\"\"Return the time to wait before the next retry. Returns `None` if the retry limit has been reached, and no more retries are possible. Returns: Time until next retry when below retry limit, and None otherwise. \"\"\" if self . _limit is not None and self . _count >= self . _limit : return None self . _count += 1 exp_backoff_interval = self . _initial * self . _multiplier ** ( self . _count - 1 ) return min ( exp_backoff_interval + random . uniform ( 0.0 , self . _jitter ), self . _max ) Functions \u00a4 __init__ ( initial_interval = DEFAULT_INTERVAL , max_interval = DEFAULT_MAX_INTERVAL , multiplier = DEFAULT_MULTIPLIER , jitter = DEFAULT_RETRY_JITTER , limit = None ) \u00a4 Create a ExponentialBackoff instance. PARAMETER DESCRIPTION initial_interval time to wait for before the first retry, in seconds. TYPE: float DEFAULT: DEFAULT_INTERVAL max_interval maximum interval, in seconds. TYPE: float DEFAULT: DEFAULT_MAX_INTERVAL multiplier exponential increment for interval. TYPE: float DEFAULT: DEFAULT_MULTIPLIER jitter a jitter to add to the retry interval. TYPE: float DEFAULT: DEFAULT_RETRY_JITTER limit max number of retries before giving up. None means no limit, and 0 means no retry. TYPE: Optional [ int ] DEFAULT: None Source code in frequenz/sdk/microgrid/client/_retry.py 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 def __init__ ( self , initial_interval : float = DEFAULT_INTERVAL , max_interval : float = DEFAULT_MAX_INTERVAL , multiplier : float = DEFAULT_MULTIPLIER , jitter : float = DEFAULT_RETRY_JITTER , limit : Optional [ int ] = None , ) -> None : \"\"\"Create a `ExponentialBackoff` instance. Args: initial_interval: time to wait for before the first retry, in seconds. max_interval: maximum interval, in seconds. multiplier: exponential increment for interval. jitter: a jitter to add to the retry interval. limit: max number of retries before giving up. `None` means no limit, and `0` means no retry. \"\"\" self . _initial = initial_interval self . _max = max_interval self . _multiplier = multiplier self . _jitter = jitter self . _limit = limit self . _count = 0 next_interval () \u00a4 Return the time to wait before the next retry. Returns None if the retry limit has been reached, and no more retries are possible. RETURNS DESCRIPTION Optional [ float ] Time until next retry when below retry limit, and None otherwise. Source code in frequenz/sdk/microgrid/client/_retry.py 148 149 150 151 152 153 154 155 156 157 158 159 160 161 def next_interval ( self ) -> Optional [ float ]: \"\"\"Return the time to wait before the next retry. Returns `None` if the retry limit has been reached, and no more retries are possible. Returns: Time until next retry when below retry limit, and None otherwise. \"\"\" if self . _limit is not None and self . _count >= self . _limit : return None self . _count += 1 exp_backoff_interval = self . _initial * self . _multiplier ** ( self . _count - 1 ) return min ( exp_backoff_interval + random . uniform ( 0.0 , self . _jitter ), self . _max ) frequenz.sdk.microgrid.client.LinearBackoff \u00a4 Bases: RetryStrategy Provides methods for calculating the interval between retries. Source code in frequenz/sdk/microgrid/client/_retry.py 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 class LinearBackoff ( RetryStrategy ): \"\"\"Provides methods for calculating the interval between retries.\"\"\" def __init__ ( self , interval : float = DEFAULT_RETRY_INTERVAL , jitter : float = DEFAULT_RETRY_JITTER , limit : Optional [ int ] = None , ) -> None : \"\"\"Create a `LinearBackoff` instance. Args: interval: time to wait for before the next retry, in seconds. jitter: a jitter to add to the retry interval. limit: max number of retries before giving up. `None` means no limit, and `0` means no retry. \"\"\" self . _interval = interval self . _jitter = jitter self . _limit = limit self . _count = 0 def next_interval ( self ) -> Optional [ float ]: \"\"\"Return the time to wait before the next retry. Returns `None` if the retry limit has been reached, and no more retries are possible. Returns: Time until next retry when below retry limit, and None otherwise. \"\"\" if self . _limit is not None and self . _count >= self . _limit : return None self . _count += 1 return self . _interval + random . uniform ( 0.0 , self . _jitter ) Functions \u00a4 __init__ ( interval = DEFAULT_RETRY_INTERVAL , jitter = DEFAULT_RETRY_JITTER , limit = None ) \u00a4 Create a LinearBackoff instance. PARAMETER DESCRIPTION interval time to wait for before the next retry, in seconds. TYPE: float DEFAULT: DEFAULT_RETRY_INTERVAL jitter a jitter to add to the retry interval. TYPE: float DEFAULT: DEFAULT_RETRY_JITTER limit max number of retries before giving up. None means no limit, and 0 means no retry. TYPE: Optional [ int ] DEFAULT: None Source code in frequenz/sdk/microgrid/client/_retry.py 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 def __init__ ( self , interval : float = DEFAULT_RETRY_INTERVAL , jitter : float = DEFAULT_RETRY_JITTER , limit : Optional [ int ] = None , ) -> None : \"\"\"Create a `LinearBackoff` instance. Args: interval: time to wait for before the next retry, in seconds. jitter: a jitter to add to the retry interval. limit: max number of retries before giving up. `None` means no limit, and `0` means no retry. \"\"\" self . _interval = interval self . _jitter = jitter self . _limit = limit self . _count = 0 next_interval () \u00a4 Return the time to wait before the next retry. Returns None if the retry limit has been reached, and no more retries are possible. RETURNS DESCRIPTION Optional [ float ] Time until next retry when below retry limit, and None otherwise. Source code in frequenz/sdk/microgrid/client/_retry.py 98 99 100 101 102 103 104 105 106 107 108 109 110 def next_interval ( self ) -> Optional [ float ]: \"\"\"Return the time to wait before the next retry. Returns `None` if the retry limit has been reached, and no more retries are possible. Returns: Time until next retry when below retry limit, and None otherwise. \"\"\" if self . _limit is not None and self . _count >= self . _limit : return None self . _count += 1 return self . _interval + random . uniform ( 0.0 , self . _jitter ) frequenz.sdk.microgrid.client.MicrogridApiClient \u00a4 Bases: ABC Base interface for microgrid API clients to implement. Source code in frequenz/sdk/microgrid/client/_client.py 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 class MicrogridApiClient ( ABC ): \"\"\"Base interface for microgrid API clients to implement.\"\"\" @abstractmethod async def components ( self ) -> Iterable [ Component ]: \"\"\"Fetch all the components present in the microgrid. Returns: Iterator whose elements are all the components in the microgrid. \"\"\" @abstractmethod async def connections ( self , starts : Optional [ Set [ int ]] = None , ends : Optional [ Set [ int ]] = None , ) -> Iterable [ Connection ]: \"\"\"Fetch the connections between components in the microgrid. Args: starts: if set and non-empty, only include connections whose start value matches one of the provided component IDs ends: if set and non-empty, only include connections whose end value matches one of the provided component IDs Returns: Microgrid connections matching the provided start and end filters. \"\"\" @abstractmethod async def meter_data ( self , component_id : int , ) -> Receiver [ MeterData ]: \"\"\"Return a channel receiver that provides a `MeterData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Args: component_id: id of the meter to get data for. Returns: A channel receiver that provides realtime meter data. \"\"\" @abstractmethod async def battery_data ( self , component_id : int , ) -> Receiver [ BatteryData ]: \"\"\"Return a channel receiver that provides a `BatteryData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Args: component_id: id of the battery to get data for. Returns: A channel receiver that provides realtime battery data. \"\"\" @abstractmethod async def inverter_data ( self , component_id : int , ) -> Receiver [ InverterData ]: \"\"\"Return a channel receiver that provides an `InverterData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Args: component_id: id of the inverter to get data for. Returns: A channel receiver that provides realtime inverter data. \"\"\" @abstractmethod async def ev_charger_data ( self , component_id : int , ) -> Receiver [ EVChargerData ]: \"\"\"Return a channel receiver that provides an `EvChargeData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Args: component_id: id of the ev charger to get data for. Returns: A channel receiver that provides realtime ev charger data. \"\"\" @abstractmethod async def set_power ( self , component_id : int , power_w : int ) -> Empty : \"\"\"Send request to the Microgrid to set power for component. If power > 0, then component will be charged with this power. If power < 0, then component will be discharged with this power. If power == 0, then stop charging or discharging component. Args: component_id: id of the component to set power. power_w: power to set for the component. Returns: Empty response. \"\"\" @abstractmethod async def set_bounds ( self , component_id : int , lower : float , upper : float ) -> None : \"\"\"Send `SetBoundsParam`s received from a channel to nitrogen. Args: component_id: ID of the component to set bounds for. lower: Lower bound to be set for the component. upper: Upper bound to be set for the component. \"\"\" Functions \u00a4 battery_data ( component_id ) async abstractmethod \u00a4 Return a channel receiver that provides a BatteryData stream. If only the latest value is required, the Receiver returned by this method can be converted into a Peekable with the into_peekable method on the Receiver. PARAMETER DESCRIPTION component_id id of the battery to get data for. TYPE: int RETURNS DESCRIPTION Receiver [ BatteryData ] A channel receiver that provides realtime battery data. Source code in frequenz/sdk/microgrid/client/_client.py 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 @abstractmethod async def battery_data ( self , component_id : int , ) -> Receiver [ BatteryData ]: \"\"\"Return a channel receiver that provides a `BatteryData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Args: component_id: id of the battery to get data for. Returns: A channel receiver that provides realtime battery data. \"\"\" components () async abstractmethod \u00a4 Fetch all the components present in the microgrid. RETURNS DESCRIPTION Iterable [ Component ] Iterator whose elements are all the components in the microgrid. Source code in frequenz/sdk/microgrid/client/_client.py 50 51 52 53 54 55 56 @abstractmethod async def components ( self ) -> Iterable [ Component ]: \"\"\"Fetch all the components present in the microgrid. Returns: Iterator whose elements are all the components in the microgrid. \"\"\" connections ( starts = None , ends = None ) async abstractmethod \u00a4 Fetch the connections between components in the microgrid. PARAMETER DESCRIPTION starts if set and non-empty, only include connections whose start value matches one of the provided component IDs TYPE: Optional [ Set [ int ]] DEFAULT: None ends if set and non-empty, only include connections whose end value matches one of the provided component IDs TYPE: Optional [ Set [ int ]] DEFAULT: None RETURNS DESCRIPTION Iterable [ Connection ] Microgrid connections matching the provided start and end filters. Source code in frequenz/sdk/microgrid/client/_client.py 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 @abstractmethod async def connections ( self , starts : Optional [ Set [ int ]] = None , ends : Optional [ Set [ int ]] = None , ) -> Iterable [ Connection ]: \"\"\"Fetch the connections between components in the microgrid. Args: starts: if set and non-empty, only include connections whose start value matches one of the provided component IDs ends: if set and non-empty, only include connections whose end value matches one of the provided component IDs Returns: Microgrid connections matching the provided start and end filters. \"\"\" ev_charger_data ( component_id ) async abstractmethod \u00a4 Return a channel receiver that provides an EvChargeData stream. If only the latest value is required, the Receiver returned by this method can be converted into a Peekable with the into_peekable method on the Receiver. PARAMETER DESCRIPTION component_id id of the ev charger to get data for. TYPE: int RETURNS DESCRIPTION Receiver [ EVChargerData ] A channel receiver that provides realtime ev charger data. Source code in frequenz/sdk/microgrid/client/_client.py 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 @abstractmethod async def ev_charger_data ( self , component_id : int , ) -> Receiver [ EVChargerData ]: \"\"\"Return a channel receiver that provides an `EvChargeData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Args: component_id: id of the ev charger to get data for. Returns: A channel receiver that provides realtime ev charger data. \"\"\" inverter_data ( component_id ) async abstractmethod \u00a4 Return a channel receiver that provides an InverterData stream. If only the latest value is required, the Receiver returned by this method can be converted into a Peekable with the into_peekable method on the Receiver. PARAMETER DESCRIPTION component_id id of the inverter to get data for. TYPE: int RETURNS DESCRIPTION Receiver [ InverterData ] A channel receiver that provides realtime inverter data. Source code in frequenz/sdk/microgrid/client/_client.py 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 @abstractmethod async def inverter_data ( self , component_id : int , ) -> Receiver [ InverterData ]: \"\"\"Return a channel receiver that provides an `InverterData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Args: component_id: id of the inverter to get data for. Returns: A channel receiver that provides realtime inverter data. \"\"\" meter_data ( component_id ) async abstractmethod \u00a4 Return a channel receiver that provides a MeterData stream. If only the latest value is required, the Receiver returned by this method can be converted into a Peekable with the into_peekable method on the Receiver. PARAMETER DESCRIPTION component_id id of the meter to get data for. TYPE: int RETURNS DESCRIPTION Receiver [ MeterData ] A channel receiver that provides realtime meter data. Source code in frequenz/sdk/microgrid/client/_client.py 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 @abstractmethod async def meter_data ( self , component_id : int , ) -> Receiver [ MeterData ]: \"\"\"Return a channel receiver that provides a `MeterData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Args: component_id: id of the meter to get data for. Returns: A channel receiver that provides realtime meter data. \"\"\" set_bounds ( component_id , lower , upper ) async abstractmethod \u00a4 Send SetBoundsParam s received from a channel to nitrogen. PARAMETER DESCRIPTION component_id ID of the component to set bounds for. TYPE: int lower Lower bound to be set for the component. TYPE: float upper Upper bound to be set for the component. TYPE: float Source code in frequenz/sdk/microgrid/client/_client.py 165 166 167 168 169 170 171 172 173 @abstractmethod async def set_bounds ( self , component_id : int , lower : float , upper : float ) -> None : \"\"\"Send `SetBoundsParam`s received from a channel to nitrogen. Args: component_id: ID of the component to set bounds for. lower: Lower bound to be set for the component. upper: Upper bound to be set for the component. \"\"\" set_power ( component_id , power_w ) async abstractmethod \u00a4 Send request to the Microgrid to set power for component. If power > 0, then component will be charged with this power. If power < 0, then component will be discharged with this power. If power == 0, then stop charging or discharging component. PARAMETER DESCRIPTION component_id id of the component to set power. TYPE: int power_w power to set for the component. TYPE: int RETURNS DESCRIPTION Empty Empty response. Source code in frequenz/sdk/microgrid/client/_client.py 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 @abstractmethod async def set_power ( self , component_id : int , power_w : int ) -> Empty : \"\"\"Send request to the Microgrid to set power for component. If power > 0, then component will be charged with this power. If power < 0, then component will be discharged with this power. If power == 0, then stop charging or discharging component. Args: component_id: id of the component to set power. power_w: power to set for the component. Returns: Empty response. \"\"\" frequenz.sdk.microgrid.client.MicrogridGrpcClient \u00a4 Bases: MicrogridApiClient Microgrid API client implementation using gRPC as the underlying protocol. Source code in frequenz/sdk/microgrid/client/_client.py 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 class MicrogridGrpcClient ( MicrogridApiClient ): \"\"\"Microgrid API client implementation using gRPC as the underlying protocol.\"\"\" def __init__ ( self , grpc_channel : grpc . aio . Channel , target : str , retry_spec : RetryStrategy = LinearBackoff (), ) -> None : \"\"\"Initialize the class instance. Args: grpc_channel: asyncio-supporting gRPC channel target: server (host:port) to be used for asyncio-supporting gRPC channel that the client should use to contact the API retry_spec: Specs on how to retry if the connection to a streaming method gets lost. \"\"\" self . target = target self . api = MicrogridStub ( grpc_channel ) self . _component_streams : Dict [ int , Broadcast [ Any ]] = {} self . _retry_spec = retry_spec async def components ( self ) -> Iterable [ Component ]: \"\"\"Fetch all the components present in the microgrid. Returns: Iterator whose elements are all the components in the microgrid. Raises: AioRpcError: if connection to Microgrid API cannot be established or when the api call exceeded timeout \"\"\" try : component_list = await self . api . ListComponents ( microgrid_pb . ComponentFilter (), timeout = DEFAULT_GRPC_CALL_TIMEOUT , ) except grpc . aio . AioRpcError as err : msg = f \"Failed to list components. Microgrid API: { self . target } . Err: { err . details () } \" raise grpc . aio . AioRpcError ( code = err . code (), initial_metadata = err . initial_metadata (), trailing_metadata = err . trailing_metadata (), details = msg , debug_error_string = err . debug_error_string (), ) components_only = filter ( lambda c : c . category not in ( microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_SENSOR , microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_LOAD , ), component_list . components , ) result : Iterable [ Component ] = map ( lambda c : Component ( c . id , _component_category_from_protobuf ( c . category )), components_only , ) return result async def connections ( self , starts : Optional [ Set [ int ]] = None , ends : Optional [ Set [ int ]] = None , ) -> Iterable [ Connection ]: \"\"\"Fetch the connections between components in the microgrid. Args: starts: if set and non-empty, only include connections whose start value matches one of the provided component IDs ends: if set and non-empty, only include connections whose end value matches one of the provided component IDs Returns: Microgrid connections matching the provided start and end filters. Raises: AioRpcError: if connection to Microgrid API cannot be established or when the api call exceeded timeout \"\"\" connection_filter = microgrid_pb . ConnectionFilter ( starts = starts , ends = ends ) try : valid_components , all_connections = await asyncio . gather ( self . components (), self . api . ListConnections ( connection_filter , timeout = DEFAULT_GRPC_CALL_TIMEOUT ), ) except grpc . aio . AioRpcError as err : msg = f \"Failed to list connections. Microgrid API: { self . target } . Err: { err . details () } \" raise grpc . aio . AioRpcError ( code = err . code (), initial_metadata = err . initial_metadata (), trailing_metadata = err . trailing_metadata (), details = msg , debug_error_string = err . debug_error_string (), ) # Filter out the components filtered in `components` method. # id=0 is an exception indicating grid component. valid_ids = { c . component_id for c in valid_components } valid_ids . add ( 0 ) connections = filter ( lambda c : ( c . start in valid_ids and c . end in valid_ids ), all_connections . connections , ) result : Iterable [ Connection ] = map ( lambda c : Connection ( c . start , c . end ), connections ) return result async def _component_data_task ( self , component_id : int , transform : Callable [[ microgrid_pb . ComponentData ], _GenericComponentData ], sender : Sender [ _GenericComponentData ], ) -> None : \"\"\"Read data from the microgrid API and send to a channel. Args: component_id: id of the component to get data for. transform: A method for transforming raw component data into the desired output type. sender: A channel sender, to send the component data to. Raises: AioRpcError: if connection to Microgrid API cannot be established \"\"\" retry_spec : RetryStrategy = self . _retry_spec . copy () while True : logger . debug ( \"Making call to `GetComponentData`, for component_id= %d \" , component_id ) try : call = self . api . GetComponentData ( microgrid_pb . ComponentIdParam ( id = component_id ), ) async for msg in call : await sender . send ( transform ( msg )) except grpc . aio . AioRpcError as err : api_details = f \"Microgrid API: { self . target } .\" logger . exception ( \"`GetComponentData`, for component_id= %d : exception: %s api: %s \" , component_id , err , api_details , ) if interval := retry_spec . next_interval (): logger . warning ( \"`GetComponentData`, for component_id= %d : connection ended, \" \"retrying %s in %0.3f seconds.\" , component_id , retry_spec . get_progress (), interval , ) await asyncio . sleep ( interval ) # type: ignore else : logger . warning ( \"`GetComponentData`, for component_id= %d : connection ended, \" \"retry limit exceeded %s .\" , component_id , retry_spec . get_progress (), ) break def _get_component_data_channel ( self , component_id : int , transform : Callable [[ microgrid_pb . ComponentData ], _GenericComponentData ], ) -> Broadcast [ _GenericComponentData ]: \"\"\"Return the broadcast channel for a given component_id. If a broadcast channel for the given component_id doesn't exist, create a new channel and a task for reading data from the microgrid api and sending them to the channel. Args: component_id: id of the component to get data for. transform: A method for transforming raw component data into the desired output type. Returns: The channel for the given component_id. \"\"\" if component_id in self . _component_streams : return self . _component_streams [ component_id ] task_name = f \"raw-component-data- { component_id } \" chan = Broadcast [ _GenericComponentData ]( task_name ) self . _component_streams [ component_id ] = chan asyncio . create_task ( self . _component_data_task ( component_id , transform , chan . new_sender (), ), name = task_name , ) return chan async def _expect_category ( self , component_id : int , expected_category : ComponentCategory , ) -> None : \"\"\"Check if the given component_id is of the expected type. Raises: ValueError: if the given id is unknown or has a different type. Args: component_id: Component id to check. expected_category: Component category that the given id is expected to have. \"\"\" try : comp = next ( comp for comp in await self . components () if comp . component_id == component_id ) except StopIteration as exc : raise ValueError ( f \"Unable to find component with id { component_id } \" ) from exc if comp . category != expected_category : raise ValueError ( f \"Component id { component_id } is a { comp . category } \" f \", not a { expected_category } .\" ) async def meter_data ( self , component_id : int , ) -> Receiver [ MeterData ]: \"\"\"Return a channel receiver that provides a `MeterData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Raises: ValueError: if the given id is unknown or has a different type. Args: component_id: id of the meter to get data for. Returns: A channel receiver that provides realtime meter data. \"\"\" await self . _expect_category ( component_id , ComponentCategory . METER , ) return self . _get_component_data_channel ( component_id , MeterData . from_proto , ) . new_receiver () async def battery_data ( self , component_id : int , ) -> Receiver [ BatteryData ]: \"\"\"Return a channel receiver that provides a `BatteryData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Raises: ValueError: if the given id is unknown or has a different type. Args: component_id: id of the battery to get data for. Returns: A channel receiver that provides realtime battery data. \"\"\" await self . _expect_category ( component_id , ComponentCategory . BATTERY , ) return self . _get_component_data_channel ( component_id , BatteryData . from_proto , ) . new_receiver () async def inverter_data ( self , component_id : int , ) -> Receiver [ InverterData ]: \"\"\"Return a channel receiver that provides an `InverterData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Raises: ValueError: if the given id is unknown or has a different type. Args: component_id: id of the inverter to get data for. Returns: A channel receiver that provides realtime inverter data. \"\"\" await self . _expect_category ( component_id , ComponentCategory . INVERTER , ) return self . _get_component_data_channel ( component_id , InverterData . from_proto , ) . new_receiver () async def ev_charger_data ( self , component_id : int , ) -> Receiver [ EVChargerData ]: \"\"\"Return a channel receiver that provides an `EvChargeData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Raises: ValueError: if the given id is unknown or has a different type. Args: component_id: id of the ev charger to get data for. Returns: A channel receiver that provides realtime ev charger data. \"\"\" await self . _expect_category ( component_id , ComponentCategory . EV_CHARGER , ) return self . _get_component_data_channel ( component_id , EVChargerData . from_proto , ) . new_receiver () async def set_power ( self , component_id : int , power_w : int ) -> Empty : \"\"\"Send request to the Microgrid to set power for component. If power > 0, then component will be charged with this power. If power < 0, then component will be discharged with this power. If power == 0, then stop charging or discharging component. Args: component_id: id of the component to set power. power_w: power to set for the component. Returns: Empty response. Raises: AioRpcError: if connection to Microgrid API cannot be established or when the api call exceeded timeout \"\"\" try : if power_w >= 0 : result : Empty = await self . api . Charge ( microgrid_pb . PowerLevelParam ( component_id = component_id , power_w = power_w ), timeout = DEFAULT_GRPC_CALL_TIMEOUT , ) else : power_w *= - 1 result = await self . api . Discharge ( microgrid_pb . PowerLevelParam ( component_id = component_id , power_w = power_w ), timeout = DEFAULT_GRPC_CALL_TIMEOUT , ) except grpc . aio . AioRpcError as err : msg = f \"Failed to set power. Microgrid API: { self . target } . Err: { err . details () } \" raise grpc . aio . AioRpcError ( code = err . code (), initial_metadata = err . initial_metadata (), trailing_metadata = err . trailing_metadata (), details = msg , debug_error_string = err . debug_error_string (), ) return result async def set_bounds ( self , component_id : int , lower : float , upper : float , ) -> None : \"\"\"Send `SetBoundsParam`s received from a channel to nitrogen. Args: component_id: ID of the component to set bounds for. lower: Lower bound to be set for the component. upper: Upper bound to be set for the component. Raises: ValueError: when upper bound is less than 0, or when lower bound is greater than 0. grpc.aio.AioRpcError: if connection to Microgrid API cannot be established or when the api call exceeded timeout \"\"\" api_details = f \"Microgrid API: { self . target } .\" if upper < 0 : raise ValueError ( f \"Upper bound { upper } must be greater than or equal to 0.\" ) if lower > 0 : raise ValueError ( f \"Lower bound { upper } must be less than or equal to 0.\" ) set_bounds_call = self . api . SetBounds ( timeout = DEFAULT_GRPC_CALL_TIMEOUT ) try : await set_bounds_call . write ( microgrid_pb . SetBoundsParam ( component_id = component_id , # pylint: disable=no-member,line-too-long target_metric = microgrid_pb . SetBoundsParam . TargetMetric . TARGET_METRIC_POWER_ACTIVE , bounds = common_pb . Bounds ( lower = lower , upper = upper ), ), ) except grpc . aio . AioRpcError as err : logger . error ( \"set_bounds write failed: %s , for message: %s , api: %s . Err: %s \" , err , next , api_details , err . details (), ) raise Functions \u00a4 __init__ ( grpc_channel , target , retry_spec = LinearBackoff ()) \u00a4 Initialize the class instance. PARAMETER DESCRIPTION grpc_channel asyncio-supporting gRPC channel TYPE: grpc . aio . Channel target server (host:port) to be used for asyncio-supporting gRPC channel that the client should use to contact the API TYPE: str retry_spec Specs on how to retry if the connection to a streaming method gets lost. TYPE: RetryStrategy DEFAULT: LinearBackoff() Source code in frequenz/sdk/microgrid/client/_client.py 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 def __init__ ( self , grpc_channel : grpc . aio . Channel , target : str , retry_spec : RetryStrategy = LinearBackoff (), ) -> None : \"\"\"Initialize the class instance. Args: grpc_channel: asyncio-supporting gRPC channel target: server (host:port) to be used for asyncio-supporting gRPC channel that the client should use to contact the API retry_spec: Specs on how to retry if the connection to a streaming method gets lost. \"\"\" self . target = target self . api = MicrogridStub ( grpc_channel ) self . _component_streams : Dict [ int , Broadcast [ Any ]] = {} self . _retry_spec = retry_spec battery_data ( component_id ) async \u00a4 Return a channel receiver that provides a BatteryData stream. If only the latest value is required, the Receiver returned by this method can be converted into a Peekable with the into_peekable method on the Receiver. RAISES DESCRIPTION ValueError if the given id is unknown or has a different type. PARAMETER DESCRIPTION component_id id of the battery to get data for. TYPE: int RETURNS DESCRIPTION Receiver [ BatteryData ] A channel receiver that provides realtime battery data. Source code in frequenz/sdk/microgrid/client/_client.py 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 async def battery_data ( self , component_id : int , ) -> Receiver [ BatteryData ]: \"\"\"Return a channel receiver that provides a `BatteryData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Raises: ValueError: if the given id is unknown or has a different type. Args: component_id: id of the battery to get data for. Returns: A channel receiver that provides realtime battery data. \"\"\" await self . _expect_category ( component_id , ComponentCategory . BATTERY , ) return self . _get_component_data_channel ( component_id , BatteryData . from_proto , ) . new_receiver () components () async \u00a4 Fetch all the components present in the microgrid. RETURNS DESCRIPTION Iterable [ Component ] Iterator whose elements are all the components in the microgrid. RAISES DESCRIPTION AioRpcError if connection to Microgrid API cannot be established or when the api call exceeded timeout Source code in frequenz/sdk/microgrid/client/_client.py 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 async def components ( self ) -> Iterable [ Component ]: \"\"\"Fetch all the components present in the microgrid. Returns: Iterator whose elements are all the components in the microgrid. Raises: AioRpcError: if connection to Microgrid API cannot be established or when the api call exceeded timeout \"\"\" try : component_list = await self . api . ListComponents ( microgrid_pb . ComponentFilter (), timeout = DEFAULT_GRPC_CALL_TIMEOUT , ) except grpc . aio . AioRpcError as err : msg = f \"Failed to list components. Microgrid API: { self . target } . Err: { err . details () } \" raise grpc . aio . AioRpcError ( code = err . code (), initial_metadata = err . initial_metadata (), trailing_metadata = err . trailing_metadata (), details = msg , debug_error_string = err . debug_error_string (), ) components_only = filter ( lambda c : c . category not in ( microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_SENSOR , microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_LOAD , ), component_list . components , ) result : Iterable [ Component ] = map ( lambda c : Component ( c . id , _component_category_from_protobuf ( c . category )), components_only , ) return result connections ( starts = None , ends = None ) async \u00a4 Fetch the connections between components in the microgrid. PARAMETER DESCRIPTION starts if set and non-empty, only include connections whose start value matches one of the provided component IDs TYPE: Optional [ Set [ int ]] DEFAULT: None ends if set and non-empty, only include connections whose end value matches one of the provided component IDs TYPE: Optional [ Set [ int ]] DEFAULT: None RETURNS DESCRIPTION Iterable [ Connection ] Microgrid connections matching the provided start and end filters. RAISES DESCRIPTION AioRpcError if connection to Microgrid API cannot be established or when the api call exceeded timeout Source code in frequenz/sdk/microgrid/client/_client.py 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 async def connections ( self , starts : Optional [ Set [ int ]] = None , ends : Optional [ Set [ int ]] = None , ) -> Iterable [ Connection ]: \"\"\"Fetch the connections between components in the microgrid. Args: starts: if set and non-empty, only include connections whose start value matches one of the provided component IDs ends: if set and non-empty, only include connections whose end value matches one of the provided component IDs Returns: Microgrid connections matching the provided start and end filters. Raises: AioRpcError: if connection to Microgrid API cannot be established or when the api call exceeded timeout \"\"\" connection_filter = microgrid_pb . ConnectionFilter ( starts = starts , ends = ends ) try : valid_components , all_connections = await asyncio . gather ( self . components (), self . api . ListConnections ( connection_filter , timeout = DEFAULT_GRPC_CALL_TIMEOUT ), ) except grpc . aio . AioRpcError as err : msg = f \"Failed to list connections. Microgrid API: { self . target } . Err: { err . details () } \" raise grpc . aio . AioRpcError ( code = err . code (), initial_metadata = err . initial_metadata (), trailing_metadata = err . trailing_metadata (), details = msg , debug_error_string = err . debug_error_string (), ) # Filter out the components filtered in `components` method. # id=0 is an exception indicating grid component. valid_ids = { c . component_id for c in valid_components } valid_ids . add ( 0 ) connections = filter ( lambda c : ( c . start in valid_ids and c . end in valid_ids ), all_connections . connections , ) result : Iterable [ Connection ] = map ( lambda c : Connection ( c . start , c . end ), connections ) return result ev_charger_data ( component_id ) async \u00a4 Return a channel receiver that provides an EvChargeData stream. If only the latest value is required, the Receiver returned by this method can be converted into a Peekable with the into_peekable method on the Receiver. RAISES DESCRIPTION ValueError if the given id is unknown or has a different type. PARAMETER DESCRIPTION component_id id of the ev charger to get data for. TYPE: int RETURNS DESCRIPTION Receiver [ EVChargerData ] A channel receiver that provides realtime ev charger data. Source code in frequenz/sdk/microgrid/client/_client.py 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 async def ev_charger_data ( self , component_id : int , ) -> Receiver [ EVChargerData ]: \"\"\"Return a channel receiver that provides an `EvChargeData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Raises: ValueError: if the given id is unknown or has a different type. Args: component_id: id of the ev charger to get data for. Returns: A channel receiver that provides realtime ev charger data. \"\"\" await self . _expect_category ( component_id , ComponentCategory . EV_CHARGER , ) return self . _get_component_data_channel ( component_id , EVChargerData . from_proto , ) . new_receiver () inverter_data ( component_id ) async \u00a4 Return a channel receiver that provides an InverterData stream. If only the latest value is required, the Receiver returned by this method can be converted into a Peekable with the into_peekable method on the Receiver. RAISES DESCRIPTION ValueError if the given id is unknown or has a different type. PARAMETER DESCRIPTION component_id id of the inverter to get data for. TYPE: int RETURNS DESCRIPTION Receiver [ InverterData ] A channel receiver that provides realtime inverter data. Source code in frequenz/sdk/microgrid/client/_client.py 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 async def inverter_data ( self , component_id : int , ) -> Receiver [ InverterData ]: \"\"\"Return a channel receiver that provides an `InverterData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Raises: ValueError: if the given id is unknown or has a different type. Args: component_id: id of the inverter to get data for. Returns: A channel receiver that provides realtime inverter data. \"\"\" await self . _expect_category ( component_id , ComponentCategory . INVERTER , ) return self . _get_component_data_channel ( component_id , InverterData . from_proto , ) . new_receiver () meter_data ( component_id ) async \u00a4 Return a channel receiver that provides a MeterData stream. If only the latest value is required, the Receiver returned by this method can be converted into a Peekable with the into_peekable method on the Receiver. RAISES DESCRIPTION ValueError if the given id is unknown or has a different type. PARAMETER DESCRIPTION component_id id of the meter to get data for. TYPE: int RETURNS DESCRIPTION Receiver [ MeterData ] A channel receiver that provides realtime meter data. Source code in frequenz/sdk/microgrid/client/_client.py 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 async def meter_data ( self , component_id : int , ) -> Receiver [ MeterData ]: \"\"\"Return a channel receiver that provides a `MeterData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Raises: ValueError: if the given id is unknown or has a different type. Args: component_id: id of the meter to get data for. Returns: A channel receiver that provides realtime meter data. \"\"\" await self . _expect_category ( component_id , ComponentCategory . METER , ) return self . _get_component_data_channel ( component_id , MeterData . from_proto , ) . new_receiver () set_bounds ( component_id , lower , upper ) async \u00a4 Send SetBoundsParam s received from a channel to nitrogen. PARAMETER DESCRIPTION component_id ID of the component to set bounds for. TYPE: int lower Lower bound to be set for the component. TYPE: float upper Upper bound to be set for the component. TYPE: float RAISES DESCRIPTION ValueError when upper bound is less than 0, or when lower bound is greater than 0. grpc . aio . AioRpcError if connection to Microgrid API cannot be established or when the api call exceeded timeout Source code in frequenz/sdk/microgrid/client/_client.py 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 async def set_bounds ( self , component_id : int , lower : float , upper : float , ) -> None : \"\"\"Send `SetBoundsParam`s received from a channel to nitrogen. Args: component_id: ID of the component to set bounds for. lower: Lower bound to be set for the component. upper: Upper bound to be set for the component. Raises: ValueError: when upper bound is less than 0, or when lower bound is greater than 0. grpc.aio.AioRpcError: if connection to Microgrid API cannot be established or when the api call exceeded timeout \"\"\" api_details = f \"Microgrid API: { self . target } .\" if upper < 0 : raise ValueError ( f \"Upper bound { upper } must be greater than or equal to 0.\" ) if lower > 0 : raise ValueError ( f \"Lower bound { upper } must be less than or equal to 0.\" ) set_bounds_call = self . api . SetBounds ( timeout = DEFAULT_GRPC_CALL_TIMEOUT ) try : await set_bounds_call . write ( microgrid_pb . SetBoundsParam ( component_id = component_id , # pylint: disable=no-member,line-too-long target_metric = microgrid_pb . SetBoundsParam . TargetMetric . TARGET_METRIC_POWER_ACTIVE , bounds = common_pb . Bounds ( lower = lower , upper = upper ), ), ) except grpc . aio . AioRpcError as err : logger . error ( \"set_bounds write failed: %s , for message: %s , api: %s . Err: %s \" , err , next , api_details , err . details (), ) raise set_power ( component_id , power_w ) async \u00a4 Send request to the Microgrid to set power for component. If power > 0, then component will be charged with this power. If power < 0, then component will be discharged with this power. If power == 0, then stop charging or discharging component. PARAMETER DESCRIPTION component_id id of the component to set power. TYPE: int power_w power to set for the component. TYPE: int RETURNS DESCRIPTION Empty Empty response. RAISES DESCRIPTION AioRpcError if connection to Microgrid API cannot be established or when the api call exceeded timeout Source code in frequenz/sdk/microgrid/client/_client.py 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 async def set_power ( self , component_id : int , power_w : int ) -> Empty : \"\"\"Send request to the Microgrid to set power for component. If power > 0, then component will be charged with this power. If power < 0, then component will be discharged with this power. If power == 0, then stop charging or discharging component. Args: component_id: id of the component to set power. power_w: power to set for the component. Returns: Empty response. Raises: AioRpcError: if connection to Microgrid API cannot be established or when the api call exceeded timeout \"\"\" try : if power_w >= 0 : result : Empty = await self . api . Charge ( microgrid_pb . PowerLevelParam ( component_id = component_id , power_w = power_w ), timeout = DEFAULT_GRPC_CALL_TIMEOUT , ) else : power_w *= - 1 result = await self . api . Discharge ( microgrid_pb . PowerLevelParam ( component_id = component_id , power_w = power_w ), timeout = DEFAULT_GRPC_CALL_TIMEOUT , ) except grpc . aio . AioRpcError as err : msg = f \"Failed to set power. Microgrid API: { self . target } . Err: { err . details () } \" raise grpc . aio . AioRpcError ( code = err . code (), initial_metadata = err . initial_metadata (), trailing_metadata = err . trailing_metadata (), details = msg , debug_error_string = err . debug_error_string (), ) return result frequenz.sdk.microgrid.client.RetryStrategy \u00a4 Bases: ABC Interface for implementing retry strategies. Source code in frequenz/sdk/microgrid/client/_retry.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 class RetryStrategy ( ABC ): \"\"\"Interface for implementing retry strategies.\"\"\" _limit : Optional [ int ] _count : int @abstractmethod def next_interval ( self ) -> Optional [ float ]: \"\"\"Return the time to wait before the next retry. Returns `None` if the retry limit has been reached, and no more retries are possible. Returns: Time until next retry when below retry limit, and None otherwise. \"\"\" def get_progress ( self ) -> str : \"\"\"Return a string denoting the retry progress. Returns: String denoting retry progress in the form \"(count/limit)\" \"\"\" if self . _limit is None : return f \"( { self . _count } /\u221e)\" return f \"( { self . _count } / { self . _limit } )\" def reset ( self ) -> None : \"\"\"Reset the retry counter. To be called as soon as a connection is successful. \"\"\" self . _count = 0 def copy ( self ) -> RetryStrategy : \"\"\"Create a new instance of `self`. Returns: A deepcopy of `self`. \"\"\" ret = deepcopy ( self ) ret . reset () return ret def __iter__ ( self ) -> Iterator [ float ]: \"\"\"Return an iterator over the retry intervals. Yields: Next retry interval in seconds. \"\"\" while True : interval = self . next_interval () if interval is None : break yield interval Functions \u00a4 __iter__ () \u00a4 Return an iterator over the retry intervals. YIELDS DESCRIPTION Iterator [ float ] Next retry interval in seconds. Source code in frequenz/sdk/microgrid/client/_retry.py 62 63 64 65 66 67 68 69 70 71 72 def __iter__ ( self ) -> Iterator [ float ]: \"\"\"Return an iterator over the retry intervals. Yields: Next retry interval in seconds. \"\"\" while True : interval = self . next_interval () if interval is None : break yield interval copy () \u00a4 Create a new instance of self . RETURNS DESCRIPTION RetryStrategy A deepcopy of self . Source code in frequenz/sdk/microgrid/client/_retry.py 52 53 54 55 56 57 58 59 60 def copy ( self ) -> RetryStrategy : \"\"\"Create a new instance of `self`. Returns: A deepcopy of `self`. \"\"\" ret = deepcopy ( self ) ret . reset () return ret get_progress () \u00a4 Return a string denoting the retry progress. RETURNS DESCRIPTION str String denoting retry progress in the form \"(count/limit)\" Source code in frequenz/sdk/microgrid/client/_retry.py 34 35 36 37 38 39 40 41 42 43 def get_progress ( self ) -> str : \"\"\"Return a string denoting the retry progress. Returns: String denoting retry progress in the form \"(count/limit)\" \"\"\" if self . _limit is None : return f \"( { self . _count } /\u221e)\" return f \"( { self . _count } / { self . _limit } )\" next_interval () abstractmethod \u00a4 Return the time to wait before the next retry. Returns None if the retry limit has been reached, and no more retries are possible. RETURNS DESCRIPTION Optional [ float ] Time until next retry when below retry limit, and None otherwise. Source code in frequenz/sdk/microgrid/client/_retry.py 23 24 25 26 27 28 29 30 31 32 @abstractmethod def next_interval ( self ) -> Optional [ float ]: \"\"\"Return the time to wait before the next retry. Returns `None` if the retry limit has been reached, and no more retries are possible. Returns: Time until next retry when below retry limit, and None otherwise. \"\"\" reset () \u00a4 Reset the retry counter. To be called as soon as a connection is successful. Source code in frequenz/sdk/microgrid/client/_retry.py 45 46 47 48 49 50 def reset ( self ) -> None : \"\"\"Reset the retry counter. To be called as soon as a connection is successful. \"\"\" self . _count = 0","title":"client"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client","text":"Microgrid API client. This package provides an easy way to connect to the microgrid API.","title":"client"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client.Connection","text":"Bases: NamedTuple Metadata for a connection between microgrid components. Source code in frequenz/sdk/microgrid/client/_connection.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 class Connection ( NamedTuple ): \"\"\"Metadata for a connection between microgrid components.\"\"\" start : int end : int def is_valid ( self ) -> bool : \"\"\"Check if this instance contains valid data. Returns: `True` if `start >= 0`, `end > 0`, and `start != end`, `False` otherwise. \"\"\" return self . start >= 0 and self . end > 0 and self . start != self . end","title":"Connection"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client.Connection-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client._connection.Connection.is_valid","text":"Check if this instance contains valid data. RETURNS DESCRIPTION bool True if start >= 0 , end > 0 , and start != end , False otherwise. Source code in frequenz/sdk/microgrid/client/_connection.py 15 16 17 18 19 20 21 22 def is_valid ( self ) -> bool : \"\"\"Check if this instance contains valid data. Returns: `True` if `start >= 0`, `end > 0`, and `start != end`, `False` otherwise. \"\"\" return self . start >= 0 and self . end > 0 and self . start != self . end","title":"is_valid()"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client.ExponentialBackoff","text":"Bases: RetryStrategy Provides methods for calculating the exponential interval between retries. Source code in frequenz/sdk/microgrid/client/_retry.py 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 class ExponentialBackoff ( RetryStrategy ): \"\"\"Provides methods for calculating the exponential interval between retries.\"\"\" DEFAULT_INTERVAL = DEFAULT_RETRY_INTERVAL DEFAULT_MAX_INTERVAL = 60.0 DEFAULT_MULTIPLIER = 2.0 # pylint: disable=too-many-arguments def __init__ ( self , initial_interval : float = DEFAULT_INTERVAL , max_interval : float = DEFAULT_MAX_INTERVAL , multiplier : float = DEFAULT_MULTIPLIER , jitter : float = DEFAULT_RETRY_JITTER , limit : Optional [ int ] = None , ) -> None : \"\"\"Create a `ExponentialBackoff` instance. Args: initial_interval: time to wait for before the first retry, in seconds. max_interval: maximum interval, in seconds. multiplier: exponential increment for interval. jitter: a jitter to add to the retry interval. limit: max number of retries before giving up. `None` means no limit, and `0` means no retry. \"\"\" self . _initial = initial_interval self . _max = max_interval self . _multiplier = multiplier self . _jitter = jitter self . _limit = limit self . _count = 0 def next_interval ( self ) -> Optional [ float ]: \"\"\"Return the time to wait before the next retry. Returns `None` if the retry limit has been reached, and no more retries are possible. Returns: Time until next retry when below retry limit, and None otherwise. \"\"\" if self . _limit is not None and self . _count >= self . _limit : return None self . _count += 1 exp_backoff_interval = self . _initial * self . _multiplier ** ( self . _count - 1 ) return min ( exp_backoff_interval + random . uniform ( 0.0 , self . _jitter ), self . _max )","title":"ExponentialBackoff"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client.ExponentialBackoff-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client._retry.ExponentialBackoff.__init__","text":"Create a ExponentialBackoff instance. PARAMETER DESCRIPTION initial_interval time to wait for before the first retry, in seconds. TYPE: float DEFAULT: DEFAULT_INTERVAL max_interval maximum interval, in seconds. TYPE: float DEFAULT: DEFAULT_MAX_INTERVAL multiplier exponential increment for interval. TYPE: float DEFAULT: DEFAULT_MULTIPLIER jitter a jitter to add to the retry interval. TYPE: float DEFAULT: DEFAULT_RETRY_JITTER limit max number of retries before giving up. None means no limit, and 0 means no retry. TYPE: Optional [ int ] DEFAULT: None Source code in frequenz/sdk/microgrid/client/_retry.py 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 def __init__ ( self , initial_interval : float = DEFAULT_INTERVAL , max_interval : float = DEFAULT_MAX_INTERVAL , multiplier : float = DEFAULT_MULTIPLIER , jitter : float = DEFAULT_RETRY_JITTER , limit : Optional [ int ] = None , ) -> None : \"\"\"Create a `ExponentialBackoff` instance. Args: initial_interval: time to wait for before the first retry, in seconds. max_interval: maximum interval, in seconds. multiplier: exponential increment for interval. jitter: a jitter to add to the retry interval. limit: max number of retries before giving up. `None` means no limit, and `0` means no retry. \"\"\" self . _initial = initial_interval self . _max = max_interval self . _multiplier = multiplier self . _jitter = jitter self . _limit = limit self . _count = 0","title":"__init__()"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client._retry.ExponentialBackoff.next_interval","text":"Return the time to wait before the next retry. Returns None if the retry limit has been reached, and no more retries are possible. RETURNS DESCRIPTION Optional [ float ] Time until next retry when below retry limit, and None otherwise. Source code in frequenz/sdk/microgrid/client/_retry.py 148 149 150 151 152 153 154 155 156 157 158 159 160 161 def next_interval ( self ) -> Optional [ float ]: \"\"\"Return the time to wait before the next retry. Returns `None` if the retry limit has been reached, and no more retries are possible. Returns: Time until next retry when below retry limit, and None otherwise. \"\"\" if self . _limit is not None and self . _count >= self . _limit : return None self . _count += 1 exp_backoff_interval = self . _initial * self . _multiplier ** ( self . _count - 1 ) return min ( exp_backoff_interval + random . uniform ( 0.0 , self . _jitter ), self . _max )","title":"next_interval()"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client.LinearBackoff","text":"Bases: RetryStrategy Provides methods for calculating the interval between retries. Source code in frequenz/sdk/microgrid/client/_retry.py 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 class LinearBackoff ( RetryStrategy ): \"\"\"Provides methods for calculating the interval between retries.\"\"\" def __init__ ( self , interval : float = DEFAULT_RETRY_INTERVAL , jitter : float = DEFAULT_RETRY_JITTER , limit : Optional [ int ] = None , ) -> None : \"\"\"Create a `LinearBackoff` instance. Args: interval: time to wait for before the next retry, in seconds. jitter: a jitter to add to the retry interval. limit: max number of retries before giving up. `None` means no limit, and `0` means no retry. \"\"\" self . _interval = interval self . _jitter = jitter self . _limit = limit self . _count = 0 def next_interval ( self ) -> Optional [ float ]: \"\"\"Return the time to wait before the next retry. Returns `None` if the retry limit has been reached, and no more retries are possible. Returns: Time until next retry when below retry limit, and None otherwise. \"\"\" if self . _limit is not None and self . _count >= self . _limit : return None self . _count += 1 return self . _interval + random . uniform ( 0.0 , self . _jitter )","title":"LinearBackoff"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client.LinearBackoff-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client._retry.LinearBackoff.__init__","text":"Create a LinearBackoff instance. PARAMETER DESCRIPTION interval time to wait for before the next retry, in seconds. TYPE: float DEFAULT: DEFAULT_RETRY_INTERVAL jitter a jitter to add to the retry interval. TYPE: float DEFAULT: DEFAULT_RETRY_JITTER limit max number of retries before giving up. None means no limit, and 0 means no retry. TYPE: Optional [ int ] DEFAULT: None Source code in frequenz/sdk/microgrid/client/_retry.py 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 def __init__ ( self , interval : float = DEFAULT_RETRY_INTERVAL , jitter : float = DEFAULT_RETRY_JITTER , limit : Optional [ int ] = None , ) -> None : \"\"\"Create a `LinearBackoff` instance. Args: interval: time to wait for before the next retry, in seconds. jitter: a jitter to add to the retry interval. limit: max number of retries before giving up. `None` means no limit, and `0` means no retry. \"\"\" self . _interval = interval self . _jitter = jitter self . _limit = limit self . _count = 0","title":"__init__()"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client._retry.LinearBackoff.next_interval","text":"Return the time to wait before the next retry. Returns None if the retry limit has been reached, and no more retries are possible. RETURNS DESCRIPTION Optional [ float ] Time until next retry when below retry limit, and None otherwise. Source code in frequenz/sdk/microgrid/client/_retry.py 98 99 100 101 102 103 104 105 106 107 108 109 110 def next_interval ( self ) -> Optional [ float ]: \"\"\"Return the time to wait before the next retry. Returns `None` if the retry limit has been reached, and no more retries are possible. Returns: Time until next retry when below retry limit, and None otherwise. \"\"\" if self . _limit is not None and self . _count >= self . _limit : return None self . _count += 1 return self . _interval + random . uniform ( 0.0 , self . _jitter )","title":"next_interval()"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client.MicrogridApiClient","text":"Bases: ABC Base interface for microgrid API clients to implement. Source code in frequenz/sdk/microgrid/client/_client.py 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 class MicrogridApiClient ( ABC ): \"\"\"Base interface for microgrid API clients to implement.\"\"\" @abstractmethod async def components ( self ) -> Iterable [ Component ]: \"\"\"Fetch all the components present in the microgrid. Returns: Iterator whose elements are all the components in the microgrid. \"\"\" @abstractmethod async def connections ( self , starts : Optional [ Set [ int ]] = None , ends : Optional [ Set [ int ]] = None , ) -> Iterable [ Connection ]: \"\"\"Fetch the connections between components in the microgrid. Args: starts: if set and non-empty, only include connections whose start value matches one of the provided component IDs ends: if set and non-empty, only include connections whose end value matches one of the provided component IDs Returns: Microgrid connections matching the provided start and end filters. \"\"\" @abstractmethod async def meter_data ( self , component_id : int , ) -> Receiver [ MeterData ]: \"\"\"Return a channel receiver that provides a `MeterData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Args: component_id: id of the meter to get data for. Returns: A channel receiver that provides realtime meter data. \"\"\" @abstractmethod async def battery_data ( self , component_id : int , ) -> Receiver [ BatteryData ]: \"\"\"Return a channel receiver that provides a `BatteryData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Args: component_id: id of the battery to get data for. Returns: A channel receiver that provides realtime battery data. \"\"\" @abstractmethod async def inverter_data ( self , component_id : int , ) -> Receiver [ InverterData ]: \"\"\"Return a channel receiver that provides an `InverterData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Args: component_id: id of the inverter to get data for. Returns: A channel receiver that provides realtime inverter data. \"\"\" @abstractmethod async def ev_charger_data ( self , component_id : int , ) -> Receiver [ EVChargerData ]: \"\"\"Return a channel receiver that provides an `EvChargeData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Args: component_id: id of the ev charger to get data for. Returns: A channel receiver that provides realtime ev charger data. \"\"\" @abstractmethod async def set_power ( self , component_id : int , power_w : int ) -> Empty : \"\"\"Send request to the Microgrid to set power for component. If power > 0, then component will be charged with this power. If power < 0, then component will be discharged with this power. If power == 0, then stop charging or discharging component. Args: component_id: id of the component to set power. power_w: power to set for the component. Returns: Empty response. \"\"\" @abstractmethod async def set_bounds ( self , component_id : int , lower : float , upper : float ) -> None : \"\"\"Send `SetBoundsParam`s received from a channel to nitrogen. Args: component_id: ID of the component to set bounds for. lower: Lower bound to be set for the component. upper: Upper bound to be set for the component. \"\"\"","title":"MicrogridApiClient"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client.MicrogridApiClient-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client._client.MicrogridApiClient.battery_data","text":"Return a channel receiver that provides a BatteryData stream. If only the latest value is required, the Receiver returned by this method can be converted into a Peekable with the into_peekable method on the Receiver. PARAMETER DESCRIPTION component_id id of the battery to get data for. TYPE: int RETURNS DESCRIPTION Receiver [ BatteryData ] A channel receiver that provides realtime battery data. Source code in frequenz/sdk/microgrid/client/_client.py 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 @abstractmethod async def battery_data ( self , component_id : int , ) -> Receiver [ BatteryData ]: \"\"\"Return a channel receiver that provides a `BatteryData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Args: component_id: id of the battery to get data for. Returns: A channel receiver that provides realtime battery data. \"\"\"","title":"battery_data()"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client._client.MicrogridApiClient.components","text":"Fetch all the components present in the microgrid. RETURNS DESCRIPTION Iterable [ Component ] Iterator whose elements are all the components in the microgrid. Source code in frequenz/sdk/microgrid/client/_client.py 50 51 52 53 54 55 56 @abstractmethod async def components ( self ) -> Iterable [ Component ]: \"\"\"Fetch all the components present in the microgrid. Returns: Iterator whose elements are all the components in the microgrid. \"\"\"","title":"components()"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client._client.MicrogridApiClient.connections","text":"Fetch the connections between components in the microgrid. PARAMETER DESCRIPTION starts if set and non-empty, only include connections whose start value matches one of the provided component IDs TYPE: Optional [ Set [ int ]] DEFAULT: None ends if set and non-empty, only include connections whose end value matches one of the provided component IDs TYPE: Optional [ Set [ int ]] DEFAULT: None RETURNS DESCRIPTION Iterable [ Connection ] Microgrid connections matching the provided start and end filters. Source code in frequenz/sdk/microgrid/client/_client.py 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 @abstractmethod async def connections ( self , starts : Optional [ Set [ int ]] = None , ends : Optional [ Set [ int ]] = None , ) -> Iterable [ Connection ]: \"\"\"Fetch the connections between components in the microgrid. Args: starts: if set and non-empty, only include connections whose start value matches one of the provided component IDs ends: if set and non-empty, only include connections whose end value matches one of the provided component IDs Returns: Microgrid connections matching the provided start and end filters. \"\"\"","title":"connections()"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client._client.MicrogridApiClient.ev_charger_data","text":"Return a channel receiver that provides an EvChargeData stream. If only the latest value is required, the Receiver returned by this method can be converted into a Peekable with the into_peekable method on the Receiver. PARAMETER DESCRIPTION component_id id of the ev charger to get data for. TYPE: int RETURNS DESCRIPTION Receiver [ EVChargerData ] A channel receiver that provides realtime ev charger data. Source code in frequenz/sdk/microgrid/client/_client.py 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 @abstractmethod async def ev_charger_data ( self , component_id : int , ) -> Receiver [ EVChargerData ]: \"\"\"Return a channel receiver that provides an `EvChargeData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Args: component_id: id of the ev charger to get data for. Returns: A channel receiver that provides realtime ev charger data. \"\"\"","title":"ev_charger_data()"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client._client.MicrogridApiClient.inverter_data","text":"Return a channel receiver that provides an InverterData stream. If only the latest value is required, the Receiver returned by this method can be converted into a Peekable with the into_peekable method on the Receiver. PARAMETER DESCRIPTION component_id id of the inverter to get data for. TYPE: int RETURNS DESCRIPTION Receiver [ InverterData ] A channel receiver that provides realtime inverter data. Source code in frequenz/sdk/microgrid/client/_client.py 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 @abstractmethod async def inverter_data ( self , component_id : int , ) -> Receiver [ InverterData ]: \"\"\"Return a channel receiver that provides an `InverterData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Args: component_id: id of the inverter to get data for. Returns: A channel receiver that provides realtime inverter data. \"\"\"","title":"inverter_data()"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client._client.MicrogridApiClient.meter_data","text":"Return a channel receiver that provides a MeterData stream. If only the latest value is required, the Receiver returned by this method can be converted into a Peekable with the into_peekable method on the Receiver. PARAMETER DESCRIPTION component_id id of the meter to get data for. TYPE: int RETURNS DESCRIPTION Receiver [ MeterData ] A channel receiver that provides realtime meter data. Source code in frequenz/sdk/microgrid/client/_client.py 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 @abstractmethod async def meter_data ( self , component_id : int , ) -> Receiver [ MeterData ]: \"\"\"Return a channel receiver that provides a `MeterData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Args: component_id: id of the meter to get data for. Returns: A channel receiver that provides realtime meter data. \"\"\"","title":"meter_data()"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client._client.MicrogridApiClient.set_bounds","text":"Send SetBoundsParam s received from a channel to nitrogen. PARAMETER DESCRIPTION component_id ID of the component to set bounds for. TYPE: int lower Lower bound to be set for the component. TYPE: float upper Upper bound to be set for the component. TYPE: float Source code in frequenz/sdk/microgrid/client/_client.py 165 166 167 168 169 170 171 172 173 @abstractmethod async def set_bounds ( self , component_id : int , lower : float , upper : float ) -> None : \"\"\"Send `SetBoundsParam`s received from a channel to nitrogen. Args: component_id: ID of the component to set bounds for. lower: Lower bound to be set for the component. upper: Upper bound to be set for the component. \"\"\"","title":"set_bounds()"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client._client.MicrogridApiClient.set_power","text":"Send request to the Microgrid to set power for component. If power > 0, then component will be charged with this power. If power < 0, then component will be discharged with this power. If power == 0, then stop charging or discharging component. PARAMETER DESCRIPTION component_id id of the component to set power. TYPE: int power_w power to set for the component. TYPE: int RETURNS DESCRIPTION Empty Empty response. Source code in frequenz/sdk/microgrid/client/_client.py 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 @abstractmethod async def set_power ( self , component_id : int , power_w : int ) -> Empty : \"\"\"Send request to the Microgrid to set power for component. If power > 0, then component will be charged with this power. If power < 0, then component will be discharged with this power. If power == 0, then stop charging or discharging component. Args: component_id: id of the component to set power. power_w: power to set for the component. Returns: Empty response. \"\"\"","title":"set_power()"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client.MicrogridGrpcClient","text":"Bases: MicrogridApiClient Microgrid API client implementation using gRPC as the underlying protocol. Source code in frequenz/sdk/microgrid/client/_client.py 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 class MicrogridGrpcClient ( MicrogridApiClient ): \"\"\"Microgrid API client implementation using gRPC as the underlying protocol.\"\"\" def __init__ ( self , grpc_channel : grpc . aio . Channel , target : str , retry_spec : RetryStrategy = LinearBackoff (), ) -> None : \"\"\"Initialize the class instance. Args: grpc_channel: asyncio-supporting gRPC channel target: server (host:port) to be used for asyncio-supporting gRPC channel that the client should use to contact the API retry_spec: Specs on how to retry if the connection to a streaming method gets lost. \"\"\" self . target = target self . api = MicrogridStub ( grpc_channel ) self . _component_streams : Dict [ int , Broadcast [ Any ]] = {} self . _retry_spec = retry_spec async def components ( self ) -> Iterable [ Component ]: \"\"\"Fetch all the components present in the microgrid. Returns: Iterator whose elements are all the components in the microgrid. Raises: AioRpcError: if connection to Microgrid API cannot be established or when the api call exceeded timeout \"\"\" try : component_list = await self . api . ListComponents ( microgrid_pb . ComponentFilter (), timeout = DEFAULT_GRPC_CALL_TIMEOUT , ) except grpc . aio . AioRpcError as err : msg = f \"Failed to list components. Microgrid API: { self . target } . Err: { err . details () } \" raise grpc . aio . AioRpcError ( code = err . code (), initial_metadata = err . initial_metadata (), trailing_metadata = err . trailing_metadata (), details = msg , debug_error_string = err . debug_error_string (), ) components_only = filter ( lambda c : c . category not in ( microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_SENSOR , microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_LOAD , ), component_list . components , ) result : Iterable [ Component ] = map ( lambda c : Component ( c . id , _component_category_from_protobuf ( c . category )), components_only , ) return result async def connections ( self , starts : Optional [ Set [ int ]] = None , ends : Optional [ Set [ int ]] = None , ) -> Iterable [ Connection ]: \"\"\"Fetch the connections between components in the microgrid. Args: starts: if set and non-empty, only include connections whose start value matches one of the provided component IDs ends: if set and non-empty, only include connections whose end value matches one of the provided component IDs Returns: Microgrid connections matching the provided start and end filters. Raises: AioRpcError: if connection to Microgrid API cannot be established or when the api call exceeded timeout \"\"\" connection_filter = microgrid_pb . ConnectionFilter ( starts = starts , ends = ends ) try : valid_components , all_connections = await asyncio . gather ( self . components (), self . api . ListConnections ( connection_filter , timeout = DEFAULT_GRPC_CALL_TIMEOUT ), ) except grpc . aio . AioRpcError as err : msg = f \"Failed to list connections. Microgrid API: { self . target } . Err: { err . details () } \" raise grpc . aio . AioRpcError ( code = err . code (), initial_metadata = err . initial_metadata (), trailing_metadata = err . trailing_metadata (), details = msg , debug_error_string = err . debug_error_string (), ) # Filter out the components filtered in `components` method. # id=0 is an exception indicating grid component. valid_ids = { c . component_id for c in valid_components } valid_ids . add ( 0 ) connections = filter ( lambda c : ( c . start in valid_ids and c . end in valid_ids ), all_connections . connections , ) result : Iterable [ Connection ] = map ( lambda c : Connection ( c . start , c . end ), connections ) return result async def _component_data_task ( self , component_id : int , transform : Callable [[ microgrid_pb . ComponentData ], _GenericComponentData ], sender : Sender [ _GenericComponentData ], ) -> None : \"\"\"Read data from the microgrid API and send to a channel. Args: component_id: id of the component to get data for. transform: A method for transforming raw component data into the desired output type. sender: A channel sender, to send the component data to. Raises: AioRpcError: if connection to Microgrid API cannot be established \"\"\" retry_spec : RetryStrategy = self . _retry_spec . copy () while True : logger . debug ( \"Making call to `GetComponentData`, for component_id= %d \" , component_id ) try : call = self . api . GetComponentData ( microgrid_pb . ComponentIdParam ( id = component_id ), ) async for msg in call : await sender . send ( transform ( msg )) except grpc . aio . AioRpcError as err : api_details = f \"Microgrid API: { self . target } .\" logger . exception ( \"`GetComponentData`, for component_id= %d : exception: %s api: %s \" , component_id , err , api_details , ) if interval := retry_spec . next_interval (): logger . warning ( \"`GetComponentData`, for component_id= %d : connection ended, \" \"retrying %s in %0.3f seconds.\" , component_id , retry_spec . get_progress (), interval , ) await asyncio . sleep ( interval ) # type: ignore else : logger . warning ( \"`GetComponentData`, for component_id= %d : connection ended, \" \"retry limit exceeded %s .\" , component_id , retry_spec . get_progress (), ) break def _get_component_data_channel ( self , component_id : int , transform : Callable [[ microgrid_pb . ComponentData ], _GenericComponentData ], ) -> Broadcast [ _GenericComponentData ]: \"\"\"Return the broadcast channel for a given component_id. If a broadcast channel for the given component_id doesn't exist, create a new channel and a task for reading data from the microgrid api and sending them to the channel. Args: component_id: id of the component to get data for. transform: A method for transforming raw component data into the desired output type. Returns: The channel for the given component_id. \"\"\" if component_id in self . _component_streams : return self . _component_streams [ component_id ] task_name = f \"raw-component-data- { component_id } \" chan = Broadcast [ _GenericComponentData ]( task_name ) self . _component_streams [ component_id ] = chan asyncio . create_task ( self . _component_data_task ( component_id , transform , chan . new_sender (), ), name = task_name , ) return chan async def _expect_category ( self , component_id : int , expected_category : ComponentCategory , ) -> None : \"\"\"Check if the given component_id is of the expected type. Raises: ValueError: if the given id is unknown or has a different type. Args: component_id: Component id to check. expected_category: Component category that the given id is expected to have. \"\"\" try : comp = next ( comp for comp in await self . components () if comp . component_id == component_id ) except StopIteration as exc : raise ValueError ( f \"Unable to find component with id { component_id } \" ) from exc if comp . category != expected_category : raise ValueError ( f \"Component id { component_id } is a { comp . category } \" f \", not a { expected_category } .\" ) async def meter_data ( self , component_id : int , ) -> Receiver [ MeterData ]: \"\"\"Return a channel receiver that provides a `MeterData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Raises: ValueError: if the given id is unknown or has a different type. Args: component_id: id of the meter to get data for. Returns: A channel receiver that provides realtime meter data. \"\"\" await self . _expect_category ( component_id , ComponentCategory . METER , ) return self . _get_component_data_channel ( component_id , MeterData . from_proto , ) . new_receiver () async def battery_data ( self , component_id : int , ) -> Receiver [ BatteryData ]: \"\"\"Return a channel receiver that provides a `BatteryData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Raises: ValueError: if the given id is unknown or has a different type. Args: component_id: id of the battery to get data for. Returns: A channel receiver that provides realtime battery data. \"\"\" await self . _expect_category ( component_id , ComponentCategory . BATTERY , ) return self . _get_component_data_channel ( component_id , BatteryData . from_proto , ) . new_receiver () async def inverter_data ( self , component_id : int , ) -> Receiver [ InverterData ]: \"\"\"Return a channel receiver that provides an `InverterData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Raises: ValueError: if the given id is unknown or has a different type. Args: component_id: id of the inverter to get data for. Returns: A channel receiver that provides realtime inverter data. \"\"\" await self . _expect_category ( component_id , ComponentCategory . INVERTER , ) return self . _get_component_data_channel ( component_id , InverterData . from_proto , ) . new_receiver () async def ev_charger_data ( self , component_id : int , ) -> Receiver [ EVChargerData ]: \"\"\"Return a channel receiver that provides an `EvChargeData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Raises: ValueError: if the given id is unknown or has a different type. Args: component_id: id of the ev charger to get data for. Returns: A channel receiver that provides realtime ev charger data. \"\"\" await self . _expect_category ( component_id , ComponentCategory . EV_CHARGER , ) return self . _get_component_data_channel ( component_id , EVChargerData . from_proto , ) . new_receiver () async def set_power ( self , component_id : int , power_w : int ) -> Empty : \"\"\"Send request to the Microgrid to set power for component. If power > 0, then component will be charged with this power. If power < 0, then component will be discharged with this power. If power == 0, then stop charging or discharging component. Args: component_id: id of the component to set power. power_w: power to set for the component. Returns: Empty response. Raises: AioRpcError: if connection to Microgrid API cannot be established or when the api call exceeded timeout \"\"\" try : if power_w >= 0 : result : Empty = await self . api . Charge ( microgrid_pb . PowerLevelParam ( component_id = component_id , power_w = power_w ), timeout = DEFAULT_GRPC_CALL_TIMEOUT , ) else : power_w *= - 1 result = await self . api . Discharge ( microgrid_pb . PowerLevelParam ( component_id = component_id , power_w = power_w ), timeout = DEFAULT_GRPC_CALL_TIMEOUT , ) except grpc . aio . AioRpcError as err : msg = f \"Failed to set power. Microgrid API: { self . target } . Err: { err . details () } \" raise grpc . aio . AioRpcError ( code = err . code (), initial_metadata = err . initial_metadata (), trailing_metadata = err . trailing_metadata (), details = msg , debug_error_string = err . debug_error_string (), ) return result async def set_bounds ( self , component_id : int , lower : float , upper : float , ) -> None : \"\"\"Send `SetBoundsParam`s received from a channel to nitrogen. Args: component_id: ID of the component to set bounds for. lower: Lower bound to be set for the component. upper: Upper bound to be set for the component. Raises: ValueError: when upper bound is less than 0, or when lower bound is greater than 0. grpc.aio.AioRpcError: if connection to Microgrid API cannot be established or when the api call exceeded timeout \"\"\" api_details = f \"Microgrid API: { self . target } .\" if upper < 0 : raise ValueError ( f \"Upper bound { upper } must be greater than or equal to 0.\" ) if lower > 0 : raise ValueError ( f \"Lower bound { upper } must be less than or equal to 0.\" ) set_bounds_call = self . api . SetBounds ( timeout = DEFAULT_GRPC_CALL_TIMEOUT ) try : await set_bounds_call . write ( microgrid_pb . SetBoundsParam ( component_id = component_id , # pylint: disable=no-member,line-too-long target_metric = microgrid_pb . SetBoundsParam . TargetMetric . TARGET_METRIC_POWER_ACTIVE , bounds = common_pb . Bounds ( lower = lower , upper = upper ), ), ) except grpc . aio . AioRpcError as err : logger . error ( \"set_bounds write failed: %s , for message: %s , api: %s . Err: %s \" , err , next , api_details , err . details (), ) raise","title":"MicrogridGrpcClient"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client.MicrogridGrpcClient-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client._client.MicrogridGrpcClient.__init__","text":"Initialize the class instance. PARAMETER DESCRIPTION grpc_channel asyncio-supporting gRPC channel TYPE: grpc . aio . Channel target server (host:port) to be used for asyncio-supporting gRPC channel that the client should use to contact the API TYPE: str retry_spec Specs on how to retry if the connection to a streaming method gets lost. TYPE: RetryStrategy DEFAULT: LinearBackoff() Source code in frequenz/sdk/microgrid/client/_client.py 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 def __init__ ( self , grpc_channel : grpc . aio . Channel , target : str , retry_spec : RetryStrategy = LinearBackoff (), ) -> None : \"\"\"Initialize the class instance. Args: grpc_channel: asyncio-supporting gRPC channel target: server (host:port) to be used for asyncio-supporting gRPC channel that the client should use to contact the API retry_spec: Specs on how to retry if the connection to a streaming method gets lost. \"\"\" self . target = target self . api = MicrogridStub ( grpc_channel ) self . _component_streams : Dict [ int , Broadcast [ Any ]] = {} self . _retry_spec = retry_spec","title":"__init__()"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client._client.MicrogridGrpcClient.battery_data","text":"Return a channel receiver that provides a BatteryData stream. If only the latest value is required, the Receiver returned by this method can be converted into a Peekable with the into_peekable method on the Receiver. RAISES DESCRIPTION ValueError if the given id is unknown or has a different type. PARAMETER DESCRIPTION component_id id of the battery to get data for. TYPE: int RETURNS DESCRIPTION Receiver [ BatteryData ] A channel receiver that provides realtime battery data. Source code in frequenz/sdk/microgrid/client/_client.py 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 async def battery_data ( self , component_id : int , ) -> Receiver [ BatteryData ]: \"\"\"Return a channel receiver that provides a `BatteryData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Raises: ValueError: if the given id is unknown or has a different type. Args: component_id: id of the battery to get data for. Returns: A channel receiver that provides realtime battery data. \"\"\" await self . _expect_category ( component_id , ComponentCategory . BATTERY , ) return self . _get_component_data_channel ( component_id , BatteryData . from_proto , ) . new_receiver ()","title":"battery_data()"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client._client.MicrogridGrpcClient.components","text":"Fetch all the components present in the microgrid. RETURNS DESCRIPTION Iterable [ Component ] Iterator whose elements are all the components in the microgrid. RAISES DESCRIPTION AioRpcError if connection to Microgrid API cannot be established or when the api call exceeded timeout Source code in frequenz/sdk/microgrid/client/_client.py 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 async def components ( self ) -> Iterable [ Component ]: \"\"\"Fetch all the components present in the microgrid. Returns: Iterator whose elements are all the components in the microgrid. Raises: AioRpcError: if connection to Microgrid API cannot be established or when the api call exceeded timeout \"\"\" try : component_list = await self . api . ListComponents ( microgrid_pb . ComponentFilter (), timeout = DEFAULT_GRPC_CALL_TIMEOUT , ) except grpc . aio . AioRpcError as err : msg = f \"Failed to list components. Microgrid API: { self . target } . Err: { err . details () } \" raise grpc . aio . AioRpcError ( code = err . code (), initial_metadata = err . initial_metadata (), trailing_metadata = err . trailing_metadata (), details = msg , debug_error_string = err . debug_error_string (), ) components_only = filter ( lambda c : c . category not in ( microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_SENSOR , microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_LOAD , ), component_list . components , ) result : Iterable [ Component ] = map ( lambda c : Component ( c . id , _component_category_from_protobuf ( c . category )), components_only , ) return result","title":"components()"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client._client.MicrogridGrpcClient.connections","text":"Fetch the connections between components in the microgrid. PARAMETER DESCRIPTION starts if set and non-empty, only include connections whose start value matches one of the provided component IDs TYPE: Optional [ Set [ int ]] DEFAULT: None ends if set and non-empty, only include connections whose end value matches one of the provided component IDs TYPE: Optional [ Set [ int ]] DEFAULT: None RETURNS DESCRIPTION Iterable [ Connection ] Microgrid connections matching the provided start and end filters. RAISES DESCRIPTION AioRpcError if connection to Microgrid API cannot be established or when the api call exceeded timeout Source code in frequenz/sdk/microgrid/client/_client.py 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 async def connections ( self , starts : Optional [ Set [ int ]] = None , ends : Optional [ Set [ int ]] = None , ) -> Iterable [ Connection ]: \"\"\"Fetch the connections between components in the microgrid. Args: starts: if set and non-empty, only include connections whose start value matches one of the provided component IDs ends: if set and non-empty, only include connections whose end value matches one of the provided component IDs Returns: Microgrid connections matching the provided start and end filters. Raises: AioRpcError: if connection to Microgrid API cannot be established or when the api call exceeded timeout \"\"\" connection_filter = microgrid_pb . ConnectionFilter ( starts = starts , ends = ends ) try : valid_components , all_connections = await asyncio . gather ( self . components (), self . api . ListConnections ( connection_filter , timeout = DEFAULT_GRPC_CALL_TIMEOUT ), ) except grpc . aio . AioRpcError as err : msg = f \"Failed to list connections. Microgrid API: { self . target } . Err: { err . details () } \" raise grpc . aio . AioRpcError ( code = err . code (), initial_metadata = err . initial_metadata (), trailing_metadata = err . trailing_metadata (), details = msg , debug_error_string = err . debug_error_string (), ) # Filter out the components filtered in `components` method. # id=0 is an exception indicating grid component. valid_ids = { c . component_id for c in valid_components } valid_ids . add ( 0 ) connections = filter ( lambda c : ( c . start in valid_ids and c . end in valid_ids ), all_connections . connections , ) result : Iterable [ Connection ] = map ( lambda c : Connection ( c . start , c . end ), connections ) return result","title":"connections()"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client._client.MicrogridGrpcClient.ev_charger_data","text":"Return a channel receiver that provides an EvChargeData stream. If only the latest value is required, the Receiver returned by this method can be converted into a Peekable with the into_peekable method on the Receiver. RAISES DESCRIPTION ValueError if the given id is unknown or has a different type. PARAMETER DESCRIPTION component_id id of the ev charger to get data for. TYPE: int RETURNS DESCRIPTION Receiver [ EVChargerData ] A channel receiver that provides realtime ev charger data. Source code in frequenz/sdk/microgrid/client/_client.py 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 async def ev_charger_data ( self , component_id : int , ) -> Receiver [ EVChargerData ]: \"\"\"Return a channel receiver that provides an `EvChargeData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Raises: ValueError: if the given id is unknown or has a different type. Args: component_id: id of the ev charger to get data for. Returns: A channel receiver that provides realtime ev charger data. \"\"\" await self . _expect_category ( component_id , ComponentCategory . EV_CHARGER , ) return self . _get_component_data_channel ( component_id , EVChargerData . from_proto , ) . new_receiver ()","title":"ev_charger_data()"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client._client.MicrogridGrpcClient.inverter_data","text":"Return a channel receiver that provides an InverterData stream. If only the latest value is required, the Receiver returned by this method can be converted into a Peekable with the into_peekable method on the Receiver. RAISES DESCRIPTION ValueError if the given id is unknown or has a different type. PARAMETER DESCRIPTION component_id id of the inverter to get data for. TYPE: int RETURNS DESCRIPTION Receiver [ InverterData ] A channel receiver that provides realtime inverter data. Source code in frequenz/sdk/microgrid/client/_client.py 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 async def inverter_data ( self , component_id : int , ) -> Receiver [ InverterData ]: \"\"\"Return a channel receiver that provides an `InverterData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Raises: ValueError: if the given id is unknown or has a different type. Args: component_id: id of the inverter to get data for. Returns: A channel receiver that provides realtime inverter data. \"\"\" await self . _expect_category ( component_id , ComponentCategory . INVERTER , ) return self . _get_component_data_channel ( component_id , InverterData . from_proto , ) . new_receiver ()","title":"inverter_data()"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client._client.MicrogridGrpcClient.meter_data","text":"Return a channel receiver that provides a MeterData stream. If only the latest value is required, the Receiver returned by this method can be converted into a Peekable with the into_peekable method on the Receiver. RAISES DESCRIPTION ValueError if the given id is unknown or has a different type. PARAMETER DESCRIPTION component_id id of the meter to get data for. TYPE: int RETURNS DESCRIPTION Receiver [ MeterData ] A channel receiver that provides realtime meter data. Source code in frequenz/sdk/microgrid/client/_client.py 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 async def meter_data ( self , component_id : int , ) -> Receiver [ MeterData ]: \"\"\"Return a channel receiver that provides a `MeterData` stream. If only the latest value is required, the `Receiver` returned by this method can be converted into a `Peekable` with the `into_peekable` method on the `Receiver.` Raises: ValueError: if the given id is unknown or has a different type. Args: component_id: id of the meter to get data for. Returns: A channel receiver that provides realtime meter data. \"\"\" await self . _expect_category ( component_id , ComponentCategory . METER , ) return self . _get_component_data_channel ( component_id , MeterData . from_proto , ) . new_receiver ()","title":"meter_data()"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client._client.MicrogridGrpcClient.set_bounds","text":"Send SetBoundsParam s received from a channel to nitrogen. PARAMETER DESCRIPTION component_id ID of the component to set bounds for. TYPE: int lower Lower bound to be set for the component. TYPE: float upper Upper bound to be set for the component. TYPE: float RAISES DESCRIPTION ValueError when upper bound is less than 0, or when lower bound is greater than 0. grpc . aio . AioRpcError if connection to Microgrid API cannot be established or when the api call exceeded timeout Source code in frequenz/sdk/microgrid/client/_client.py 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 async def set_bounds ( self , component_id : int , lower : float , upper : float , ) -> None : \"\"\"Send `SetBoundsParam`s received from a channel to nitrogen. Args: component_id: ID of the component to set bounds for. lower: Lower bound to be set for the component. upper: Upper bound to be set for the component. Raises: ValueError: when upper bound is less than 0, or when lower bound is greater than 0. grpc.aio.AioRpcError: if connection to Microgrid API cannot be established or when the api call exceeded timeout \"\"\" api_details = f \"Microgrid API: { self . target } .\" if upper < 0 : raise ValueError ( f \"Upper bound { upper } must be greater than or equal to 0.\" ) if lower > 0 : raise ValueError ( f \"Lower bound { upper } must be less than or equal to 0.\" ) set_bounds_call = self . api . SetBounds ( timeout = DEFAULT_GRPC_CALL_TIMEOUT ) try : await set_bounds_call . write ( microgrid_pb . SetBoundsParam ( component_id = component_id , # pylint: disable=no-member,line-too-long target_metric = microgrid_pb . SetBoundsParam . TargetMetric . TARGET_METRIC_POWER_ACTIVE , bounds = common_pb . Bounds ( lower = lower , upper = upper ), ), ) except grpc . aio . AioRpcError as err : logger . error ( \"set_bounds write failed: %s , for message: %s , api: %s . Err: %s \" , err , next , api_details , err . details (), ) raise","title":"set_bounds()"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client._client.MicrogridGrpcClient.set_power","text":"Send request to the Microgrid to set power for component. If power > 0, then component will be charged with this power. If power < 0, then component will be discharged with this power. If power == 0, then stop charging or discharging component. PARAMETER DESCRIPTION component_id id of the component to set power. TYPE: int power_w power to set for the component. TYPE: int RETURNS DESCRIPTION Empty Empty response. RAISES DESCRIPTION AioRpcError if connection to Microgrid API cannot be established or when the api call exceeded timeout Source code in frequenz/sdk/microgrid/client/_client.py 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 async def set_power ( self , component_id : int , power_w : int ) -> Empty : \"\"\"Send request to the Microgrid to set power for component. If power > 0, then component will be charged with this power. If power < 0, then component will be discharged with this power. If power == 0, then stop charging or discharging component. Args: component_id: id of the component to set power. power_w: power to set for the component. Returns: Empty response. Raises: AioRpcError: if connection to Microgrid API cannot be established or when the api call exceeded timeout \"\"\" try : if power_w >= 0 : result : Empty = await self . api . Charge ( microgrid_pb . PowerLevelParam ( component_id = component_id , power_w = power_w ), timeout = DEFAULT_GRPC_CALL_TIMEOUT , ) else : power_w *= - 1 result = await self . api . Discharge ( microgrid_pb . PowerLevelParam ( component_id = component_id , power_w = power_w ), timeout = DEFAULT_GRPC_CALL_TIMEOUT , ) except grpc . aio . AioRpcError as err : msg = f \"Failed to set power. Microgrid API: { self . target } . Err: { err . details () } \" raise grpc . aio . AioRpcError ( code = err . code (), initial_metadata = err . initial_metadata (), trailing_metadata = err . trailing_metadata (), details = msg , debug_error_string = err . debug_error_string (), ) return result","title":"set_power()"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client.RetryStrategy","text":"Bases: ABC Interface for implementing retry strategies. Source code in frequenz/sdk/microgrid/client/_retry.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 class RetryStrategy ( ABC ): \"\"\"Interface for implementing retry strategies.\"\"\" _limit : Optional [ int ] _count : int @abstractmethod def next_interval ( self ) -> Optional [ float ]: \"\"\"Return the time to wait before the next retry. Returns `None` if the retry limit has been reached, and no more retries are possible. Returns: Time until next retry when below retry limit, and None otherwise. \"\"\" def get_progress ( self ) -> str : \"\"\"Return a string denoting the retry progress. Returns: String denoting retry progress in the form \"(count/limit)\" \"\"\" if self . _limit is None : return f \"( { self . _count } /\u221e)\" return f \"( { self . _count } / { self . _limit } )\" def reset ( self ) -> None : \"\"\"Reset the retry counter. To be called as soon as a connection is successful. \"\"\" self . _count = 0 def copy ( self ) -> RetryStrategy : \"\"\"Create a new instance of `self`. Returns: A deepcopy of `self`. \"\"\" ret = deepcopy ( self ) ret . reset () return ret def __iter__ ( self ) -> Iterator [ float ]: \"\"\"Return an iterator over the retry intervals. Yields: Next retry interval in seconds. \"\"\" while True : interval = self . next_interval () if interval is None : break yield interval","title":"RetryStrategy"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client.RetryStrategy-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client._retry.RetryStrategy.__iter__","text":"Return an iterator over the retry intervals. YIELDS DESCRIPTION Iterator [ float ] Next retry interval in seconds. Source code in frequenz/sdk/microgrid/client/_retry.py 62 63 64 65 66 67 68 69 70 71 72 def __iter__ ( self ) -> Iterator [ float ]: \"\"\"Return an iterator over the retry intervals. Yields: Next retry interval in seconds. \"\"\" while True : interval = self . next_interval () if interval is None : break yield interval","title":"__iter__()"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client._retry.RetryStrategy.copy","text":"Create a new instance of self . RETURNS DESCRIPTION RetryStrategy A deepcopy of self . Source code in frequenz/sdk/microgrid/client/_retry.py 52 53 54 55 56 57 58 59 60 def copy ( self ) -> RetryStrategy : \"\"\"Create a new instance of `self`. Returns: A deepcopy of `self`. \"\"\" ret = deepcopy ( self ) ret . reset () return ret","title":"copy()"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client._retry.RetryStrategy.get_progress","text":"Return a string denoting the retry progress. RETURNS DESCRIPTION str String denoting retry progress in the form \"(count/limit)\" Source code in frequenz/sdk/microgrid/client/_retry.py 34 35 36 37 38 39 40 41 42 43 def get_progress ( self ) -> str : \"\"\"Return a string denoting the retry progress. Returns: String denoting retry progress in the form \"(count/limit)\" \"\"\" if self . _limit is None : return f \"( { self . _count } /\u221e)\" return f \"( { self . _count } / { self . _limit } )\"","title":"get_progress()"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client._retry.RetryStrategy.next_interval","text":"Return the time to wait before the next retry. Returns None if the retry limit has been reached, and no more retries are possible. RETURNS DESCRIPTION Optional [ float ] Time until next retry when below retry limit, and None otherwise. Source code in frequenz/sdk/microgrid/client/_retry.py 23 24 25 26 27 28 29 30 31 32 @abstractmethod def next_interval ( self ) -> Optional [ float ]: \"\"\"Return the time to wait before the next retry. Returns `None` if the retry limit has been reached, and no more retries are possible. Returns: Time until next retry when below retry limit, and None otherwise. \"\"\"","title":"next_interval()"},{"location":"reference/frequenz/sdk/microgrid/client/#frequenz.sdk.microgrid.client._retry.RetryStrategy.reset","text":"Reset the retry counter. To be called as soon as a connection is successful. Source code in frequenz/sdk/microgrid/client/_retry.py 45 46 47 48 49 50 def reset ( self ) -> None : \"\"\"Reset the retry counter. To be called as soon as a connection is successful. \"\"\" self . _count = 0","title":"reset()"},{"location":"reference/frequenz/sdk/microgrid/component/","text":"frequenz.sdk.microgrid.component \u00a4 Microgrid component abstractions. This package provides classes to operate con microgrid components. Classes \u00a4 frequenz.sdk.microgrid.component.BatteryData dataclass \u00a4 Bases: ComponentData A wrapper class for holding battery data. ATTRIBUTE DESCRIPTION soc battery's overall SoC in percent (%). TYPE: float soc_lower_bound the SoC below which discharge commands will be blocked by the system, in percent (%). TYPE: float soc_upper_bound the SoC above which charge commands will be blocked by the system, in percent (%). TYPE: float capacity the capacity of the battery in Wh (Watt-hour) TYPE: float power_lower_bound the maximum discharge power, in Watts, represented in the passive sign convention. This will be a negative number, or zero if no discharging is possible. TYPE: float power_upper_bound the maximum charge power, in Watts, represented in the passive sign convention. This will be a positive number, or zero if no charging is possible. TYPE: float temperature_max the maximum temperature of all the blocks in a battery, in Celcius (\u00b0C). TYPE: float Source code in frequenz/sdk/microgrid/component/_component_data.py 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 @dataclass ( frozen = True ) class BatteryData ( ComponentData ): \"\"\"A wrapper class for holding battery data. Attributes: soc: battery's overall SoC in percent (%). soc_lower_bound: the SoC below which discharge commands will be blocked by the system, in percent (%). soc_upper_bound: the SoC above which charge commands will be blocked by the system, in percent (%). capacity: the capacity of the battery in Wh (Watt-hour) power_lower_bound: the maximum discharge power, in Watts, represented in the passive sign convention. This will be a negative number, or zero if no discharging is possible. power_upper_bound: the maximum charge power, in Watts, represented in the passive sign convention. This will be a positive number, or zero if no charging is possible. temperature_max: the maximum temperature of all the blocks in a battery, in Celcius (\u00b0C). \"\"\" soc : float soc_lower_bound : float soc_upper_bound : float capacity : float power_lower_bound : float power_upper_bound : float temperature_max : float @classmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> BatteryData : \"\"\"Create BatteryData from a protobuf message. Args: raw: raw component data as decoded from the wire. Returns: Instance of BatteryData created from the protobuf message. \"\"\" battery_data = cls ( component_id = raw . id , timestamp = raw . ts . ToDatetime ( tzinfo = pytz . UTC ), soc = raw . battery . data . soc . avg , soc_lower_bound = raw . battery . data . soc . system_bounds . lower , soc_upper_bound = raw . battery . data . soc . system_bounds . upper , capacity = raw . battery . properties . capacity , power_lower_bound = raw . battery . data . dc . power . system_bounds . lower , power_upper_bound = raw . battery . data . dc . power . system_bounds . upper , temperature_max = raw . battery . data . temperature . max , ) battery_data . _set_raw ( raw = raw ) return battery_data Functions \u00a4 from_proto ( raw ) classmethod \u00a4 Create BatteryData from a protobuf message. PARAMETER DESCRIPTION raw raw component data as decoded from the wire. TYPE: microgrid_pb . ComponentData RETURNS DESCRIPTION BatteryData Instance of BatteryData created from the protobuf message. Source code in frequenz/sdk/microgrid/component/_component_data.py 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 @classmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> BatteryData : \"\"\"Create BatteryData from a protobuf message. Args: raw: raw component data as decoded from the wire. Returns: Instance of BatteryData created from the protobuf message. \"\"\" battery_data = cls ( component_id = raw . id , timestamp = raw . ts . ToDatetime ( tzinfo = pytz . UTC ), soc = raw . battery . data . soc . avg , soc_lower_bound = raw . battery . data . soc . system_bounds . lower , soc_upper_bound = raw . battery . data . soc . system_bounds . upper , capacity = raw . battery . properties . capacity , power_lower_bound = raw . battery . data . dc . power . system_bounds . lower , power_upper_bound = raw . battery . data . dc . power . system_bounds . upper , temperature_max = raw . battery . data . temperature . max , ) battery_data . _set_raw ( raw = raw ) return battery_data frequenz.sdk.microgrid.component.Component dataclass \u00a4 Metadata for a single microgrid component. Source code in frequenz/sdk/microgrid/component/_component.py 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 @dataclass ( frozen = True ) class Component : \"\"\"Metadata for a single microgrid component.\"\"\" component_id : int category : ComponentCategory def is_valid ( self ) -> bool : \"\"\"Check if this instance contains valid data. Returns: `True` if `id > 0` and `type` is a valid `ComponentCategory`, or if `id == 0` and `type` is `GRID`, `False` otherwise \"\"\" return ( self . component_id > 0 and any ( t == self . category for t in ComponentCategory ) ) or ( self . component_id == 0 and self . category == ComponentCategory . GRID ) Functions \u00a4 is_valid () \u00a4 Check if this instance contains valid data. RETURNS DESCRIPTION bool True if id > 0 and type is a valid ComponentCategory , or if id == 0 and type is GRID , False otherwise Source code in frequenz/sdk/microgrid/component/_component.py 66 67 68 69 70 71 72 73 74 75 def is_valid ( self ) -> bool : \"\"\"Check if this instance contains valid data. Returns: `True` if `id > 0` and `type` is a valid `ComponentCategory`, or if `id == 0` and `type` is `GRID`, `False` otherwise \"\"\" return ( self . component_id > 0 and any ( t == self . category for t in ComponentCategory ) ) or ( self . component_id == 0 and self . category == ComponentCategory . GRID ) frequenz.sdk.microgrid.component.ComponentCategory \u00a4 Bases: Enum Possible types of microgrid component. Source code in frequenz/sdk/microgrid/component/_component.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 class ComponentCategory ( Enum ): \"\"\"Possible types of microgrid component.\"\"\" NONE = microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_UNSPECIFIED GRID = microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_GRID JUNCTION = microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_JUNCTION METER = microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_METER INVERTER = microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_INVERTER BATTERY = microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_BATTERY EV_CHARGER = microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_EV_CHARGER LOAD = microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_LOAD # types not yet supported by the API but which can be inferred # from available graph info PV_ARRAY = 1000001 CHP = 1000002 # combined heat and power plant frequenz.sdk.microgrid.component.ComponentData dataclass \u00a4 Bases: ABC A private base class for strongly typed component data classes. ATTRIBUTE DESCRIPTION component_id the ID identifying this component in the microgrid TYPE: int timestamp the timestamp of when the data was measured. TYPE: datetime raw raw component data as decoded from the wire TYPE: Optional [ microgrid_pb . ComponentData ] Source code in frequenz/sdk/microgrid/component/_component_data.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 @dataclass ( frozen = True ) class ComponentData ( ABC ): \"\"\"A private base class for strongly typed component data classes. Attributes: component_id: the ID identifying this component in the microgrid timestamp: the timestamp of when the data was measured. raw: raw component data as decoded from the wire \"\"\" component_id : int timestamp : datetime # The `raw` attribute is excluded from the constructor as it can only be provided # when instantiating `ComponentData` using the `from_proto` method, which reads # data from a protobuf message. The whole protobuf message is stored as the `raw` # attribute. When `ComponentData` is not instantiated from a protobuf message, # i.e. using the constructor, `raw` will be set to `None`. raw : Optional [ microgrid_pb . ComponentData ] = field ( default = None , init = False ) def _set_raw ( self , raw : microgrid_pb . ComponentData ) -> None : \"\"\"Store raw protobuf message. It is preferred to keep the dataclasses immutable (frozen) and make the `raw` attribute read-only, which is why the approach of writing to `__dict__` was used, instead of mutating the `self.raw = raw` attribute directly. Args: raw: raw component data as decoded from the wire. \"\"\" self . __dict__ [ \"raw\" ] = raw @classmethod @abstractmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> ComponentData : \"\"\"Create ComponentData from a protobuf message. Args: raw: raw component data as decoded from the wire. \"\"\" Functions \u00a4 from_proto ( raw ) classmethod abstractmethod \u00a4 Create ComponentData from a protobuf message. PARAMETER DESCRIPTION raw raw component data as decoded from the wire. TYPE: microgrid_pb . ComponentData Source code in frequenz/sdk/microgrid/component/_component_data.py 49 50 51 52 53 54 55 56 @classmethod @abstractmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> ComponentData : \"\"\"Create ComponentData from a protobuf message. Args: raw: raw component data as decoded from the wire. \"\"\" frequenz.sdk.microgrid.component.ComponentMetricId \u00a4 Bases: Enum An enum representing the various metrics available in the microgrid. Source code in frequenz/sdk/microgrid/component/_component.py 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 class ComponentMetricId ( Enum ): \"\"\"An enum representing the various metrics available in the microgrid.\"\"\" ACTIVE_POWER = \"active_power\" CURRENT_PHASE_1 = \"current_phase_1\" CURRENT_PHASE_2 = \"current_phase_2\" CURRENT_PHASE_3 = \"current_phase_3\" VOLTAGE_PHASE_1 = \"voltage_phase_1\" VOLTAGE_PHASE_2 = \"voltage_phase_2\" VOLTAGE_PHASE_3 = \"voltage_phase_3\" SOC = \"soc\" SOC_LOWER_BOUND = \"soc_lower_bound\" SOC_UPPER_BOUND = \"soc_upper_bound\" CAPACITY = \"capacity\" POWER_LOWER_BOUND = \"power_lower_bound\" POWER_UPPER_BOUND = \"power_upper_bound\" ACTIVE_POWER_LOWER_BOUND = \"active_power_lower_bound\" ACTIVE_POWER_UPPER_BOUND = \"active_power_upper_bound\" frequenz.sdk.microgrid.component.EVChargerCableState \u00a4 Bases: Enum Cable states of an EV Charger. Source code in frequenz/sdk/microgrid/component/_component_states.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 class EVChargerCableState ( Enum ): \"\"\"Cable states of an EV Charger.\"\"\" UNSPECIFIED = ev_charger_pb . CableState . CABLE_STATE_UNSPECIFIED UNPLUGGED = ev_charger_pb . CableState . CABLE_STATE_UNPLUGGED CHARGING_STATION_PLUGGED = ( ev_charger_pb . CableState . CABLE_STATE_CHARGING_STATION_PLUGGED ) CHARGING_STATION_LOCKED = ( ev_charger_pb . CableState . CABLE_STATE_CHARGING_STATION_LOCKED ) EV_PLUGGED = ev_charger_pb . CableState . CABLE_STATE_EV_PLUGGED EV_LOCKED = ev_charger_pb . CableState . CABLE_STATE_EV_LOCKED @classmethod def from_pb ( cls , evc_state : ev_charger_pb . CableState . ValueType ) -> EVChargerCableState : \"\"\"Convert a protobuf CableState value to EVChargerCableState enum. Args: evc_state: protobuf cable state to convert. Returns: Enum value corresponding to the protobuf message. \"\"\" if not any ( t . value == evc_state for t in EVChargerCableState ): return cls . UNSPECIFIED return EVChargerCableState ( evc_state ) Functions \u00a4 from_pb ( evc_state ) classmethod \u00a4 Convert a protobuf CableState value to EVChargerCableState enum. PARAMETER DESCRIPTION evc_state protobuf cable state to convert. TYPE: ev_charger_pb . CableState . ValueType RETURNS DESCRIPTION EVChargerCableState Enum value corresponding to the protobuf message. Source code in frequenz/sdk/microgrid/component/_component_states.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 @classmethod def from_pb ( cls , evc_state : ev_charger_pb . CableState . ValueType ) -> EVChargerCableState : \"\"\"Convert a protobuf CableState value to EVChargerCableState enum. Args: evc_state: protobuf cable state to convert. Returns: Enum value corresponding to the protobuf message. \"\"\" if not any ( t . value == evc_state for t in EVChargerCableState ): return cls . UNSPECIFIED return EVChargerCableState ( evc_state ) frequenz.sdk.microgrid.component.EVChargerData dataclass \u00a4 Bases: ComponentData A wrapper class for holding ev_charger data. ATTRIBUTE DESCRIPTION active_power_consumption the 3-phase active power, in Watts, represented in the passive sign convention. +ve current means consumption, away from the grid. -ve current means supply into the grid. current_per_phase AC current in Amperes (A) for phase/line 1,2 and 3 respectively. +ve current means consumption, away from the grid. -ve current means supply into the grid. TYPE: Tuple [ float , float , float ] voltage_per_phase the AC voltage in Volts (V) between the line and the neutral wire for phase/line 1,2 and 3 respectively. TYPE: Tuple [ float , float , float ] cable_state the state of the ev charger's cable TYPE: EVChargerCableState Source code in frequenz/sdk/microgrid/component/_component_data.py 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 @dataclass ( frozen = True ) class EVChargerData ( ComponentData ): \"\"\"A wrapper class for holding ev_charger data. Attributes: active_power_consumption: the 3-phase active power, in Watts, represented in the passive sign convention. +ve current means consumption, away from the grid. -ve current means supply into the grid. current_per_phase: AC current in Amperes (A) for phase/line 1,2 and 3 respectively. +ve current means consumption, away from the grid. -ve current means supply into the grid. voltage_per_phase: the AC voltage in Volts (V) between the line and the neutral wire for phase/line 1,2 and 3 respectively. cable_state: the state of the ev charger's cable \"\"\" active_power : float current_per_phase : Tuple [ float , float , float ] voltage_per_phase : Tuple [ float , float , float ] cable_state : EVChargerCableState @classmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> EVChargerData : \"\"\"Create EVChargerData from a protobuf message. Args: raw: raw component data as decoded from the wire. Returns: Instance of EVChargerData created from the protobuf message. \"\"\" ev_charger_data = cls ( component_id = raw . id , timestamp = raw . ts . ToDatetime ( tzinfo = pytz . UTC ), active_power = raw . ev_charger . data . ac . power_active . value , current_per_phase = ( raw . ev_charger . data . ac . phase_1 . current . value , raw . ev_charger . data . ac . phase_2 . current . value , raw . ev_charger . data . ac . phase_3 . current . value , ), voltage_per_phase = ( raw . ev_charger . data . ac . phase_1 . voltage . value , raw . ev_charger . data . ac . phase_2 . voltage . value , raw . ev_charger . data . ac . phase_3 . voltage . value , ), cable_state = EVChargerCableState . from_pb ( raw . ev_charger . state . cable_state ), ) ev_charger_data . _set_raw ( raw = raw ) return ev_charger_data Functions \u00a4 from_proto ( raw ) classmethod \u00a4 Create EVChargerData from a protobuf message. PARAMETER DESCRIPTION raw raw component data as decoded from the wire. TYPE: microgrid_pb . ComponentData RETURNS DESCRIPTION EVChargerData Instance of EVChargerData created from the protobuf message. Source code in frequenz/sdk/microgrid/component/_component_data.py 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 @classmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> EVChargerData : \"\"\"Create EVChargerData from a protobuf message. Args: raw: raw component data as decoded from the wire. Returns: Instance of EVChargerData created from the protobuf message. \"\"\" ev_charger_data = cls ( component_id = raw . id , timestamp = raw . ts . ToDatetime ( tzinfo = pytz . UTC ), active_power = raw . ev_charger . data . ac . power_active . value , current_per_phase = ( raw . ev_charger . data . ac . phase_1 . current . value , raw . ev_charger . data . ac . phase_2 . current . value , raw . ev_charger . data . ac . phase_3 . current . value , ), voltage_per_phase = ( raw . ev_charger . data . ac . phase_1 . voltage . value , raw . ev_charger . data . ac . phase_2 . voltage . value , raw . ev_charger . data . ac . phase_3 . voltage . value , ), cable_state = EVChargerCableState . from_pb ( raw . ev_charger . state . cable_state ), ) ev_charger_data . _set_raw ( raw = raw ) return ev_charger_data frequenz.sdk.microgrid.component.InverterData dataclass \u00a4 Bases: ComponentData A wrapper class for holding inverter data. ATTRIBUTE DESCRIPTION active_power the 3-phase active power, in Watts, represented in the passive sign convention. +ve current means consumption, away from the grid. -ve current means supply into the grid. TYPE: float active_power_lower_bound the maximum discharge power, in Watts, represented in the passive sign convention. This will be a negative number, or zero if no discharging is possible. TYPE: float active_power_upper_bound the maximum charge power, in Watts, represented in the passive sign convention. This will be a positive number, or zero if no charging is possible. TYPE: float Source code in frequenz/sdk/microgrid/component/_component_data.py 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 @dataclass ( frozen = True ) class InverterData ( ComponentData ): \"\"\"A wrapper class for holding inverter data. Attributes: active_power: the 3-phase active power, in Watts, represented in the passive sign convention. +ve current means consumption, away from the grid. -ve current means supply into the grid. active_power_lower_bound: the maximum discharge power, in Watts, represented in the passive sign convention. This will be a negative number, or zero if no discharging is possible. active_power_upper_bound: the maximum charge power, in Watts, represented in the passive sign convention. This will be a positive number, or zero if no charging is possible. \"\"\" active_power : float active_power_lower_bound : float active_power_upper_bound : float @classmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> InverterData : \"\"\"Create InverterData from a protobuf message. Args: raw: raw component data as decoded from the wire. Returns: Instance of InverterData created from the protobuf message. \"\"\" inverter_data = cls ( component_id = raw . id , timestamp = raw . ts . ToDatetime ( tzinfo = pytz . UTC ), active_power = raw . inverter . data . ac . power_active . value , active_power_lower_bound = raw . inverter . data . ac . power_active . system_bounds . lower , active_power_upper_bound = raw . inverter . data . ac . power_active . system_bounds . upper , ) inverter_data . _set_raw ( raw = raw ) return inverter_data Functions \u00a4 from_proto ( raw ) classmethod \u00a4 Create InverterData from a protobuf message. PARAMETER DESCRIPTION raw raw component data as decoded from the wire. TYPE: microgrid_pb . ComponentData RETURNS DESCRIPTION InverterData Instance of InverterData created from the protobuf message. Source code in frequenz/sdk/microgrid/component/_component_data.py 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 @classmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> InverterData : \"\"\"Create InverterData from a protobuf message. Args: raw: raw component data as decoded from the wire. Returns: Instance of InverterData created from the protobuf message. \"\"\" inverter_data = cls ( component_id = raw . id , timestamp = raw . ts . ToDatetime ( tzinfo = pytz . UTC ), active_power = raw . inverter . data . ac . power_active . value , active_power_lower_bound = raw . inverter . data . ac . power_active . system_bounds . lower , active_power_upper_bound = raw . inverter . data . ac . power_active . system_bounds . upper , ) inverter_data . _set_raw ( raw = raw ) return inverter_data frequenz.sdk.microgrid.component.MeterData dataclass \u00a4 Bases: ComponentData A wrapper class for holding meter data. ATTRIBUTE DESCRIPTION active_power the 3-phase active power, in Watts, represented in the passive sign convention. +ve current means consumption, away from the grid. -ve current means supply into the grid. TYPE: float current_per_phase AC current in Amperes (A) for phase/line 1,2 and 3 respectively. +ve current means consumption, away from the grid. -ve current means supply into the grid. TYPE: Tuple [ float , float , float ] voltage_per_phase the AC voltage in Volts (V) between the line and the neutral wire for phase/line 1,2 and 3 respectively. TYPE: Tuple [ float , float , float ] frequency the AC power frequency in Hertz (Hz). TYPE: float Source code in frequenz/sdk/microgrid/component/_component_data.py 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 @dataclass ( frozen = True ) class MeterData ( ComponentData ): \"\"\"A wrapper class for holding meter data. Attributes: active_power: the 3-phase active power, in Watts, represented in the passive sign convention. +ve current means consumption, away from the grid. -ve current means supply into the grid. current_per_phase: AC current in Amperes (A) for phase/line 1,2 and 3 respectively. +ve current means consumption, away from the grid. -ve current means supply into the grid. voltage_per_phase: the AC voltage in Volts (V) between the line and the neutral wire for phase/line 1,2 and 3 respectively. frequency: the AC power frequency in Hertz (Hz). \"\"\" active_power : float current_per_phase : Tuple [ float , float , float ] voltage_per_phase : Tuple [ float , float , float ] frequency : float @classmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> MeterData : \"\"\"Create MeterData from a protobuf message. Args: raw: raw component data as decoded from the wire. Returns: Instance of MeterData created from the protobuf message. \"\"\" meter_data = cls ( component_id = raw . id , timestamp = raw . ts . ToDatetime ( tzinfo = pytz . UTC ), active_power = raw . meter . data . ac . power_active . value , current_per_phase = ( raw . meter . data . ac . phase_1 . current . value , raw . meter . data . ac . phase_2 . current . value , raw . meter . data . ac . phase_3 . current . value , ), voltage_per_phase = ( raw . meter . data . ac . phase_1 . voltage . value , raw . meter . data . ac . phase_2 . voltage . value , raw . meter . data . ac . phase_3 . voltage . value , ), frequency = raw . meter . data . ac . frequency . value , ) meter_data . _set_raw ( raw = raw ) return meter_data Functions \u00a4 from_proto ( raw ) classmethod \u00a4 Create MeterData from a protobuf message. PARAMETER DESCRIPTION raw raw component data as decoded from the wire. TYPE: microgrid_pb . ComponentData RETURNS DESCRIPTION MeterData Instance of MeterData created from the protobuf message. Source code in frequenz/sdk/microgrid/component/_component_data.py 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 @classmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> MeterData : \"\"\"Create MeterData from a protobuf message. Args: raw: raw component data as decoded from the wire. Returns: Instance of MeterData created from the protobuf message. \"\"\" meter_data = cls ( component_id = raw . id , timestamp = raw . ts . ToDatetime ( tzinfo = pytz . UTC ), active_power = raw . meter . data . ac . power_active . value , current_per_phase = ( raw . meter . data . ac . phase_1 . current . value , raw . meter . data . ac . phase_2 . current . value , raw . meter . data . ac . phase_3 . current . value , ), voltage_per_phase = ( raw . meter . data . ac . phase_1 . voltage . value , raw . meter . data . ac . phase_2 . voltage . value , raw . meter . data . ac . phase_3 . voltage . value , ), frequency = raw . meter . data . ac . frequency . value , ) meter_data . _set_raw ( raw = raw ) return meter_data","title":"component"},{"location":"reference/frequenz/sdk/microgrid/component/#frequenz.sdk.microgrid.component","text":"Microgrid component abstractions. This package provides classes to operate con microgrid components.","title":"component"},{"location":"reference/frequenz/sdk/microgrid/component/#frequenz.sdk.microgrid.component-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/microgrid/component/#frequenz.sdk.microgrid.component.BatteryData","text":"Bases: ComponentData A wrapper class for holding battery data. ATTRIBUTE DESCRIPTION soc battery's overall SoC in percent (%). TYPE: float soc_lower_bound the SoC below which discharge commands will be blocked by the system, in percent (%). TYPE: float soc_upper_bound the SoC above which charge commands will be blocked by the system, in percent (%). TYPE: float capacity the capacity of the battery in Wh (Watt-hour) TYPE: float power_lower_bound the maximum discharge power, in Watts, represented in the passive sign convention. This will be a negative number, or zero if no discharging is possible. TYPE: float power_upper_bound the maximum charge power, in Watts, represented in the passive sign convention. This will be a positive number, or zero if no charging is possible. TYPE: float temperature_max the maximum temperature of all the blocks in a battery, in Celcius (\u00b0C). TYPE: float Source code in frequenz/sdk/microgrid/component/_component_data.py 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 @dataclass ( frozen = True ) class BatteryData ( ComponentData ): \"\"\"A wrapper class for holding battery data. Attributes: soc: battery's overall SoC in percent (%). soc_lower_bound: the SoC below which discharge commands will be blocked by the system, in percent (%). soc_upper_bound: the SoC above which charge commands will be blocked by the system, in percent (%). capacity: the capacity of the battery in Wh (Watt-hour) power_lower_bound: the maximum discharge power, in Watts, represented in the passive sign convention. This will be a negative number, or zero if no discharging is possible. power_upper_bound: the maximum charge power, in Watts, represented in the passive sign convention. This will be a positive number, or zero if no charging is possible. temperature_max: the maximum temperature of all the blocks in a battery, in Celcius (\u00b0C). \"\"\" soc : float soc_lower_bound : float soc_upper_bound : float capacity : float power_lower_bound : float power_upper_bound : float temperature_max : float @classmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> BatteryData : \"\"\"Create BatteryData from a protobuf message. Args: raw: raw component data as decoded from the wire. Returns: Instance of BatteryData created from the protobuf message. \"\"\" battery_data = cls ( component_id = raw . id , timestamp = raw . ts . ToDatetime ( tzinfo = pytz . UTC ), soc = raw . battery . data . soc . avg , soc_lower_bound = raw . battery . data . soc . system_bounds . lower , soc_upper_bound = raw . battery . data . soc . system_bounds . upper , capacity = raw . battery . properties . capacity , power_lower_bound = raw . battery . data . dc . power . system_bounds . lower , power_upper_bound = raw . battery . data . dc . power . system_bounds . upper , temperature_max = raw . battery . data . temperature . max , ) battery_data . _set_raw ( raw = raw ) return battery_data","title":"BatteryData"},{"location":"reference/frequenz/sdk/microgrid/component/#frequenz.sdk.microgrid.component.BatteryData-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/microgrid/component/#frequenz.sdk.microgrid.component._component_data.BatteryData.from_proto","text":"Create BatteryData from a protobuf message. PARAMETER DESCRIPTION raw raw component data as decoded from the wire. TYPE: microgrid_pb . ComponentData RETURNS DESCRIPTION BatteryData Instance of BatteryData created from the protobuf message. Source code in frequenz/sdk/microgrid/component/_component_data.py 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 @classmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> BatteryData : \"\"\"Create BatteryData from a protobuf message. Args: raw: raw component data as decoded from the wire. Returns: Instance of BatteryData created from the protobuf message. \"\"\" battery_data = cls ( component_id = raw . id , timestamp = raw . ts . ToDatetime ( tzinfo = pytz . UTC ), soc = raw . battery . data . soc . avg , soc_lower_bound = raw . battery . data . soc . system_bounds . lower , soc_upper_bound = raw . battery . data . soc . system_bounds . upper , capacity = raw . battery . properties . capacity , power_lower_bound = raw . battery . data . dc . power . system_bounds . lower , power_upper_bound = raw . battery . data . dc . power . system_bounds . upper , temperature_max = raw . battery . data . temperature . max , ) battery_data . _set_raw ( raw = raw ) return battery_data","title":"from_proto()"},{"location":"reference/frequenz/sdk/microgrid/component/#frequenz.sdk.microgrid.component.Component","text":"Metadata for a single microgrid component. Source code in frequenz/sdk/microgrid/component/_component.py 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 @dataclass ( frozen = True ) class Component : \"\"\"Metadata for a single microgrid component.\"\"\" component_id : int category : ComponentCategory def is_valid ( self ) -> bool : \"\"\"Check if this instance contains valid data. Returns: `True` if `id > 0` and `type` is a valid `ComponentCategory`, or if `id == 0` and `type` is `GRID`, `False` otherwise \"\"\" return ( self . component_id > 0 and any ( t == self . category for t in ComponentCategory ) ) or ( self . component_id == 0 and self . category == ComponentCategory . GRID )","title":"Component"},{"location":"reference/frequenz/sdk/microgrid/component/#frequenz.sdk.microgrid.component.Component-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/microgrid/component/#frequenz.sdk.microgrid.component._component.Component.is_valid","text":"Check if this instance contains valid data. RETURNS DESCRIPTION bool True if id > 0 and type is a valid ComponentCategory , or if id == 0 and type is GRID , False otherwise Source code in frequenz/sdk/microgrid/component/_component.py 66 67 68 69 70 71 72 73 74 75 def is_valid ( self ) -> bool : \"\"\"Check if this instance contains valid data. Returns: `True` if `id > 0` and `type` is a valid `ComponentCategory`, or if `id == 0` and `type` is `GRID`, `False` otherwise \"\"\" return ( self . component_id > 0 and any ( t == self . category for t in ComponentCategory ) ) or ( self . component_id == 0 and self . category == ComponentCategory . GRID )","title":"is_valid()"},{"location":"reference/frequenz/sdk/microgrid/component/#frequenz.sdk.microgrid.component.ComponentCategory","text":"Bases: Enum Possible types of microgrid component. Source code in frequenz/sdk/microgrid/component/_component.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 class ComponentCategory ( Enum ): \"\"\"Possible types of microgrid component.\"\"\" NONE = microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_UNSPECIFIED GRID = microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_GRID JUNCTION = microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_JUNCTION METER = microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_METER INVERTER = microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_INVERTER BATTERY = microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_BATTERY EV_CHARGER = microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_EV_CHARGER LOAD = microgrid_pb . ComponentCategory . COMPONENT_CATEGORY_LOAD # types not yet supported by the API but which can be inferred # from available graph info PV_ARRAY = 1000001 CHP = 1000002 # combined heat and power plant","title":"ComponentCategory"},{"location":"reference/frequenz/sdk/microgrid/component/#frequenz.sdk.microgrid.component.ComponentData","text":"Bases: ABC A private base class for strongly typed component data classes. ATTRIBUTE DESCRIPTION component_id the ID identifying this component in the microgrid TYPE: int timestamp the timestamp of when the data was measured. TYPE: datetime raw raw component data as decoded from the wire TYPE: Optional [ microgrid_pb . ComponentData ] Source code in frequenz/sdk/microgrid/component/_component_data.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 @dataclass ( frozen = True ) class ComponentData ( ABC ): \"\"\"A private base class for strongly typed component data classes. Attributes: component_id: the ID identifying this component in the microgrid timestamp: the timestamp of when the data was measured. raw: raw component data as decoded from the wire \"\"\" component_id : int timestamp : datetime # The `raw` attribute is excluded from the constructor as it can only be provided # when instantiating `ComponentData` using the `from_proto` method, which reads # data from a protobuf message. The whole protobuf message is stored as the `raw` # attribute. When `ComponentData` is not instantiated from a protobuf message, # i.e. using the constructor, `raw` will be set to `None`. raw : Optional [ microgrid_pb . ComponentData ] = field ( default = None , init = False ) def _set_raw ( self , raw : microgrid_pb . ComponentData ) -> None : \"\"\"Store raw protobuf message. It is preferred to keep the dataclasses immutable (frozen) and make the `raw` attribute read-only, which is why the approach of writing to `__dict__` was used, instead of mutating the `self.raw = raw` attribute directly. Args: raw: raw component data as decoded from the wire. \"\"\" self . __dict__ [ \"raw\" ] = raw @classmethod @abstractmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> ComponentData : \"\"\"Create ComponentData from a protobuf message. Args: raw: raw component data as decoded from the wire. \"\"\"","title":"ComponentData"},{"location":"reference/frequenz/sdk/microgrid/component/#frequenz.sdk.microgrid.component.ComponentData-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/microgrid/component/#frequenz.sdk.microgrid.component._component_data.ComponentData.from_proto","text":"Create ComponentData from a protobuf message. PARAMETER DESCRIPTION raw raw component data as decoded from the wire. TYPE: microgrid_pb . ComponentData Source code in frequenz/sdk/microgrid/component/_component_data.py 49 50 51 52 53 54 55 56 @classmethod @abstractmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> ComponentData : \"\"\"Create ComponentData from a protobuf message. Args: raw: raw component data as decoded from the wire. \"\"\"","title":"from_proto()"},{"location":"reference/frequenz/sdk/microgrid/component/#frequenz.sdk.microgrid.component.ComponentMetricId","text":"Bases: Enum An enum representing the various metrics available in the microgrid. Source code in frequenz/sdk/microgrid/component/_component.py 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 class ComponentMetricId ( Enum ): \"\"\"An enum representing the various metrics available in the microgrid.\"\"\" ACTIVE_POWER = \"active_power\" CURRENT_PHASE_1 = \"current_phase_1\" CURRENT_PHASE_2 = \"current_phase_2\" CURRENT_PHASE_3 = \"current_phase_3\" VOLTAGE_PHASE_1 = \"voltage_phase_1\" VOLTAGE_PHASE_2 = \"voltage_phase_2\" VOLTAGE_PHASE_3 = \"voltage_phase_3\" SOC = \"soc\" SOC_LOWER_BOUND = \"soc_lower_bound\" SOC_UPPER_BOUND = \"soc_upper_bound\" CAPACITY = \"capacity\" POWER_LOWER_BOUND = \"power_lower_bound\" POWER_UPPER_BOUND = \"power_upper_bound\" ACTIVE_POWER_LOWER_BOUND = \"active_power_lower_bound\" ACTIVE_POWER_UPPER_BOUND = \"active_power_upper_bound\"","title":"ComponentMetricId"},{"location":"reference/frequenz/sdk/microgrid/component/#frequenz.sdk.microgrid.component.EVChargerCableState","text":"Bases: Enum Cable states of an EV Charger. Source code in frequenz/sdk/microgrid/component/_component_states.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 class EVChargerCableState ( Enum ): \"\"\"Cable states of an EV Charger.\"\"\" UNSPECIFIED = ev_charger_pb . CableState . CABLE_STATE_UNSPECIFIED UNPLUGGED = ev_charger_pb . CableState . CABLE_STATE_UNPLUGGED CHARGING_STATION_PLUGGED = ( ev_charger_pb . CableState . CABLE_STATE_CHARGING_STATION_PLUGGED ) CHARGING_STATION_LOCKED = ( ev_charger_pb . CableState . CABLE_STATE_CHARGING_STATION_LOCKED ) EV_PLUGGED = ev_charger_pb . CableState . CABLE_STATE_EV_PLUGGED EV_LOCKED = ev_charger_pb . CableState . CABLE_STATE_EV_LOCKED @classmethod def from_pb ( cls , evc_state : ev_charger_pb . CableState . ValueType ) -> EVChargerCableState : \"\"\"Convert a protobuf CableState value to EVChargerCableState enum. Args: evc_state: protobuf cable state to convert. Returns: Enum value corresponding to the protobuf message. \"\"\" if not any ( t . value == evc_state for t in EVChargerCableState ): return cls . UNSPECIFIED return EVChargerCableState ( evc_state )","title":"EVChargerCableState"},{"location":"reference/frequenz/sdk/microgrid/component/#frequenz.sdk.microgrid.component.EVChargerCableState-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/microgrid/component/#frequenz.sdk.microgrid.component._component_states.EVChargerCableState.from_pb","text":"Convert a protobuf CableState value to EVChargerCableState enum. PARAMETER DESCRIPTION evc_state protobuf cable state to convert. TYPE: ev_charger_pb . CableState . ValueType RETURNS DESCRIPTION EVChargerCableState Enum value corresponding to the protobuf message. Source code in frequenz/sdk/microgrid/component/_component_states.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 @classmethod def from_pb ( cls , evc_state : ev_charger_pb . CableState . ValueType ) -> EVChargerCableState : \"\"\"Convert a protobuf CableState value to EVChargerCableState enum. Args: evc_state: protobuf cable state to convert. Returns: Enum value corresponding to the protobuf message. \"\"\" if not any ( t . value == evc_state for t in EVChargerCableState ): return cls . UNSPECIFIED return EVChargerCableState ( evc_state )","title":"from_pb()"},{"location":"reference/frequenz/sdk/microgrid/component/#frequenz.sdk.microgrid.component.EVChargerData","text":"Bases: ComponentData A wrapper class for holding ev_charger data. ATTRIBUTE DESCRIPTION active_power_consumption the 3-phase active power, in Watts, represented in the passive sign convention. +ve current means consumption, away from the grid. -ve current means supply into the grid. current_per_phase AC current in Amperes (A) for phase/line 1,2 and 3 respectively. +ve current means consumption, away from the grid. -ve current means supply into the grid. TYPE: Tuple [ float , float , float ] voltage_per_phase the AC voltage in Volts (V) between the line and the neutral wire for phase/line 1,2 and 3 respectively. TYPE: Tuple [ float , float , float ] cable_state the state of the ev charger's cable TYPE: EVChargerCableState Source code in frequenz/sdk/microgrid/component/_component_data.py 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 @dataclass ( frozen = True ) class EVChargerData ( ComponentData ): \"\"\"A wrapper class for holding ev_charger data. Attributes: active_power_consumption: the 3-phase active power, in Watts, represented in the passive sign convention. +ve current means consumption, away from the grid. -ve current means supply into the grid. current_per_phase: AC current in Amperes (A) for phase/line 1,2 and 3 respectively. +ve current means consumption, away from the grid. -ve current means supply into the grid. voltage_per_phase: the AC voltage in Volts (V) between the line and the neutral wire for phase/line 1,2 and 3 respectively. cable_state: the state of the ev charger's cable \"\"\" active_power : float current_per_phase : Tuple [ float , float , float ] voltage_per_phase : Tuple [ float , float , float ] cable_state : EVChargerCableState @classmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> EVChargerData : \"\"\"Create EVChargerData from a protobuf message. Args: raw: raw component data as decoded from the wire. Returns: Instance of EVChargerData created from the protobuf message. \"\"\" ev_charger_data = cls ( component_id = raw . id , timestamp = raw . ts . ToDatetime ( tzinfo = pytz . UTC ), active_power = raw . ev_charger . data . ac . power_active . value , current_per_phase = ( raw . ev_charger . data . ac . phase_1 . current . value , raw . ev_charger . data . ac . phase_2 . current . value , raw . ev_charger . data . ac . phase_3 . current . value , ), voltage_per_phase = ( raw . ev_charger . data . ac . phase_1 . voltage . value , raw . ev_charger . data . ac . phase_2 . voltage . value , raw . ev_charger . data . ac . phase_3 . voltage . value , ), cable_state = EVChargerCableState . from_pb ( raw . ev_charger . state . cable_state ), ) ev_charger_data . _set_raw ( raw = raw ) return ev_charger_data","title":"EVChargerData"},{"location":"reference/frequenz/sdk/microgrid/component/#frequenz.sdk.microgrid.component.EVChargerData-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/microgrid/component/#frequenz.sdk.microgrid.component._component_data.EVChargerData.from_proto","text":"Create EVChargerData from a protobuf message. PARAMETER DESCRIPTION raw raw component data as decoded from the wire. TYPE: microgrid_pb . ComponentData RETURNS DESCRIPTION EVChargerData Instance of EVChargerData created from the protobuf message. Source code in frequenz/sdk/microgrid/component/_component_data.py 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 @classmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> EVChargerData : \"\"\"Create EVChargerData from a protobuf message. Args: raw: raw component data as decoded from the wire. Returns: Instance of EVChargerData created from the protobuf message. \"\"\" ev_charger_data = cls ( component_id = raw . id , timestamp = raw . ts . ToDatetime ( tzinfo = pytz . UTC ), active_power = raw . ev_charger . data . ac . power_active . value , current_per_phase = ( raw . ev_charger . data . ac . phase_1 . current . value , raw . ev_charger . data . ac . phase_2 . current . value , raw . ev_charger . data . ac . phase_3 . current . value , ), voltage_per_phase = ( raw . ev_charger . data . ac . phase_1 . voltage . value , raw . ev_charger . data . ac . phase_2 . voltage . value , raw . ev_charger . data . ac . phase_3 . voltage . value , ), cable_state = EVChargerCableState . from_pb ( raw . ev_charger . state . cable_state ), ) ev_charger_data . _set_raw ( raw = raw ) return ev_charger_data","title":"from_proto()"},{"location":"reference/frequenz/sdk/microgrid/component/#frequenz.sdk.microgrid.component.InverterData","text":"Bases: ComponentData A wrapper class for holding inverter data. ATTRIBUTE DESCRIPTION active_power the 3-phase active power, in Watts, represented in the passive sign convention. +ve current means consumption, away from the grid. -ve current means supply into the grid. TYPE: float active_power_lower_bound the maximum discharge power, in Watts, represented in the passive sign convention. This will be a negative number, or zero if no discharging is possible. TYPE: float active_power_upper_bound the maximum charge power, in Watts, represented in the passive sign convention. This will be a positive number, or zero if no charging is possible. TYPE: float Source code in frequenz/sdk/microgrid/component/_component_data.py 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 @dataclass ( frozen = True ) class InverterData ( ComponentData ): \"\"\"A wrapper class for holding inverter data. Attributes: active_power: the 3-phase active power, in Watts, represented in the passive sign convention. +ve current means consumption, away from the grid. -ve current means supply into the grid. active_power_lower_bound: the maximum discharge power, in Watts, represented in the passive sign convention. This will be a negative number, or zero if no discharging is possible. active_power_upper_bound: the maximum charge power, in Watts, represented in the passive sign convention. This will be a positive number, or zero if no charging is possible. \"\"\" active_power : float active_power_lower_bound : float active_power_upper_bound : float @classmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> InverterData : \"\"\"Create InverterData from a protobuf message. Args: raw: raw component data as decoded from the wire. Returns: Instance of InverterData created from the protobuf message. \"\"\" inverter_data = cls ( component_id = raw . id , timestamp = raw . ts . ToDatetime ( tzinfo = pytz . UTC ), active_power = raw . inverter . data . ac . power_active . value , active_power_lower_bound = raw . inverter . data . ac . power_active . system_bounds . lower , active_power_upper_bound = raw . inverter . data . ac . power_active . system_bounds . upper , ) inverter_data . _set_raw ( raw = raw ) return inverter_data","title":"InverterData"},{"location":"reference/frequenz/sdk/microgrid/component/#frequenz.sdk.microgrid.component.InverterData-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/microgrid/component/#frequenz.sdk.microgrid.component._component_data.InverterData.from_proto","text":"Create InverterData from a protobuf message. PARAMETER DESCRIPTION raw raw component data as decoded from the wire. TYPE: microgrid_pb . ComponentData RETURNS DESCRIPTION InverterData Instance of InverterData created from the protobuf message. Source code in frequenz/sdk/microgrid/component/_component_data.py 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 @classmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> InverterData : \"\"\"Create InverterData from a protobuf message. Args: raw: raw component data as decoded from the wire. Returns: Instance of InverterData created from the protobuf message. \"\"\" inverter_data = cls ( component_id = raw . id , timestamp = raw . ts . ToDatetime ( tzinfo = pytz . UTC ), active_power = raw . inverter . data . ac . power_active . value , active_power_lower_bound = raw . inverter . data . ac . power_active . system_bounds . lower , active_power_upper_bound = raw . inverter . data . ac . power_active . system_bounds . upper , ) inverter_data . _set_raw ( raw = raw ) return inverter_data","title":"from_proto()"},{"location":"reference/frequenz/sdk/microgrid/component/#frequenz.sdk.microgrid.component.MeterData","text":"Bases: ComponentData A wrapper class for holding meter data. ATTRIBUTE DESCRIPTION active_power the 3-phase active power, in Watts, represented in the passive sign convention. +ve current means consumption, away from the grid. -ve current means supply into the grid. TYPE: float current_per_phase AC current in Amperes (A) for phase/line 1,2 and 3 respectively. +ve current means consumption, away from the grid. -ve current means supply into the grid. TYPE: Tuple [ float , float , float ] voltage_per_phase the AC voltage in Volts (V) between the line and the neutral wire for phase/line 1,2 and 3 respectively. TYPE: Tuple [ float , float , float ] frequency the AC power frequency in Hertz (Hz). TYPE: float Source code in frequenz/sdk/microgrid/component/_component_data.py 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 @dataclass ( frozen = True ) class MeterData ( ComponentData ): \"\"\"A wrapper class for holding meter data. Attributes: active_power: the 3-phase active power, in Watts, represented in the passive sign convention. +ve current means consumption, away from the grid. -ve current means supply into the grid. current_per_phase: AC current in Amperes (A) for phase/line 1,2 and 3 respectively. +ve current means consumption, away from the grid. -ve current means supply into the grid. voltage_per_phase: the AC voltage in Volts (V) between the line and the neutral wire for phase/line 1,2 and 3 respectively. frequency: the AC power frequency in Hertz (Hz). \"\"\" active_power : float current_per_phase : Tuple [ float , float , float ] voltage_per_phase : Tuple [ float , float , float ] frequency : float @classmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> MeterData : \"\"\"Create MeterData from a protobuf message. Args: raw: raw component data as decoded from the wire. Returns: Instance of MeterData created from the protobuf message. \"\"\" meter_data = cls ( component_id = raw . id , timestamp = raw . ts . ToDatetime ( tzinfo = pytz . UTC ), active_power = raw . meter . data . ac . power_active . value , current_per_phase = ( raw . meter . data . ac . phase_1 . current . value , raw . meter . data . ac . phase_2 . current . value , raw . meter . data . ac . phase_3 . current . value , ), voltage_per_phase = ( raw . meter . data . ac . phase_1 . voltage . value , raw . meter . data . ac . phase_2 . voltage . value , raw . meter . data . ac . phase_3 . voltage . value , ), frequency = raw . meter . data . ac . frequency . value , ) meter_data . _set_raw ( raw = raw ) return meter_data","title":"MeterData"},{"location":"reference/frequenz/sdk/microgrid/component/#frequenz.sdk.microgrid.component.MeterData-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/microgrid/component/#frequenz.sdk.microgrid.component._component_data.MeterData.from_proto","text":"Create MeterData from a protobuf message. PARAMETER DESCRIPTION raw raw component data as decoded from the wire. TYPE: microgrid_pb . ComponentData RETURNS DESCRIPTION MeterData Instance of MeterData created from the protobuf message. Source code in frequenz/sdk/microgrid/component/_component_data.py 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 @classmethod def from_proto ( cls , raw : microgrid_pb . ComponentData ) -> MeterData : \"\"\"Create MeterData from a protobuf message. Args: raw: raw component data as decoded from the wire. Returns: Instance of MeterData created from the protobuf message. \"\"\" meter_data = cls ( component_id = raw . id , timestamp = raw . ts . ToDatetime ( tzinfo = pytz . UTC ), active_power = raw . meter . data . ac . power_active . value , current_per_phase = ( raw . meter . data . ac . phase_1 . current . value , raw . meter . data . ac . phase_2 . current . value , raw . meter . data . ac . phase_3 . current . value , ), voltage_per_phase = ( raw . meter . data . ac . phase_1 . voltage . value , raw . meter . data . ac . phase_2 . voltage . value , raw . meter . data . ac . phase_3 . voltage . value , ), frequency = raw . meter . data . ac . frequency . value , ) meter_data . _set_raw ( raw = raw ) return meter_data","title":"from_proto()"},{"location":"reference/frequenz/sdk/power/","text":"frequenz.sdk.power \u00a4 Utilities to manage power in a microgrid. Classes \u00a4 frequenz.sdk.power.DistributionAlgorithm \u00a4 Distribute power between many components. The purpose of this tool is to keep equal SoC level in the batteries. It takes total power that should be to be set for some subset of battery-inverter pairs. The total power is distributed between given battery-inverter pairs. Distribution is calculated based on data below: Battery current SoC. Battery upper and lower SoC bound. Battery capacity. Battery lower and upper power bound. Inverter lower and upper active power bound. Distribution algorithm \u00a4 Lets assume that: N - number of batteries power_w - power to distribute capacity[i] - capacity of i'th battery available_soc[i] - how much SoC remained to reach: SoC upper bound - if need to distribute power that charges inverters. SoC lower bound - if need to distribute power that discharges inverters. 0 - if SoC is outside SoC bounds. total_capacity - sum(c for c in capacity.values()) capacity_ratio[i] - capacity[i]/total_capacity We would like our distribution to meet the equation: distribution [ i ] = power_w * capacity_ratio [ i ] * x [ i ] where: sum ( capacity_ratio [ i ] * x [ i ] for i in range ( N )) == 1 Let y be our unknown, the proportion to discharge each battery would be (1): x [ i ] = available_soc [ i ] * y We can compute y from equation above (2): sum ( capacity_ratio [ i ] * x [ i ] for i in range ( N )) == 1 # => sum ( capacity_ratio [ i ] * available_soc [ i ] * y for i in range ( N )) == 1 # => y = 1 / sum ( capacity_ratio [ i ] * available_soc [ i ]) Now we know everything and we can compute distribution: distribution [ i ] = power_w * capacity_ratio [ i ] * x [ i ] # from (1) distribution [ i ] = \\ power_w * capacity_ratio [ i ] * available_soc [ i ] * y # from (2) distribution [ i ] = power_w * capacity_ratio [ i ] * available_soc [ i ] * \\ 1 / sum ( capacity_ratio [ i ] * available_soc [ i ]) Let: battery_availability_ratio [ i ] = capacity_ratio [ i ] * available_soc [ i ] total_battery_availability_ratio = sum ( battery_availability_ratio ) Then: distribution [ i ] = power_w * battery_availability_ratio [ i ] \\ / total_battery_availability_ratio Source code in frequenz/sdk/power/_distribution_algorithm.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 class DistributionAlgorithm : r \"\"\"Distribute power between many components. The purpose of this tool is to keep equal SoC level in the batteries. It takes total power that should be to be set for some subset of battery-inverter pairs. The total power is distributed between given battery-inverter pairs. Distribution is calculated based on data below: * Battery current SoC. * Battery upper and lower SoC bound. * Battery capacity. * Battery lower and upper power bound. * Inverter lower and upper active power bound. # Distribution algorithm Lets assume that: * `N` - number of batteries * `power_w` - power to distribute * `capacity[i]` - capacity of i'th battery * `available_soc[i]` - how much SoC remained to reach: * SoC upper bound - if need to distribute power that charges inverters. * SoC lower bound - if need to distribute power that discharges inverters. * `0` - if SoC is outside SoC bounds. * `total_capacity` - `sum(c for c in capacity.values())` * `capacity_ratio[i]` - `capacity[i]/total_capacity` We would like our distribution to meet the equation: ``` python distribution[i] = power_w * capacity_ratio[i] * x[i] ``` where: ``` python sum(capacity_ratio[i] * x[i] for i in range(N)) == 1 ``` Let `y` be our unknown, the proportion to discharge each battery would be (1): ``` python x[i] = available_soc[i]*y ``` We can compute `y` from equation above (2): ``` python sum(capacity_ratio[i] * x[i] for i in range(N)) == 1 # => sum(capacity_ratio[i] * available_soc[i] * y for i in range(N)) == 1 # => y = 1 / sum(capacity_ratio[i] * available_soc[i]) ``` Now we know everything and we can compute distribution: ``` python distribution[i] = power_w * capacity_ratio[i] * x[i] # from (1) distribution[i] = \\ power_w * capacity_ratio[i] * available_soc[i] * y # from (2) distribution[i] = power_w * capacity_ratio[i] * available_soc[i] * \\ 1/sum(capacity_ratio[i] * available_soc[i]) ``` Let: ``` python battery_availability_ratio[i] = capacity_ratio[i] * available_soc[i] total_battery_availability_ratio = sum(battery_availability_ratio) ``` Then: ``` python distribution[i] = power_w * battery_availability_ratio[i] \\ / total_battery_availability_ratio ``` \"\"\" def __init__ ( self , distributor_exponent : float = 1 ) -> None : \"\"\"Create distribution algorithm instance. Args: distributor_exponent: How fast the batteries should strive to the equal SoC level. Should be float >= 0. Defaults=1. For example for distributor_exponent equal: * 1 - means that proportion will be linear from SoC. * 2 - means proportion would be like squared from SoC * 3 - means proportion would be like x^3 from SoC. Example: Lets say we have two batteries `Bat1` and `Bat2`. All parameters except SoC are equal. SoC bounds for each battery is `lower = 20`, `upper = 80`. # Example 1 Let: * `Bat1.soc = 70` and `Bat2.soc = 50`. * `Bat1.available_soc = 10`, `Bat2.available_soc = 30` * `Bat1.available_soc / Bat2.available_soc = 3` We need to distribute 8000W. If `distribution_exponent` is: * `0`: distribution for each battery will be the equal. ``` python Bat1.distribution = 4000; Bat2.distribution = 4000 ``` * `1`: then `Bat2` will have 3x more power assigned then `Bat1`. ``` python 10 * x + 30 * x = 8000 x = 200 Bat1.distribution = 2000; Bat2.distribution = 6000 ``` * `2`: then `Bat2` will have 9x more power assigned then `Bat1`. ``` python 10^2 * x + 30^2 * x = 8000 x = 80 Bat1.distribution = 800; Bat2.distribution = 7200 ``` * `3`: then `Bat2` will have 27x more power assigned then `Bat1`. ``` python 10^3 * x + 30^3 * x = 8000 x = 0,285714286 Bat1.distribution = 285; Bat2.distribution = 7715 ``` # Example 2 Let: * `Bat1.soc = 50` and `Bat2.soc = 20`. * `Bat1.available_soc = 30`, `Bat2.available_soc = 60` * `Bat1.available_soc / Bat2.available_soc = 2` We need to distribute 900W. If `distribution_exponent` is: * `0`: distribution for each battery will be the same. ``` python Bat1.distribution = 4500; Bat2.distribution = 450 ``` * `1`: then `Bat2` will have 2x more power assigned then `Bat1`. ``` python 30 * x + 60 * x = 900 x = 100 Bat1.distribution = 300; Bat2.distribution = 600 ``` * `2`: then `Bat2` will have 4x more power assigned then `Bat1`. ``` python 30^2 * x + 60^2 * x = 900 x = 0.2 Bat1.distribution = 180; Bat2.distribution = 720 ``` * `3`: then `Bat2` will have 8x more power assigned then `Bat1`. ``` python 30^3 * x + 60^3 * x = 900 x = 0,003703704 Bat1.distribution = 100; Bat2.distribution = 800 ``` # Example 3 Let: * `Bat1.soc = 44` and `Bat2.soc = 64`. * `Bat1.available_soc = 36 (80 - 44)`, `Bat2.available_soc = 16 (80 - 64)` We need to distribute 900W. If `distribution_exponent` is: * `0`: distribution for each battery will be the equal. ``` python Bat1.distribution = 450; Bat2.distribution = 450 ``` * `0.5`: then `Bat2` will have 6/4x more power assigned then `Bat1`. ``` python sqrt(36) * x + sqrt(16) * x = 900 x = 100 Bat1.distribution = 600; Bat2.distribution = 400 ``` Raises: ValueError: If distributor_exponent < 0 \"\"\" super () . __init__ () if distributor_exponent < 0 : raise ValueError ( \"Distribution factor should be float >= 0.\" ) self . _distributor_exponent : float = distributor_exponent def _total_capacity ( self , components : List [ InvBatPair ]) -> float : \"\"\"Sum capacity between all batteries in the components list. Args: components: list of the components Raises: ValueError: If total capacity is 0. Returns: Sum of all batteries capacity in the components list. \"\"\" total_capacity : float = sum ( bat . capacity for bat , _ in components ) if total_capacity == 0.0 : msg = \"All batteries have capacity 0.\" _logger . error ( msg ) raise ValueError ( msg ) return total_capacity def _compute_battery_availability_ratio ( self , components : List [ InvBatPair ], available_soc : Dict [ int , float ] ) -> Tuple [ List [ Tuple [ InvBatPair , float ]], float ]: r \"\"\"Compute battery ratio and the total sum of all of them. battery_availability_ratio = capacity_ratio[i] * available_soc[i] Where: capacity_ratio[i] = components[i].battery.capacity \\ / sum(battery.capacity for battery, _ in components) Args: components: list of the components available_soc: How much SoC remained to reach * SoC upper bound - if need to distribute consumption power * SoC lower bound - if need to distribute supply power Returns: Tuple where first argument is battery availability ratio for each battery-inverter pair. The list is sorted by ratio in descending order. The second element of the tuple is total sum of all battery ratios in the list. \"\"\" total_capacity = self . _total_capacity ( components ) battery_availability_ratio : List [ Tuple [ InvBatPair , float ]] = [] total_battery_availability_ratio : float = 0.0 for pair in components : battery = pair [ 0 ] capacity_ratio = battery . capacity / total_capacity soc_factor = pow ( available_soc [ battery . component_id ], self . _distributor_exponent ) ratio = capacity_ratio * soc_factor battery_availability_ratio . append (( pair , ratio )) total_battery_availability_ratio += ratio battery_availability_ratio . sort ( key = lambda item : item [ 1 ], reverse = True ) return battery_availability_ratio , total_battery_availability_ratio def _distribute_power ( self , components : List [ InvBatPair ], power_w : int , available_soc : Dict [ int , float ], upper_bounds : Dict [ int , int ], ) -> DistributionResult : # pylint: disable=too-many-locals \"\"\"Distribute power between given components. After this method power should be distributed between batteries in a way that equalize SoC between batteries. Args: components: list of components. power_w: power to distribute available_soc: how much SoC remained to reach: * SoC upper bound - if need to distribute consumption power * SoC lower bound - if need to distribute supply power upper_bounds: Min between upper bound of each pair in the components list: * supply upper bound - if need to distribute consumption power * consumption lower bound - if need to distribute supply power Returns: Distribution result. \"\"\" ( battery_availability_ratio , sum_ratio , ) = self . _compute_battery_availability_ratio ( components , available_soc ) distribution : Dict [ int , int ] = {} # sum_ratio == 0 means that all batteries are fully charged / discharged if sum_ratio == 0.0 : distribution = { inverter . component_id : 0 for _ , inverter in components } return DistributionResult ( distribution , power_w ) distributed_power = 0 power_to_distribute : int = power_w used_ratio : float = 0.0 ratio = sum_ratio for pair , battery_ratio in battery_availability_ratio : inverter = pair [ 1 ] # ratio = 0, means all remaining batteries reach max SoC lvl or have no # capacity if ratio == 0.0 : distribution [ inverter . component_id ] = 0 continue distribution [ inverter . component_id ] = floor ( power_to_distribute * battery_ratio / ratio ) used_ratio += battery_ratio # If the power allocated for that inverter is out of bound, # then we need to distribute more power over all remaining batteries. upper_bound = upper_bounds [ inverter . component_id ] if distribution [ inverter . component_id ] > upper_bound : distribution [ inverter . component_id ] = upper_bound distributed_power += upper_bound # Distribute only the remaining power. power_to_distribute = power_w - distributed_power # Distribute between remaining batteries ratio = sum_ratio - used_ratio else : distributed_power += distribution [ inverter . component_id ] return DistributionResult ( distribution , power_w - distributed_power ) def _greedy_distribute_remaining_power ( self , distribution : Dict [ int , int ], upper_bounds : Dict [ int , int ], remaining_power : int , ) -> DistributionResult : \"\"\"Add remaining power greedily to the given distribution. Distribution for each inverter will not exceed its upper bound. Args: distribution: distribution upper_bounds: upper bounds inverter and adjacent battery in distribution. remaining_power: power to distribute Returns: Return the power for each inverter in given distribution. \"\"\" if remaining_power == 0 : return DistributionResult ( distribution , remaining_power ) new_distribution : Dict [ int , int ] = {} for inverter_id , power in distribution . items (): if remaining_power == 0 or power == 0 : new_distribution [ inverter_id ] = power else : remaining_power_capacity : int = upper_bounds [ inverter_id ] - power to_add = min ( remaining_power_capacity , remaining_power ) new_distribution [ inverter_id ] = power + to_add remaining_power -= to_add return DistributionResult ( new_distribution , remaining_power ) def distribute_power ( self , power : int , components : List [ InvBatPair ] ) -> DistributionResult : \"\"\"Distribute given power between given components. Args: power: Power to distribute components: InvBatPaired components data. Each pair should have data for battery and adjacent inverter. Returns: Distribution result \"\"\" if power >= 0 : return self . _distribute_consume_power ( power , components ) return self . _distribute_supply_power ( power , components ) def _distribute_consume_power ( self , power_w : int , components : List [ InvBatPair ] ) -> DistributionResult : \"\"\"Distribute power between the given components. Distribute power in a way that the SoC level between given components will: * stay on the same level, equal in all given components * will try to align himself to the same level. Args: power_w: power to distribute components: list of components between which the power should be distributed. Returns: Distribution result, batteries with no SoC and capacity won't be used. \"\"\" # If SoC exceeded bound then remaining SoC should be 0. # Otherwise algorithm would try to supply power from that battery # in order to keep equal SoC level. available_soc : Dict [ int , float ] = {} for battery , _ in components : available_soc [ battery . component_id ] = max ( 0.0 , battery . soc_upper_bound - battery . soc ) bounds : Dict [ int , int ] = {} for battery , inverter in components : # We can supply/consume with int only inverter_bound = inverter . active_power_upper_bound battery_bound = battery . power_upper_bound bounds [ inverter . component_id ] = floor ( min ( inverter_bound , battery_bound )) result : DistributionResult = self . _distribute_power ( components , power_w , available_soc , bounds ) return self . _greedy_distribute_remaining_power ( result . distribution , bounds , result . remaining_power ) def _distribute_supply_power ( self , power_w : int , components : List [ InvBatPair ] ) -> DistributionResult : \"\"\"Distribute power between the given components. Distribute power in a way that the SoC level between given components will: * stay on the same level, equal in all given components * will try to align himself to the same level. Args: power_w: power to distribute components: list of components between which the power should be distributed. Returns: Distribution result. \"\"\" available_soc : Dict [ int , float ] = {} for battery , _ in components : available_soc [ battery . component_id ] = max ( 0.0 , battery . soc - battery . soc_lower_bound ) bounds : Dict [ int , int ] = {} for battery , inverter in components : # We can consume with int only inverter_bound = inverter . active_power_lower_bound battery_bound = battery . power_lower_bound bounds [ inverter . component_id ] = - 1 * ceil ( max ( inverter_bound , battery_bound ) ) result : DistributionResult = self . _distribute_power ( components , - 1 * power_w , available_soc , bounds ) result = self . _greedy_distribute_remaining_power ( result . distribution , bounds , result . remaining_power ) for inverter_id in result . distribution . keys (): result . distribution [ inverter_id ] *= - 1 result . remaining_power *= - 1 return result Functions \u00a4 __init__ ( distributor_exponent = 1 ) \u00a4 Create distribution algorithm instance. PARAMETER DESCRIPTION distributor_exponent How fast the batteries should strive to the equal SoC level. Should be float >= 0. Defaults=1. For example for distributor_exponent equal: * 1 - means that proportion will be linear from SoC. * 2 - means proportion would be like squared from SoC * 3 - means proportion would be like x^3 from SoC. TYPE: float DEFAULT: 1 Example Lets say we have two batteries Bat1 and Bat2 . All parameters except SoC are equal. SoC bounds for each battery is lower = 20 , upper = 80 . Example 1 \u00a4 Let: Bat1.soc = 70 and Bat2.soc = 50 . Bat1.available_soc = 10 , Bat2.available_soc = 30 Bat1.available_soc / Bat2.available_soc = 3 We need to distribute 8000W. If distribution_exponent is: 0 : distribution for each battery will be the equal. Bat1 . distribution = 4000 ; Bat2 . distribution = 4000 1 : then Bat2 will have 3x more power assigned then Bat1 . 10 * x + 30 * x = 8000 x = 200 Bat1 . distribution = 2000 ; Bat2 . distribution = 6000 2 : then Bat2 will have 9x more power assigned then Bat1 . 10 ^ 2 * x + 30 ^ 2 * x = 8000 x = 80 Bat1 . distribution = 800 ; Bat2 . distribution = 7200 3 : then Bat2 will have 27x more power assigned then Bat1 . 10 ^ 3 * x + 30 ^ 3 * x = 8000 x = 0 , 285714286 Bat1 . distribution = 285 ; Bat2 . distribution = 7715 Example 2 \u00a4 Let: Bat1.soc = 50 and Bat2.soc = 20 . Bat1.available_soc = 30 , Bat2.available_soc = 60 Bat1.available_soc / Bat2.available_soc = 2 We need to distribute 900W. If distribution_exponent is: 0 : distribution for each battery will be the same. Bat1 . distribution = 4500 ; Bat2 . distribution = 450 1 : then Bat2 will have 2x more power assigned then Bat1 . 30 * x + 60 * x = 900 x = 100 Bat1 . distribution = 300 ; Bat2 . distribution = 600 2 : then Bat2 will have 4x more power assigned then Bat1 . 30 ^ 2 * x + 60 ^ 2 * x = 900 x = 0.2 Bat1 . distribution = 180 ; Bat2 . distribution = 720 3 : then Bat2 will have 8x more power assigned then Bat1 . 30 ^ 3 * x + 60 ^ 3 * x = 900 x = 0 , 003703704 Bat1 . distribution = 100 ; Bat2 . distribution = 800 Example 3 \u00a4 Let: Bat1.soc = 44 and Bat2.soc = 64 . Bat1.available_soc = 36 (80 - 44) , Bat2.available_soc = 16 (80 - 64) We need to distribute 900W. If distribution_exponent is: 0 : distribution for each battery will be the equal. Bat1 . distribution = 450 ; Bat2 . distribution = 450 0.5 : then Bat2 will have 6/4x more power assigned then Bat1 . sqrt ( 36 ) * x + sqrt ( 16 ) * x = 900 x = 100 Bat1 . distribution = 600 ; Bat2 . distribution = 400 RAISES DESCRIPTION ValueError If distributor_exponent < 0 Source code in frequenz/sdk/power/_distribution_algorithm.py 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 def __init__ ( self , distributor_exponent : float = 1 ) -> None : \"\"\"Create distribution algorithm instance. Args: distributor_exponent: How fast the batteries should strive to the equal SoC level. Should be float >= 0. Defaults=1. For example for distributor_exponent equal: * 1 - means that proportion will be linear from SoC. * 2 - means proportion would be like squared from SoC * 3 - means proportion would be like x^3 from SoC. Example: Lets say we have two batteries `Bat1` and `Bat2`. All parameters except SoC are equal. SoC bounds for each battery is `lower = 20`, `upper = 80`. # Example 1 Let: * `Bat1.soc = 70` and `Bat2.soc = 50`. * `Bat1.available_soc = 10`, `Bat2.available_soc = 30` * `Bat1.available_soc / Bat2.available_soc = 3` We need to distribute 8000W. If `distribution_exponent` is: * `0`: distribution for each battery will be the equal. ``` python Bat1.distribution = 4000; Bat2.distribution = 4000 ``` * `1`: then `Bat2` will have 3x more power assigned then `Bat1`. ``` python 10 * x + 30 * x = 8000 x = 200 Bat1.distribution = 2000; Bat2.distribution = 6000 ``` * `2`: then `Bat2` will have 9x more power assigned then `Bat1`. ``` python 10^2 * x + 30^2 * x = 8000 x = 80 Bat1.distribution = 800; Bat2.distribution = 7200 ``` * `3`: then `Bat2` will have 27x more power assigned then `Bat1`. ``` python 10^3 * x + 30^3 * x = 8000 x = 0,285714286 Bat1.distribution = 285; Bat2.distribution = 7715 ``` # Example 2 Let: * `Bat1.soc = 50` and `Bat2.soc = 20`. * `Bat1.available_soc = 30`, `Bat2.available_soc = 60` * `Bat1.available_soc / Bat2.available_soc = 2` We need to distribute 900W. If `distribution_exponent` is: * `0`: distribution for each battery will be the same. ``` python Bat1.distribution = 4500; Bat2.distribution = 450 ``` * `1`: then `Bat2` will have 2x more power assigned then `Bat1`. ``` python 30 * x + 60 * x = 900 x = 100 Bat1.distribution = 300; Bat2.distribution = 600 ``` * `2`: then `Bat2` will have 4x more power assigned then `Bat1`. ``` python 30^2 * x + 60^2 * x = 900 x = 0.2 Bat1.distribution = 180; Bat2.distribution = 720 ``` * `3`: then `Bat2` will have 8x more power assigned then `Bat1`. ``` python 30^3 * x + 60^3 * x = 900 x = 0,003703704 Bat1.distribution = 100; Bat2.distribution = 800 ``` # Example 3 Let: * `Bat1.soc = 44` and `Bat2.soc = 64`. * `Bat1.available_soc = 36 (80 - 44)`, `Bat2.available_soc = 16 (80 - 64)` We need to distribute 900W. If `distribution_exponent` is: * `0`: distribution for each battery will be the equal. ``` python Bat1.distribution = 450; Bat2.distribution = 450 ``` * `0.5`: then `Bat2` will have 6/4x more power assigned then `Bat1`. ``` python sqrt(36) * x + sqrt(16) * x = 900 x = 100 Bat1.distribution = 600; Bat2.distribution = 400 ``` Raises: ValueError: If distributor_exponent < 0 \"\"\" super () . __init__ () if distributor_exponent < 0 : raise ValueError ( \"Distribution factor should be float >= 0.\" ) self . _distributor_exponent : float = distributor_exponent distribute_power ( power , components ) \u00a4 Distribute given power between given components. PARAMETER DESCRIPTION power Power to distribute TYPE: int components InvBatPaired components data. Each pair should have data for battery and adjacent inverter. TYPE: List [ InvBatPair ] RETURNS DESCRIPTION DistributionResult Distribution result Source code in frequenz/sdk/power/_distribution_algorithm.py 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 def distribute_power ( self , power : int , components : List [ InvBatPair ] ) -> DistributionResult : \"\"\"Distribute given power between given components. Args: power: Power to distribute components: InvBatPaired components data. Each pair should have data for battery and adjacent inverter. Returns: Distribution result \"\"\" if power >= 0 : return self . _distribute_consume_power ( power , components ) return self . _distribute_supply_power ( power , components ) frequenz.sdk.power.DistributionResult dataclass \u00a4 Distribution result. Source code in frequenz/sdk/power/_distribution_algorithm.py 26 27 28 29 30 31 32 33 34 35 36 37 38 @dataclass class DistributionResult : \"\"\"Distribution result.\"\"\" distribution : Dict [ int , int ] \"\"\"The power to be set for each inverter. The key is inverter ID, and the value is the power that should be set for that inverter. \"\"\" remaining_power : int \"\"\"The power which could not be distributed because of bounds.\"\"\" Attributes \u00a4 distribution : Dict [ int , int ] class-attribute \u00a4 The power to be set for each inverter. The key is inverter ID, and the value is the power that should be set for that inverter. remaining_power : int class-attribute \u00a4 The power which could not be distributed because of bounds. frequenz.sdk.power.InvBatPair \u00a4 Bases: NamedTuple InvBatPair with inverter and adjacent battery data. Source code in frequenz/sdk/power/_distribution_algorithm.py 16 17 18 19 20 21 22 23 class InvBatPair ( NamedTuple ): \"\"\"InvBatPair with inverter and adjacent battery data.\"\"\" battery : BatteryData \"\"\"The battery data.\"\"\" inverter : InverterData \"\"\"The inverter data.\"\"\" Attributes \u00a4 battery : BatteryData class-attribute \u00a4 The battery data. inverter : InverterData class-attribute \u00a4 The inverter data.","title":"power"},{"location":"reference/frequenz/sdk/power/#frequenz.sdk.power","text":"Utilities to manage power in a microgrid.","title":"power"},{"location":"reference/frequenz/sdk/power/#frequenz.sdk.power-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/power/#frequenz.sdk.power.DistributionAlgorithm","text":"Distribute power between many components. The purpose of this tool is to keep equal SoC level in the batteries. It takes total power that should be to be set for some subset of battery-inverter pairs. The total power is distributed between given battery-inverter pairs. Distribution is calculated based on data below: Battery current SoC. Battery upper and lower SoC bound. Battery capacity. Battery lower and upper power bound. Inverter lower and upper active power bound.","title":"DistributionAlgorithm"},{"location":"reference/frequenz/sdk/power/#frequenz.sdk.power.DistributionAlgorithm--distribution-algorithm","text":"Lets assume that: N - number of batteries power_w - power to distribute capacity[i] - capacity of i'th battery available_soc[i] - how much SoC remained to reach: SoC upper bound - if need to distribute power that charges inverters. SoC lower bound - if need to distribute power that discharges inverters. 0 - if SoC is outside SoC bounds. total_capacity - sum(c for c in capacity.values()) capacity_ratio[i] - capacity[i]/total_capacity We would like our distribution to meet the equation: distribution [ i ] = power_w * capacity_ratio [ i ] * x [ i ] where: sum ( capacity_ratio [ i ] * x [ i ] for i in range ( N )) == 1 Let y be our unknown, the proportion to discharge each battery would be (1): x [ i ] = available_soc [ i ] * y We can compute y from equation above (2): sum ( capacity_ratio [ i ] * x [ i ] for i in range ( N )) == 1 # => sum ( capacity_ratio [ i ] * available_soc [ i ] * y for i in range ( N )) == 1 # => y = 1 / sum ( capacity_ratio [ i ] * available_soc [ i ]) Now we know everything and we can compute distribution: distribution [ i ] = power_w * capacity_ratio [ i ] * x [ i ] # from (1) distribution [ i ] = \\ power_w * capacity_ratio [ i ] * available_soc [ i ] * y # from (2) distribution [ i ] = power_w * capacity_ratio [ i ] * available_soc [ i ] * \\ 1 / sum ( capacity_ratio [ i ] * available_soc [ i ]) Let: battery_availability_ratio [ i ] = capacity_ratio [ i ] * available_soc [ i ] total_battery_availability_ratio = sum ( battery_availability_ratio ) Then: distribution [ i ] = power_w * battery_availability_ratio [ i ] \\ / total_battery_availability_ratio Source code in frequenz/sdk/power/_distribution_algorithm.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 class DistributionAlgorithm : r \"\"\"Distribute power between many components. The purpose of this tool is to keep equal SoC level in the batteries. It takes total power that should be to be set for some subset of battery-inverter pairs. The total power is distributed between given battery-inverter pairs. Distribution is calculated based on data below: * Battery current SoC. * Battery upper and lower SoC bound. * Battery capacity. * Battery lower and upper power bound. * Inverter lower and upper active power bound. # Distribution algorithm Lets assume that: * `N` - number of batteries * `power_w` - power to distribute * `capacity[i]` - capacity of i'th battery * `available_soc[i]` - how much SoC remained to reach: * SoC upper bound - if need to distribute power that charges inverters. * SoC lower bound - if need to distribute power that discharges inverters. * `0` - if SoC is outside SoC bounds. * `total_capacity` - `sum(c for c in capacity.values())` * `capacity_ratio[i]` - `capacity[i]/total_capacity` We would like our distribution to meet the equation: ``` python distribution[i] = power_w * capacity_ratio[i] * x[i] ``` where: ``` python sum(capacity_ratio[i] * x[i] for i in range(N)) == 1 ``` Let `y` be our unknown, the proportion to discharge each battery would be (1): ``` python x[i] = available_soc[i]*y ``` We can compute `y` from equation above (2): ``` python sum(capacity_ratio[i] * x[i] for i in range(N)) == 1 # => sum(capacity_ratio[i] * available_soc[i] * y for i in range(N)) == 1 # => y = 1 / sum(capacity_ratio[i] * available_soc[i]) ``` Now we know everything and we can compute distribution: ``` python distribution[i] = power_w * capacity_ratio[i] * x[i] # from (1) distribution[i] = \\ power_w * capacity_ratio[i] * available_soc[i] * y # from (2) distribution[i] = power_w * capacity_ratio[i] * available_soc[i] * \\ 1/sum(capacity_ratio[i] * available_soc[i]) ``` Let: ``` python battery_availability_ratio[i] = capacity_ratio[i] * available_soc[i] total_battery_availability_ratio = sum(battery_availability_ratio) ``` Then: ``` python distribution[i] = power_w * battery_availability_ratio[i] \\ / total_battery_availability_ratio ``` \"\"\" def __init__ ( self , distributor_exponent : float = 1 ) -> None : \"\"\"Create distribution algorithm instance. Args: distributor_exponent: How fast the batteries should strive to the equal SoC level. Should be float >= 0. Defaults=1. For example for distributor_exponent equal: * 1 - means that proportion will be linear from SoC. * 2 - means proportion would be like squared from SoC * 3 - means proportion would be like x^3 from SoC. Example: Lets say we have two batteries `Bat1` and `Bat2`. All parameters except SoC are equal. SoC bounds for each battery is `lower = 20`, `upper = 80`. # Example 1 Let: * `Bat1.soc = 70` and `Bat2.soc = 50`. * `Bat1.available_soc = 10`, `Bat2.available_soc = 30` * `Bat1.available_soc / Bat2.available_soc = 3` We need to distribute 8000W. If `distribution_exponent` is: * `0`: distribution for each battery will be the equal. ``` python Bat1.distribution = 4000; Bat2.distribution = 4000 ``` * `1`: then `Bat2` will have 3x more power assigned then `Bat1`. ``` python 10 * x + 30 * x = 8000 x = 200 Bat1.distribution = 2000; Bat2.distribution = 6000 ``` * `2`: then `Bat2` will have 9x more power assigned then `Bat1`. ``` python 10^2 * x + 30^2 * x = 8000 x = 80 Bat1.distribution = 800; Bat2.distribution = 7200 ``` * `3`: then `Bat2` will have 27x more power assigned then `Bat1`. ``` python 10^3 * x + 30^3 * x = 8000 x = 0,285714286 Bat1.distribution = 285; Bat2.distribution = 7715 ``` # Example 2 Let: * `Bat1.soc = 50` and `Bat2.soc = 20`. * `Bat1.available_soc = 30`, `Bat2.available_soc = 60` * `Bat1.available_soc / Bat2.available_soc = 2` We need to distribute 900W. If `distribution_exponent` is: * `0`: distribution for each battery will be the same. ``` python Bat1.distribution = 4500; Bat2.distribution = 450 ``` * `1`: then `Bat2` will have 2x more power assigned then `Bat1`. ``` python 30 * x + 60 * x = 900 x = 100 Bat1.distribution = 300; Bat2.distribution = 600 ``` * `2`: then `Bat2` will have 4x more power assigned then `Bat1`. ``` python 30^2 * x + 60^2 * x = 900 x = 0.2 Bat1.distribution = 180; Bat2.distribution = 720 ``` * `3`: then `Bat2` will have 8x more power assigned then `Bat1`. ``` python 30^3 * x + 60^3 * x = 900 x = 0,003703704 Bat1.distribution = 100; Bat2.distribution = 800 ``` # Example 3 Let: * `Bat1.soc = 44` and `Bat2.soc = 64`. * `Bat1.available_soc = 36 (80 - 44)`, `Bat2.available_soc = 16 (80 - 64)` We need to distribute 900W. If `distribution_exponent` is: * `0`: distribution for each battery will be the equal. ``` python Bat1.distribution = 450; Bat2.distribution = 450 ``` * `0.5`: then `Bat2` will have 6/4x more power assigned then `Bat1`. ``` python sqrt(36) * x + sqrt(16) * x = 900 x = 100 Bat1.distribution = 600; Bat2.distribution = 400 ``` Raises: ValueError: If distributor_exponent < 0 \"\"\" super () . __init__ () if distributor_exponent < 0 : raise ValueError ( \"Distribution factor should be float >= 0.\" ) self . _distributor_exponent : float = distributor_exponent def _total_capacity ( self , components : List [ InvBatPair ]) -> float : \"\"\"Sum capacity between all batteries in the components list. Args: components: list of the components Raises: ValueError: If total capacity is 0. Returns: Sum of all batteries capacity in the components list. \"\"\" total_capacity : float = sum ( bat . capacity for bat , _ in components ) if total_capacity == 0.0 : msg = \"All batteries have capacity 0.\" _logger . error ( msg ) raise ValueError ( msg ) return total_capacity def _compute_battery_availability_ratio ( self , components : List [ InvBatPair ], available_soc : Dict [ int , float ] ) -> Tuple [ List [ Tuple [ InvBatPair , float ]], float ]: r \"\"\"Compute battery ratio and the total sum of all of them. battery_availability_ratio = capacity_ratio[i] * available_soc[i] Where: capacity_ratio[i] = components[i].battery.capacity \\ / sum(battery.capacity for battery, _ in components) Args: components: list of the components available_soc: How much SoC remained to reach * SoC upper bound - if need to distribute consumption power * SoC lower bound - if need to distribute supply power Returns: Tuple where first argument is battery availability ratio for each battery-inverter pair. The list is sorted by ratio in descending order. The second element of the tuple is total sum of all battery ratios in the list. \"\"\" total_capacity = self . _total_capacity ( components ) battery_availability_ratio : List [ Tuple [ InvBatPair , float ]] = [] total_battery_availability_ratio : float = 0.0 for pair in components : battery = pair [ 0 ] capacity_ratio = battery . capacity / total_capacity soc_factor = pow ( available_soc [ battery . component_id ], self . _distributor_exponent ) ratio = capacity_ratio * soc_factor battery_availability_ratio . append (( pair , ratio )) total_battery_availability_ratio += ratio battery_availability_ratio . sort ( key = lambda item : item [ 1 ], reverse = True ) return battery_availability_ratio , total_battery_availability_ratio def _distribute_power ( self , components : List [ InvBatPair ], power_w : int , available_soc : Dict [ int , float ], upper_bounds : Dict [ int , int ], ) -> DistributionResult : # pylint: disable=too-many-locals \"\"\"Distribute power between given components. After this method power should be distributed between batteries in a way that equalize SoC between batteries. Args: components: list of components. power_w: power to distribute available_soc: how much SoC remained to reach: * SoC upper bound - if need to distribute consumption power * SoC lower bound - if need to distribute supply power upper_bounds: Min between upper bound of each pair in the components list: * supply upper bound - if need to distribute consumption power * consumption lower bound - if need to distribute supply power Returns: Distribution result. \"\"\" ( battery_availability_ratio , sum_ratio , ) = self . _compute_battery_availability_ratio ( components , available_soc ) distribution : Dict [ int , int ] = {} # sum_ratio == 0 means that all batteries are fully charged / discharged if sum_ratio == 0.0 : distribution = { inverter . component_id : 0 for _ , inverter in components } return DistributionResult ( distribution , power_w ) distributed_power = 0 power_to_distribute : int = power_w used_ratio : float = 0.0 ratio = sum_ratio for pair , battery_ratio in battery_availability_ratio : inverter = pair [ 1 ] # ratio = 0, means all remaining batteries reach max SoC lvl or have no # capacity if ratio == 0.0 : distribution [ inverter . component_id ] = 0 continue distribution [ inverter . component_id ] = floor ( power_to_distribute * battery_ratio / ratio ) used_ratio += battery_ratio # If the power allocated for that inverter is out of bound, # then we need to distribute more power over all remaining batteries. upper_bound = upper_bounds [ inverter . component_id ] if distribution [ inverter . component_id ] > upper_bound : distribution [ inverter . component_id ] = upper_bound distributed_power += upper_bound # Distribute only the remaining power. power_to_distribute = power_w - distributed_power # Distribute between remaining batteries ratio = sum_ratio - used_ratio else : distributed_power += distribution [ inverter . component_id ] return DistributionResult ( distribution , power_w - distributed_power ) def _greedy_distribute_remaining_power ( self , distribution : Dict [ int , int ], upper_bounds : Dict [ int , int ], remaining_power : int , ) -> DistributionResult : \"\"\"Add remaining power greedily to the given distribution. Distribution for each inverter will not exceed its upper bound. Args: distribution: distribution upper_bounds: upper bounds inverter and adjacent battery in distribution. remaining_power: power to distribute Returns: Return the power for each inverter in given distribution. \"\"\" if remaining_power == 0 : return DistributionResult ( distribution , remaining_power ) new_distribution : Dict [ int , int ] = {} for inverter_id , power in distribution . items (): if remaining_power == 0 or power == 0 : new_distribution [ inverter_id ] = power else : remaining_power_capacity : int = upper_bounds [ inverter_id ] - power to_add = min ( remaining_power_capacity , remaining_power ) new_distribution [ inverter_id ] = power + to_add remaining_power -= to_add return DistributionResult ( new_distribution , remaining_power ) def distribute_power ( self , power : int , components : List [ InvBatPair ] ) -> DistributionResult : \"\"\"Distribute given power between given components. Args: power: Power to distribute components: InvBatPaired components data. Each pair should have data for battery and adjacent inverter. Returns: Distribution result \"\"\" if power >= 0 : return self . _distribute_consume_power ( power , components ) return self . _distribute_supply_power ( power , components ) def _distribute_consume_power ( self , power_w : int , components : List [ InvBatPair ] ) -> DistributionResult : \"\"\"Distribute power between the given components. Distribute power in a way that the SoC level between given components will: * stay on the same level, equal in all given components * will try to align himself to the same level. Args: power_w: power to distribute components: list of components between which the power should be distributed. Returns: Distribution result, batteries with no SoC and capacity won't be used. \"\"\" # If SoC exceeded bound then remaining SoC should be 0. # Otherwise algorithm would try to supply power from that battery # in order to keep equal SoC level. available_soc : Dict [ int , float ] = {} for battery , _ in components : available_soc [ battery . component_id ] = max ( 0.0 , battery . soc_upper_bound - battery . soc ) bounds : Dict [ int , int ] = {} for battery , inverter in components : # We can supply/consume with int only inverter_bound = inverter . active_power_upper_bound battery_bound = battery . power_upper_bound bounds [ inverter . component_id ] = floor ( min ( inverter_bound , battery_bound )) result : DistributionResult = self . _distribute_power ( components , power_w , available_soc , bounds ) return self . _greedy_distribute_remaining_power ( result . distribution , bounds , result . remaining_power ) def _distribute_supply_power ( self , power_w : int , components : List [ InvBatPair ] ) -> DistributionResult : \"\"\"Distribute power between the given components. Distribute power in a way that the SoC level between given components will: * stay on the same level, equal in all given components * will try to align himself to the same level. Args: power_w: power to distribute components: list of components between which the power should be distributed. Returns: Distribution result. \"\"\" available_soc : Dict [ int , float ] = {} for battery , _ in components : available_soc [ battery . component_id ] = max ( 0.0 , battery . soc - battery . soc_lower_bound ) bounds : Dict [ int , int ] = {} for battery , inverter in components : # We can consume with int only inverter_bound = inverter . active_power_lower_bound battery_bound = battery . power_lower_bound bounds [ inverter . component_id ] = - 1 * ceil ( max ( inverter_bound , battery_bound ) ) result : DistributionResult = self . _distribute_power ( components , - 1 * power_w , available_soc , bounds ) result = self . _greedy_distribute_remaining_power ( result . distribution , bounds , result . remaining_power ) for inverter_id in result . distribution . keys (): result . distribution [ inverter_id ] *= - 1 result . remaining_power *= - 1 return result","title":"Distribution algorithm"},{"location":"reference/frequenz/sdk/power/#frequenz.sdk.power.DistributionAlgorithm-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/power/#frequenz.sdk.power._distribution_algorithm.DistributionAlgorithm.__init__","text":"Create distribution algorithm instance. PARAMETER DESCRIPTION distributor_exponent How fast the batteries should strive to the equal SoC level. Should be float >= 0. Defaults=1. For example for distributor_exponent equal: * 1 - means that proportion will be linear from SoC. * 2 - means proportion would be like squared from SoC * 3 - means proportion would be like x^3 from SoC. TYPE: float DEFAULT: 1 Example Lets say we have two batteries Bat1 and Bat2 . All parameters except SoC are equal. SoC bounds for each battery is lower = 20 , upper = 80 .","title":"__init__()"},{"location":"reference/frequenz/sdk/power/#frequenz.sdk.power._distribution_algorithm.DistributionAlgorithm.__init__--example-1","text":"Let: Bat1.soc = 70 and Bat2.soc = 50 . Bat1.available_soc = 10 , Bat2.available_soc = 30 Bat1.available_soc / Bat2.available_soc = 3 We need to distribute 8000W. If distribution_exponent is: 0 : distribution for each battery will be the equal. Bat1 . distribution = 4000 ; Bat2 . distribution = 4000 1 : then Bat2 will have 3x more power assigned then Bat1 . 10 * x + 30 * x = 8000 x = 200 Bat1 . distribution = 2000 ; Bat2 . distribution = 6000 2 : then Bat2 will have 9x more power assigned then Bat1 . 10 ^ 2 * x + 30 ^ 2 * x = 8000 x = 80 Bat1 . distribution = 800 ; Bat2 . distribution = 7200 3 : then Bat2 will have 27x more power assigned then Bat1 . 10 ^ 3 * x + 30 ^ 3 * x = 8000 x = 0 , 285714286 Bat1 . distribution = 285 ; Bat2 . distribution = 7715","title":"Example 1"},{"location":"reference/frequenz/sdk/power/#frequenz.sdk.power._distribution_algorithm.DistributionAlgorithm.__init__--example-2","text":"Let: Bat1.soc = 50 and Bat2.soc = 20 . Bat1.available_soc = 30 , Bat2.available_soc = 60 Bat1.available_soc / Bat2.available_soc = 2 We need to distribute 900W. If distribution_exponent is: 0 : distribution for each battery will be the same. Bat1 . distribution = 4500 ; Bat2 . distribution = 450 1 : then Bat2 will have 2x more power assigned then Bat1 . 30 * x + 60 * x = 900 x = 100 Bat1 . distribution = 300 ; Bat2 . distribution = 600 2 : then Bat2 will have 4x more power assigned then Bat1 . 30 ^ 2 * x + 60 ^ 2 * x = 900 x = 0.2 Bat1 . distribution = 180 ; Bat2 . distribution = 720 3 : then Bat2 will have 8x more power assigned then Bat1 . 30 ^ 3 * x + 60 ^ 3 * x = 900 x = 0 , 003703704 Bat1 . distribution = 100 ; Bat2 . distribution = 800","title":"Example 2"},{"location":"reference/frequenz/sdk/power/#frequenz.sdk.power._distribution_algorithm.DistributionAlgorithm.__init__--example-3","text":"Let: Bat1.soc = 44 and Bat2.soc = 64 . Bat1.available_soc = 36 (80 - 44) , Bat2.available_soc = 16 (80 - 64) We need to distribute 900W. If distribution_exponent is: 0 : distribution for each battery will be the equal. Bat1 . distribution = 450 ; Bat2 . distribution = 450 0.5 : then Bat2 will have 6/4x more power assigned then Bat1 . sqrt ( 36 ) * x + sqrt ( 16 ) * x = 900 x = 100 Bat1 . distribution = 600 ; Bat2 . distribution = 400 RAISES DESCRIPTION ValueError If distributor_exponent < 0 Source code in frequenz/sdk/power/_distribution_algorithm.py 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 def __init__ ( self , distributor_exponent : float = 1 ) -> None : \"\"\"Create distribution algorithm instance. Args: distributor_exponent: How fast the batteries should strive to the equal SoC level. Should be float >= 0. Defaults=1. For example for distributor_exponent equal: * 1 - means that proportion will be linear from SoC. * 2 - means proportion would be like squared from SoC * 3 - means proportion would be like x^3 from SoC. Example: Lets say we have two batteries `Bat1` and `Bat2`. All parameters except SoC are equal. SoC bounds for each battery is `lower = 20`, `upper = 80`. # Example 1 Let: * `Bat1.soc = 70` and `Bat2.soc = 50`. * `Bat1.available_soc = 10`, `Bat2.available_soc = 30` * `Bat1.available_soc / Bat2.available_soc = 3` We need to distribute 8000W. If `distribution_exponent` is: * `0`: distribution for each battery will be the equal. ``` python Bat1.distribution = 4000; Bat2.distribution = 4000 ``` * `1`: then `Bat2` will have 3x more power assigned then `Bat1`. ``` python 10 * x + 30 * x = 8000 x = 200 Bat1.distribution = 2000; Bat2.distribution = 6000 ``` * `2`: then `Bat2` will have 9x more power assigned then `Bat1`. ``` python 10^2 * x + 30^2 * x = 8000 x = 80 Bat1.distribution = 800; Bat2.distribution = 7200 ``` * `3`: then `Bat2` will have 27x more power assigned then `Bat1`. ``` python 10^3 * x + 30^3 * x = 8000 x = 0,285714286 Bat1.distribution = 285; Bat2.distribution = 7715 ``` # Example 2 Let: * `Bat1.soc = 50` and `Bat2.soc = 20`. * `Bat1.available_soc = 30`, `Bat2.available_soc = 60` * `Bat1.available_soc / Bat2.available_soc = 2` We need to distribute 900W. If `distribution_exponent` is: * `0`: distribution for each battery will be the same. ``` python Bat1.distribution = 4500; Bat2.distribution = 450 ``` * `1`: then `Bat2` will have 2x more power assigned then `Bat1`. ``` python 30 * x + 60 * x = 900 x = 100 Bat1.distribution = 300; Bat2.distribution = 600 ``` * `2`: then `Bat2` will have 4x more power assigned then `Bat1`. ``` python 30^2 * x + 60^2 * x = 900 x = 0.2 Bat1.distribution = 180; Bat2.distribution = 720 ``` * `3`: then `Bat2` will have 8x more power assigned then `Bat1`. ``` python 30^3 * x + 60^3 * x = 900 x = 0,003703704 Bat1.distribution = 100; Bat2.distribution = 800 ``` # Example 3 Let: * `Bat1.soc = 44` and `Bat2.soc = 64`. * `Bat1.available_soc = 36 (80 - 44)`, `Bat2.available_soc = 16 (80 - 64)` We need to distribute 900W. If `distribution_exponent` is: * `0`: distribution for each battery will be the equal. ``` python Bat1.distribution = 450; Bat2.distribution = 450 ``` * `0.5`: then `Bat2` will have 6/4x more power assigned then `Bat1`. ``` python sqrt(36) * x + sqrt(16) * x = 900 x = 100 Bat1.distribution = 600; Bat2.distribution = 400 ``` Raises: ValueError: If distributor_exponent < 0 \"\"\" super () . __init__ () if distributor_exponent < 0 : raise ValueError ( \"Distribution factor should be float >= 0.\" ) self . _distributor_exponent : float = distributor_exponent","title":"Example 3"},{"location":"reference/frequenz/sdk/power/#frequenz.sdk.power._distribution_algorithm.DistributionAlgorithm.distribute_power","text":"Distribute given power between given components. PARAMETER DESCRIPTION power Power to distribute TYPE: int components InvBatPaired components data. Each pair should have data for battery and adjacent inverter. TYPE: List [ InvBatPair ] RETURNS DESCRIPTION DistributionResult Distribution result Source code in frequenz/sdk/power/_distribution_algorithm.py 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 def distribute_power ( self , power : int , components : List [ InvBatPair ] ) -> DistributionResult : \"\"\"Distribute given power between given components. Args: power: Power to distribute components: InvBatPaired components data. Each pair should have data for battery and adjacent inverter. Returns: Distribution result \"\"\" if power >= 0 : return self . _distribute_consume_power ( power , components ) return self . _distribute_supply_power ( power , components )","title":"distribute_power()"},{"location":"reference/frequenz/sdk/power/#frequenz.sdk.power.DistributionResult","text":"Distribution result. Source code in frequenz/sdk/power/_distribution_algorithm.py 26 27 28 29 30 31 32 33 34 35 36 37 38 @dataclass class DistributionResult : \"\"\"Distribution result.\"\"\" distribution : Dict [ int , int ] \"\"\"The power to be set for each inverter. The key is inverter ID, and the value is the power that should be set for that inverter. \"\"\" remaining_power : int \"\"\"The power which could not be distributed because of bounds.\"\"\"","title":"DistributionResult"},{"location":"reference/frequenz/sdk/power/#frequenz.sdk.power.DistributionResult-attributes","text":"","title":"Attributes"},{"location":"reference/frequenz/sdk/power/#frequenz.sdk.power._distribution_algorithm.DistributionResult.distribution","text":"The power to be set for each inverter. The key is inverter ID, and the value is the power that should be set for that inverter.","title":"distribution"},{"location":"reference/frequenz/sdk/power/#frequenz.sdk.power._distribution_algorithm.DistributionResult.remaining_power","text":"The power which could not be distributed because of bounds.","title":"remaining_power"},{"location":"reference/frequenz/sdk/power/#frequenz.sdk.power.InvBatPair","text":"Bases: NamedTuple InvBatPair with inverter and adjacent battery data. Source code in frequenz/sdk/power/_distribution_algorithm.py 16 17 18 19 20 21 22 23 class InvBatPair ( NamedTuple ): \"\"\"InvBatPair with inverter and adjacent battery data.\"\"\" battery : BatteryData \"\"\"The battery data.\"\"\" inverter : InverterData \"\"\"The inverter data.\"\"\"","title":"InvBatPair"},{"location":"reference/frequenz/sdk/power/#frequenz.sdk.power.InvBatPair-attributes","text":"","title":"Attributes"},{"location":"reference/frequenz/sdk/power/#frequenz.sdk.power._distribution_algorithm.InvBatPair.battery","text":"The battery data.","title":"battery"},{"location":"reference/frequenz/sdk/power/#frequenz.sdk.power._distribution_algorithm.InvBatPair.inverter","text":"The inverter data.","title":"inverter"},{"location":"reference/frequenz/sdk/timeseries/","text":"frequenz.sdk.timeseries \u00a4 Handling of timeseries streams. A timeseries is a stream (normally an async iterator) of samples . This module provides tools to operate on timeseries. Attributes \u00a4 frequenz . sdk . timeseries . ResamplingFunction = Callable [[ Sequence [ Sample ], float ], float ] module-attribute \u00a4 Resampling function type. A resampling function produces a new sample based on a list of pre-existing samples. It can do \"upsampling\" when there data rate of the input_samples period is smaller than the resampling_period_s , or \"downsampling\" if it is bigger. In general a resampling window is the same as the resampling_period_s , and this function might receive input samples from multiple windows in the past to enable extrapolation, but no samples from the future (so the timestamp of the new sample that is going to be produced will always be bigger than the biggest timestamp in the input data). PARAMETER DESCRIPTION input_samples the sequence of pre-existing samples. TYPE: Sequence [ Sample ] resampling_period_s the period in seconds (i.e. how ofter a new sample is produced. TYPE: float RETURNS DESCRIPTION new_sample The value of new sample produced after the resampling. TYPE: float Classes \u00a4 frequenz.sdk.timeseries.GroupResampler \u00a4 Ingests samples and produces resampled data for a group of timeseries. Like the Resampler but handles a group of timeseries. Source code in frequenz/sdk/timeseries/_resampler.py 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 class GroupResampler : \"\"\"Ingests samples and produces resampled data for a group of timeseries. Like the [Resampler][frequenz.sdk.timeseries.Resampler] but handles a group of timeseries. \"\"\" def __init__ ( self , * , resampling_period_s : float , initial_resampling_function : ResamplingFunction , max_data_age_in_periods : float = 3.0 , ) -> None : \"\"\"Initialize the ComponentMetricGroupResampler. Args: resampling_period_s: value describing how often resampling should be performed, in seconds initial_resampling_function: function to be applied to a sequence of samples within a resampling period to produce a single output sample max_data_age_in_periods: max age that samples shouldn't exceed in order to be used in the resampling function \"\"\" self . _resampling_period_s = resampling_period_s self . _max_data_age_in_periods : float = max_data_age_in_periods self . _initial_resampling_function : ResamplingFunction = ( initial_resampling_function ) self . _resamplers : Dict [ str , Resampler ] = {} def add_time_series ( self , time_series_id : str ) -> None : \"\"\"Create a new resampler for a specific time series. If resampler already exists for the provided `time_series_id`, it will be used without creating a new one. Args: time_series_id: time series id \"\"\" if time_series_id in self . _resamplers : return self . _resamplers [ time_series_id ] = Resampler ( resampling_period_s = self . _resampling_period_s , max_data_age_in_periods = self . _max_data_age_in_periods , resampling_function = self . _initial_resampling_function , ) def remove_timeseries ( self , time_series_id : str ) -> None : \"\"\"Remove a resampler for a specific time series. Args: time_series_id: time series id, for which to remove the resampler Raises: KeyError: if resampler for the provided timer_series_id doesn't exist \"\"\" try : del self . _resamplers [ time_series_id ] except KeyError as err : raise KeyError ( f \"No resampler for time series { time_series_id } found!\" ) from err def add_sample ( self , time_series_id : str , sample : Sample ) -> None : \"\"\"Add a sample for a specific time series. Args: time_series_id: time series id, which the sample should be added to sample: sample to be added Raises: KeyError: if resampler for the provided timer_series_id doesn't exist \"\"\" try : self . _resamplers [ time_series_id ] . add_sample ( sample ) except KeyError as err : raise KeyError ( f \"No resampler for time series { time_series_id } found!\" ) from err def resample ( self , timestamp : Optional [ datetime ] = None ) -> Generator [ Tuple [ str , Sample ], None , None ]: \"\"\"Resample samples for all time series. Args: timestamp: the timestamp to use to emit the new samples (and to consider stored samples relevant for resampling. If `None`, the current datetime (in UTC) will be used. Yields: iterator of time series ids and their newly resampled samples \"\"\" if timestamp is None : timestamp = datetime . now ( timezone . utc ) for time_series_id , resampler in self . _resamplers . items (): yield time_series_id , Sample ( timestamp = timestamp , value = resampler . resample ( timestamp ) ) Functions \u00a4 __init__ ( * , resampling_period_s , initial_resampling_function , max_data_age_in_periods = 3.0 ) \u00a4 Initialize the ComponentMetricGroupResampler. PARAMETER DESCRIPTION resampling_period_s value describing how often resampling should be performed, in seconds TYPE: float initial_resampling_function function to be applied to a sequence of samples within a resampling period to produce a single output sample TYPE: ResamplingFunction max_data_age_in_periods max age that samples shouldn't exceed in order to be used in the resampling function TYPE: float DEFAULT: 3.0 Source code in frequenz/sdk/timeseries/_resampler.py 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 def __init__ ( self , * , resampling_period_s : float , initial_resampling_function : ResamplingFunction , max_data_age_in_periods : float = 3.0 , ) -> None : \"\"\"Initialize the ComponentMetricGroupResampler. Args: resampling_period_s: value describing how often resampling should be performed, in seconds initial_resampling_function: function to be applied to a sequence of samples within a resampling period to produce a single output sample max_data_age_in_periods: max age that samples shouldn't exceed in order to be used in the resampling function \"\"\" self . _resampling_period_s = resampling_period_s self . _max_data_age_in_periods : float = max_data_age_in_periods self . _initial_resampling_function : ResamplingFunction = ( initial_resampling_function ) self . _resamplers : Dict [ str , Resampler ] = {} add_sample ( time_series_id , sample ) \u00a4 Add a sample for a specific time series. PARAMETER DESCRIPTION time_series_id time series id, which the sample should be added to TYPE: str sample sample to be added TYPE: Sample RAISES DESCRIPTION KeyError if resampler for the provided timer_series_id doesn't exist Source code in frequenz/sdk/timeseries/_resampler.py 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 def add_sample ( self , time_series_id : str , sample : Sample ) -> None : \"\"\"Add a sample for a specific time series. Args: time_series_id: time series id, which the sample should be added to sample: sample to be added Raises: KeyError: if resampler for the provided timer_series_id doesn't exist \"\"\" try : self . _resamplers [ time_series_id ] . add_sample ( sample ) except KeyError as err : raise KeyError ( f \"No resampler for time series { time_series_id } found!\" ) from err add_time_series ( time_series_id ) \u00a4 Create a new resampler for a specific time series. If resampler already exists for the provided time_series_id , it will be used without creating a new one. PARAMETER DESCRIPTION time_series_id time series id TYPE: str Source code in frequenz/sdk/timeseries/_resampler.py 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 def add_time_series ( self , time_series_id : str ) -> None : \"\"\"Create a new resampler for a specific time series. If resampler already exists for the provided `time_series_id`, it will be used without creating a new one. Args: time_series_id: time series id \"\"\" if time_series_id in self . _resamplers : return self . _resamplers [ time_series_id ] = Resampler ( resampling_period_s = self . _resampling_period_s , max_data_age_in_periods = self . _max_data_age_in_periods , resampling_function = self . _initial_resampling_function , ) remove_timeseries ( time_series_id ) \u00a4 Remove a resampler for a specific time series. PARAMETER DESCRIPTION time_series_id time series id, for which to remove the resampler TYPE: str RAISES DESCRIPTION KeyError if resampler for the provided timer_series_id doesn't exist Source code in frequenz/sdk/timeseries/_resampler.py 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 def remove_timeseries ( self , time_series_id : str ) -> None : \"\"\"Remove a resampler for a specific time series. Args: time_series_id: time series id, for which to remove the resampler Raises: KeyError: if resampler for the provided timer_series_id doesn't exist \"\"\" try : del self . _resamplers [ time_series_id ] except KeyError as err : raise KeyError ( f \"No resampler for time series { time_series_id } found!\" ) from err resample ( timestamp = None ) \u00a4 Resample samples for all time series. PARAMETER DESCRIPTION timestamp the timestamp to use to emit the new samples (and to consider stored samples relevant for resampling. If None , the current datetime (in UTC) will be used. TYPE: Optional [ datetime ] DEFAULT: None YIELDS DESCRIPTION Generator [ Tuple [ str , Sample ], None, None] iterator of time series ids and their newly resampled samples Source code in frequenz/sdk/timeseries/_resampler.py 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 def resample ( self , timestamp : Optional [ datetime ] = None ) -> Generator [ Tuple [ str , Sample ], None , None ]: \"\"\"Resample samples for all time series. Args: timestamp: the timestamp to use to emit the new samples (and to consider stored samples relevant for resampling. If `None`, the current datetime (in UTC) will be used. Yields: iterator of time series ids and their newly resampled samples \"\"\" if timestamp is None : timestamp = datetime . now ( timezone . utc ) for time_series_id , resampler in self . _resamplers . items (): yield time_series_id , Sample ( timestamp = timestamp , value = resampler . resample ( timestamp ) ) frequenz.sdk.timeseries.Resampler \u00a4 Ingests samples and produces resampled data for one timeseries. Samples are stored in an internal ring buffer. All collected samples that are newer than resampling_period_s * max_data_age_in_periods seconds will be passed to the provided ResamplingFunction . Source code in frequenz/sdk/timeseries/_resampler.py 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 class Resampler : \"\"\"Ingests samples and produces resampled data for one timeseries. Samples are stored in an internal ring buffer. All collected samples that are newer than `resampling_period_s * max_data_age_in_periods` seconds will be passed to the provided [ResamplingFunction][frequenz.sdk.timeseries.ResamplingFunction]. \"\"\" def __init__ ( self , resampling_period_s : float , max_data_age_in_periods : float , resampling_function : ResamplingFunction , ) -> None : \"\"\"Initialize the ComponentMetricResampler. Args: resampling_period_s: value describing how often resampling should be performed, in seconds max_data_age_in_periods: max age that samples shouldn't exceed in order to be used in the resampling function resampling_function: function to be applied to a sequence of samples within a resampling period to produce a single output sample \"\"\" self . _resampling_period_s = resampling_period_s self . _max_data_age_in_periods : float = max_data_age_in_periods self . _buffer : Deque [ Sample ] = deque () self . _resampling_function : ResamplingFunction = resampling_function def add_sample ( self , sample : Sample ) -> None : \"\"\"Add a new sample. Args: sample: sample to be added to the buffer \"\"\" self . _buffer . append ( sample ) def _remove_outdated_samples ( self , threshold : datetime ) -> None : \"\"\"Remove samples that are older than the provided time threshold. It is assumed that items in the buffer are in a sorted order (ascending order by timestamp). The removal works by traversing the buffer starting from the oldest sample (smallest timestamp) and comparing sample's timestamp with the threshold. If the sample's threshold is smaller than `threshold`, it means that the sample is outdated and it is removed from the buffer. This continues until the first sample that is with timestamp greater or equal to `threshold` is encountered, then buffer is considered up to date. Args: threshold: samples whose timestamp is older than the threshold are considered outdated and should be remove from the buffer \"\"\" while self . _buffer : sample : Sample = self . _buffer [ 0 ] if sample . timestamp >= threshold : return self . _buffer . popleft () def resample ( self , timestamp : Optional [ datetime ] = None ) -> Optional [ float ]: \"\"\"Resample samples from the buffer and produce a single sample. Args: timestamp: the timestamp to use to as the current resampling timestamp when calculating which stored past samples are relevant to pass to the resampling function. If `None`, the current datetime (in UTC) will be used. Returns: Samples resampled into a single sample or `None` if the `resampling_function` cannot produce a valid Sample. \"\"\" if timestamp is None : timestamp = datetime . now ( timezone . utc ) threshold = timestamp - timedelta ( seconds = self . _max_data_age_in_periods * self . _resampling_period_s ) self . _remove_outdated_samples ( threshold = threshold ) if len ( self . _buffer ) == 0 : return None return self . _resampling_function ( self . _buffer , self . _resampling_period_s ) Functions \u00a4 __init__ ( resampling_period_s , max_data_age_in_periods , resampling_function ) \u00a4 Initialize the ComponentMetricResampler. PARAMETER DESCRIPTION resampling_period_s value describing how often resampling should be performed, in seconds TYPE: float max_data_age_in_periods max age that samples shouldn't exceed in order to be used in the resampling function TYPE: float resampling_function function to be applied to a sequence of samples within a resampling period to produce a single output sample TYPE: ResamplingFunction Source code in frequenz/sdk/timeseries/_resampler.py 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 def __init__ ( self , resampling_period_s : float , max_data_age_in_periods : float , resampling_function : ResamplingFunction , ) -> None : \"\"\"Initialize the ComponentMetricResampler. Args: resampling_period_s: value describing how often resampling should be performed, in seconds max_data_age_in_periods: max age that samples shouldn't exceed in order to be used in the resampling function resampling_function: function to be applied to a sequence of samples within a resampling period to produce a single output sample \"\"\" self . _resampling_period_s = resampling_period_s self . _max_data_age_in_periods : float = max_data_age_in_periods self . _buffer : Deque [ Sample ] = deque () self . _resampling_function : ResamplingFunction = resampling_function add_sample ( sample ) \u00a4 Add a new sample. PARAMETER DESCRIPTION sample sample to be added to the buffer TYPE: Sample Source code in frequenz/sdk/timeseries/_resampler.py 70 71 72 73 74 75 76 def add_sample ( self , sample : Sample ) -> None : \"\"\"Add a new sample. Args: sample: sample to be added to the buffer \"\"\" self . _buffer . append ( sample ) resample ( timestamp = None ) \u00a4 Resample samples from the buffer and produce a single sample. PARAMETER DESCRIPTION timestamp the timestamp to use to as the current resampling timestamp when calculating which stored past samples are relevant to pass to the resampling function. If None , the current datetime (in UTC) will be used. TYPE: Optional [ datetime ] DEFAULT: None RETURNS DESCRIPTION Optional [ float ] Samples resampled into a single sample or None if the resampling_function cannot produce a valid Sample. Source code in frequenz/sdk/timeseries/_resampler.py 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 def resample ( self , timestamp : Optional [ datetime ] = None ) -> Optional [ float ]: \"\"\"Resample samples from the buffer and produce a single sample. Args: timestamp: the timestamp to use to as the current resampling timestamp when calculating which stored past samples are relevant to pass to the resampling function. If `None`, the current datetime (in UTC) will be used. Returns: Samples resampled into a single sample or `None` if the `resampling_function` cannot produce a valid Sample. \"\"\" if timestamp is None : timestamp = datetime . now ( timezone . utc ) threshold = timestamp - timedelta ( seconds = self . _max_data_age_in_periods * self . _resampling_period_s ) self . _remove_outdated_samples ( threshold = threshold ) if len ( self . _buffer ) == 0 : return None return self . _resampling_function ( self . _buffer , self . _resampling_period_s ) frequenz.sdk.timeseries.Sample dataclass \u00a4 A measurement taken at a particular point in time. The value could be None if a component is malfunctioning or data is lacking for another reason, but a sample still needs to be sent to have a coherent view on a group of component metrics for a particular timestamp. Source code in frequenz/sdk/timeseries/_sample.py 11 12 13 14 15 16 17 18 19 20 21 @dataclass ( frozen = True ) class Sample : \"\"\"A measurement taken at a particular point in time. The `value` could be `None` if a component is malfunctioning or data is lacking for another reason, but a sample still needs to be sent to have a coherent view on a group of component metrics for a particular timestamp. \"\"\" timestamp : datetime value : Optional [ float ] = None","title":"timeseries"},{"location":"reference/frequenz/sdk/timeseries/#frequenz.sdk.timeseries","text":"Handling of timeseries streams. A timeseries is a stream (normally an async iterator) of samples . This module provides tools to operate on timeseries.","title":"timeseries"},{"location":"reference/frequenz/sdk/timeseries/#frequenz.sdk.timeseries-attributes","text":"","title":"Attributes"},{"location":"reference/frequenz/sdk/timeseries/#frequenz.sdk.timeseries.ResamplingFunction","text":"Resampling function type. A resampling function produces a new sample based on a list of pre-existing samples. It can do \"upsampling\" when there data rate of the input_samples period is smaller than the resampling_period_s , or \"downsampling\" if it is bigger. In general a resampling window is the same as the resampling_period_s , and this function might receive input samples from multiple windows in the past to enable extrapolation, but no samples from the future (so the timestamp of the new sample that is going to be produced will always be bigger than the biggest timestamp in the input data). PARAMETER DESCRIPTION input_samples the sequence of pre-existing samples. TYPE: Sequence [ Sample ] resampling_period_s the period in seconds (i.e. how ofter a new sample is produced. TYPE: float RETURNS DESCRIPTION new_sample The value of new sample produced after the resampling. TYPE: float","title":"ResamplingFunction"},{"location":"reference/frequenz/sdk/timeseries/#frequenz.sdk.timeseries-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/timeseries/#frequenz.sdk.timeseries.GroupResampler","text":"Ingests samples and produces resampled data for a group of timeseries. Like the Resampler but handles a group of timeseries. Source code in frequenz/sdk/timeseries/_resampler.py 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 class GroupResampler : \"\"\"Ingests samples and produces resampled data for a group of timeseries. Like the [Resampler][frequenz.sdk.timeseries.Resampler] but handles a group of timeseries. \"\"\" def __init__ ( self , * , resampling_period_s : float , initial_resampling_function : ResamplingFunction , max_data_age_in_periods : float = 3.0 , ) -> None : \"\"\"Initialize the ComponentMetricGroupResampler. Args: resampling_period_s: value describing how often resampling should be performed, in seconds initial_resampling_function: function to be applied to a sequence of samples within a resampling period to produce a single output sample max_data_age_in_periods: max age that samples shouldn't exceed in order to be used in the resampling function \"\"\" self . _resampling_period_s = resampling_period_s self . _max_data_age_in_periods : float = max_data_age_in_periods self . _initial_resampling_function : ResamplingFunction = ( initial_resampling_function ) self . _resamplers : Dict [ str , Resampler ] = {} def add_time_series ( self , time_series_id : str ) -> None : \"\"\"Create a new resampler for a specific time series. If resampler already exists for the provided `time_series_id`, it will be used without creating a new one. Args: time_series_id: time series id \"\"\" if time_series_id in self . _resamplers : return self . _resamplers [ time_series_id ] = Resampler ( resampling_period_s = self . _resampling_period_s , max_data_age_in_periods = self . _max_data_age_in_periods , resampling_function = self . _initial_resampling_function , ) def remove_timeseries ( self , time_series_id : str ) -> None : \"\"\"Remove a resampler for a specific time series. Args: time_series_id: time series id, for which to remove the resampler Raises: KeyError: if resampler for the provided timer_series_id doesn't exist \"\"\" try : del self . _resamplers [ time_series_id ] except KeyError as err : raise KeyError ( f \"No resampler for time series { time_series_id } found!\" ) from err def add_sample ( self , time_series_id : str , sample : Sample ) -> None : \"\"\"Add a sample for a specific time series. Args: time_series_id: time series id, which the sample should be added to sample: sample to be added Raises: KeyError: if resampler for the provided timer_series_id doesn't exist \"\"\" try : self . _resamplers [ time_series_id ] . add_sample ( sample ) except KeyError as err : raise KeyError ( f \"No resampler for time series { time_series_id } found!\" ) from err def resample ( self , timestamp : Optional [ datetime ] = None ) -> Generator [ Tuple [ str , Sample ], None , None ]: \"\"\"Resample samples for all time series. Args: timestamp: the timestamp to use to emit the new samples (and to consider stored samples relevant for resampling. If `None`, the current datetime (in UTC) will be used. Yields: iterator of time series ids and their newly resampled samples \"\"\" if timestamp is None : timestamp = datetime . now ( timezone . utc ) for time_series_id , resampler in self . _resamplers . items (): yield time_series_id , Sample ( timestamp = timestamp , value = resampler . resample ( timestamp ) )","title":"GroupResampler"},{"location":"reference/frequenz/sdk/timeseries/#frequenz.sdk.timeseries.GroupResampler-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/timeseries/#frequenz.sdk.timeseries._resampler.GroupResampler.__init__","text":"Initialize the ComponentMetricGroupResampler. PARAMETER DESCRIPTION resampling_period_s value describing how often resampling should be performed, in seconds TYPE: float initial_resampling_function function to be applied to a sequence of samples within a resampling period to produce a single output sample TYPE: ResamplingFunction max_data_age_in_periods max age that samples shouldn't exceed in order to be used in the resampling function TYPE: float DEFAULT: 3.0 Source code in frequenz/sdk/timeseries/_resampler.py 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 def __init__ ( self , * , resampling_period_s : float , initial_resampling_function : ResamplingFunction , max_data_age_in_periods : float = 3.0 , ) -> None : \"\"\"Initialize the ComponentMetricGroupResampler. Args: resampling_period_s: value describing how often resampling should be performed, in seconds initial_resampling_function: function to be applied to a sequence of samples within a resampling period to produce a single output sample max_data_age_in_periods: max age that samples shouldn't exceed in order to be used in the resampling function \"\"\" self . _resampling_period_s = resampling_period_s self . _max_data_age_in_periods : float = max_data_age_in_periods self . _initial_resampling_function : ResamplingFunction = ( initial_resampling_function ) self . _resamplers : Dict [ str , Resampler ] = {}","title":"__init__()"},{"location":"reference/frequenz/sdk/timeseries/#frequenz.sdk.timeseries._resampler.GroupResampler.add_sample","text":"Add a sample for a specific time series. PARAMETER DESCRIPTION time_series_id time series id, which the sample should be added to TYPE: str sample sample to be added TYPE: Sample RAISES DESCRIPTION KeyError if resampler for the provided timer_series_id doesn't exist Source code in frequenz/sdk/timeseries/_resampler.py 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 def add_sample ( self , time_series_id : str , sample : Sample ) -> None : \"\"\"Add a sample for a specific time series. Args: time_series_id: time series id, which the sample should be added to sample: sample to be added Raises: KeyError: if resampler for the provided timer_series_id doesn't exist \"\"\" try : self . _resamplers [ time_series_id ] . add_sample ( sample ) except KeyError as err : raise KeyError ( f \"No resampler for time series { time_series_id } found!\" ) from err","title":"add_sample()"},{"location":"reference/frequenz/sdk/timeseries/#frequenz.sdk.timeseries._resampler.GroupResampler.add_time_series","text":"Create a new resampler for a specific time series. If resampler already exists for the provided time_series_id , it will be used without creating a new one. PARAMETER DESCRIPTION time_series_id time series id TYPE: str Source code in frequenz/sdk/timeseries/_resampler.py 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 def add_time_series ( self , time_series_id : str ) -> None : \"\"\"Create a new resampler for a specific time series. If resampler already exists for the provided `time_series_id`, it will be used without creating a new one. Args: time_series_id: time series id \"\"\" if time_series_id in self . _resamplers : return self . _resamplers [ time_series_id ] = Resampler ( resampling_period_s = self . _resampling_period_s , max_data_age_in_periods = self . _max_data_age_in_periods , resampling_function = self . _initial_resampling_function , )","title":"add_time_series()"},{"location":"reference/frequenz/sdk/timeseries/#frequenz.sdk.timeseries._resampler.GroupResampler.remove_timeseries","text":"Remove a resampler for a specific time series. PARAMETER DESCRIPTION time_series_id time series id, for which to remove the resampler TYPE: str RAISES DESCRIPTION KeyError if resampler for the provided timer_series_id doesn't exist Source code in frequenz/sdk/timeseries/_resampler.py 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 def remove_timeseries ( self , time_series_id : str ) -> None : \"\"\"Remove a resampler for a specific time series. Args: time_series_id: time series id, for which to remove the resampler Raises: KeyError: if resampler for the provided timer_series_id doesn't exist \"\"\" try : del self . _resamplers [ time_series_id ] except KeyError as err : raise KeyError ( f \"No resampler for time series { time_series_id } found!\" ) from err","title":"remove_timeseries()"},{"location":"reference/frequenz/sdk/timeseries/#frequenz.sdk.timeseries._resampler.GroupResampler.resample","text":"Resample samples for all time series. PARAMETER DESCRIPTION timestamp the timestamp to use to emit the new samples (and to consider stored samples relevant for resampling. If None , the current datetime (in UTC) will be used. TYPE: Optional [ datetime ] DEFAULT: None YIELDS DESCRIPTION Generator [ Tuple [ str , Sample ], None, None] iterator of time series ids and their newly resampled samples Source code in frequenz/sdk/timeseries/_resampler.py 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 def resample ( self , timestamp : Optional [ datetime ] = None ) -> Generator [ Tuple [ str , Sample ], None , None ]: \"\"\"Resample samples for all time series. Args: timestamp: the timestamp to use to emit the new samples (and to consider stored samples relevant for resampling. If `None`, the current datetime (in UTC) will be used. Yields: iterator of time series ids and their newly resampled samples \"\"\" if timestamp is None : timestamp = datetime . now ( timezone . utc ) for time_series_id , resampler in self . _resamplers . items (): yield time_series_id , Sample ( timestamp = timestamp , value = resampler . resample ( timestamp ) )","title":"resample()"},{"location":"reference/frequenz/sdk/timeseries/#frequenz.sdk.timeseries.Resampler","text":"Ingests samples and produces resampled data for one timeseries. Samples are stored in an internal ring buffer. All collected samples that are newer than resampling_period_s * max_data_age_in_periods seconds will be passed to the provided ResamplingFunction . Source code in frequenz/sdk/timeseries/_resampler.py 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 class Resampler : \"\"\"Ingests samples and produces resampled data for one timeseries. Samples are stored in an internal ring buffer. All collected samples that are newer than `resampling_period_s * max_data_age_in_periods` seconds will be passed to the provided [ResamplingFunction][frequenz.sdk.timeseries.ResamplingFunction]. \"\"\" def __init__ ( self , resampling_period_s : float , max_data_age_in_periods : float , resampling_function : ResamplingFunction , ) -> None : \"\"\"Initialize the ComponentMetricResampler. Args: resampling_period_s: value describing how often resampling should be performed, in seconds max_data_age_in_periods: max age that samples shouldn't exceed in order to be used in the resampling function resampling_function: function to be applied to a sequence of samples within a resampling period to produce a single output sample \"\"\" self . _resampling_period_s = resampling_period_s self . _max_data_age_in_periods : float = max_data_age_in_periods self . _buffer : Deque [ Sample ] = deque () self . _resampling_function : ResamplingFunction = resampling_function def add_sample ( self , sample : Sample ) -> None : \"\"\"Add a new sample. Args: sample: sample to be added to the buffer \"\"\" self . _buffer . append ( sample ) def _remove_outdated_samples ( self , threshold : datetime ) -> None : \"\"\"Remove samples that are older than the provided time threshold. It is assumed that items in the buffer are in a sorted order (ascending order by timestamp). The removal works by traversing the buffer starting from the oldest sample (smallest timestamp) and comparing sample's timestamp with the threshold. If the sample's threshold is smaller than `threshold`, it means that the sample is outdated and it is removed from the buffer. This continues until the first sample that is with timestamp greater or equal to `threshold` is encountered, then buffer is considered up to date. Args: threshold: samples whose timestamp is older than the threshold are considered outdated and should be remove from the buffer \"\"\" while self . _buffer : sample : Sample = self . _buffer [ 0 ] if sample . timestamp >= threshold : return self . _buffer . popleft () def resample ( self , timestamp : Optional [ datetime ] = None ) -> Optional [ float ]: \"\"\"Resample samples from the buffer and produce a single sample. Args: timestamp: the timestamp to use to as the current resampling timestamp when calculating which stored past samples are relevant to pass to the resampling function. If `None`, the current datetime (in UTC) will be used. Returns: Samples resampled into a single sample or `None` if the `resampling_function` cannot produce a valid Sample. \"\"\" if timestamp is None : timestamp = datetime . now ( timezone . utc ) threshold = timestamp - timedelta ( seconds = self . _max_data_age_in_periods * self . _resampling_period_s ) self . _remove_outdated_samples ( threshold = threshold ) if len ( self . _buffer ) == 0 : return None return self . _resampling_function ( self . _buffer , self . _resampling_period_s )","title":"Resampler"},{"location":"reference/frequenz/sdk/timeseries/#frequenz.sdk.timeseries.Resampler-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/timeseries/#frequenz.sdk.timeseries._resampler.Resampler.__init__","text":"Initialize the ComponentMetricResampler. PARAMETER DESCRIPTION resampling_period_s value describing how often resampling should be performed, in seconds TYPE: float max_data_age_in_periods max age that samples shouldn't exceed in order to be used in the resampling function TYPE: float resampling_function function to be applied to a sequence of samples within a resampling period to produce a single output sample TYPE: ResamplingFunction Source code in frequenz/sdk/timeseries/_resampler.py 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 def __init__ ( self , resampling_period_s : float , max_data_age_in_periods : float , resampling_function : ResamplingFunction , ) -> None : \"\"\"Initialize the ComponentMetricResampler. Args: resampling_period_s: value describing how often resampling should be performed, in seconds max_data_age_in_periods: max age that samples shouldn't exceed in order to be used in the resampling function resampling_function: function to be applied to a sequence of samples within a resampling period to produce a single output sample \"\"\" self . _resampling_period_s = resampling_period_s self . _max_data_age_in_periods : float = max_data_age_in_periods self . _buffer : Deque [ Sample ] = deque () self . _resampling_function : ResamplingFunction = resampling_function","title":"__init__()"},{"location":"reference/frequenz/sdk/timeseries/#frequenz.sdk.timeseries._resampler.Resampler.add_sample","text":"Add a new sample. PARAMETER DESCRIPTION sample sample to be added to the buffer TYPE: Sample Source code in frequenz/sdk/timeseries/_resampler.py 70 71 72 73 74 75 76 def add_sample ( self , sample : Sample ) -> None : \"\"\"Add a new sample. Args: sample: sample to be added to the buffer \"\"\" self . _buffer . append ( sample )","title":"add_sample()"},{"location":"reference/frequenz/sdk/timeseries/#frequenz.sdk.timeseries._resampler.Resampler.resample","text":"Resample samples from the buffer and produce a single sample. PARAMETER DESCRIPTION timestamp the timestamp to use to as the current resampling timestamp when calculating which stored past samples are relevant to pass to the resampling function. If None , the current datetime (in UTC) will be used. TYPE: Optional [ datetime ] DEFAULT: None RETURNS DESCRIPTION Optional [ float ] Samples resampled into a single sample or None if the resampling_function cannot produce a valid Sample. Source code in frequenz/sdk/timeseries/_resampler.py 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 def resample ( self , timestamp : Optional [ datetime ] = None ) -> Optional [ float ]: \"\"\"Resample samples from the buffer and produce a single sample. Args: timestamp: the timestamp to use to as the current resampling timestamp when calculating which stored past samples are relevant to pass to the resampling function. If `None`, the current datetime (in UTC) will be used. Returns: Samples resampled into a single sample or `None` if the `resampling_function` cannot produce a valid Sample. \"\"\" if timestamp is None : timestamp = datetime . now ( timezone . utc ) threshold = timestamp - timedelta ( seconds = self . _max_data_age_in_periods * self . _resampling_period_s ) self . _remove_outdated_samples ( threshold = threshold ) if len ( self . _buffer ) == 0 : return None return self . _resampling_function ( self . _buffer , self . _resampling_period_s )","title":"resample()"},{"location":"reference/frequenz/sdk/timeseries/#frequenz.sdk.timeseries.Sample","text":"A measurement taken at a particular point in time. The value could be None if a component is malfunctioning or data is lacking for another reason, but a sample still needs to be sent to have a coherent view on a group of component metrics for a particular timestamp. Source code in frequenz/sdk/timeseries/_sample.py 11 12 13 14 15 16 17 18 19 20 21 @dataclass ( frozen = True ) class Sample : \"\"\"A measurement taken at a particular point in time. The `value` could be `None` if a component is malfunctioning or data is lacking for another reason, but a sample still needs to be sent to have a coherent view on a group of component metrics for a particular timestamp. \"\"\" timestamp : datetime value : Optional [ float ] = None","title":"Sample"},{"location":"reference/frequenz/sdk/timeseries/logical_meter/","text":"frequenz.sdk.timeseries.logical_meter \u00a4 A logical meter for calculating high level metrics for a microgrid. Classes \u00a4 frequenz.sdk.timeseries.logical_meter.LogicalMeter \u00a4 A logical meter for calculating high level metrics in a microgrid. LogicalMeter can be used to run formulas on resampled component metric streams. Formulas can have Component IDs that are preceeded by a pound symbol(\"#\"), and these operators: +, -, *, /, (, ). For example, the input string: \"#20 + #5\" is a formula for adding metrics from two components with ids 20 and 5. Source code in frequenz/sdk/timeseries/logical_meter/_logical_meter.py 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 class LogicalMeter : \"\"\"A logical meter for calculating high level metrics in a microgrid. LogicalMeter can be used to run formulas on resampled component metric streams. Formulas can have Component IDs that are preceeded by a pound symbol(\"#\"), and these operators: +, -, *, /, (, ). For example, the input string: \"#20 + #5\" is a formula for adding metrics from two components with ids 20 and 5. \"\"\" def __init__ ( self , channel_registry : ChannelRegistry , resampler_subscription_sender : Sender [ ComponentMetricRequest ], ) -> None : \"\"\"Create a `LogicalMeter instance`. Args: channel_registry: A channel registry instance shared with the resampling actor. resampler_subscription_sender: A sender for sending metric requests to the resampling actor. \"\"\" self . _channel_registry = channel_registry self . _resampler_subscription_sender = resampler_subscription_sender # Use a randomly generated uuid to create a unique namespace name for the local # meter to use when communicating with the resampling actor. self . _namespace = f \"logical-meter- { uuid . uuid4 () } \" self . _output_channels : Dict [ str , Broadcast [ Sample ]] = {} self . _tasks : List [ asyncio . Task [ None ]] = [] async def _engine_from_formula_string ( self , formula : str , metric_id : ComponentMetricId ) -> FormulaEngine : builder = FormulaBuilder ( self . _namespace , self . _channel_registry , self . _resampler_subscription_sender , metric_id , ) return await builder . from_string ( formula ) async def _run_formula ( self , formula : FormulaEngine , sender : Sender [ Sample ] ) -> None : \"\"\"Run the formula repeatedly and send the results to a channel. Args: formula: The formula to run. sender: A sender for sending the formula results to. \"\"\" while msg := await formula . apply (): await sender . send ( msg ) async def start_formula ( self , formula : str , component_metric_id : ComponentMetricId , ) -> Receiver [ Sample ]: \"\"\"Start execution of the given formula name. Args: formula: formula to execute. component_metric_id: The metric ID to use when fetching receivers from the resampling actor. Returns: A Receiver that streams values with the formulas applied. \"\"\" channel_key = formula + component_metric_id . value if channel_key in self . _output_channels : return self . _output_channels [ channel_key ] . new_receiver () formula_engine = await self . _engine_from_formula_string ( formula , component_metric_id , ) out_chan = Broadcast [ Sample ]( channel_key ) self . _output_channels [ channel_key ] = out_chan self . _tasks . append ( asyncio . create_task ( self . _run_formula ( formula_engine , out_chan . new_sender ()) ) ) return out_chan . new_receiver () Functions \u00a4 __init__ ( channel_registry , resampler_subscription_sender ) \u00a4 Create a LogicalMeter instance . PARAMETER DESCRIPTION channel_registry A channel registry instance shared with the resampling actor. TYPE: ChannelRegistry resampler_subscription_sender A sender for sending metric requests to the resampling actor. TYPE: Sender [ ComponentMetricRequest ] Source code in frequenz/sdk/timeseries/logical_meter/_logical_meter.py 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 def __init__ ( self , channel_registry : ChannelRegistry , resampler_subscription_sender : Sender [ ComponentMetricRequest ], ) -> None : \"\"\"Create a `LogicalMeter instance`. Args: channel_registry: A channel registry instance shared with the resampling actor. resampler_subscription_sender: A sender for sending metric requests to the resampling actor. \"\"\" self . _channel_registry = channel_registry self . _resampler_subscription_sender = resampler_subscription_sender # Use a randomly generated uuid to create a unique namespace name for the local # meter to use when communicating with the resampling actor. self . _namespace = f \"logical-meter- { uuid . uuid4 () } \" self . _output_channels : Dict [ str , Broadcast [ Sample ]] = {} self . _tasks : List [ asyncio . Task [ None ]] = [] start_formula ( formula , component_metric_id ) async \u00a4 Start execution of the given formula name. PARAMETER DESCRIPTION formula formula to execute. TYPE: str component_metric_id The metric ID to use when fetching receivers from the resampling actor. TYPE: ComponentMetricId RETURNS DESCRIPTION Receiver [ Sample ] A Receiver that streams values with the formulas applied. Source code in frequenz/sdk/timeseries/logical_meter/_logical_meter.py 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 async def start_formula ( self , formula : str , component_metric_id : ComponentMetricId , ) -> Receiver [ Sample ]: \"\"\"Start execution of the given formula name. Args: formula: formula to execute. component_metric_id: The metric ID to use when fetching receivers from the resampling actor. Returns: A Receiver that streams values with the formulas applied. \"\"\" channel_key = formula + component_metric_id . value if channel_key in self . _output_channels : return self . _output_channels [ channel_key ] . new_receiver () formula_engine = await self . _engine_from_formula_string ( formula , component_metric_id , ) out_chan = Broadcast [ Sample ]( channel_key ) self . _output_channels [ channel_key ] = out_chan self . _tasks . append ( asyncio . create_task ( self . _run_formula ( formula_engine , out_chan . new_sender ()) ) ) return out_chan . new_receiver ()","title":"logical_meter"},{"location":"reference/frequenz/sdk/timeseries/logical_meter/#frequenz.sdk.timeseries.logical_meter","text":"A logical meter for calculating high level metrics for a microgrid.","title":"logical_meter"},{"location":"reference/frequenz/sdk/timeseries/logical_meter/#frequenz.sdk.timeseries.logical_meter-classes","text":"","title":"Classes"},{"location":"reference/frequenz/sdk/timeseries/logical_meter/#frequenz.sdk.timeseries.logical_meter.LogicalMeter","text":"A logical meter for calculating high level metrics in a microgrid. LogicalMeter can be used to run formulas on resampled component metric streams. Formulas can have Component IDs that are preceeded by a pound symbol(\"#\"), and these operators: +, -, *, /, (, ). For example, the input string: \"#20 + #5\" is a formula for adding metrics from two components with ids 20 and 5. Source code in frequenz/sdk/timeseries/logical_meter/_logical_meter.py 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 class LogicalMeter : \"\"\"A logical meter for calculating high level metrics in a microgrid. LogicalMeter can be used to run formulas on resampled component metric streams. Formulas can have Component IDs that are preceeded by a pound symbol(\"#\"), and these operators: +, -, *, /, (, ). For example, the input string: \"#20 + #5\" is a formula for adding metrics from two components with ids 20 and 5. \"\"\" def __init__ ( self , channel_registry : ChannelRegistry , resampler_subscription_sender : Sender [ ComponentMetricRequest ], ) -> None : \"\"\"Create a `LogicalMeter instance`. Args: channel_registry: A channel registry instance shared with the resampling actor. resampler_subscription_sender: A sender for sending metric requests to the resampling actor. \"\"\" self . _channel_registry = channel_registry self . _resampler_subscription_sender = resampler_subscription_sender # Use a randomly generated uuid to create a unique namespace name for the local # meter to use when communicating with the resampling actor. self . _namespace = f \"logical-meter- { uuid . uuid4 () } \" self . _output_channels : Dict [ str , Broadcast [ Sample ]] = {} self . _tasks : List [ asyncio . Task [ None ]] = [] async def _engine_from_formula_string ( self , formula : str , metric_id : ComponentMetricId ) -> FormulaEngine : builder = FormulaBuilder ( self . _namespace , self . _channel_registry , self . _resampler_subscription_sender , metric_id , ) return await builder . from_string ( formula ) async def _run_formula ( self , formula : FormulaEngine , sender : Sender [ Sample ] ) -> None : \"\"\"Run the formula repeatedly and send the results to a channel. Args: formula: The formula to run. sender: A sender for sending the formula results to. \"\"\" while msg := await formula . apply (): await sender . send ( msg ) async def start_formula ( self , formula : str , component_metric_id : ComponentMetricId , ) -> Receiver [ Sample ]: \"\"\"Start execution of the given formula name. Args: formula: formula to execute. component_metric_id: The metric ID to use when fetching receivers from the resampling actor. Returns: A Receiver that streams values with the formulas applied. \"\"\" channel_key = formula + component_metric_id . value if channel_key in self . _output_channels : return self . _output_channels [ channel_key ] . new_receiver () formula_engine = await self . _engine_from_formula_string ( formula , component_metric_id , ) out_chan = Broadcast [ Sample ]( channel_key ) self . _output_channels [ channel_key ] = out_chan self . _tasks . append ( asyncio . create_task ( self . _run_formula ( formula_engine , out_chan . new_sender ()) ) ) return out_chan . new_receiver ()","title":"LogicalMeter"},{"location":"reference/frequenz/sdk/timeseries/logical_meter/#frequenz.sdk.timeseries.logical_meter.LogicalMeter-functions","text":"","title":"Functions"},{"location":"reference/frequenz/sdk/timeseries/logical_meter/#frequenz.sdk.timeseries.logical_meter._logical_meter.LogicalMeter.__init__","text":"Create a LogicalMeter instance . PARAMETER DESCRIPTION channel_registry A channel registry instance shared with the resampling actor. TYPE: ChannelRegistry resampler_subscription_sender A sender for sending metric requests to the resampling actor. TYPE: Sender [ ComponentMetricRequest ] Source code in frequenz/sdk/timeseries/logical_meter/_logical_meter.py 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 def __init__ ( self , channel_registry : ChannelRegistry , resampler_subscription_sender : Sender [ ComponentMetricRequest ], ) -> None : \"\"\"Create a `LogicalMeter instance`. Args: channel_registry: A channel registry instance shared with the resampling actor. resampler_subscription_sender: A sender for sending metric requests to the resampling actor. \"\"\" self . _channel_registry = channel_registry self . _resampler_subscription_sender = resampler_subscription_sender # Use a randomly generated uuid to create a unique namespace name for the local # meter to use when communicating with the resampling actor. self . _namespace = f \"logical-meter- { uuid . uuid4 () } \" self . _output_channels : Dict [ str , Broadcast [ Sample ]] = {} self . _tasks : List [ asyncio . Task [ None ]] = []","title":"__init__()"},{"location":"reference/frequenz/sdk/timeseries/logical_meter/#frequenz.sdk.timeseries.logical_meter._logical_meter.LogicalMeter.start_formula","text":"Start execution of the given formula name. PARAMETER DESCRIPTION formula formula to execute. TYPE: str component_metric_id The metric ID to use when fetching receivers from the resampling actor. TYPE: ComponentMetricId RETURNS DESCRIPTION Receiver [ Sample ] A Receiver that streams values with the formulas applied. Source code in frequenz/sdk/timeseries/logical_meter/_logical_meter.py 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 async def start_formula ( self , formula : str , component_metric_id : ComponentMetricId , ) -> Receiver [ Sample ]: \"\"\"Start execution of the given formula name. Args: formula: formula to execute. component_metric_id: The metric ID to use when fetching receivers from the resampling actor. Returns: A Receiver that streams values with the formulas applied. \"\"\" channel_key = formula + component_metric_id . value if channel_key in self . _output_channels : return self . _output_channels [ channel_key ] . new_receiver () formula_engine = await self . _engine_from_formula_string ( formula , component_metric_id , ) out_chan = Broadcast [ Sample ]( channel_key ) self . _output_channels [ channel_key ] = out_chan self . _tasks . append ( asyncio . create_task ( self . _run_formula ( formula_engine , out_chan . new_sender ()) ) ) return out_chan . new_receiver ()","title":"start_formula()"}]}